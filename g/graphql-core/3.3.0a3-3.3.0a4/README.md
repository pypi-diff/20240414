# Comparing `tmp/graphql_core-3.3.0a3.tar.gz` & `tmp/graphql_core-3.3.0a4.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "graphql_core-3.3.0a3.tar", max compression
+gzip compressed data, was "graphql_core-3.3.0a4.tar", max compression
```

## Comparing `graphql_core-3.3.0a3.tar` & `graphql_core-3.3.0a4.tar`

### file list

```diff
@@ -1,337 +1,337 @@
--rw-r--r--   0        0        0      544 2023-06-04 19:57:31.180083 graphql_core-3.3.0a3/.bumpversion.cfg
--rw-r--r--   0        0        0      292 2023-06-04 19:57:31.180083 graphql_core-3.3.0a3/.editorconfig
--rw-r--r--   0        0        0      218 2023-06-04 19:57:31.180083 graphql_core-3.3.0a3/.flake8
--rw-r--r--   0        0        0      341 2023-06-04 19:57:31.180083 graphql_core-3.3.0a3/.readthedocs.yaml
--rw-r--r--   0        0        0        7 2023-06-04 19:57:31.180083 graphql_core-3.3.0a3/CODEOWNERS
--rw-r--r--   0        0        0     1180 2023-06-04 19:57:31.180083 graphql_core-3.3.0a3/LICENSE
--rw-r--r--   0        0        0     9889 2023-06-04 19:57:31.180083 graphql_core-3.3.0a3/README.md
--rw-r--r--   0        0        0      728 2023-06-04 19:57:31.180083 graphql_core-3.3.0a3/SECURITY.md
--rw-r--r--   0        0        0      634 2023-06-04 19:57:31.180083 graphql_core-3.3.0a3/docs/Makefile
--rw-r--r--   0        0        0    15407 2023-06-04 19:57:31.180083 graphql_core-3.3.0a3/docs/conf.py
--rw-r--r--   0        0        0     5754 2023-06-04 19:57:31.180083 graphql_core-3.3.0a3/docs/diffs.rst
--rw-r--r--   0        0        0      248 2023-06-04 19:57:31.180083 graphql_core-3.3.0a3/docs/index.rst
--rw-r--r--   0        0        0     3254 2023-06-04 19:57:31.180083 graphql_core-3.3.0a3/docs/intro.rst
--rw-r--r--   0        0        0      760 2023-06-04 19:57:31.180083 graphql_core-3.3.0a3/docs/make.bat
--rw-r--r--   0        0        0      304 2023-06-04 19:57:31.184083 graphql_core-3.3.0a3/docs/modules/error.rst
--rw-r--r--   0        0        0     1397 2023-06-04 19:57:31.184083 graphql_core-3.3.0a3/docs/modules/execution.rst
--rw-r--r--   0        0        0      397 2023-06-04 19:57:31.184083 graphql_core-3.3.0a3/docs/modules/graphql.rst
--rw-r--r--   0        0        0     4457 2023-06-04 19:57:31.184083 graphql_core-3.3.0a3/docs/modules/language.rst
--rw-r--r--   0        0        0      832 2023-06-04 19:57:31.184083 graphql_core-3.3.0a3/docs/modules/pyutils.rst
--rw-r--r--   0        0        0     4492 2023-06-04 19:57:31.184083 graphql_core-3.3.0a3/docs/modules/type.rst
--rw-r--r--   0        0        0     2421 2023-06-04 19:57:31.184083 graphql_core-3.3.0a3/docs/modules/utilities.rst
--rw-r--r--   0        0        0     3255 2023-06-04 19:57:31.184083 graphql_core-3.3.0a3/docs/modules/validation.rst
--rw-r--r--   0        0        0       40 2023-06-04 19:57:31.184083 graphql_core-3.3.0a3/docs/requirements.txt
--rw-r--r--   0        0        0     1430 2023-06-04 19:57:31.184083 graphql_core-3.3.0a3/docs/usage/extension.rst
--rw-r--r--   0        0        0      278 2023-06-04 19:57:31.184083 graphql_core-3.3.0a3/docs/usage/index.rst
--rw-r--r--   0        0        0     2382 2023-06-04 19:57:31.184083 graphql_core-3.3.0a3/docs/usage/introspection.rst
--rw-r--r--   0        0        0     2082 2023-06-04 19:57:31.184083 graphql_core-3.3.0a3/docs/usage/methods.rst
--rw-r--r--   0        0        0     1258 2023-06-04 19:57:31.184083 graphql_core-3.3.0a3/docs/usage/other.rst
--rw-r--r--   0        0        0     2706 2023-06-04 19:57:31.184083 graphql_core-3.3.0a3/docs/usage/parser.rst
--rw-r--r--   0        0        0     3920 2023-06-04 19:57:31.184083 graphql_core-3.3.0a3/docs/usage/queries.rst
--rw-r--r--   0        0        0     3899 2023-06-04 19:57:31.184083 graphql_core-3.3.0a3/docs/usage/resolvers.rst
--rw-r--r--   0        0        0     7586 2023-06-04 19:57:31.184083 graphql_core-3.3.0a3/docs/usage/schema.rst
--rw-r--r--   0        0        0     2632 2023-06-04 19:57:31.184083 graphql_core-3.3.0a3/docs/usage/sdl.rst
--rw-r--r--   0        0        0     1719 2023-06-04 19:57:31.184083 graphql_core-3.3.0a3/docs/usage/validator.rst
--rw-r--r--   0        0        0   100343 2023-06-04 19:57:31.184083 graphql_core-3.3.0a3/poetry.lock
--rw-r--r--   0        0        0     4644 2023-06-04 19:57:31.184083 graphql_core-3.3.0a3/pyproject.toml
--rw-r--r--   0        0        0    21762 2023-06-04 19:57:31.184083 graphql_core-3.3.0a3/src/graphql/__init__.py
--rw-r--r--   0        0        0      432 2023-06-04 19:57:31.184083 graphql_core-3.3.0a3/src/graphql/error/__init__.py
--rw-r--r--   0        0        0     8790 2023-06-04 19:57:31.184083 graphql_core-3.3.0a3/src/graphql/error/graphql_error.py
--rw-r--r--   0        0        0     1859 2023-06-04 19:57:31.184083 graphql_core-3.3.0a3/src/graphql/error/located_error.py
--rw-r--r--   0        0        0      571 2023-06-04 19:57:31.184083 graphql_core-3.3.0a3/src/graphql/error/syntax_error.py
--rw-r--r--   0        0        0     2050 2023-06-04 19:57:31.184083 graphql_core-3.3.0a3/src/graphql/execution/__init__.py
--rw-r--r--   0        0        0     2328 2023-06-04 19:57:31.184083 graphql_core-3.3.0a3/src/graphql/execution/async_iterables.py
--rw-r--r--   0        0        0     8459 2023-06-04 19:57:31.184083 graphql_core-3.3.0a3/src/graphql/execution/collect_fields.py
--rw-r--r--   0        0        0   103011 2023-06-04 19:57:31.184083 graphql_core-3.3.0a3/src/graphql/execution/execute.py
--rw-r--r--   0        0        0     2599 2023-06-04 19:57:31.184083 graphql_core-3.3.0a3/src/graphql/execution/middleware.py
--rw-r--r--   0        0        0     8741 2023-06-04 19:57:31.184083 graphql_core-3.3.0a3/src/graphql/execution/values.py
--rw-r--r--   0        0        0     7078 2023-06-04 19:57:31.184083 graphql_core-3.3.0a3/src/graphql/graphql.py
--rw-r--r--   0        0        0     5094 2023-06-04 19:57:31.184083 graphql_core-3.3.0a3/src/graphql/language/__init__.py
--rw-r--r--   0        0        0    22384 2023-06-04 19:57:31.184083 graphql_core-3.3.0a3/src/graphql/language/ast.py
--rw-r--r--   0        0        0     4949 2023-06-04 19:57:31.184083 graphql_core-3.3.0a3/src/graphql/language/block_string.py
--rw-r--r--   0        0        0      871 2023-06-04 19:57:31.184083 graphql_core-3.3.0a3/src/graphql/language/character_classes.py
--rw-r--r--   0        0        0      831 2023-06-04 19:57:31.184083 graphql_core-3.3.0a3/src/graphql/language/directive_locations.py
--rw-r--r--   0        0        0    19447 2023-06-04 19:57:31.184083 graphql_core-3.3.0a3/src/graphql/language/lexer.py
--rw-r--r--   0        0        0     1252 2023-06-04 19:57:31.184083 graphql_core-3.3.0a3/src/graphql/language/location.py
--rw-r--r--   0        0        0    47129 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/language/parser.py
--rw-r--r--   0        0        0     3216 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/language/predicates.py
--rw-r--r--   0        0        0     2714 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/language/print_location.py
--rw-r--r--   0        0        0     1738 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/language/print_string.py
--rw-r--r--   0        0        0    14088 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/language/printer.py
--rw-r--r--   0        0        0     2552 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/language/source.py
--rw-r--r--   0        0        0      566 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/language/token_kind.py
--rw-r--r--   0        0        0    13043 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/language/visitor.py
--rw-r--r--   0        0        0       66 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/py.typed
--rw-r--r--   0        0        0     1805 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/pyutils/__init__.py
--rw-r--r--   0        0        0     1428 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/pyutils/async_reduce.py
--rw-r--r--   0        0        0      272 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/pyutils/awaitable_or_value.py
--rw-r--r--   0        0        0     1048 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/pyutils/cached_property.py
--rw-r--r--   0        0        0      716 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/pyutils/convert_case.py
--rw-r--r--   0        0        0     1960 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/pyutils/description.py
--rw-r--r--   0        0        0      612 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/pyutils/did_you_mean.py
--rw-r--r--   0        0        0      765 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/pyutils/format_list.py
--rw-r--r--   0        0        0      129 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/pyutils/frozen_error.py
--rw-r--r--   0        0        0      472 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/pyutils/group_by.py
--rw-r--r--   0        0        0      279 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/pyutils/identity_func.py
--rw-r--r--   0        0        0     5794 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/pyutils/inspect.py
--rw-r--r--   0        0        0      972 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/pyutils/is_awaitable.py
--rw-r--r--   0        0        0     1164 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/pyutils/is_iterable.py
--rw-r--r--   0        0        0      251 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/pyutils/merge_kwargs.py
--rw-r--r--   0        0        0      478 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/pyutils/natural_compare.py
--rw-r--r--   0        0        0      975 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/pyutils/path.py
--rw-r--r--   0        0        0      234 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/pyutils/print_path_list.py
--rw-r--r--   0        0        0     2485 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/pyutils/simple_pub_sub.py
--rw-r--r--   0        0        0     3571 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/pyutils/suggestion_list.py
--rw-r--r--   0        0        0     1281 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/pyutils/undefined.py
--rw-r--r--   0        0        0     7326 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/type/__init__.py
--rw-r--r--   0        0        0     1053 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/type/assert_name.py
--rw-r--r--   0        0        0    53077 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/type/definition.py
--rw-r--r--   0        0        0     8834 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/type/directives.py
--rw-r--r--   0        0        0    22693 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/type/introspection.py
--rw-r--r--   0        0        0    10843 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/type/scalars.py
--rw-r--r--   0        0        0    17941 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/type/schema.py
--rw-r--r--   0        0        0    24140 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/type/validate.py
--rw-r--r--   0        0        0     3424 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/utilities/__init__.py
--rw-r--r--   0        0        0     4548 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/utilities/ast_from_value.py
--rw-r--r--   0        0        0     1596 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/utilities/ast_to_dict.py
--rw-r--r--   0        0        0     3504 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/utilities/build_ast_schema.py
--rw-r--r--   0        0        0    17219 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/utilities/build_client_schema.py
--rw-r--r--   0        0        0     5498 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/utilities/coerce_input_value.py
--rw-r--r--   0        0        0      571 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/utilities/concat_ast.py
--rw-r--r--   0        0        0    29899 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/utilities/extend_schema.py
--rw-r--r--   0        0        0    20730 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/utilities/find_breaking_changes.py
--rw-r--r--   0        0        0     7946 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/utilities/get_introspection_query.py
--rw-r--r--   0        0        0     1088 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/utilities/get_operation_ast.py
--rw-r--r--   0        0        0     1596 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/utilities/introspection_from_schema.py
--rw-r--r--   0        0        0     6351 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/utilities/lexicographic_sort_schema.py
--rw-r--r--   0        0        0     8797 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/utilities/print_schema.py
--rw-r--r--   0        0        0     3539 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/utilities/separate_operations.py
--rw-r--r--   0        0        0     1142 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/utilities/sort_value_node.py
--rw-r--r--   0        0        0     2933 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/utilities/strip_ignored_characters.py
--rw-r--r--   0        0        0     4054 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/utilities/type_comparators.py
--rw-r--r--   0        0        0     2003 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/utilities/type_from_ast.py
--rw-r--r--   0        0        0    10119 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/utilities/type_info.py
--rw-r--r--   0        0        0     5555 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/utilities/value_from_ast.py
--rw-r--r--   0        0        0     3116 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/utilities/value_from_ast_untyped.py
--rw-r--r--   0        0        0     6125 2023-06-04 19:57:31.188083 graphql_core-3.3.0a3/src/graphql/validation/__init__.py
--rw-r--r--   0        0        0     1080 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/rules/__init__.py
--rw-r--r--   0        0        0       46 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/rules/custom/__init__.py
--rw-r--r--   0        0        0     4319 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/rules/custom/no_deprecated.py
--rw-r--r--   0        0        0     1140 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/rules/custom/no_schema_introspection.py
--rw-r--r--   0        0        0     1930 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/rules/defer_stream_directive_label.py
--rw-r--r--   0        0        0     2456 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/rules/defer_stream_directive_on_root_field.py
--rw-r--r--   0        0        0     1529 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/rules/executable_definitions.py
--rw-r--r--   0        0        0     4636 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/rules/fields_on_correct_type.py
--rw-r--r--   0        0        0     1850 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/rules/fragments_on_composite_types.py
--rw-r--r--   0        0        0     3590 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/rules/known_argument_names.py
--rw-r--r--   0        0        0     4458 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/rules/known_directives.py
--rw-r--r--   0        0        0      795 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/rules/known_fragment_names.py
--rw-r--r--   0        0        0     2956 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/rules/known_type_names.py
--rw-r--r--   0        0        0     1237 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/rules/lone_anonymous_operation.py
--rw-r--r--   0        0        0     1289 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/rules/lone_schema_definition.py
--rw-r--r--   0        0        0     3114 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/rules/no_fragment_cycles.py
--rw-r--r--   0        0        0     1736 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/rules/no_undefined_variables.py
--rw-r--r--   0        0        0     1768 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/rules/no_unused_fragments.py
--rw-r--r--   0        0        0     1804 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/rules/no_unused_variables.py
--rw-r--r--   0        0        0    29499 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/rules/overlapping_fields_can_be_merged.py
--rw-r--r--   0        0        0     2312 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/rules/possible_fragment_spreads.py
--rw-r--r--   0        0        0     3696 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/rules/possible_type_extensions.py
--rw-r--r--   0        0        0     4462 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/rules/provided_required_arguments.py
--rw-r--r--   0        0        0     1434 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/rules/scalar_leafs.py
--rw-r--r--   0        0        0     3182 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/rules/single_field_subscriptions.py
--rw-r--r--   0        0        0     1793 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/rules/stream_directive_on_list_field.py
--rw-r--r--   0        0        0     2873 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/rules/unique_argument_definition_names.py
--rw-r--r--   0        0        0     1250 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/rules/unique_argument_names.py
--rw-r--r--   0        0        0     1571 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/rules/unique_directive_names.py
--rw-r--r--   0        0        0     3116 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/rules/unique_directives_per_location.py
--rw-r--r--   0        0        0     2135 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/rules/unique_enum_value_names.py
--rw-r--r--   0        0        0     2575 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/rules/unique_field_definition_names.py
--rw-r--r--   0        0        0     1332 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/rules/unique_fragment_names.py
--rw-r--r--   0        0        0     1424 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/rules/unique_input_field_names.py
--rw-r--r--   0        0        0     1473 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/rules/unique_operation_names.py
--rw-r--r--   0        0        0     2376 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/rules/unique_operation_types.py
--rw-r--r--   0        0        0     1724 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/rules/unique_type_names.py
--rw-r--r--   0        0        0     1090 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/rules/unique_variable_names.py
--rw-r--r--   0        0        0     5677 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/rules/values_of_correct_type.py
--rw-r--r--   0        0        0     1189 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/rules/variables_are_input_types.py
--rw-r--r--   0        0        0     3630 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/rules/variables_in_allowed_position.py
--rw-r--r--   0        0        0     6219 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/specified_rules.py
--rw-r--r--   0        0        0     4225 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/validate.py
--rw-r--r--   0        0        0     8712 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/validation/validation_context.py
--rw-r--r--   0        0        0     1354 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/src/graphql/version.py
--rw-r--r--   0        0        0       24 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/tests/__init__.py
--rw-r--r--   0        0        0      310 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/tests/benchmarks/__init__.py
--rw-r--r--   0        0        0     1040 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/tests/benchmarks/test_async_iterable.py
--rw-r--r--   0        0        0      376 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/tests/benchmarks/test_build_ast_schema.py
--rw-r--r--   0        0        0      437 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/tests/benchmarks/test_build_client_schema.py
--rw-r--r--   0        0        0     1190 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/tests/benchmarks/test_execution_async.py
--rw-r--r--   0        0        0      860 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/tests/benchmarks/test_execution_sync.py
--rw-r--r--   0        0        0      428 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/tests/benchmarks/test_graphql_schema.py
--rw-r--r--   0        0        0      463 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/tests/benchmarks/test_introspection_from_schema.py
--rw-r--r--   0        0        0      358 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/tests/benchmarks/test_parser.py
--rw-r--r--   0        0        0      425 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/tests/benchmarks/test_validate_gql.py
--rw-r--r--   0        0        0     1094 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/tests/benchmarks/test_validate_invalid_gql.py
--rw-r--r--   0        0        0      321 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/tests/benchmarks/test_validate_sdl.py
--rw-r--r--   0        0        0      744 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/tests/benchmarks/test_visit.py
--rw-r--r--   0        0        0      622 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/tests/conftest.py
--rw-r--r--   0        0        0       30 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/tests/error/__init__.py
--rw-r--r--   0        0        0    13303 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/tests/error/test_graphql_error.py
--rw-r--r--   0        0        0     1237 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/tests/error/test_located_error.py
--rw-r--r--   0        0        0     2829 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/tests/error/test_print_location.py
--rw-r--r--   0        0        0       34 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/tests/execution/__init__.py
--rw-r--r--   0        0        0    17452 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/tests/execution/test_abstract.py
--rw-r--r--   0        0        0     4013 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/tests/execution/test_customize.py
--rw-r--r--   0        0        0    28846 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/tests/execution/test_defer.py
--rw-r--r--   0        0        0     7024 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/tests/execution/test_directives.py
--rw-r--r--   0        0        0     4558 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/tests/execution/test_execution_result.py
--rw-r--r--   0        0        0    31603 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/tests/execution/test_executor.py
--rw-r--r--   0        0        0     6251 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/tests/execution/test_flatten_async_iterable.py
--rw-r--r--   0        0        0    13557 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/tests/execution/test_lists.py
--rw-r--r--   0        0        0     9197 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/tests/execution/test_map_async_iterable.py
--rw-r--r--   0        0        0    11445 2023-06-04 19:57:31.192083 graphql_core-3.3.0a3/tests/execution/test_middleware.py
--rw-r--r--   0        0        0    10141 2023-06-04 19:57:31.196083 graphql_core-3.3.0a3/tests/execution/test_mutations.py
--rw-r--r--   0        0        0    22626 2023-06-04 19:57:31.196083 graphql_core-3.3.0a3/tests/execution/test_nonnull.py
--rw-r--r--   0        0        0     5503 2023-06-04 19:57:31.196083 graphql_core-3.3.0a3/tests/execution/test_parallel.py
--rw-r--r--   0        0        0     7888 2023-06-04 19:57:31.196083 graphql_core-3.3.0a3/tests/execution/test_resolve.py
--rw-r--r--   0        0        0     5989 2023-06-04 19:57:31.196083 graphql_core-3.3.0a3/tests/execution/test_schema.py
--rw-r--r--   0        0        0    56960 2023-06-04 19:57:31.196083 graphql_core-3.3.0a3/tests/execution/test_stream.py
--rw-r--r--   0        0        0    38581 2023-06-04 19:57:31.196083 graphql_core-3.3.0a3/tests/execution/test_subscribe.py
--rw-r--r--   0        0        0     8529 2023-06-04 19:57:31.196083 graphql_core-3.3.0a3/tests/execution/test_sync.py
--rw-r--r--   0        0        0    14916 2023-06-04 19:57:31.196083 graphql_core-3.3.0a3/tests/execution/test_union_interface.py
--rw-r--r--   0        0        0    34877 2023-06-04 19:57:31.196083 graphql_core-3.3.0a3/tests/execution/test_variables.py
--rw-r--r--   0        0        0     1114 2023-06-04 19:57:31.196083 graphql_core-3.3.0a3/tests/fixtures/__init__.py
--rw-r--r--   0        0        0   345926 2023-06-04 19:57:31.200083 graphql_core-3.3.0a3/tests/fixtures/github_schema.graphql
--rw-r--r--   0        0        0  1826295 2023-06-04 19:57:31.204084 graphql_core-3.3.0a3/tests/fixtures/github_schema.json
--rw-r--r--   0        0        0     1466 2023-06-04 19:57:31.204084 graphql_core-3.3.0a3/tests/fixtures/kitchen_sink.graphql
--rw-r--r--   0        0        0     2876 2023-06-04 19:57:31.204084 graphql_core-3.3.0a3/tests/fixtures/schema_kitchen_sink.graphql
--rw-r--r--   0        0        0       33 2023-06-04 19:57:31.204084 graphql_core-3.3.0a3/tests/language/__init__.py
--rw-r--r--   0        0        0     9897 2023-06-04 19:57:31.204084 graphql_core-3.3.0a3/tests/language/test_ast.py
--rw-r--r--   0        0        0     7040 2023-06-04 19:57:31.204084 graphql_core-3.3.0a3/tests/language/test_block_string.py
--rw-r--r--   0        0        0     1782 2023-06-04 19:57:31.204084 graphql_core-3.3.0a3/tests/language/test_block_string_fuzz.py
--rw-r--r--   0        0        0     2414 2023-06-04 19:57:31.204084 graphql_core-3.3.0a3/tests/language/test_character_classes.py
--rw-r--r--   0        0        0    25166 2023-06-04 19:57:31.204084 graphql_core-3.3.0a3/tests/language/test_lexer.py
--rw-r--r--   0        0        0     1707 2023-06-04 19:57:31.204084 graphql_core-3.3.0a3/tests/language/test_location.py
--rw-r--r--   0        0        0    31230 2023-06-04 19:57:31.204084 graphql_core-3.3.0a3/tests/language/test_parser.py
--rw-r--r--   0        0        0     5409 2023-06-04 19:57:31.204084 graphql_core-3.3.0a3/tests/language/test_predicates.py
--rw-r--r--   0        0        0     2437 2023-06-04 19:57:31.204084 graphql_core-3.3.0a3/tests/language/test_print_string.py
--rw-r--r--   0        0        0     7206 2023-06-04 19:57:31.204084 graphql_core-3.3.0a3/tests/language/test_printer.py
--rw-r--r--   0        0        0    30299 2023-06-04 19:57:31.204084 graphql_core-3.3.0a3/tests/language/test_schema_parser.py
--rw-r--r--   0        0        0     5208 2023-06-04 19:57:31.204084 graphql_core-3.3.0a3/tests/language/test_schema_printer.py
--rw-r--r--   0        0        0     3594 2023-06-04 19:57:31.204084 graphql_core-3.3.0a3/tests/language/test_source.py
--rw-r--r--   0        0        0    72552 2023-06-04 19:57:31.204084 graphql_core-3.3.0a3/tests/language/test_visitor.py
--rw-r--r--   0        0        0       32 2023-06-04 19:57:31.204084 graphql_core-3.3.0a3/tests/pyutils/__init__.py
--rw-r--r--   0        0        0     2042 2023-06-04 19:57:31.204084 graphql_core-3.3.0a3/tests/pyutils/test_async_reduce.py
--rw-r--r--   0        0        0      697 2023-06-04 19:57:31.204084 graphql_core-3.3.0a3/tests/pyutils/test_cached_property.py
--rw-r--r--   0        0        0     2019 2023-06-04 19:57:31.204084 graphql_core-3.3.0a3/tests/pyutils/test_convert_case.py
--rw-r--r--   0        0        0     8935 2023-06-04 19:57:31.204084 graphql_core-3.3.0a3/tests/pyutils/test_description.py
--rw-r--r--   0        0        0      769 2023-06-04 19:57:31.204084 graphql_core-3.3.0a3/tests/pyutils/test_did_you_mean.py
--rw-r--r--   0        0        0     1040 2023-06-04 19:57:31.204084 graphql_core-3.3.0a3/tests/pyutils/test_format_list.py
--rw-r--r--   0        0        0      159 2023-06-04 19:57:31.204084 graphql_core-3.3.0a3/tests/pyutils/test_frozen_error.py
--rw-r--r--   0        0        0     1424 2023-06-04 19:57:31.204084 graphql_core-3.3.0a3/tests/pyutils/test_group_by.py
--rw-r--r--   0        0        0      635 2023-06-04 19:57:31.204084 graphql_core-3.3.0a3/tests/pyutils/test_identity_func.py
--rw-r--r--   0        0        0    12244 2023-06-04 19:57:31.204084 graphql_core-3.3.0a3/tests/pyutils/test_inspect.py
--rw-r--r--   0        0        0     3579 2023-06-04 19:57:31.204084 graphql_core-3.3.0a3/tests/pyutils/test_is_awaitable.py
--rw-r--r--   0        0        0     7744 2023-06-04 19:57:31.204084 graphql_core-3.3.0a3/tests/pyutils/test_is_iterable.py
--rw-r--r--   0        0        0      606 2023-06-04 19:57:31.204084 graphql_core-3.3.0a3/tests/pyutils/test_merge_kwargs.py
--rw-r--r--   0        0        0      860 2023-06-04 19:57:31.204084 graphql_core-3.3.0a3/tests/pyutils/test_natural_compare.py
--rw-r--r--   0        0        0      790 2023-06-04 19:57:31.204084 graphql_core-3.3.0a3/tests/pyutils/test_path.py
--rw-r--r--   0        0        0      426 2023-06-04 19:57:31.204084 graphql_core-3.3.0a3/tests/pyutils/test_print_path_list.py
--rw-r--r--   0        0        0     2960 2023-06-04 19:57:31.204084 graphql_core-3.3.0a3/tests/pyutils/test_simple_pub_sub.py
--rw-r--r--   0        0        0     2222 2023-06-04 19:57:31.204084 graphql_core-3.3.0a3/tests/pyutils/test_suggestion_list.py
--rw-r--r--   0        0        0     1628 2023-06-04 19:57:31.204084 graphql_core-3.3.0a3/tests/pyutils/test_undefined.py
--rw-r--r--   0        0        0     3835 2023-06-04 19:57:31.204084 graphql_core-3.3.0a3/tests/star_wars_data.py
--rw-r--r--   0        0        0     7871 2023-06-04 19:57:31.204084 graphql_core-3.3.0a3/tests/star_wars_schema.py
--rw-r--r--   0        0        0    13482 2023-06-04 19:57:31.208084 graphql_core-3.3.0a3/tests/test_docs.py
--rw-r--r--   0        0        0    11566 2023-06-04 19:57:31.208084 graphql_core-3.3.0a3/tests/test_star_wars_introspection.py
--rw-r--r--   0        0        0    13972 2023-06-04 19:57:31.208084 graphql_core-3.3.0a3/tests/test_star_wars_query.py
--rw-r--r--   0        0        0     3121 2023-06-04 19:57:31.208084 graphql_core-3.3.0a3/tests/test_star_wars_validation.py
--rw-r--r--   0        0        0    17760 2023-06-04 19:57:31.208084 graphql_core-3.3.0a3/tests/test_user_registry.py
--rw-r--r--   0        0        0     4162 2023-06-04 19:57:31.208084 graphql_core-3.3.0a3/tests/test_version.py
--rw-r--r--   0        0        0       29 2023-06-04 19:57:31.208084 graphql_core-3.3.0a3/tests/type/__init__.py
--rw-r--r--   0        0        0     2524 2023-06-04 19:57:31.208084 graphql_core-3.3.0a3/tests/type/test_assert_name.py
--rw-r--r--   0        0        0     5788 2023-06-04 19:57:31.208084 graphql_core-3.3.0a3/tests/type/test_custom_scalars.py
--rw-r--r--   0        0        0    52328 2023-06-04 19:57:31.208084 graphql_core-3.3.0a3/tests/type/test_definition.py
--rw-r--r--   0        0        0     6956 2023-06-04 19:57:31.208084 graphql_core-3.3.0a3/tests/type/test_directives.py
--rw-r--r--   0        0        0    10707 2023-06-04 19:57:31.208084 graphql_core-3.3.0a3/tests/type/test_enum.py
--rw-r--r--   0        0        0    10095 2023-06-04 19:57:31.208084 graphql_core-3.3.0a3/tests/type/test_extensions.py
--rw-r--r--   0        0        0    61708 2023-06-04 19:57:31.208084 graphql_core-3.3.0a3/tests/type/test_introspection.py
--rw-r--r--   0        0        0    22321 2023-06-04 19:57:31.208084 graphql_core-3.3.0a3/tests/type/test_predicate.py
--rw-r--r--   0        0        0    28854 2023-06-04 19:57:31.208084 graphql_core-3.3.0a3/tests/type/test_scalars.py
--rw-r--r--   0        0        0    16843 2023-06-04 19:57:31.208084 graphql_core-3.3.0a3/tests/type/test_schema.py
--rw-r--r--   0        0        0    73423 2023-06-04 19:57:31.208084 graphql_core-3.3.0a3/tests/type/test_validation.py
--rw-r--r--   0        0        0       34 2023-06-04 19:57:31.208084 graphql_core-3.3.0a3/tests/utilities/__init__.py
--rw-r--r--   0        0        0     9413 2023-06-04 19:57:31.208084 graphql_core-3.3.0a3/tests/utilities/test_ast_from_value.py
--rw-r--r--   0        0        0    27485 2023-06-04 19:57:31.208084 graphql_core-3.3.0a3/tests/utilities/test_ast_to_dict.py
--rw-r--r--   0        0        0    36040 2023-06-04 19:57:31.208084 graphql_core-3.3.0a3/tests/utilities/test_build_ast_schema.py
--rw-r--r--   0        0        0    35279 2023-06-04 19:57:31.208084 graphql_core-3.3.0a3/tests/utilities/test_build_client_schema.py
--rw-r--r--   0        0        0    13789 2023-06-04 19:57:31.208084 graphql_core-3.3.0a3/tests/utilities/test_coerce_input_value.py
--rw-r--r--   0        0        0      769 2023-06-04 19:57:31.208084 graphql_core-3.3.0a3/tests/utilities/test_concat_ast.py
--rw-r--r--   0        0        0    43753 2023-06-04 19:57:31.208084 graphql_core-3.3.0a3/tests/utilities/test_extend_schema.py
--rw-r--r--   0        0        0    37071 2023-06-04 19:57:31.208084 graphql_core-3.3.0a3/tests/utilities/test_find_breaking_changes.py
--rw-r--r--   0        0        0     3340 2023-06-04 19:57:31.208084 graphql_core-3.3.0a3/tests/utilities/test_get_introspection_query.py
--rw-r--r--   0        0        0     1989 2023-06-04 19:57:31.208084 graphql_core-3.3.0a3/tests/utilities/test_get_operation_ast.py
--rw-r--r--   0        0        0     6548 2023-06-04 19:57:31.208084 graphql_core-3.3.0a3/tests/utilities/test_introspection_from_schema.py
--rw-r--r--   0        0        0     7825 2023-06-04 19:57:31.208084 graphql_core-3.3.0a3/tests/utilities/test_lexicographic_sort_schema.py
--rw-r--r--   0        0        0    26814 2023-06-04 19:57:31.208084 graphql_core-3.3.0a3/tests/utilities/test_print_schema.py
--rw-r--r--   0        0        0     4839 2023-06-04 19:57:31.208084 graphql_core-3.3.0a3/tests/utilities/test_separate_operations.py
--rw-r--r--   0        0        0     1320 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/utilities/test_sort_value_node.py
--rw-r--r--   0        0        0     8332 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/utilities/test_strip_ignored_characters.py
--rw-r--r--   0        0        0     9165 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/utilities/test_strip_ignored_characters_fuzz.py
--rw-r--r--   0        0        0     3962 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/utilities/test_type_comparators.py
--rw-r--r--   0        0        0     1371 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/utilities/test_type_from_ast.py
--rw-r--r--   0        0        0    20156 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/utilities/test_type_info.py
--rw-r--r--   0        0        0    10359 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/utilities/test_value_from_ast.py
--rw-r--r--   0        0        0     2788 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/utilities/test_value_from_ast_untyped.py
--rw-r--r--   0        0        0      361 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/utils/__init__.py
--rw-r--r--   0        0        0      840 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/utils/assert_equal_awaitables_or_values.py
--rw-r--r--   0        0        0      327 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/utils/assert_matching_values.py
--rw-r--r--   0        0        0      207 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/utils/dedent.py
--rw-r--r--   0        0        0      378 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/utils/gen_fuzz_strings.py
--rw-r--r--   0        0        0     1631 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/utils/test_assert_equal_awaitables_or_values.py
--rw-r--r--   0        0        0      424 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/utils/test_assert_matching_values.py
--rw-r--r--   0        0        0     2268 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/utils/test_dedent.py
--rw-r--r--   0        0        0     1570 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/utils/test_gen_fuzz_strings.py
--rw-r--r--   0        0        0      133 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/validation/__init__.py
--rw-r--r--   0        0        0     3510 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/validation/harness.py
--rw-r--r--   0        0        0     4825 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/validation/test_defer_stream_directive_label.py
--rw-r--r--   0        0        0     6925 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/validation/test_defer_stream_directive_on_root_field.py
--rw-r--r--   0        0        0     2235 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/validation/test_executable_definitions.py
--rw-r--r--   0        0        0    12731 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/validation/test_fields_on_correct_type.py
--rw-r--r--   0        0        0     3392 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/validation/test_fragments_on_composite_types.py
--rw-r--r--   0        0        0     9805 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/validation/test_known_argument_names.py
--rw-r--r--   0        0        0    14060 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/validation/test_known_directives.py
--rw-r--r--   0        0        0     1845 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/validation/test_known_fragment_names.py
--rw-r--r--   0        0        0    10758 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/validation/test_known_type_names.py
--rw-r--r--   0        0        0     2603 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/validation/test_lone_anonymous_operation.py
--rw-r--r--   0        0        0     3469 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/validation/test_lone_schema_definition.py
--rw-r--r--   0        0        0     8895 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/validation/test_no_deprecated.py
--rw-r--r--   0        0        0     7659 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/validation/test_no_fragment_cycles.py
--rw-r--r--   0        0        0     3951 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/validation/test_no_schema_introspection.py
--rw-r--r--   0        0        0    10185 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/validation/test_no_undefined_variables.py
--rw-r--r--   0        0        0     4070 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/validation/test_no_unused_fragments.py
--rw-r--r--   0        0        0     6265 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/validation/test_no_unused_variables.py
--rw-r--r--   0        0        0    38196 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/validation/test_overlapping_fields_can_be_merged.py
--rw-r--r--   0        0        0    10022 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/validation/test_possible_fragment_spreads.py
--rw-r--r--   0        0        0     8735 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/validation/test_possible_type_extensions.py
--rw-r--r--   0        0        0    10622 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/validation/test_provided_required_arguments.py
--rw-r--r--   0        0        0     4161 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/validation/test_scalar_leafs.py
--rw-r--r--   0        0        0     8228 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/validation/test_single_field_subscriptions.py
--rw-r--r--   0        0        0     2120 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/validation/test_stream_directive_on_list_field.py
--rw-r--r--   0        0        0     4194 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/validation/test_unique_argument_definition_names.py
--rw-r--r--   0        0        0     3560 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/validation/test_unique_argument_names.py
--rw-r--r--   0        0        0     2733 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/validation/test_unique_directive_names.py
--rw-r--r--   0        0        0    10909 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/validation/test_unique_directives_per_location.py
--rw-r--r--   0        0        0     4672 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/validation/test_unique_enum_value_names.py
--rw-r--r--   0        0        0    11248 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/validation/test_unique_field_definition_names.py
--rw-r--r--   0        0        0     2541 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/validation/test_unique_fragment_names.py
--rw-r--r--   0        0        0     2610 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/validation/test_unique_input_field_names.py
--rw-r--r--   0        0        0     2862 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/validation/test_unique_operation_names.py
--rw-r--r--   0        0        0     9880 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/validation/test_unique_operation_types.py
--rw-r--r--   0        0        0     4350 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/validation/test_unique_type_names.py
--rw-r--r--   0        0        0     1334 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/validation/test_unique_variable_names.py
--rw-r--r--   0        0        0     4962 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/validation/test_validation.py
--rw-r--r--   0        0        0    36134 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/validation/test_values_of_correct_type.py
--rw-r--r--   0        0        0     1514 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/validation/test_variables_are_input_types.py
--rw-r--r--   0        0        0    10191 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tests/validation/test_variables_in_allowed_position.py
--rw-r--r--   0        0        0     1431 2023-06-04 19:57:31.212084 graphql_core-3.3.0a3/tox.ini
--rw-r--r--   0        0        0    11011 1970-01-01 00:00:00.000000 graphql_core-3.3.0a3/PKG-INFO
+-rw-r--r--   0        0        0      544 2024-02-17 11:26:41.325034 graphql_core-3.3.0a4/.bumpversion.cfg
+-rw-r--r--   0        0        0      292 2024-02-17 11:26:41.325034 graphql_core-3.3.0a4/.editorconfig
+-rw-r--r--   0        0        0      341 2024-02-17 11:26:41.325034 graphql_core-3.3.0a4/.readthedocs.yaml
+-rw-r--r--   0        0        0        7 2024-02-17 11:26:41.325034 graphql_core-3.3.0a4/CODEOWNERS
+-rw-r--r--   0        0        0     1180 2024-02-17 11:26:41.325034 graphql_core-3.3.0a4/LICENSE
+-rw-r--r--   0        0        0    10001 2024-02-17 11:26:41.325034 graphql_core-3.3.0a4/README.md
+-rw-r--r--   0        0        0      728 2024-02-17 11:26:41.325034 graphql_core-3.3.0a4/SECURITY.md
+-rw-r--r--   0        0        0      634 2024-02-17 11:26:41.325034 graphql_core-3.3.0a4/docs/Makefile
+-rw-r--r--   0        0        0    15505 2024-02-17 11:26:41.325034 graphql_core-3.3.0a4/docs/conf.py
+-rw-r--r--   0        0        0     5754 2024-02-17 11:26:41.325034 graphql_core-3.3.0a4/docs/diffs.rst
+-rw-r--r--   0        0        0      248 2024-02-17 11:26:41.325034 graphql_core-3.3.0a4/docs/index.rst
+-rw-r--r--   0        0        0     3254 2024-02-17 11:26:41.325034 graphql_core-3.3.0a4/docs/intro.rst
+-rw-r--r--   0        0        0      760 2024-02-17 11:26:41.325034 graphql_core-3.3.0a4/docs/make.bat
+-rw-r--r--   0        0        0      304 2024-02-17 11:26:41.325034 graphql_core-3.3.0a4/docs/modules/error.rst
+-rw-r--r--   0        0        0     1397 2024-02-17 11:26:41.325034 graphql_core-3.3.0a4/docs/modules/execution.rst
+-rw-r--r--   0        0        0      397 2024-02-17 11:26:41.325034 graphql_core-3.3.0a4/docs/modules/graphql.rst
+-rw-r--r--   0        0        0     4457 2024-02-17 11:26:41.325034 graphql_core-3.3.0a4/docs/modules/language.rst
+-rw-r--r--   0        0        0      832 2024-02-17 11:26:41.325034 graphql_core-3.3.0a4/docs/modules/pyutils.rst
+-rw-r--r--   0        0        0     4492 2024-02-17 11:26:41.325034 graphql_core-3.3.0a4/docs/modules/type.rst
+-rw-r--r--   0        0        0     2421 2024-02-17 11:26:41.325034 graphql_core-3.3.0a4/docs/modules/utilities.rst
+-rw-r--r--   0        0        0     3255 2024-02-17 11:26:41.325034 graphql_core-3.3.0a4/docs/modules/validation.rst
+-rw-r--r--   0        0        0       40 2024-02-17 11:26:41.325034 graphql_core-3.3.0a4/docs/requirements.txt
+-rw-r--r--   0        0        0     1430 2024-02-17 11:26:41.325034 graphql_core-3.3.0a4/docs/usage/extension.rst
+-rw-r--r--   0        0        0      278 2024-02-17 11:26:41.325034 graphql_core-3.3.0a4/docs/usage/index.rst
+-rw-r--r--   0        0        0     2382 2024-02-17 11:26:41.325034 graphql_core-3.3.0a4/docs/usage/introspection.rst
+-rw-r--r--   0        0        0     2082 2024-02-17 11:26:41.325034 graphql_core-3.3.0a4/docs/usage/methods.rst
+-rw-r--r--   0        0        0     1258 2024-02-17 11:26:41.325034 graphql_core-3.3.0a4/docs/usage/other.rst
+-rw-r--r--   0        0        0     2706 2024-02-17 11:26:41.325034 graphql_core-3.3.0a4/docs/usage/parser.rst
+-rw-r--r--   0        0        0     3920 2024-02-17 11:26:41.325034 graphql_core-3.3.0a4/docs/usage/queries.rst
+-rw-r--r--   0        0        0     3899 2024-02-17 11:26:41.325034 graphql_core-3.3.0a4/docs/usage/resolvers.rst
+-rw-r--r--   0        0        0     7586 2024-02-17 11:26:41.325034 graphql_core-3.3.0a4/docs/usage/schema.rst
+-rw-r--r--   0        0        0     2632 2024-02-17 11:26:41.325034 graphql_core-3.3.0a4/docs/usage/sdl.rst
+-rw-r--r--   0        0        0     1719 2024-02-17 11:26:41.325034 graphql_core-3.3.0a4/docs/usage/validator.rst
+-rw-r--r--   0        0        0    91953 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/poetry.lock
+-rw-r--r--   0        0        0     8830 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/pyproject.toml
+-rw-r--r--   0        0        0    21762 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/__init__.py
+-rw-r--r--   0        0        0      432 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/error/__init__.py
+-rw-r--r--   0        0        0     8815 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/error/graphql_error.py
+-rw-r--r--   0        0        0     1708 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/error/located_error.py
+-rw-r--r--   0        0        0      630 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/error/syntax_error.py
+-rw-r--r--   0        0        0     2050 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/execution/__init__.py
+-rw-r--r--   0        0        0     2369 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/execution/async_iterables.py
+-rw-r--r--   0        0        0     8479 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/execution/collect_fields.py
+-rw-r--r--   0        0        0   103391 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/execution/execute.py
+-rw-r--r--   0        0        0     2632 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/execution/middleware.py
+-rw-r--r--   0        0        0     8714 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/execution/values.py
+-rw-r--r--   0        0        0     7130 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/graphql.py
+-rw-r--r--   0        0        0     5094 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/language/__init__.py
+-rw-r--r--   0        0        0    22511 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/language/ast.py
+-rw-r--r--   0        0        0     4981 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/language/block_string.py
+-rw-r--r--   0        0        0      896 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/language/character_classes.py
+-rw-r--r--   0        0        0      857 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/language/directive_locations.py
+-rw-r--r--   0        0        0    19551 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/language/lexer.py
+-rw-r--r--   0        0        0     1307 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/language/location.py
+-rw-r--r--   0        0        0    47185 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/language/parser.py
+-rw-r--r--   0        0        0     3251 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/language/predicates.py
+-rw-r--r--   0        0        0     2753 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/language/print_location.py
+-rw-r--r--   0        0        0     1785 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/language/print_string.py
+-rw-r--r--   0        0        0    14104 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/language/printer.py
+-rw-r--r--   0        0        0     2603 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/language/source.py
+-rw-r--r--   0        0        0      584 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/language/token_kind.py
+-rw-r--r--   0        0        0    13122 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/language/visitor.py
+-rw-r--r--   0        0        0       66 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/py.typed
+-rw-r--r--   0        0        0     1805 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/pyutils/__init__.py
+-rw-r--r--   0        0        0     1458 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/pyutils/async_reduce.py
+-rw-r--r--   0        0        0      302 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/pyutils/awaitable_or_value.py
+-rw-r--r--   0        0        0     1072 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/pyutils/cached_property.py
+-rw-r--r--   0        0        0      762 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/pyutils/convert_case.py
+-rw-r--r--   0        0        0     2104 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/pyutils/description.py
+-rw-r--r--   0        0        0      641 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/pyutils/did_you_mean.py
+-rw-r--r--   0        0        0      805 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/pyutils/format_list.py
+-rw-r--r--   0        0        0      173 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/pyutils/frozen_error.py
+-rw-r--r--   0        0        0      496 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/pyutils/group_by.py
+-rw-r--r--   0        0        0      303 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/pyutils/identity_func.py
+-rw-r--r--   0        0        0     5758 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/pyutils/inspect.py
+-rw-r--r--   0        0        0     1014 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/pyutils/is_awaitable.py
+-rw-r--r--   0        0        0     1204 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/pyutils/is_iterable.py
+-rw-r--r--   0        0        0      273 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/pyutils/merge_kwargs.py
+-rw-r--r--   0        0        0      503 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/pyutils/natural_compare.py
+-rw-r--r--   0        0        0      997 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/pyutils/path.py
+-rw-r--r--   0        0        0      256 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/pyutils/print_path_list.py
+-rw-r--r--   0        0        0     2725 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/pyutils/simple_pub_sub.py
+-rw-r--r--   0        0        0     3607 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/pyutils/suggestion_list.py
+-rw-r--r--   0        0        0     1354 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/pyutils/undefined.py
+-rw-r--r--   0        0        0     7326 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/type/__init__.py
+-rw-r--r--   0        0        0     1179 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/type/assert_name.py
+-rw-r--r--   0        0        0    56942 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/type/definition.py
+-rw-r--r--   0        0        0     9054 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/type/directives.py
+-rw-r--r--   0        0        0    22881 2024-02-17 11:26:41.329033 graphql_core-3.3.0a4/src/graphql/type/introspection.py
+-rw-r--r--   0        0        0    10964 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/type/scalars.py
+-rw-r--r--   0        0        0    18534 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/type/schema.py
+-rw-r--r--   0        0        0    24212 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/type/validate.py
+-rw-r--r--   0        0        0     3424 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/utilities/__init__.py
+-rw-r--r--   0        0        0     4659 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/utilities/ast_from_value.py
+-rw-r--r--   0        0        0     1647 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/utilities/ast_to_dict.py
+-rw-r--r--   0        0        0     3548 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/utilities/build_ast_schema.py
+-rw-r--r--   0        0        0    17627 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/utilities/build_client_schema.py
+-rw-r--r--   0        0        0     5595 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/utilities/coerce_input_value.py
+-rw-r--r--   0        0        0      595 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/utilities/concat_ast.py
+-rw-r--r--   0        0        0    32140 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/utilities/extend_schema.py
+-rw-r--r--   0        0        0    20974 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/utilities/find_breaking_changes.py
+-rw-r--r--   0        0        0     7976 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/utilities/get_introspection_query.py
+-rw-r--r--   0        0        0     1118 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/utilities/get_operation_ast.py
+-rw-r--r--   0        0        0     1706 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/utilities/introspection_from_schema.py
+-rw-r--r--   0        0        0     6442 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/utilities/lexicographic_sort_schema.py
+-rw-r--r--   0        0        0     9902 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/utilities/print_schema.py
+-rw-r--r--   0        0        0     3578 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/utilities/separate_operations.py
+-rw-r--r--   0        0        0     1168 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/utilities/sort_value_node.py
+-rw-r--r--   0        0        0     2963 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/utilities/strip_ignored_characters.py
+-rw-r--r--   0        0        0     4086 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/utilities/type_comparators.py
+-rw-r--r--   0        0        0     2103 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/utilities/type_from_ast.py
+-rw-r--r--   0        0        0    10165 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/utilities/type_info.py
+-rw-r--r--   0        0        0     5683 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/utilities/value_from_ast.py
+-rw-r--r--   0        0        0     3207 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/utilities/value_from_ast_untyped.py
+-rw-r--r--   0        0        0     6125 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/__init__.py
+-rw-r--r--   0        0        0     1126 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/rules/__init__.py
+-rw-r--r--   0        0        0       46 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/rules/custom/__init__.py
+-rw-r--r--   0        0        0     4344 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/rules/custom/no_deprecated.py
+-rw-r--r--   0        0        0     1175 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/rules/custom/no_schema_introspection.py
+-rw-r--r--   0        0        0     1978 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/rules/defer_stream_directive_label.py
+-rw-r--r--   0        0        0     2504 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/rules/defer_stream_directive_on_root_field.py
+-rw-r--r--   0        0        0     1563 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/rules/executable_definitions.py
+-rw-r--r--   0        0        0     4665 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/rules/fields_on_correct_type.py
+-rw-r--r--   0        0        0     1889 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/rules/fragments_on_composite_types.py
+-rw-r--r--   0        0        0     3652 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/rules/known_argument_names.py
+-rw-r--r--   0        0        0     4496 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/rules/known_directives.py
+-rw-r--r--   0        0        0      827 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/rules/known_fragment_names.py
+-rw-r--r--   0        0        0     2993 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/rules/known_type_names.py
+-rw-r--r--   0        0        0     1281 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/rules/lone_anonymous_operation.py
+-rw-r--r--   0        0        0     1331 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/rules/lone_schema_definition.py
+-rw-r--r--   0        0        0     3152 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/rules/no_fragment_cycles.py
+-rw-r--r--   0        0        0     1778 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/rules/no_undefined_variables.py
+-rw-r--r--   0        0        0     1807 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/rules/no_unused_fragments.py
+-rw-r--r--   0        0        0     1843 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/rules/no_unused_variables.py
+-rw-r--r--   0        0        0    29803 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/rules/overlapping_fields_can_be_merged.py
+-rw-r--r--   0        0        0     2348 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/rules/possible_fragment_spreads.py
+-rw-r--r--   0        0        0     3793 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/rules/possible_type_extensions.py
+-rw-r--r--   0        0        0     4531 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/rules/provided_required_arguments.py
+-rw-r--r--   0        0        0     1458 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/rules/scalar_leafs.py
+-rw-r--r--   0        0        0     3220 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/rules/single_field_subscriptions.py
+-rw-r--r--   0        0        0     1846 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/rules/stream_directive_on_list_field.py
+-rw-r--r--   0        0        0     2917 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/rules/unique_argument_definition_names.py
+-rw-r--r--   0        0        0     1284 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/rules/unique_argument_names.py
+-rw-r--r--   0        0        0     1613 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/rules/unique_directive_names.py
+-rw-r--r--   0        0        0     3171 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/rules/unique_directives_per_location.py
+-rw-r--r--   0        0        0     2178 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/rules/unique_enum_value_names.py
+-rw-r--r--   0        0        0     2624 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/rules/unique_field_definition_names.py
+-rw-r--r--   0        0        0     1373 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/rules/unique_fragment_names.py
+-rw-r--r--   0        0        0     1468 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/rules/unique_input_field_names.py
+-rw-r--r--   0        0        0     1515 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/rules/unique_operation_names.py
+-rw-r--r--   0        0        0     2456 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/rules/unique_operation_types.py
+-rw-r--r--   0        0        0     1761 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/rules/unique_type_names.py
+-rw-r--r--   0        0        0     1123 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/rules/unique_variable_names.py
+-rw-r--r--   0        0        0     5735 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/rules/values_of_correct_type.py
+-rw-r--r--   0        0        0     1226 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/rules/variables_are_input_types.py
+-rw-r--r--   0        0        0     3679 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/rules/variables_in_allowed_position.py
+-rw-r--r--   0        0        0     6241 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/specified_rules.py
+-rw-r--r--   0        0        0     4224 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/validate.py
+-rw-r--r--   0        0        0     8771 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/validation/validation_context.py
+-rw-r--r--   0        0        0     1388 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/src/graphql/version.py
+-rw-r--r--   0        0        0       24 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/tests/__init__.py
+-rw-r--r--   0        0        0      310 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/tests/benchmarks/__init__.py
+-rw-r--r--   0        0        0     1039 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/tests/benchmarks/test_async_iterable.py
+-rw-r--r--   0        0        0      376 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/tests/benchmarks/test_build_ast_schema.py
+-rw-r--r--   0        0        0      442 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/tests/benchmarks/test_build_client_schema.py
+-rw-r--r--   0        0        0     1191 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/tests/benchmarks/test_execution_async.py
+-rw-r--r--   0        0        0      861 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/tests/benchmarks/test_execution_sync.py
+-rw-r--r--   0        0        0      428 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/tests/benchmarks/test_graphql_schema.py
+-rw-r--r--   0        0        0      463 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/tests/benchmarks/test_introspection_from_schema.py
+-rw-r--r--   0        0        0      358 2024-02-17 11:26:41.333033 graphql_core-3.3.0a4/tests/benchmarks/test_parser.py
+-rw-r--r--   0        0        0      553 2024-02-17 11:26:41.337034 graphql_core-3.3.0a4/tests/benchmarks/test_repeated_fields.py
+-rw-r--r--   0        0        0      425 2024-02-17 11:26:41.337034 graphql_core-3.3.0a4/tests/benchmarks/test_validate_gql.py
+-rw-r--r--   0        0        0     1094 2024-02-17 11:26:41.337034 graphql_core-3.3.0a4/tests/benchmarks/test_validate_invalid_gql.py
+-rw-r--r--   0        0        0      321 2024-02-17 11:26:41.337034 graphql_core-3.3.0a4/tests/benchmarks/test_validate_sdl.py
+-rw-r--r--   0        0        0      744 2024-02-17 11:26:41.337034 graphql_core-3.3.0a4/tests/benchmarks/test_visit.py
+-rw-r--r--   0        0        0      622 2024-02-17 11:26:41.337034 graphql_core-3.3.0a4/tests/conftest.py
+-rw-r--r--   0        0        0       30 2024-02-17 11:26:41.337034 graphql_core-3.3.0a4/tests/error/__init__.py
+-rw-r--r--   0        0        0    13387 2024-02-17 11:26:41.337034 graphql_core-3.3.0a4/tests/error/test_graphql_error.py
+-rw-r--r--   0        0        0     1237 2024-02-17 11:26:41.337034 graphql_core-3.3.0a4/tests/error/test_located_error.py
+-rw-r--r--   0        0        0     2829 2024-02-17 11:26:41.337034 graphql_core-3.3.0a4/tests/error/test_print_location.py
+-rw-r--r--   0        0        0       34 2024-02-17 11:26:41.337034 graphql_core-3.3.0a4/tests/execution/__init__.py
+-rw-r--r--   0        0        0    17453 2024-02-17 11:26:41.337034 graphql_core-3.3.0a4/tests/execution/test_abstract.py
+-rw-r--r--   0        0        0     4047 2024-02-17 11:26:41.337034 graphql_core-3.3.0a4/tests/execution/test_customize.py
+-rw-r--r--   0        0        0    30483 2024-02-17 11:26:41.337034 graphql_core-3.3.0a4/tests/execution/test_defer.py
+-rw-r--r--   0        0        0     7023 2024-02-17 11:26:41.337034 graphql_core-3.3.0a4/tests/execution/test_directives.py
+-rw-r--r--   0        0        0     4521 2024-02-17 11:26:41.337034 graphql_core-3.3.0a4/tests/execution/test_execution_result.py
+-rw-r--r--   0        0        0    33196 2024-02-17 11:26:41.337034 graphql_core-3.3.0a4/tests/execution/test_executor.py
+-rw-r--r--   0        0        0     6370 2024-02-17 11:26:41.337034 graphql_core-3.3.0a4/tests/execution/test_flatten_async_iterable.py
+-rw-r--r--   0        0        0    13845 2024-02-17 11:26:41.337034 graphql_core-3.3.0a4/tests/execution/test_lists.py
+-rw-r--r--   0        0        0     8708 2024-02-17 11:26:41.337034 graphql_core-3.3.0a4/tests/execution/test_map_async_iterable.py
+-rw-r--r--   0        0        0    11451 2024-02-17 11:26:41.337034 graphql_core-3.3.0a4/tests/execution/test_middleware.py
+-rw-r--r--   0        0        0    10175 2024-02-17 11:26:41.337034 graphql_core-3.3.0a4/tests/execution/test_mutations.py
+-rw-r--r--   0        0        0    22704 2024-02-17 11:26:41.337034 graphql_core-3.3.0a4/tests/execution/test_nonnull.py
+-rw-r--r--   0        0        0     5537 2024-02-17 11:26:41.337034 graphql_core-3.3.0a4/tests/execution/test_parallel.py
+-rw-r--r--   0        0        0     7905 2024-02-17 11:26:41.337034 graphql_core-3.3.0a4/tests/execution/test_resolve.py
+-rw-r--r--   0        0        0     6017 2024-02-17 11:26:41.337034 graphql_core-3.3.0a4/tests/execution/test_schema.py
+-rw-r--r--   0        0        0    61790 2024-02-17 11:26:41.337034 graphql_core-3.3.0a4/tests/execution/test_stream.py
+-rw-r--r--   0        0        0    38927 2024-02-17 11:26:41.337034 graphql_core-3.3.0a4/tests/execution/test_subscribe.py
+-rw-r--r--   0        0        0     8643 2024-02-17 11:26:41.337034 graphql_core-3.3.0a4/tests/execution/test_sync.py
+-rw-r--r--   0        0        0    14943 2024-02-17 11:26:41.337034 graphql_core-3.3.0a4/tests/execution/test_union_interface.py
+-rw-r--r--   0        0        0    36793 2024-02-17 11:26:41.337034 graphql_core-3.3.0a4/tests/execution/test_variables.py
+-rw-r--r--   0        0        0     1196 2024-02-17 11:26:41.337034 graphql_core-3.3.0a4/tests/fixtures/__init__.py
+-rw-r--r--   0        0        0   345926 2024-02-17 11:26:41.341034 graphql_core-3.3.0a4/tests/fixtures/github_schema.graphql
+-rw-r--r--   0        0        0  1826295 2024-02-17 11:26:41.345034 graphql_core-3.3.0a4/tests/fixtures/github_schema.json
+-rw-r--r--   0        0        0     1466 2024-02-17 11:26:41.345034 graphql_core-3.3.0a4/tests/fixtures/kitchen_sink.graphql
+-rw-r--r--   0        0        0     2876 2024-02-17 11:26:41.345034 graphql_core-3.3.0a4/tests/fixtures/schema_kitchen_sink.graphql
+-rw-r--r--   0        0        0       33 2024-02-17 11:26:41.345034 graphql_core-3.3.0a4/tests/language/__init__.py
+-rw-r--r--   0        0        0     9933 2024-02-17 11:26:41.345034 graphql_core-3.3.0a4/tests/language/test_ast.py
+-rw-r--r--   0        0        0     7040 2024-02-17 11:26:41.345034 graphql_core-3.3.0a4/tests/language/test_block_string.py
+-rw-r--r--   0        0        0     1787 2024-02-17 11:26:41.345034 graphql_core-3.3.0a4/tests/language/test_block_string_fuzz.py
+-rw-r--r--   0        0        0     2430 2024-02-17 11:26:41.345034 graphql_core-3.3.0a4/tests/language/test_character_classes.py
+-rw-r--r--   0        0        0    25143 2024-02-17 11:26:41.345034 graphql_core-3.3.0a4/tests/language/test_lexer.py
+-rw-r--r--   0        0        0     1851 2024-02-17 11:26:41.345034 graphql_core-3.3.0a4/tests/language/test_location.py
+-rw-r--r--   0        0        0    31342 2024-02-17 11:26:41.345034 graphql_core-3.3.0a4/tests/language/test_parser.py
+-rw-r--r--   0        0        0     5408 2024-02-17 11:26:41.345034 graphql_core-3.3.0a4/tests/language/test_predicates.py
+-rw-r--r--   0        0        0     2437 2024-02-17 11:26:41.345034 graphql_core-3.3.0a4/tests/language/test_print_string.py
+-rw-r--r--   0        0        0     7207 2024-02-17 11:26:41.345034 graphql_core-3.3.0a4/tests/language/test_printer.py
+-rw-r--r--   0        0        0    30292 2024-02-17 11:26:41.345034 graphql_core-3.3.0a4/tests/language/test_schema_parser.py
+-rw-r--r--   0        0        0     5202 2024-02-17 11:26:41.345034 graphql_core-3.3.0a4/tests/language/test_schema_printer.py
+-rw-r--r--   0        0        0     3743 2024-02-17 11:26:41.345034 graphql_core-3.3.0a4/tests/language/test_source.py
+-rw-r--r--   0        0        0    72924 2024-02-17 11:26:41.345034 graphql_core-3.3.0a4/tests/language/test_visitor.py
+-rw-r--r--   0        0        0       32 2024-02-17 11:26:41.345034 graphql_core-3.3.0a4/tests/pyutils/__init__.py
+-rw-r--r--   0        0        0     2067 2024-02-17 11:26:41.345034 graphql_core-3.3.0a4/tests/pyutils/test_async_reduce.py
+-rw-r--r--   0        0        0      697 2024-02-17 11:26:41.345034 graphql_core-3.3.0a4/tests/pyutils/test_cached_property.py
+-rw-r--r--   0        0        0     2019 2024-02-17 11:26:41.345034 graphql_core-3.3.0a4/tests/pyutils/test_convert_case.py
+-rw-r--r--   0        0        0     8936 2024-02-17 11:26:41.345034 graphql_core-3.3.0a4/tests/pyutils/test_description.py
+-rw-r--r--   0        0        0      769 2024-02-17 11:26:41.349033 graphql_core-3.3.0a4/tests/pyutils/test_did_you_mean.py
+-rw-r--r--   0        0        0     1129 2024-02-17 11:26:41.349033 graphql_core-3.3.0a4/tests/pyutils/test_format_list.py
+-rw-r--r--   0        0        0      159 2024-02-17 11:26:41.349033 graphql_core-3.3.0a4/tests/pyutils/test_frozen_error.py
+-rw-r--r--   0        0        0     1444 2024-02-17 11:26:41.349033 graphql_core-3.3.0a4/tests/pyutils/test_group_by.py
+-rw-r--r--   0        0        0      635 2024-02-17 11:26:41.349033 graphql_core-3.3.0a4/tests/pyutils/test_identity_func.py
+-rw-r--r--   0        0        0    12285 2024-02-17 11:26:41.349033 graphql_core-3.3.0a4/tests/pyutils/test_inspect.py
+-rw-r--r--   0        0        0     3609 2024-02-17 11:26:41.349033 graphql_core-3.3.0a4/tests/pyutils/test_is_awaitable.py
+-rw-r--r--   0        0        0     7776 2024-02-17 11:26:41.349033 graphql_core-3.3.0a4/tests/pyutils/test_is_iterable.py
+-rw-r--r--   0        0        0      605 2024-02-17 11:26:41.349033 graphql_core-3.3.0a4/tests/pyutils/test_merge_kwargs.py
+-rw-r--r--   0        0        0      859 2024-02-17 11:26:41.349033 graphql_core-3.3.0a4/tests/pyutils/test_natural_compare.py
+-rw-r--r--   0        0        0      790 2024-02-17 11:26:41.349033 graphql_core-3.3.0a4/tests/pyutils/test_path.py
+-rw-r--r--   0        0        0      426 2024-02-17 11:26:41.349033 graphql_core-3.3.0a4/tests/pyutils/test_print_path_list.py
+-rw-r--r--   0        0        0     2991 2024-02-17 11:26:41.349033 graphql_core-3.3.0a4/tests/pyutils/test_simple_pub_sub.py
+-rw-r--r--   0        0        0     2222 2024-02-17 11:26:41.349033 graphql_core-3.3.0a4/tests/pyutils/test_suggestion_list.py
+-rw-r--r--   0        0        0     1590 2024-02-17 11:26:41.349033 graphql_core-3.3.0a4/tests/pyutils/test_undefined.py
+-rw-r--r--   0        0        0     3913 2024-02-17 11:26:41.349033 graphql_core-3.3.0a4/tests/star_wars_data.py
+-rw-r--r--   0        0        0     7871 2024-02-17 11:26:41.349033 graphql_core-3.3.0a4/tests/star_wars_schema.py
+-rw-r--r--   0        0        0    13653 2024-02-17 11:26:41.349033 graphql_core-3.3.0a4/tests/test_docs.py
+-rw-r--r--   0        0        0    11566 2024-02-17 11:26:41.349033 graphql_core-3.3.0a4/tests/test_star_wars_introspection.py
+-rw-r--r--   0        0        0    14123 2024-02-17 11:26:41.349033 graphql_core-3.3.0a4/tests/test_star_wars_query.py
+-rw-r--r--   0        0        0     3121 2024-02-17 11:26:41.349033 graphql_core-3.3.0a4/tests/test_star_wars_validation.py
+-rw-r--r--   0        0        0    17912 2024-02-17 11:26:41.349033 graphql_core-3.3.0a4/tests/test_user_registry.py
+-rw-r--r--   0        0        0     4161 2024-02-17 11:26:41.349033 graphql_core-3.3.0a4/tests/test_version.py
+-rw-r--r--   0        0        0       29 2024-02-17 11:26:41.349033 graphql_core-3.3.0a4/tests/type/__init__.py
+-rw-r--r--   0        0        0     2568 2024-02-17 11:26:41.349033 graphql_core-3.3.0a4/tests/type/test_assert_name.py
+-rw-r--r--   0        0        0     5787 2024-02-17 11:26:41.349033 graphql_core-3.3.0a4/tests/type/test_custom_scalars.py
+-rw-r--r--   0        0        0    52811 2024-02-17 11:26:41.349033 graphql_core-3.3.0a4/tests/type/test_definition.py
+-rw-r--r--   0        0        0     7182 2024-02-17 11:26:41.349033 graphql_core-3.3.0a4/tests/type/test_directives.py
+-rw-r--r--   0        0        0    10741 2024-02-17 11:26:41.349033 graphql_core-3.3.0a4/tests/type/test_enum.py
+-rw-r--r--   0        0        0    10107 2024-02-17 11:26:41.349033 graphql_core-3.3.0a4/tests/type/test_extensions.py
+-rw-r--r--   0        0        0    61708 2024-02-17 11:26:41.349033 graphql_core-3.3.0a4/tests/type/test_introspection.py
+-rw-r--r--   0        0        0    22629 2024-02-17 11:26:41.349033 graphql_core-3.3.0a4/tests/type/test_predicate.py
+-rw-r--r--   0        0        0    29260 2024-02-17 11:26:41.349033 graphql_core-3.3.0a4/tests/type/test_scalars.py
+-rw-r--r--   0        0        0    16858 2024-02-17 11:26:41.349033 graphql_core-3.3.0a4/tests/type/test_schema.py
+-rw-r--r--   0        0        0    73471 2024-02-17 11:26:41.349033 graphql_core-3.3.0a4/tests/type/test_validation.py
+-rw-r--r--   0        0        0       34 2024-02-17 11:26:41.349033 graphql_core-3.3.0a4/tests/utilities/__init__.py
+-rw-r--r--   0        0        0     9495 2024-02-17 11:26:41.349033 graphql_core-3.3.0a4/tests/utilities/test_ast_from_value.py
+-rw-r--r--   0        0        0    27494 2024-02-17 11:26:41.349033 graphql_core-3.3.0a4/tests/utilities/test_ast_to_dict.py
+-rw-r--r--   0        0        0    36127 2024-02-17 11:26:41.349033 graphql_core-3.3.0a4/tests/utilities/test_build_ast_schema.py
+-rw-r--r--   0        0        0    35412 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/utilities/test_build_client_schema.py
+-rw-r--r--   0        0        0    13790 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/utilities/test_coerce_input_value.py
+-rw-r--r--   0        0        0      769 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/utilities/test_concat_ast.py
+-rw-r--r--   0        0        0    44171 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/utilities/test_extend_schema.py
+-rw-r--r--   0        0        0    37071 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/utilities/test_find_breaking_changes.py
+-rw-r--r--   0        0        0     3339 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/utilities/test_get_introspection_query.py
+-rw-r--r--   0        0        0     1989 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/utilities/test_get_operation_ast.py
+-rw-r--r--   0        0        0     6567 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/utilities/test_introspection_from_schema.py
+-rw-r--r--   0        0        0     7825 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/utilities/test_lexicographic_sort_schema.py
+-rw-r--r--   0        0        0    26812 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/utilities/test_print_schema.py
+-rw-r--r--   0        0        0     4839 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/utilities/test_separate_operations.py
+-rw-r--r--   0        0        0     1320 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/utilities/test_sort_value_node.py
+-rw-r--r--   0        0        0     8326 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/utilities/test_strip_ignored_characters.py
+-rw-r--r--   0        0        0     9313 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/utilities/test_strip_ignored_characters_fuzz.py
+-rw-r--r--   0        0        0     3962 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/utilities/test_type_comparators.py
+-rw-r--r--   0        0        0     1365 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/utilities/test_type_from_ast.py
+-rw-r--r--   0        0        0    20147 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/utilities/test_type_info.py
+-rw-r--r--   0        0        0    10394 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/utilities/test_value_from_ast.py
+-rw-r--r--   0        0        0     2788 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/utilities/test_value_from_ast_untyped.py
+-rw-r--r--   0        0        0      360 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/utils/__init__.py
+-rw-r--r--   0        0        0      839 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/utils/assert_equal_awaitables_or_values.py
+-rw-r--r--   0        0        0      326 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/utils/assert_matching_values.py
+-rw-r--r--   0        0        0      206 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/utils/dedent.py
+-rw-r--r--   0        0        0      377 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/utils/gen_fuzz_strings.py
+-rw-r--r--   0        0        0     1661 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/utils/test_assert_equal_awaitables_or_values.py
+-rw-r--r--   0        0        0      419 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/utils/test_assert_matching_values.py
+-rw-r--r--   0        0        0     2268 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/utils/test_dedent.py
+-rw-r--r--   0        0        0     1570 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/utils/test_gen_fuzz_strings.py
+-rw-r--r--   0        0        0      110 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/validation/__init__.py
+-rw-r--r--   0        0        0     3509 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/validation/harness.py
+-rw-r--r--   0        0        0     4824 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/validation/test_defer_stream_directive_label.py
+-rw-r--r--   0        0        0     6931 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/validation/test_defer_stream_directive_on_root_field.py
+-rw-r--r--   0        0        0     2234 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/validation/test_executable_definitions.py
+-rw-r--r--   0        0        0    12730 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/validation/test_fields_on_correct_type.py
+-rw-r--r--   0        0        0     3391 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/validation/test_fragments_on_composite_types.py
+-rw-r--r--   0        0        0     9804 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/validation/test_known_argument_names.py
+-rw-r--r--   0        0        0    14059 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/validation/test_known_directives.py
+-rw-r--r--   0        0        0     1844 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/validation/test_known_fragment_names.py
+-rw-r--r--   0        0        0    10757 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/validation/test_known_type_names.py
+-rw-r--r--   0        0        0     2602 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/validation/test_lone_anonymous_operation.py
+-rw-r--r--   0        0        0     3468 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/validation/test_lone_schema_definition.py
+-rw-r--r--   0        0        0     8895 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/validation/test_no_deprecated.py
+-rw-r--r--   0        0        0     7658 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/validation/test_no_fragment_cycles.py
+-rw-r--r--   0        0        0     3950 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/validation/test_no_schema_introspection.py
+-rw-r--r--   0        0        0    10184 2024-02-17 11:26:41.353033 graphql_core-3.3.0a4/tests/validation/test_no_undefined_variables.py
+-rw-r--r--   0        0        0     4069 2024-02-17 11:26:41.357033 graphql_core-3.3.0a4/tests/validation/test_no_unused_fragments.py
+-rw-r--r--   0        0        0     6264 2024-02-17 11:26:41.357033 graphql_core-3.3.0a4/tests/validation/test_no_unused_variables.py
+-rw-r--r--   0        0        0    38853 2024-02-17 11:26:41.357033 graphql_core-3.3.0a4/tests/validation/test_overlapping_fields_can_be_merged.py
+-rw-r--r--   0        0        0    10021 2024-02-17 11:26:41.357033 graphql_core-3.3.0a4/tests/validation/test_possible_fragment_spreads.py
+-rw-r--r--   0        0        0     8734 2024-02-17 11:26:41.357033 graphql_core-3.3.0a4/tests/validation/test_possible_type_extensions.py
+-rw-r--r--   0        0        0    10621 2024-02-17 11:26:41.357033 graphql_core-3.3.0a4/tests/validation/test_provided_required_arguments.py
+-rw-r--r--   0        0        0     4160 2024-02-17 11:26:41.357033 graphql_core-3.3.0a4/tests/validation/test_scalar_leafs.py
+-rw-r--r--   0        0        0     8227 2024-02-17 11:26:41.357033 graphql_core-3.3.0a4/tests/validation/test_single_field_subscriptions.py
+-rw-r--r--   0        0        0     2119 2024-02-17 11:26:41.357033 graphql_core-3.3.0a4/tests/validation/test_stream_directive_on_list_field.py
+-rw-r--r--   0        0        0     4193 2024-02-17 11:26:41.357033 graphql_core-3.3.0a4/tests/validation/test_unique_argument_definition_names.py
+-rw-r--r--   0        0        0     3559 2024-02-17 11:26:41.357033 graphql_core-3.3.0a4/tests/validation/test_unique_argument_names.py
+-rw-r--r--   0        0        0     2732 2024-02-17 11:26:41.357033 graphql_core-3.3.0a4/tests/validation/test_unique_directive_names.py
+-rw-r--r--   0        0        0    10908 2024-02-17 11:26:41.357033 graphql_core-3.3.0a4/tests/validation/test_unique_directives_per_location.py
+-rw-r--r--   0        0        0     4671 2024-02-17 11:26:41.357033 graphql_core-3.3.0a4/tests/validation/test_unique_enum_value_names.py
+-rw-r--r--   0        0        0    11247 2024-02-17 11:26:41.357033 graphql_core-3.3.0a4/tests/validation/test_unique_field_definition_names.py
+-rw-r--r--   0        0        0     2540 2024-02-17 11:26:41.357033 graphql_core-3.3.0a4/tests/validation/test_unique_fragment_names.py
+-rw-r--r--   0        0        0     2609 2024-02-17 11:26:41.357033 graphql_core-3.3.0a4/tests/validation/test_unique_input_field_names.py
+-rw-r--r--   0        0        0     2861 2024-02-17 11:26:41.357033 graphql_core-3.3.0a4/tests/validation/test_unique_operation_names.py
+-rw-r--r--   0        0        0     9879 2024-02-17 11:26:41.357033 graphql_core-3.3.0a4/tests/validation/test_unique_operation_types.py
+-rw-r--r--   0        0        0     4349 2024-02-17 11:26:41.357033 graphql_core-3.3.0a4/tests/validation/test_unique_type_names.py
+-rw-r--r--   0        0        0     1333 2024-02-17 11:26:41.357033 graphql_core-3.3.0a4/tests/validation/test_unique_variable_names.py
+-rw-r--r--   0        0        0     4957 2024-02-17 11:26:41.357033 graphql_core-3.3.0a4/tests/validation/test_validation.py
+-rw-r--r--   0        0        0    36134 2024-02-17 11:26:41.357033 graphql_core-3.3.0a4/tests/validation/test_values_of_correct_type.py
+-rw-r--r--   0        0        0     1513 2024-02-17 11:26:41.357033 graphql_core-3.3.0a4/tests/validation/test_variables_are_input_types.py
+-rw-r--r--   0        0        0    10190 2024-02-17 11:26:41.357033 graphql_core-3.3.0a4/tests/validation/test_variables_in_allowed_position.py
+-rw-r--r--   0        0        0     1247 2024-02-17 11:26:41.357033 graphql_core-3.3.0a4/tox.ini
+-rw-r--r--   0        0        0    11277 1970-01-01 00:00:00.000000 graphql_core-3.3.0a4/PKG-INFO
```

### Comparing `graphql_core-3.3.0a3/.bumpversion.cfg` & `graphql_core-3.3.0a4/.bumpversion.cfg`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 [bumpversion]
-current_version = 3.3.0a3
+current_version = 3.3.0a4
 commit = False
 tag = False
 
 [bumpversion:file:src/graphql/version.py]
 search = version = "{current_version}"
 replace = version = "{new_version}"
```

### Comparing `graphql_core-3.3.0a3/LICENSE` & `graphql_core-3.3.0a4/LICENSE`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/README.md` & `graphql_core-3.3.0a4/README.md`

 * *Files 2% similar despite different names*

```diff
@@ -11,17 +11,17 @@
 [![Code Style](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/ambv/black)
 
 An extensive test suite with over 2300 unit tests and 100% coverage comprises a
 replication of the complete test suite of GraphQL.js, making sure this port is
 reliable and compatible with GraphQL.js.
 
 The current stable version 3.2.3 of GraphQL-core is up-to-date with GraphQL.js
-version 16.6.0 and supports Python version 3.6 and newer.
+version 16.6.0 and supports Python version 3.7 and newer.
 
-You can also try out the latest alpha version 3.3.0a3 of GraphQL-core
+You can also try out the latest alpha version 3.3.0a4 of GraphQL-core
 which is up-to-date with GraphQL.js version 17.0.0a2.
 Please note that this new minor version of GraphQL-core does not support
 Python 3.6 anymore.
 
 Note that for various reasons, GraphQL-core does not use SemVer like GraphQL.js.
 Changes in the major version of GraphQL.js are reflected in the minor version of
 GraphQL-core instead. This means there can be breaking changes in the API
@@ -192,21 +192,22 @@
   Python versions
 * to be very close to the GraphQL.js reference implementation, while still providing
   a Pythonic API and code style
 * to make extensive use of Python type hints, similar to how GraphQL.js used Flow
   (and is now using TypeScript)
 * to use [black](https://github.com/ambv/black) to achieve a consistent code style
   while saving time and mental energy for more important matters
+  (we are now using [ruff](https://github.com/astral-sh/ruff) instead)
 * to replicate the complete Mocha-based test suite of GraphQL.js
   using [pytest](https://docs.pytest.org/)
   with [pytest-describe](https://pypi.org/project/pytest-describe/)
 
 Some restrictions (mostly in line with the design goals):
 
-* requires Python 3.6 or newer
+* requires Python 3.6 or newer (Python 3.7 and newer in latest version)
 * does not support some already deprecated methods and options of GraphQL.js
 * supports asynchronous operations only via async.io
   (does not support the additional executors in GraphQL-core)
 
 
 ## Integration with other libraries and roadmap
```

### Comparing `graphql_core-3.3.0a3/SECURITY.md` & `graphql_core-3.3.0a4/SECURITY.md`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/docs/Makefile` & `graphql_core-3.3.0a4/docs/Makefile`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/docs/conf.py` & `graphql_core-3.3.0a4/docs/conf.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-# -*- coding: utf-8 -*-
 #
 # GraphQL-core 3 documentation build configuration file, created by
 # sphinx-quickstart on Thu Jun 21 16:28:30 2018.
 #
 # This file is execfile()d with the current directory set to its
 # containing dir.
 #
@@ -26,117 +25,125 @@
 #
 # needs_sphinx = '1.0'
 
 # Add any Sphinx extension module names here, as strings. They can be
 # extensions coming with Sphinx (named 'sphinx.ext.*') or your custom
 # ones.
 extensions = [
-    'sphinx.ext.autodoc',
+    "sphinx.ext.autodoc",
 ]
 
 # Add any paths that contain templates here, relative to this directory.
-templates_path = ['_templates']
+templates_path = ["_templates"]
 
 # The suffix(es) of source filenames.
 # You can specify multiple suffix as a list of string:
 #
 # source_suffix = ['.rst', '.md']
-source_suffix = '.rst'
+source_suffix = ".rst"
 
 # The encoding of source files.
 #
 # source_encoding = 'utf-8-sig'
 
 # The master toctree document.
-master_doc = 'index'
+master_doc = "index"
 
 # General information about the project.
-project = 'GraphQL-core 3'
-copyright = '2023, Christoph Zwerschke'
-author = 'Christoph Zwerschke'
+project = "GraphQL-core 3"
+copyright = "2024, Christoph Zwerschke"
+author = "Christoph Zwerschke"
 
 # The version info for the project you're documenting, acts as replacement for
 # |version| and |release|, also used in various other places throughout the
 # built documents.
 #
 # The short X.Y version.
 # version = '3.3'
 # The full version, including alpha/beta/rc tags.
-version = release = '3.3.0a3'
+version = release = "3.3.0a4"
 
 # The language for content autogenerated by Sphinx. Refer to documentation
 # for a list of supported languages.
 #
 # This is also used if you do content translation via gettext catalogs.
 # Usually you set "language" from the command line for these cases.
-language = 'en'
+language = "en"
 
 # There are two options for replacing |today|: either, you set today to some
 # non-false value, then it is used:
 #
 # today = ''
 #
 # Else, today_fmt is used as the format for a strftime call.
 #
 # today_fmt = '%B %d, %Y'
 
 # List of patterns, relative to source directory, that match files and
 # directories to ignore when looking for source files.
 # This patterns also effect to html_static_path and html_extra_path
-exclude_patterns = ['_build', 'Thumbs.db', '.DS_Store']
+exclude_patterns = ["_build", "Thumbs.db", ".DS_Store"]
 
 # AutoDoc configuration
 autoclass_content = "class"
 autodoc_default_options = {
-    'members': True,
-    'inherited-members': True,
-    'undoc-members': True,
-    'show-inheritance': True
+    "members": True,
+    "inherited-members": True,
+    "undoc-members": True,
+    "show-inheritance": True,
 }
 autosummary_generate = True
 
 autodoc_type_aliases = {
-    'AwaitableOrValue': 'graphql.pyutils.AwaitableOrValue',
-    'FormattedSourceLocation': 'graphql.language.FormattedSourceLocation',
-    'Middleware': 'graphql.execution.Middleware',
-    'TypeMap': 'graphql.schema.TypeMap'
+    "AwaitableOrValue": "graphql.pyutils.AwaitableOrValue",
+    "FormattedSourceLocation": "graphql.language.FormattedSourceLocation",
+    "Middleware": "graphql.execution.Middleware",
+    "TypeMap": "graphql.schema.TypeMap",
 }
 
 # GraphQL-core top level modules with submodules that can be omitted.
 # Sometimes autodoc cannot find classes since it is looking for the
 # qualified form, but the documentation has the shorter form.
 # We need to give autodoc a little help in this cases.
 graphql_modules = {
-    'error': ['graphql_error'],
-    'execution': ['execute', 'middleware'],
-    'language': ['ast', 'directive_locations', 'location',
-                 'source', 'token_kind', 'visitor'],
-    'pyutils': ['simple_pub_sub', 'frozen_list', 'path'],
-    'type': ['definition', 'directives', 'schema'],
-    'utilities': ['find_breaking_changes', 'type_info'],
-    'validation': ['rules', 'validation_context']}
+    "error": ["graphql_error"],
+    "execution": ["execute", "middleware"],
+    "language": [
+        "ast",
+        "directive_locations",
+        "location",
+        "source",
+        "token_kind",
+        "visitor",
+    ],
+    "pyutils": ["simple_pub_sub", "frozen_list", "path"],
+    "type": ["definition", "directives", "schema"],
+    "utilities": ["find_breaking_changes", "type_info"],
+    "validation": ["rules", "validation_context"],
+}
 
 # GraphQL-core classes that autodoc sometimes cannot find
 # (e.g. where specified as string in type hints).
 # We need to give autodoc a little help in this cases, too:
 graphql_classes = {
-    'GraphQLAbstractType': 'type',
-    'GraphQLFieldResolver': 'type',
-    'GraphQLObjectType': 'type',
-    'GraphQLOutputType': 'type',
-    'GraphQLTypeResolver': 'type',
-    'AwaitableOrValue': 'execution',
-    'Middleware': 'execution',
-    'Node': 'language',
-    'Source': 'language',
-    'SourceLocation': 'language'
+    "GraphQLAbstractType": "type",
+    "GraphQLFieldResolver": "type",
+    "GraphQLObjectType": "type",
+    "GraphQLOutputType": "type",
+    "GraphQLTypeResolver": "type",
+    "AwaitableOrValue": "execution",
+    "Middleware": "execution",
+    "Node": "language",
+    "Source": "language",
+    "SourceLocation": "language",
 }
 
 # ignore the following undocumented or internal references:
-ignore_references = set('''
+ignore_references = set(
+    """
 GNT GT KT T VT
 enum.Enum
 traceback
 types.TracebackType
 TypeMap
 AsyncPayloadRecord
 AwaitableOrValue
@@ -159,93 +166,95 @@
 graphql.execution.execute.StreamRecord
 graphql.language.lexer.EscapeSequence
 graphql.language.visitor.EnterLeaveVisitor
 graphql.type.schema.InterfaceImplementations
 graphql.validation.validation_context.VariableUsage
 graphql.validation.rules.known_argument_names.KnownArgumentNamesOnDirectivesRule
 graphql.validation.rules.provided_required_arguments.ProvidedRequiredArgumentsOnDirectivesRule
-'''.split())
+""".split()
+)
 
 ignore_references.update(__builtins__.keys())
 
 
 def on_missing_reference(app, env, node, contnode):
     """Fix or skip any missing references."""
-    if node.get('refdomain') != 'py':
+    if node.get("refdomain") != "py":
         return None
-    target = node.get('reftarget')
+    target = node.get("reftarget")
     if not target:
         return None
-    if target in ignore_references or target.endswith('Kwargs'):
+    if target in ignore_references or target.endswith("Kwargs"):
         return contnode
-    typ = node.get('reftype')
-    name = target.rsplit('.', 1)[-1]
-    if name in ('GT', 'GNT', 'KT', 'T', 'VT'):
+    typ = node.get("reftype")
+    name = target.rsplit(".", 1)[-1]
+    if name in ("GT", "GNT", "KT", "T", "VT"):
         return contnode
-    if typ == 'obj':
-        if target.startswith('typing.'):
-            if name in ('Any', 'Optional', 'Union'):
+    if typ == "obj":
+        if target.startswith("typing."):
+            if name in ("Any", "Optional", "Union"):
                 return contnode
-    if typ != 'class':
+    if typ != "class":
         return None
-    if '.' in target:  # maybe too specific
-        base_module, target = target.split('.', 1)
-        if base_module == 'graphql':
-            if '.' not in target:
+    if "." in target:  # maybe too specific
+        base_module, target = target.split(".", 1)
+        if base_module == "graphql":
+            if "." not in target:
                 return None
-            base_module, target = target.split('.', 1)
-        if '.' not in target:
+            base_module, target = target.split(".", 1)
+        if "." not in target:
             return None
         sub_modules = graphql_modules.get(base_module)
         if not sub_modules:
-            return
-        sub_module = target.split('.', 1)[0]
+            return None
+        sub_module = target.split(".", 1)[0]
         if sub_module not in sub_modules:
             return None
-        target = 'graphql.' + base_module + '.' + target.rsplit('.', 1)[-1]
+        target = "graphql." + base_module + "." + target.rsplit(".", 1)[-1]
     else:  # maybe not specific enough
         base_module = graphql_classes.get(target)
         if not base_module:
             return None
-        target = 'graphql.' + base_module + '.' + target
+        target = "graphql." + base_module + "." + target
     # replace target
-    if contnode.__class__.__name__ == 'Text':
+    if contnode.__class__.__name__ == "Text":
         contnode = contnode.__class__(target)
-    elif contnode.__class__.__name__ == 'literal':
+    elif contnode.__class__.__name__ == "literal":
         if len(contnode.children) != 1:
             return None
         textnode = contnode.children[0]
         contnode.children[0] = textnode.__class__(target)
     else:
         return None
-    node['reftarget'] = target
-    fromdoc = node.get('refdoc')
+    node["reftarget"] = target
+    fromdoc = node.get("refdoc")
     if not fromdoc:
-        doc_module = node.get('py:module')
+        doc_module = node.get("py:module")
         if doc_module:
-            if doc_module.startswith('graphql.'):
-                doc_module = doc_module.split('.', 1)[-1]
-            if doc_module not in graphql_modules and doc_module != 'graphql':
+            if doc_module.startswith("graphql."):
+                doc_module = doc_module.split(".", 1)[-1]
+            if doc_module not in graphql_modules and doc_module != "graphql":
                 doc_module = None
-        fromdoc = 'modules/' + (doc_module or base_module)
+        fromdoc = "modules/" + (doc_module or base_module)
     # try resolving again with replaced target
-    return env.domains['py'].resolve_xref(
-        env, fromdoc, app.builder, typ, target, node, contnode)
+    return env.domains["py"].resolve_xref(
+        env, fromdoc, app.builder, typ, target, node, contnode
+    )
 
 
 def on_skip_member(_app, what, name, _obj, skip, _options):
-    if what == 'class' and name == "__init__":
+    if what == "class" and name == "__init__":
         # we could set "special-members" to "__init__",
         # but this gives an error when documenting modules
         return False
     return skip
 
 
 def setup(app):
-    app.connect('missing-reference', on_missing_reference)
+    app.connect("missing-reference", on_missing_reference)
     app.connect("autodoc-skip-member", on_skip_member)
 
 
 # be nitpicky (handle all possible problems in on_missing_reference)
 nitpicky = True
 
 
@@ -265,15 +274,15 @@
 
 # If true, sectionauthor and moduleauthor directives will be shown in the
 # output. They are ignored by default.
 #
 # show_authors = False
 
 # The name of the Pygments (syntax highlighting) style to use.
-pygments_style = 'sphinx'
+pygments_style = "sphinx"
 
 # A list of ignored prefixes for module index sorting.
 # modindex_common_prefix = []
 
 # If true, keep warnings as "system message" paragraphs in the built documents.
 # keep_warnings = False
 
@@ -281,23 +290,21 @@
 todo_include_todos = False
 
 # -- Options for HTML output ----------------------------------------------
 
 # The theme to use for HTML and HTML Help pages.  See the documentation for
 # a list of builtin themes.
 #
-html_theme = 'sphinx_rtd_theme'
+html_theme = "sphinx_rtd_theme"
 
 # Theme options are theme-specific and customize the look and feel of a theme
 # further.  For a list of options available for each theme, see the
 # documentation.
 #
-html_theme_options = {
-    'navigation_depth': 5
-}
+html_theme_options = {"navigation_depth": 5}
 
 # Add any paths that contain custom themes here, relative to this directory.
 # html_theme_path = []
 
 # The name for this set of Sphinx documents.
 # "<project> v<release> documentation" by default.
 #
@@ -397,42 +404,44 @@
 
 # The name of a javascript file (relative to the configuration directory) that
 # implements a search results scorer. If empty, the default will be used.
 #
 # html_search_scorer = 'scorer.js'
 
 # Output file base name for HTML help builder.
-htmlhelp_basename = 'GraphQL-core-3-doc'
+htmlhelp_basename = "GraphQL-core-3-doc"
 
 # -- Options for LaTeX output ---------------------------------------------
 
 latex_elements = {
-     # The paper size ('letterpaper' or 'a4paper').
-     #
-     # 'papersize': 'letterpaper',
-
-     # The font size ('10pt', '11pt' or '12pt').
-     #
-     # 'pointsize': '10pt',
-
-     # Additional stuff for the LaTeX preamble.
-     #
-     # 'preamble': '',
-
-     # Latex figure (float) alignment
-     #
-     # 'figure_align': 'htbp',
+    # The paper size ('letterpaper' or 'a4paper').
+    #
+    # 'papersize': 'letterpaper',
+    # The font size ('10pt', '11pt' or '12pt').
+    #
+    # 'pointsize': '10pt',
+    # Additional stuff for the LaTeX preamble.
+    #
+    # 'preamble': '',
+    # Latex figure (float) alignment
+    #
+    # 'figure_align': 'htbp',
 }
 
 # Grouping the document tree into LaTeX files. List of tuples
 # (source start file, target name, title,
 #  author, documentclass [howto, manual, or own class]).
 latex_documents = [
-    (master_doc, 'GraphQL-core-3.tex', 'GraphQL-core 3 Documentation',
-     'Christoph Zwerschke', 'manual'),
+    (
+        master_doc,
+        "GraphQL-core-3.tex",
+        "GraphQL-core 3 Documentation",
+        "Christoph Zwerschke",
+        "manual",
+    ),
 ]
 
 # The name of an image file (relative to this directory) to place at the top of
 # the title page.
 #
 # latex_logo = None
 
@@ -458,33 +467,36 @@
 # latex_domain_indices = True
 
 
 # -- Options for manual page output ---------------------------------------
 
 # One entry per manual page. List of tuples
 # (source start file, name, description, authors, manual section).
-man_pages = [
-    (master_doc, 'graphql-core', 'GraphQL-core 3 Documentation',
-     [author], 1)
-]
+man_pages = [(master_doc, "graphql-core", "GraphQL-core 3 Documentation", [author], 1)]
 
 # If true, show URL addresses after external links.
 #
 # man_show_urls = False
 
 
 # -- Options for Texinfo output -------------------------------------------
 
 # Grouping the document tree into Texinfo files. List of tuples
 # (source start file, target name, title, author,
 #  dir menu entry, description, category)
 texinfo_documents = [
-    (master_doc, 'GraphQL-core', 'GraphQL-core 3 Documentation',
-     author, 'GraphQL-core 3', 'One line description of project.',
-     'Miscellaneous'),
+    (
+        master_doc,
+        "GraphQL-core",
+        "GraphQL-core 3 Documentation",
+        author,
+        "GraphQL-core 3",
+        "One line description of project.",
+        "Miscellaneous",
+    ),
 ]
 
 # Documents to append as an appendix to all manuals.
 #
 # texinfo_appendices = []
 
 # If false, no module index is generated.
```

### Comparing `graphql_core-3.3.0a3/docs/diffs.rst` & `graphql_core-3.3.0a4/docs/diffs.rst`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/docs/intro.rst` & `graphql_core-3.3.0a4/docs/intro.rst`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/docs/make.bat` & `graphql_core-3.3.0a4/docs/make.bat`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/docs/modules/execution.rst` & `graphql_core-3.3.0a4/docs/modules/execution.rst`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/docs/modules/language.rst` & `graphql_core-3.3.0a4/docs/modules/language.rst`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/docs/modules/pyutils.rst` & `graphql_core-3.3.0a4/docs/modules/pyutils.rst`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/docs/modules/type.rst` & `graphql_core-3.3.0a4/docs/modules/type.rst`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/docs/modules/utilities.rst` & `graphql_core-3.3.0a4/docs/modules/utilities.rst`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/docs/modules/validation.rst` & `graphql_core-3.3.0a4/docs/modules/validation.rst`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/docs/usage/extension.rst` & `graphql_core-3.3.0a4/docs/usage/extension.rst`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/docs/usage/introspection.rst` & `graphql_core-3.3.0a4/docs/usage/introspection.rst`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/docs/usage/methods.rst` & `graphql_core-3.3.0a4/docs/usage/methods.rst`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/docs/usage/other.rst` & `graphql_core-3.3.0a4/docs/usage/other.rst`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/docs/usage/parser.rst` & `graphql_core-3.3.0a4/docs/usage/parser.rst`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/docs/usage/queries.rst` & `graphql_core-3.3.0a4/docs/usage/queries.rst`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/docs/usage/resolvers.rst` & `graphql_core-3.3.0a4/docs/usage/resolvers.rst`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/docs/usage/schema.rst` & `graphql_core-3.3.0a4/docs/usage/schema.rst`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/docs/usage/sdl.rst` & `graphql_core-3.3.0a4/docs/usage/sdl.rst`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/docs/usage/validator.rst` & `graphql_core-3.3.0a4/docs/usage/validator.rst`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/poetry.lock` & `graphql_core-3.3.0a4/poetry.lock`

 * *Files 6% similar despite different names*

```diff
@@ -1,282 +1,180 @@
-# This file is automatically @generated by Poetry 1.5.0 and should not be changed by hand.
+# This file is automatically @generated by Poetry 1.7.1 and should not be changed by hand.
 
 [[package]]
 name = "alabaster"
 version = "0.7.13"
 description = "A configurable sidebar-enabled Sphinx theme"
 optional = false
 python-versions = ">=3.6"
 files = [
     {file = "alabaster-0.7.13-py3-none-any.whl", hash = "sha256:1ee19aca801bbabb5ba3f5f258e4422dfa86f82f3e9cefb0859b283cdd7f62a3"},
     {file = "alabaster-0.7.13.tar.gz", hash = "sha256:a27a4a084d5e690e16e01e03ad2b2e552c61a65469419b907243193de1a84ae2"},
 ]
 
 [[package]]
-name = "appdirs"
-version = "1.4.4"
-description = "A small Python module for determining appropriate platform-specific dirs, e.g. a \"user data dir\"."
-optional = false
-python-versions = "*"
-files = [
-    {file = "appdirs-1.4.4-py2.py3-none-any.whl", hash = "sha256:a841dacd6b99318a741b166adb07e19ee71a274450e68237b4650ca1055ab128"},
-    {file = "appdirs-1.4.4.tar.gz", hash = "sha256:7d5d0167b2b1ba821647616af46a749d1c653740dd0d2415100fe26e27afdf41"},
-]
-
-[[package]]
-name = "attrs"
-version = "23.1.0"
-description = "Classes Without Boilerplate"
-optional = false
-python-versions = ">=3.7"
-files = [
-    {file = "attrs-23.1.0-py3-none-any.whl", hash = "sha256:1f28b4522cdc2fb4256ac1a020c78acf9cba2c6b461ccd2c126f3aa8e8335d04"},
-    {file = "attrs-23.1.0.tar.gz", hash = "sha256:6279836d581513a26f1bf235f9acd333bc9115683f14f7e8fae46c98fc50e015"},
-]
-
-[package.dependencies]
-importlib-metadata = {version = "*", markers = "python_version < \"3.8\""}
-
-[package.extras]
-cov = ["attrs[tests]", "coverage[toml] (>=5.3)"]
-dev = ["attrs[docs,tests]", "pre-commit"]
-docs = ["furo", "myst-parser", "sphinx", "sphinx-notfound-page", "sphinxcontrib-towncrier", "towncrier", "zope-interface"]
-tests = ["attrs[tests-no-zope]", "zope-interface"]
-tests-no-zope = ["cloudpickle", "hypothesis", "mypy (>=1.1.1)", "pympler", "pytest (>=4.3.0)", "pytest-mypy-plugins", "pytest-xdist[psutil]"]
-
-[[package]]
 name = "babel"
-version = "2.12.1"
+version = "2.14.0"
 description = "Internationalization utilities"
 optional = false
 python-versions = ">=3.7"
 files = [
-    {file = "Babel-2.12.1-py3-none-any.whl", hash = "sha256:b4246fb7677d3b98f501a39d43396d3cafdc8eadb045f4a31be01863f655c610"},
-    {file = "Babel-2.12.1.tar.gz", hash = "sha256:cc2d99999cd01d44420ae725a21c9e3711b3aadc7976d6147f622d8581963455"},
+    {file = "Babel-2.14.0-py3-none-any.whl", hash = "sha256:efb1a25b7118e67ce3a259bed20545c29cb68be8ad2c784c83689981b7a57287"},
+    {file = "Babel-2.14.0.tar.gz", hash = "sha256:6919867db036398ba21eb5c7a0f6b28ab8cbc3ae7a73a44ebe34ae74a4e7d363"},
 ]
 
 [package.dependencies]
 pytz = {version = ">=2015.7", markers = "python_version < \"3.9\""}
 
-[[package]]
-name = "bandit"
-version = "1.7.5"
-description = "Security oriented static analyser for python code."
-optional = false
-python-versions = ">=3.7"
-files = [
-    {file = "bandit-1.7.5-py3-none-any.whl", hash = "sha256:75665181dc1e0096369112541a056c59d1c5f66f9bb74a8d686c3c362b83f549"},
-    {file = "bandit-1.7.5.tar.gz", hash = "sha256:bdfc739baa03b880c2d15d0431b31c658ffc348e907fe197e54e0389dd59e11e"},
-]
-
-[package.dependencies]
-colorama = {version = ">=0.3.9", markers = "platform_system == \"Windows\""}
-GitPython = ">=1.0.1"
-PyYAML = ">=5.3.1"
-rich = "*"
-stevedore = ">=1.20.0"
-
-[package.extras]
-test = ["beautifulsoup4 (>=4.8.0)", "coverage (>=4.5.4)", "fixtures (>=3.0.0)", "flake8 (>=4.0.0)", "pylint (==1.9.4)", "stestr (>=2.5.0)", "testscenarios (>=0.5.0)", "testtools (>=2.3.0)", "tomli (>=1.1.0)"]
-toml = ["tomli (>=1.1.0)"]
-yaml = ["PyYAML"]
-
-[[package]]
-name = "black"
-version = "23.3.0"
-description = "The uncompromising code formatter."
-optional = false
-python-versions = ">=3.7"
-files = [
-    {file = "black-23.3.0-cp310-cp310-macosx_10_16_arm64.whl", hash = "sha256:0945e13506be58bf7db93ee5853243eb368ace1c08a24c65ce108986eac65915"},
-    {file = "black-23.3.0-cp310-cp310-macosx_10_16_universal2.whl", hash = "sha256:67de8d0c209eb5b330cce2469503de11bca4085880d62f1628bd9972cc3366b9"},
-    {file = "black-23.3.0-cp310-cp310-macosx_10_16_x86_64.whl", hash = "sha256:7c3eb7cea23904399866c55826b31c1f55bbcd3890ce22ff70466b907b6775c2"},
-    {file = "black-23.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:32daa9783106c28815d05b724238e30718f34155653d4d6e125dc7daec8e260c"},
-    {file = "black-23.3.0-cp310-cp310-win_amd64.whl", hash = "sha256:35d1381d7a22cc5b2be2f72c7dfdae4072a3336060635718cc7e1ede24221d6c"},
-    {file = "black-23.3.0-cp311-cp311-macosx_10_16_arm64.whl", hash = "sha256:a8a968125d0a6a404842fa1bf0b349a568634f856aa08ffaff40ae0dfa52e7c6"},
-    {file = "black-23.3.0-cp311-cp311-macosx_10_16_universal2.whl", hash = "sha256:c7ab5790333c448903c4b721b59c0d80b11fe5e9803d8703e84dcb8da56fec1b"},
-    {file = "black-23.3.0-cp311-cp311-macosx_10_16_x86_64.whl", hash = "sha256:a6f6886c9869d4daae2d1715ce34a19bbc4b95006d20ed785ca00fa03cba312d"},
-    {file = "black-23.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:6f3c333ea1dd6771b2d3777482429864f8e258899f6ff05826c3a4fcc5ce3f70"},
-    {file = "black-23.3.0-cp311-cp311-win_amd64.whl", hash = "sha256:11c410f71b876f961d1de77b9699ad19f939094c3a677323f43d7a29855fe326"},
-    {file = "black-23.3.0-cp37-cp37m-macosx_10_16_x86_64.whl", hash = "sha256:1d06691f1eb8de91cd1b322f21e3bfc9efe0c7ca1f0e1eb1db44ea367dff656b"},
-    {file = "black-23.3.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:50cb33cac881766a5cd9913e10ff75b1e8eb71babf4c7104f2e9c52da1fb7de2"},
-    {file = "black-23.3.0-cp37-cp37m-win_amd64.whl", hash = "sha256:e114420bf26b90d4b9daa597351337762b63039752bdf72bf361364c1aa05925"},
-    {file = "black-23.3.0-cp38-cp38-macosx_10_16_arm64.whl", hash = "sha256:48f9d345675bb7fbc3dd85821b12487e1b9a75242028adad0333ce36ed2a6d27"},
-    {file = "black-23.3.0-cp38-cp38-macosx_10_16_universal2.whl", hash = "sha256:714290490c18fb0126baa0fca0a54ee795f7502b44177e1ce7624ba1c00f2331"},
-    {file = "black-23.3.0-cp38-cp38-macosx_10_16_x86_64.whl", hash = "sha256:064101748afa12ad2291c2b91c960be28b817c0c7eaa35bec09cc63aa56493c5"},
-    {file = "black-23.3.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:562bd3a70495facf56814293149e51aa1be9931567474993c7942ff7d3533961"},
-    {file = "black-23.3.0-cp38-cp38-win_amd64.whl", hash = "sha256:e198cf27888ad6f4ff331ca1c48ffc038848ea9f031a3b40ba36aced7e22f2c8"},
-    {file = "black-23.3.0-cp39-cp39-macosx_10_16_arm64.whl", hash = "sha256:3238f2aacf827d18d26db07524e44741233ae09a584273aa059066d644ca7b30"},
-    {file = "black-23.3.0-cp39-cp39-macosx_10_16_universal2.whl", hash = "sha256:f0bd2f4a58d6666500542b26354978218a9babcdc972722f4bf90779524515f3"},
-    {file = "black-23.3.0-cp39-cp39-macosx_10_16_x86_64.whl", hash = "sha256:92c543f6854c28a3c7f39f4d9b7694f9a6eb9d3c5e2ece488c327b6e7ea9b266"},
-    {file = "black-23.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:3a150542a204124ed00683f0db1f5cf1c2aaaa9cc3495b7a3b5976fb136090ab"},
-    {file = "black-23.3.0-cp39-cp39-win_amd64.whl", hash = "sha256:6b39abdfb402002b8a7d030ccc85cf5afff64ee90fa4c5aebc531e3ad0175ddb"},
-    {file = "black-23.3.0-py3-none-any.whl", hash = "sha256:ec751418022185b0c1bb7d7736e6933d40bbb14c14a0abcf9123d1b159f98dd4"},
-    {file = "black-23.3.0.tar.gz", hash = "sha256:1c7b8d606e728a41ea1ccbd7264677e494e87cf630e399262ced92d4a8dac940"},
-]
-
-[package.dependencies]
-click = ">=8.0.0"
-mypy-extensions = ">=0.4.3"
-packaging = ">=22.0"
-pathspec = ">=0.9.0"
-platformdirs = ">=2"
-tomli = {version = ">=1.1.0", markers = "python_version < \"3.11\""}
-typed-ast = {version = ">=1.4.2", markers = "python_version < \"3.8\" and implementation_name == \"cpython\""}
-typing-extensions = {version = ">=3.10.0.0", markers = "python_version < \"3.10\""}
-
 [package.extras]
-colorama = ["colorama (>=0.4.3)"]
-d = ["aiohttp (>=3.7.4)"]
-jupyter = ["ipython (>=7.8.0)", "tokenize-rt (>=3.2.0)"]
-uvloop = ["uvloop (>=0.15.2)"]
+dev = ["freezegun (>=1.0,<2.0)", "pytest (>=6.0)", "pytest-cov"]
 
 [[package]]
 name = "bump2version"
 version = "1.0.1"
 description = "Version-bump your software with a single command!"
 optional = false
 python-versions = ">=3.5"
 files = [
     {file = "bump2version-1.0.1-py2.py3-none-any.whl", hash = "sha256:37f927ea17cde7ae2d7baf832f8e80ce3777624554a653006c9144f8017fe410"},
     {file = "bump2version-1.0.1.tar.gz", hash = "sha256:762cb2bfad61f4ec8e2bdf452c7c267416f8c70dd9ecb1653fd0bbb01fa936e6"},
 ]
 
 [[package]]
 name = "cachetools"
-version = "5.3.1"
+version = "5.3.2"
 description = "Extensible memoizing collections and decorators"
 optional = false
 python-versions = ">=3.7"
 files = [
-    {file = "cachetools-5.3.1-py3-none-any.whl", hash = "sha256:95ef631eeaea14ba2e36f06437f36463aac3a096799e876ee55e5cdccb102590"},
-    {file = "cachetools-5.3.1.tar.gz", hash = "sha256:dce83f2d9b4e1f732a8cd44af8e8fab2dbe46201467fc98b3ef8f269092bf62b"},
+    {file = "cachetools-5.3.2-py3-none-any.whl", hash = "sha256:861f35a13a451f94e301ce2bec7cac63e881232ccce7ed67fab9b5df4d3beaa1"},
+    {file = "cachetools-5.3.2.tar.gz", hash = "sha256:086ee420196f7b2ab9ca2db2520aca326318b68fe5ba8bc4d49cca91add450f2"},
 ]
 
 [[package]]
 name = "certifi"
-version = "2023.5.7"
+version = "2024.2.2"
 description = "Python package for providing Mozilla's CA Bundle."
 optional = false
 python-versions = ">=3.6"
 files = [
-    {file = "certifi-2023.5.7-py3-none-any.whl", hash = "sha256:c6c2e98f5c7869efca1f8916fed228dd91539f9f1b444c314c06eef02980c716"},
-    {file = "certifi-2023.5.7.tar.gz", hash = "sha256:0f0d56dc5a6ad56fd4ba36484d6cc34451e1c6548c61daad8c320169f91eddc7"},
+    {file = "certifi-2024.2.2-py3-none-any.whl", hash = "sha256:dc383c07b76109f368f6106eee2b593b04a011ea4d55f652c6ca24a754d1cdd1"},
+    {file = "certifi-2024.2.2.tar.gz", hash = "sha256:0569859f95fc761b18b45ef421b1290a0f65f147e92a1e5eb3e635f9a5e4e66f"},
 ]
 
 [[package]]
 name = "chardet"
-version = "5.1.0"
+version = "5.2.0"
 description = "Universal encoding detector for Python 3"
 optional = false
 python-versions = ">=3.7"
 files = [
-    {file = "chardet-5.1.0-py3-none-any.whl", hash = "sha256:362777fb014af596ad31334fde1e8c327dfdb076e1960d1694662d46a6917ab9"},
-    {file = "chardet-5.1.0.tar.gz", hash = "sha256:0d62712b956bc154f85fb0a266e2a3c5913c2967e00348701b32411d6def31e5"},
+    {file = "chardet-5.2.0-py3-none-any.whl", hash = "sha256:e1cf59446890a00105fe7b7912492ea04b6e6f06d4b742b2c788469e34c82970"},
+    {file = "chardet-5.2.0.tar.gz", hash = "sha256:1b3b6ff479a8c414bc3fa2c0852995695c4a026dcd6d0633b2dd092ca39c1cf7"},
 ]
 
 [[package]]
 name = "charset-normalizer"
-version = "3.1.0"
+version = "3.3.2"
 description = "The Real First Universal Charset Detector. Open, modern and actively maintained alternative to Chardet."
 optional = false
 python-versions = ">=3.7.0"
 files = [
-    {file = "charset-normalizer-3.1.0.tar.gz", hash = "sha256:34e0a2f9c370eb95597aae63bf85eb5e96826d81e3dcf88b8886012906f509b5"},
-    {file = "charset_normalizer-3.1.0-cp310-cp310-macosx_10_9_universal2.whl", hash = "sha256:e0ac8959c929593fee38da1c2b64ee9778733cdf03c482c9ff1d508b6b593b2b"},
-    {file = "charset_normalizer-3.1.0-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:d7fc3fca01da18fbabe4625d64bb612b533533ed10045a2ac3dd194bfa656b60"},
-    {file = "charset_normalizer-3.1.0-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:04eefcee095f58eaabe6dc3cc2262f3bcd776d2c67005880894f447b3f2cb9c1"},
-    {file = "charset_normalizer-3.1.0-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:20064ead0717cf9a73a6d1e779b23d149b53daf971169289ed2ed43a71e8d3b0"},
-    {file = "charset_normalizer-3.1.0-cp310-cp310-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:1435ae15108b1cb6fffbcea2af3d468683b7afed0169ad718451f8db5d1aff6f"},
-    {file = "charset_normalizer-3.1.0-cp310-cp310-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:c84132a54c750fda57729d1e2599bb598f5fa0344085dbde5003ba429a4798c0"},
-    {file = "charset_normalizer-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:75f2568b4189dda1c567339b48cba4ac7384accb9c2a7ed655cd86b04055c795"},
-    {file = "charset_normalizer-3.1.0-cp310-cp310-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:11d3bcb7be35e7b1bba2c23beedac81ee893ac9871d0ba79effc7fc01167db6c"},
-    {file = "charset_normalizer-3.1.0-cp310-cp310-musllinux_1_1_aarch64.whl", hash = "sha256:891cf9b48776b5c61c700b55a598621fdb7b1e301a550365571e9624f270c203"},
-    {file = "charset_normalizer-3.1.0-cp310-cp310-musllinux_1_1_i686.whl", hash = "sha256:5f008525e02908b20e04707a4f704cd286d94718f48bb33edddc7d7b584dddc1"},
-    {file = "charset_normalizer-3.1.0-cp310-cp310-musllinux_1_1_ppc64le.whl", hash = "sha256:b06f0d3bf045158d2fb8837c5785fe9ff9b8c93358be64461a1089f5da983137"},
-    {file = "charset_normalizer-3.1.0-cp310-cp310-musllinux_1_1_s390x.whl", hash = "sha256:49919f8400b5e49e961f320c735388ee686a62327e773fa5b3ce6721f7e785ce"},
-    {file = "charset_normalizer-3.1.0-cp310-cp310-musllinux_1_1_x86_64.whl", hash = "sha256:22908891a380d50738e1f978667536f6c6b526a2064156203d418f4856d6e86a"},
-    {file = "charset_normalizer-3.1.0-cp310-cp310-win32.whl", hash = "sha256:12d1a39aa6b8c6f6248bb54550efcc1c38ce0d8096a146638fd4738e42284448"},
-    {file = "charset_normalizer-3.1.0-cp310-cp310-win_amd64.whl", hash = "sha256:65ed923f84a6844de5fd29726b888e58c62820e0769b76565480e1fdc3d062f8"},
-    {file = "charset_normalizer-3.1.0-cp311-cp311-macosx_10_9_universal2.whl", hash = "sha256:9a3267620866c9d17b959a84dd0bd2d45719b817245e49371ead79ed4f710d19"},
-    {file = "charset_normalizer-3.1.0-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:6734e606355834f13445b6adc38b53c0fd45f1a56a9ba06c2058f86893ae8017"},
-    {file = "charset_normalizer-3.1.0-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:f8303414c7b03f794347ad062c0516cee0e15f7a612abd0ce1e25caf6ceb47df"},
-    {file = "charset_normalizer-3.1.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:aaf53a6cebad0eae578f062c7d462155eada9c172bd8c4d250b8c1d8eb7f916a"},
-    {file = "charset_normalizer-3.1.0-cp311-cp311-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:3dc5b6a8ecfdc5748a7e429782598e4f17ef378e3e272eeb1340ea57c9109f41"},
-    {file = "charset_normalizer-3.1.0-cp311-cp311-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:e1b25e3ad6c909f398df8921780d6a3d120d8c09466720226fc621605b6f92b1"},
-    {file = "charset_normalizer-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:0ca564606d2caafb0abe6d1b5311c2649e8071eb241b2d64e75a0d0065107e62"},
-    {file = "charset_normalizer-3.1.0-cp311-cp311-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:b82fab78e0b1329e183a65260581de4375f619167478dddab510c6c6fb04d9b6"},
-    {file = "charset_normalizer-3.1.0-cp311-cp311-musllinux_1_1_aarch64.whl", hash = "sha256:bd7163182133c0c7701b25e604cf1611c0d87712e56e88e7ee5d72deab3e76b5"},
-    {file = "charset_normalizer-3.1.0-cp311-cp311-musllinux_1_1_i686.whl", hash = "sha256:11d117e6c63e8f495412d37e7dc2e2fff09c34b2d09dbe2bee3c6229577818be"},
-    {file = "charset_normalizer-3.1.0-cp311-cp311-musllinux_1_1_ppc64le.whl", hash = "sha256:cf6511efa4801b9b38dc5546d7547d5b5c6ef4b081c60b23e4d941d0eba9cbeb"},
-    {file = "charset_normalizer-3.1.0-cp311-cp311-musllinux_1_1_s390x.whl", hash = "sha256:abc1185d79f47c0a7aaf7e2412a0eb2c03b724581139193d2d82b3ad8cbb00ac"},
-    {file = "charset_normalizer-3.1.0-cp311-cp311-musllinux_1_1_x86_64.whl", hash = "sha256:cb7b2ab0188829593b9de646545175547a70d9a6e2b63bf2cd87a0a391599324"},
-    {file = "charset_normalizer-3.1.0-cp311-cp311-win32.whl", hash = "sha256:c36bcbc0d5174a80d6cccf43a0ecaca44e81d25be4b7f90f0ed7bcfbb5a00909"},
-    {file = "charset_normalizer-3.1.0-cp311-cp311-win_amd64.whl", hash = "sha256:cca4def576f47a09a943666b8f829606bcb17e2bc2d5911a46c8f8da45f56755"},
-    {file = "charset_normalizer-3.1.0-cp37-cp37m-macosx_10_9_x86_64.whl", hash = "sha256:0c95f12b74681e9ae127728f7e5409cbbef9cd914d5896ef238cc779b8152373"},
-    {file = "charset_normalizer-3.1.0-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:fca62a8301b605b954ad2e9c3666f9d97f63872aa4efcae5492baca2056b74ab"},
-    {file = "charset_normalizer-3.1.0-cp37-cp37m-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:ac0aa6cd53ab9a31d397f8303f92c42f534693528fafbdb997c82bae6e477ad9"},
-    {file = "charset_normalizer-3.1.0-cp37-cp37m-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:c3af8e0f07399d3176b179f2e2634c3ce9c1301379a6b8c9c9aeecd481da494f"},
-    {file = "charset_normalizer-3.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:3a5fc78f9e3f501a1614a98f7c54d3969f3ad9bba8ba3d9b438c3bc5d047dd28"},
-    {file = "charset_normalizer-3.1.0-cp37-cp37m-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:628c985afb2c7d27a4800bfb609e03985aaecb42f955049957814e0491d4006d"},
-    {file = "charset_normalizer-3.1.0-cp37-cp37m-musllinux_1_1_aarch64.whl", hash = "sha256:74db0052d985cf37fa111828d0dd230776ac99c740e1a758ad99094be4f1803d"},
-    {file = "charset_normalizer-3.1.0-cp37-cp37m-musllinux_1_1_i686.whl", hash = "sha256:1e8fcdd8f672a1c4fc8d0bd3a2b576b152d2a349782d1eb0f6b8e52e9954731d"},
-    {file = "charset_normalizer-3.1.0-cp37-cp37m-musllinux_1_1_ppc64le.whl", hash = "sha256:04afa6387e2b282cf78ff3dbce20f0cc071c12dc8f685bd40960cc68644cfea6"},
-    {file = "charset_normalizer-3.1.0-cp37-cp37m-musllinux_1_1_s390x.whl", hash = "sha256:dd5653e67b149503c68c4018bf07e42eeed6b4e956b24c00ccdf93ac79cdff84"},
-    {file = "charset_normalizer-3.1.0-cp37-cp37m-musllinux_1_1_x86_64.whl", hash = "sha256:d2686f91611f9e17f4548dbf050e75b079bbc2a82be565832bc8ea9047b61c8c"},
-    {file = "charset_normalizer-3.1.0-cp37-cp37m-win32.whl", hash = "sha256:4155b51ae05ed47199dc5b2a4e62abccb274cee6b01da5b895099b61b1982974"},
-    {file = "charset_normalizer-3.1.0-cp37-cp37m-win_amd64.whl", hash = "sha256:322102cdf1ab682ecc7d9b1c5eed4ec59657a65e1c146a0da342b78f4112db23"},
-    {file = "charset_normalizer-3.1.0-cp38-cp38-macosx_10_9_universal2.whl", hash = "sha256:e633940f28c1e913615fd624fcdd72fdba807bf53ea6925d6a588e84e1151531"},
-    {file = "charset_normalizer-3.1.0-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:3a06f32c9634a8705f4ca9946d667609f52cf130d5548881401f1eb2c39b1e2c"},
-    {file = "charset_normalizer-3.1.0-cp38-cp38-macosx_11_0_arm64.whl", hash = "sha256:7381c66e0561c5757ffe616af869b916c8b4e42b367ab29fedc98481d1e74e14"},
-    {file = "charset_normalizer-3.1.0-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:3573d376454d956553c356df45bb824262c397c6e26ce43e8203c4c540ee0acb"},
-    {file = "charset_normalizer-3.1.0-cp38-cp38-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:e89df2958e5159b811af9ff0f92614dabf4ff617c03a4c1c6ff53bf1c399e0e1"},
-    {file = "charset_normalizer-3.1.0-cp38-cp38-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:78cacd03e79d009d95635e7d6ff12c21eb89b894c354bd2b2ed0b4763373693b"},
-    {file = "charset_normalizer-3.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:de5695a6f1d8340b12a5d6d4484290ee74d61e467c39ff03b39e30df62cf83a0"},
-    {file = "charset_normalizer-3.1.0-cp38-cp38-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:1c60b9c202d00052183c9be85e5eaf18a4ada0a47d188a83c8f5c5b23252f649"},
-    {file = "charset_normalizer-3.1.0-cp38-cp38-musllinux_1_1_aarch64.whl", hash = "sha256:f645caaf0008bacf349875a974220f1f1da349c5dbe7c4ec93048cdc785a3326"},
-    {file = "charset_normalizer-3.1.0-cp38-cp38-musllinux_1_1_i686.whl", hash = "sha256:ea9f9c6034ea2d93d9147818f17c2a0860d41b71c38b9ce4d55f21b6f9165a11"},
-    {file = "charset_normalizer-3.1.0-cp38-cp38-musllinux_1_1_ppc64le.whl", hash = "sha256:80d1543d58bd3d6c271b66abf454d437a438dff01c3e62fdbcd68f2a11310d4b"},
-    {file = "charset_normalizer-3.1.0-cp38-cp38-musllinux_1_1_s390x.whl", hash = "sha256:73dc03a6a7e30b7edc5b01b601e53e7fc924b04e1835e8e407c12c037e81adbd"},
-    {file = "charset_normalizer-3.1.0-cp38-cp38-musllinux_1_1_x86_64.whl", hash = "sha256:6f5c2e7bc8a4bf7c426599765b1bd33217ec84023033672c1e9a8b35eaeaaaf8"},
-    {file = "charset_normalizer-3.1.0-cp38-cp38-win32.whl", hash = "sha256:12a2b561af122e3d94cdb97fe6fb2bb2b82cef0cdca131646fdb940a1eda04f0"},
-    {file = "charset_normalizer-3.1.0-cp38-cp38-win_amd64.whl", hash = "sha256:3160a0fd9754aab7d47f95a6b63ab355388d890163eb03b2d2b87ab0a30cfa59"},
-    {file = "charset_normalizer-3.1.0-cp39-cp39-macosx_10_9_universal2.whl", hash = "sha256:38e812a197bf8e71a59fe55b757a84c1f946d0ac114acafaafaf21667a7e169e"},
-    {file = "charset_normalizer-3.1.0-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:6baf0baf0d5d265fa7944feb9f7451cc316bfe30e8df1a61b1bb08577c554f31"},
-    {file = "charset_normalizer-3.1.0-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:8f25e17ab3039b05f762b0a55ae0b3632b2e073d9c8fc88e89aca31a6198e88f"},
-    {file = "charset_normalizer-3.1.0-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:3747443b6a904001473370d7810aa19c3a180ccd52a7157aacc264a5ac79265e"},
-    {file = "charset_normalizer-3.1.0-cp39-cp39-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:b116502087ce8a6b7a5f1814568ccbd0e9f6cfd99948aa59b0e241dc57cf739f"},
-    {file = "charset_normalizer-3.1.0-cp39-cp39-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:d16fd5252f883eb074ca55cb622bc0bee49b979ae4e8639fff6ca3ff44f9f854"},
-    {file = "charset_normalizer-3.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:21fa558996782fc226b529fdd2ed7866c2c6ec91cee82735c98a197fae39f706"},
-    {file = "charset_normalizer-3.1.0-cp39-cp39-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:6f6c7a8a57e9405cad7485f4c9d3172ae486cfef1344b5ddd8e5239582d7355e"},
-    {file = "charset_normalizer-3.1.0-cp39-cp39-musllinux_1_1_aarch64.whl", hash = "sha256:ac3775e3311661d4adace3697a52ac0bab17edd166087d493b52d4f4f553f9f0"},
-    {file = "charset_normalizer-3.1.0-cp39-cp39-musllinux_1_1_i686.whl", hash = "sha256:10c93628d7497c81686e8e5e557aafa78f230cd9e77dd0c40032ef90c18f2230"},
-    {file = "charset_normalizer-3.1.0-cp39-cp39-musllinux_1_1_ppc64le.whl", hash = "sha256:6f4f4668e1831850ebcc2fd0b1cd11721947b6dc7c00bf1c6bd3c929ae14f2c7"},
-    {file = "charset_normalizer-3.1.0-cp39-cp39-musllinux_1_1_s390x.whl", hash = "sha256:0be65ccf618c1e7ac9b849c315cc2e8a8751d9cfdaa43027d4f6624bd587ab7e"},
-    {file = "charset_normalizer-3.1.0-cp39-cp39-musllinux_1_1_x86_64.whl", hash = "sha256:53d0a3fa5f8af98a1e261de6a3943ca631c526635eb5817a87a59d9a57ebf48f"},
-    {file = "charset_normalizer-3.1.0-cp39-cp39-win32.whl", hash = "sha256:a04f86f41a8916fe45ac5024ec477f41f886b3c435da2d4e3d2709b22ab02af1"},
-    {file = "charset_normalizer-3.1.0-cp39-cp39-win_amd64.whl", hash = "sha256:830d2948a5ec37c386d3170c483063798d7879037492540f10a475e3fd6f244b"},
-    {file = "charset_normalizer-3.1.0-py3-none-any.whl", hash = "sha256:3d9098b479e78c85080c98e1e35ff40b4a31d8953102bb0fd7d1b6f8a2111a3d"},
-]
-
-[[package]]
-name = "click"
-version = "8.1.3"
-description = "Composable command line interface toolkit"
-optional = false
-python-versions = ">=3.7"
-files = [
-    {file = "click-8.1.3-py3-none-any.whl", hash = "sha256:bb4d8133cb15a609f44e8213d9b391b0809795062913b383c62be0ee95b1db48"},
-    {file = "click-8.1.3.tar.gz", hash = "sha256:7682dc8afb30297001674575ea00d1814d808d6a36af415a82bd481d37ba7b8e"},
+    {file = "charset-normalizer-3.3.2.tar.gz", hash = "sha256:f30c3cb33b24454a82faecaf01b19c18562b1e89558fb6c56de4d9118a032fd5"},
+    {file = "charset_normalizer-3.3.2-cp310-cp310-macosx_10_9_universal2.whl", hash = "sha256:25baf083bf6f6b341f4121c2f3c548875ee6f5339300e08be3f2b2ba1721cdd3"},
+    {file = "charset_normalizer-3.3.2-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:06435b539f889b1f6f4ac1758871aae42dc3a8c0e24ac9e60c2384973ad73027"},
+    {file = "charset_normalizer-3.3.2-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:9063e24fdb1e498ab71cb7419e24622516c4a04476b17a2dab57e8baa30d6e03"},
+    {file = "charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:6897af51655e3691ff853668779c7bad41579facacf5fd7253b0133308cf000d"},
+    {file = "charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:1d3193f4a680c64b4b6a9115943538edb896edc190f0b222e73761716519268e"},
+    {file = "charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:cd70574b12bb8a4d2aaa0094515df2463cb429d8536cfb6c7ce983246983e5a6"},
+    {file = "charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:8465322196c8b4d7ab6d1e049e4c5cb460d0394da4a27d23cc242fbf0034b6b5"},
+    {file = "charset_normalizer-3.3.2-cp310-cp310-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:a9a8e9031d613fd2009c182b69c7b2c1ef8239a0efb1df3f7c8da66d5dd3d537"},
+    {file = "charset_normalizer-3.3.2-cp310-cp310-musllinux_1_1_aarch64.whl", hash = "sha256:beb58fe5cdb101e3a055192ac291b7a21e3b7ef4f67fa1d74e331a7f2124341c"},
+    {file = "charset_normalizer-3.3.2-cp310-cp310-musllinux_1_1_i686.whl", hash = "sha256:e06ed3eb3218bc64786f7db41917d4e686cc4856944f53d5bdf83a6884432e12"},
+    {file = "charset_normalizer-3.3.2-cp310-cp310-musllinux_1_1_ppc64le.whl", hash = "sha256:2e81c7b9c8979ce92ed306c249d46894776a909505d8f5a4ba55b14206e3222f"},
+    {file = "charset_normalizer-3.3.2-cp310-cp310-musllinux_1_1_s390x.whl", hash = "sha256:572c3763a264ba47b3cf708a44ce965d98555f618ca42c926a9c1616d8f34269"},
+    {file = "charset_normalizer-3.3.2-cp310-cp310-musllinux_1_1_x86_64.whl", hash = "sha256:fd1abc0d89e30cc4e02e4064dc67fcc51bd941eb395c502aac3ec19fab46b519"},
+    {file = "charset_normalizer-3.3.2-cp310-cp310-win32.whl", hash = "sha256:3d47fa203a7bd9c5b6cee4736ee84ca03b8ef23193c0d1ca99b5089f72645c73"},
+    {file = "charset_normalizer-3.3.2-cp310-cp310-win_amd64.whl", hash = "sha256:10955842570876604d404661fbccbc9c7e684caf432c09c715ec38fbae45ae09"},
+    {file = "charset_normalizer-3.3.2-cp311-cp311-macosx_10_9_universal2.whl", hash = "sha256:802fe99cca7457642125a8a88a084cef28ff0cf9407060f7b93dca5aa25480db"},
+    {file = "charset_normalizer-3.3.2-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:573f6eac48f4769d667c4442081b1794f52919e7edada77495aaed9236d13a96"},
+    {file = "charset_normalizer-3.3.2-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:549a3a73da901d5bc3ce8d24e0600d1fa85524c10287f6004fbab87672bf3e1e"},
+    {file = "charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:f27273b60488abe721a075bcca6d7f3964f9f6f067c8c4c605743023d7d3944f"},
+    {file = "charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:1ceae2f17a9c33cb48e3263960dc5fc8005351ee19db217e9b1bb15d28c02574"},
+    {file = "charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:65f6f63034100ead094b8744b3b97965785388f308a64cf8d7c34f2f2e5be0c4"},
+    {file = "charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:753f10e867343b4511128c6ed8c82f7bec3bd026875576dfd88483c5c73b2fd8"},
+    {file = "charset_normalizer-3.3.2-cp311-cp311-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:4a78b2b446bd7c934f5dcedc588903fb2f5eec172f3d29e52a9096a43722adfc"},
+    {file = "charset_normalizer-3.3.2-cp311-cp311-musllinux_1_1_aarch64.whl", hash = "sha256:e537484df0d8f426ce2afb2d0f8e1c3d0b114b83f8850e5f2fbea0e797bd82ae"},
+    {file = "charset_normalizer-3.3.2-cp311-cp311-musllinux_1_1_i686.whl", hash = "sha256:eb6904c354526e758fda7167b33005998fb68c46fbc10e013ca97f21ca5c8887"},
+    {file = "charset_normalizer-3.3.2-cp311-cp311-musllinux_1_1_ppc64le.whl", hash = "sha256:deb6be0ac38ece9ba87dea880e438f25ca3eddfac8b002a2ec3d9183a454e8ae"},
+    {file = "charset_normalizer-3.3.2-cp311-cp311-musllinux_1_1_s390x.whl", hash = "sha256:4ab2fe47fae9e0f9dee8c04187ce5d09f48eabe611be8259444906793ab7cbce"},
+    {file = "charset_normalizer-3.3.2-cp311-cp311-musllinux_1_1_x86_64.whl", hash = "sha256:80402cd6ee291dcb72644d6eac93785fe2c8b9cb30893c1af5b8fdd753b9d40f"},
+    {file = "charset_normalizer-3.3.2-cp311-cp311-win32.whl", hash = "sha256:7cd13a2e3ddeed6913a65e66e94b51d80a041145a026c27e6bb76c31a853c6ab"},
+    {file = "charset_normalizer-3.3.2-cp311-cp311-win_amd64.whl", hash = "sha256:663946639d296df6a2bb2aa51b60a2454ca1cb29835324c640dafb5ff2131a77"},
+    {file = "charset_normalizer-3.3.2-cp312-cp312-macosx_10_9_universal2.whl", hash = "sha256:0b2b64d2bb6d3fb9112bafa732def486049e63de9618b5843bcdd081d8144cd8"},
+    {file = "charset_normalizer-3.3.2-cp312-cp312-macosx_10_9_x86_64.whl", hash = "sha256:ddbb2551d7e0102e7252db79ba445cdab71b26640817ab1e3e3648dad515003b"},
+    {file = "charset_normalizer-3.3.2-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:55086ee1064215781fff39a1af09518bc9255b50d6333f2e4c74ca09fac6a8f6"},
+    {file = "charset_normalizer-3.3.2-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:8f4a014bc36d3c57402e2977dada34f9c12300af536839dc38c0beab8878f38a"},
+    {file = "charset_normalizer-3.3.2-cp312-cp312-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:a10af20b82360ab00827f916a6058451b723b4e65030c5a18577c8b2de5b3389"},
+    {file = "charset_normalizer-3.3.2-cp312-cp312-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:8d756e44e94489e49571086ef83b2bb8ce311e730092d2c34ca8f7d925cb20aa"},
+    {file = "charset_normalizer-3.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:90d558489962fd4918143277a773316e56c72da56ec7aa3dc3dbbe20fdfed15b"},
+    {file = "charset_normalizer-3.3.2-cp312-cp312-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:6ac7ffc7ad6d040517be39eb591cac5ff87416c2537df6ba3cba3bae290c0fed"},
+    {file = "charset_normalizer-3.3.2-cp312-cp312-musllinux_1_1_aarch64.whl", hash = "sha256:7ed9e526742851e8d5cc9e6cf41427dfc6068d4f5a3bb03659444b4cabf6bc26"},
+    {file = "charset_normalizer-3.3.2-cp312-cp312-musllinux_1_1_i686.whl", hash = "sha256:8bdb58ff7ba23002a4c5808d608e4e6c687175724f54a5dade5fa8c67b604e4d"},
+    {file = "charset_normalizer-3.3.2-cp312-cp312-musllinux_1_1_ppc64le.whl", hash = "sha256:6b3251890fff30ee142c44144871185dbe13b11bab478a88887a639655be1068"},
+    {file = "charset_normalizer-3.3.2-cp312-cp312-musllinux_1_1_s390x.whl", hash = "sha256:b4a23f61ce87adf89be746c8a8974fe1c823c891d8f86eb218bb957c924bb143"},
+    {file = "charset_normalizer-3.3.2-cp312-cp312-musllinux_1_1_x86_64.whl", hash = "sha256:efcb3f6676480691518c177e3b465bcddf57cea040302f9f4e6e191af91174d4"},
+    {file = "charset_normalizer-3.3.2-cp312-cp312-win32.whl", hash = "sha256:d965bba47ddeec8cd560687584e88cf699fd28f192ceb452d1d7ee807c5597b7"},
+    {file = "charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl", hash = "sha256:96b02a3dc4381e5494fad39be677abcb5e6634bf7b4fa83a6dd3112607547001"},
+    {file = "charset_normalizer-3.3.2-cp37-cp37m-macosx_10_9_x86_64.whl", hash = "sha256:95f2a5796329323b8f0512e09dbb7a1860c46a39da62ecb2324f116fa8fdc85c"},
+    {file = "charset_normalizer-3.3.2-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:c002b4ffc0be611f0d9da932eb0f704fe2602a9a949d1f738e4c34c75b0863d5"},
+    {file = "charset_normalizer-3.3.2-cp37-cp37m-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:a981a536974bbc7a512cf44ed14938cf01030a99e9b3a06dd59578882f06f985"},
+    {file = "charset_normalizer-3.3.2-cp37-cp37m-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:3287761bc4ee9e33561a7e058c72ac0938c4f57fe49a09eae428fd88aafe7bb6"},
+    {file = "charset_normalizer-3.3.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:42cb296636fcc8b0644486d15c12376cb9fa75443e00fb25de0b8602e64c1714"},
+    {file = "charset_normalizer-3.3.2-cp37-cp37m-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:0a55554a2fa0d408816b3b5cedf0045f4b8e1a6065aec45849de2d6f3f8e9786"},
+    {file = "charset_normalizer-3.3.2-cp37-cp37m-musllinux_1_1_aarch64.whl", hash = "sha256:c083af607d2515612056a31f0a8d9e0fcb5876b7bfc0abad3ecd275bc4ebc2d5"},
+    {file = "charset_normalizer-3.3.2-cp37-cp37m-musllinux_1_1_i686.whl", hash = "sha256:87d1351268731db79e0f8e745d92493ee2841c974128ef629dc518b937d9194c"},
+    {file = "charset_normalizer-3.3.2-cp37-cp37m-musllinux_1_1_ppc64le.whl", hash = "sha256:bd8f7df7d12c2db9fab40bdd87a7c09b1530128315d047a086fa3ae3435cb3a8"},
+    {file = "charset_normalizer-3.3.2-cp37-cp37m-musllinux_1_1_s390x.whl", hash = "sha256:c180f51afb394e165eafe4ac2936a14bee3eb10debc9d9e4db8958fe36afe711"},
+    {file = "charset_normalizer-3.3.2-cp37-cp37m-musllinux_1_1_x86_64.whl", hash = "sha256:8c622a5fe39a48f78944a87d4fb8a53ee07344641b0562c540d840748571b811"},
+    {file = "charset_normalizer-3.3.2-cp37-cp37m-win32.whl", hash = "sha256:db364eca23f876da6f9e16c9da0df51aa4f104a972735574842618b8c6d999d4"},
+    {file = "charset_normalizer-3.3.2-cp37-cp37m-win_amd64.whl", hash = "sha256:86216b5cee4b06df986d214f664305142d9c76df9b6512be2738aa72a2048f99"},
+    {file = "charset_normalizer-3.3.2-cp38-cp38-macosx_10_9_universal2.whl", hash = "sha256:6463effa3186ea09411d50efc7d85360b38d5f09b870c48e4600f63af490e56a"},
+    {file = "charset_normalizer-3.3.2-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:6c4caeef8fa63d06bd437cd4bdcf3ffefe6738fb1b25951440d80dc7df8c03ac"},
+    {file = "charset_normalizer-3.3.2-cp38-cp38-macosx_11_0_arm64.whl", hash = "sha256:37e55c8e51c236f95b033f6fb391d7d7970ba5fe7ff453dad675e88cf303377a"},
+    {file = "charset_normalizer-3.3.2-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:fb69256e180cb6c8a894fee62b3afebae785babc1ee98b81cdf68bbca1987f33"},
+    {file = "charset_normalizer-3.3.2-cp38-cp38-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:ae5f4161f18c61806f411a13b0310bea87f987c7d2ecdbdaad0e94eb2e404238"},
+    {file = "charset_normalizer-3.3.2-cp38-cp38-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:b2b0a0c0517616b6869869f8c581d4eb2dd83a4d79e0ebcb7d373ef9956aeb0a"},
+    {file = "charset_normalizer-3.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:45485e01ff4d3630ec0d9617310448a8702f70e9c01906b0d0118bdf9d124cf2"},
+    {file = "charset_normalizer-3.3.2-cp38-cp38-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:eb00ed941194665c332bf8e078baf037d6c35d7c4f3102ea2d4f16ca94a26dc8"},
+    {file = "charset_normalizer-3.3.2-cp38-cp38-musllinux_1_1_aarch64.whl", hash = "sha256:2127566c664442652f024c837091890cb1942c30937add288223dc895793f898"},
+    {file = "charset_normalizer-3.3.2-cp38-cp38-musllinux_1_1_i686.whl", hash = "sha256:a50aebfa173e157099939b17f18600f72f84eed3049e743b68ad15bd69b6bf99"},
+    {file = "charset_normalizer-3.3.2-cp38-cp38-musllinux_1_1_ppc64le.whl", hash = "sha256:4d0d1650369165a14e14e1e47b372cfcb31d6ab44e6e33cb2d4e57265290044d"},
+    {file = "charset_normalizer-3.3.2-cp38-cp38-musllinux_1_1_s390x.whl", hash = "sha256:923c0c831b7cfcb071580d3f46c4baf50f174be571576556269530f4bbd79d04"},
+    {file = "charset_normalizer-3.3.2-cp38-cp38-musllinux_1_1_x86_64.whl", hash = "sha256:06a81e93cd441c56a9b65d8e1d043daeb97a3d0856d177d5c90ba85acb3db087"},
+    {file = "charset_normalizer-3.3.2-cp38-cp38-win32.whl", hash = "sha256:6ef1d82a3af9d3eecdba2321dc1b3c238245d890843e040e41e470ffa64c3e25"},
+    {file = "charset_normalizer-3.3.2-cp38-cp38-win_amd64.whl", hash = "sha256:eb8821e09e916165e160797a6c17edda0679379a4be5c716c260e836e122f54b"},
+    {file = "charset_normalizer-3.3.2-cp39-cp39-macosx_10_9_universal2.whl", hash = "sha256:c235ebd9baae02f1b77bcea61bce332cb4331dc3617d254df3323aa01ab47bd4"},
+    {file = "charset_normalizer-3.3.2-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:5b4c145409bef602a690e7cfad0a15a55c13320ff7a3ad7ca59c13bb8ba4d45d"},
+    {file = "charset_normalizer-3.3.2-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:68d1f8a9e9e37c1223b656399be5d6b448dea850bed7d0f87a8311f1ff3dabb0"},
+    {file = "charset_normalizer-3.3.2-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:22afcb9f253dac0696b5a4be4a1c0f8762f8239e21b99680099abd9b2b1b2269"},
+    {file = "charset_normalizer-3.3.2-cp39-cp39-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:e27ad930a842b4c5eb8ac0016b0a54f5aebbe679340c26101df33424142c143c"},
+    {file = "charset_normalizer-3.3.2-cp39-cp39-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:1f79682fbe303db92bc2b1136016a38a42e835d932bab5b3b1bfcfbf0640e519"},
+    {file = "charset_normalizer-3.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:b261ccdec7821281dade748d088bb6e9b69e6d15b30652b74cbbac25e280b796"},
+    {file = "charset_normalizer-3.3.2-cp39-cp39-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:122c7fa62b130ed55f8f285bfd56d5f4b4a5b503609d181f9ad85e55c89f4185"},
+    {file = "charset_normalizer-3.3.2-cp39-cp39-musllinux_1_1_aarch64.whl", hash = "sha256:d0eccceffcb53201b5bfebb52600a5fb483a20b61da9dbc885f8b103cbe7598c"},
+    {file = "charset_normalizer-3.3.2-cp39-cp39-musllinux_1_1_i686.whl", hash = "sha256:9f96df6923e21816da7e0ad3fd47dd8f94b2a5ce594e00677c0013018b813458"},
+    {file = "charset_normalizer-3.3.2-cp39-cp39-musllinux_1_1_ppc64le.whl", hash = "sha256:7f04c839ed0b6b98b1a7501a002144b76c18fb1c1850c8b98d458ac269e26ed2"},
+    {file = "charset_normalizer-3.3.2-cp39-cp39-musllinux_1_1_s390x.whl", hash = "sha256:34d1c8da1e78d2e001f363791c98a272bb734000fcef47a491c1e3b0505657a8"},
+    {file = "charset_normalizer-3.3.2-cp39-cp39-musllinux_1_1_x86_64.whl", hash = "sha256:ff8fa367d09b717b2a17a052544193ad76cd49979c805768879cb63d9ca50561"},
+    {file = "charset_normalizer-3.3.2-cp39-cp39-win32.whl", hash = "sha256:aed38f6e4fb3f5d6bf81bfa990a07806be9d83cf7bacef998ab1a9bd660a581f"},
+    {file = "charset_normalizer-3.3.2-cp39-cp39-win_amd64.whl", hash = "sha256:b01b88d45a6fcb69667cd6d2f7a9aeb4bf53760d7fc536bf679ec94fe9f3ff3d"},
+    {file = "charset_normalizer-3.3.2-py3-none-any.whl", hash = "sha256:3e4d1f6587322d2788836a99c69062fbb091331ec940e02d12d179c1d53e25fc"},
 ]
 
-[package.dependencies]
-colorama = {version = "*", markers = "platform_system == \"Windows\""}
-importlib-metadata = {version = "*", markers = "python_version < \"3.8\""}
-
 [[package]]
 name = "colorama"
 version = "0.4.6"
 description = "Cross-platform colored terminal text."
 optional = false
 python-versions = "!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*,!=3.5.*,!=3.6.*,>=2.7"
 files = [
@@ -357,196 +255,99 @@
 tomli = {version = "*", optional = true, markers = "python_full_version <= \"3.11.0a6\" and extra == \"toml\""}
 
 [package.extras]
 toml = ["tomli"]
 
 [[package]]
 name = "distlib"
-version = "0.3.6"
+version = "0.3.8"
 description = "Distribution utilities"
 optional = false
 python-versions = "*"
 files = [
-    {file = "distlib-0.3.6-py2.py3-none-any.whl", hash = "sha256:f35c4b692542ca110de7ef0bea44d73981caeb34ca0b9b6b2e6d7790dda8f80e"},
-    {file = "distlib-0.3.6.tar.gz", hash = "sha256:14bad2d9b04d3a36127ac97f30b12a19268f211063d8f8ee4f47108896e11b46"},
+    {file = "distlib-0.3.8-py2.py3-none-any.whl", hash = "sha256:034db59a0b96f8ca18035f36290806a9a6e6bd9d1ff91e45a7f172eb17e51784"},
+    {file = "distlib-0.3.8.tar.gz", hash = "sha256:1530ea13e350031b6312d8580ddb6b27a104275a31106523b8f123787f494f64"},
 ]
 
 [[package]]
 name = "docutils"
-version = "0.17.1"
+version = "0.19"
 description = "Docutils -- Python Documentation Utilities"
 optional = false
-python-versions = ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*"
+python-versions = ">=3.7"
 files = [
-    {file = "docutils-0.17.1-py2.py3-none-any.whl", hash = "sha256:cf316c8370a737a022b72b56874f6602acf974a37a9fba42ec2876387549fc61"},
-    {file = "docutils-0.17.1.tar.gz", hash = "sha256:686577d2e4c32380bb50cbb22f575ed742d58168cee37e99117a854bcd88f125"},
+    {file = "docutils-0.19-py3-none-any.whl", hash = "sha256:5e1de4d849fee02c63b040a4a3fd567f4ab104defd8a5511fbbc24a8a017efbc"},
+    {file = "docutils-0.19.tar.gz", hash = "sha256:33995a6753c30b7f577febfc2c50411fec6aac7f7ffeb7c4cfe5991072dcf9e6"},
 ]
 
 [[package]]
 name = "docutils"
-version = "0.18.1"
+version = "0.20.1"
 description = "Docutils -- Python Documentation Utilities"
 optional = false
-python-versions = ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*"
+python-versions = ">=3.7"
 files = [
-    {file = "docutils-0.18.1-py2.py3-none-any.whl", hash = "sha256:23010f129180089fbcd3bc08cfefccb3b890b0050e1ca00c867036e9d161b98c"},
-    {file = "docutils-0.18.1.tar.gz", hash = "sha256:679987caf361a7539d76e584cbeddc311e3aee937877c87346f31debc63e9d06"},
+    {file = "docutils-0.20.1-py3-none-any.whl", hash = "sha256:96f387a2c5562db4476f09f13bbab2192e764cac08ebbf3a34a95d9b1e4a59d6"},
+    {file = "docutils-0.20.1.tar.gz", hash = "sha256:f08a4e276c3a1583a86dce3e34aba3fe04d02bba2dd51ed16106244e8a923e3b"},
 ]
 
 [[package]]
 name = "exceptiongroup"
-version = "1.1.1"
+version = "1.2.0"
 description = "Backport of PEP 654 (exception groups)"
 optional = false
 python-versions = ">=3.7"
 files = [
-    {file = "exceptiongroup-1.1.1-py3-none-any.whl", hash = "sha256:232c37c63e4f682982c8b6459f33a8981039e5fb8756b2074364e5055c498c9e"},
-    {file = "exceptiongroup-1.1.1.tar.gz", hash = "sha256:d484c3090ba2889ae2928419117447a14daf3c1231d5e30d0aae34f354f01785"},
+    {file = "exceptiongroup-1.2.0-py3-none-any.whl", hash = "sha256:4bfd3996ac73b41e9b9628b04e079f193850720ea5945fc96a08633c66912f14"},
+    {file = "exceptiongroup-1.2.0.tar.gz", hash = "sha256:91f5c769735f051a4290d52edd0858999b57e5876e9f85937691bd4c9fa3ed68"},
 ]
 
 [package.extras]
 test = ["pytest (>=6)"]
 
 [[package]]
 name = "filelock"
-version = "3.12.0"
+version = "3.12.2"
 description = "A platform independent file lock."
 optional = false
 python-versions = ">=3.7"
 files = [
-    {file = "filelock-3.12.0-py3-none-any.whl", hash = "sha256:ad98852315c2ab702aeb628412cbf7e95b7ce8c3bf9565670b4eaecf1db370a9"},
-    {file = "filelock-3.12.0.tar.gz", hash = "sha256:fc03ae43288c013d2ea83c8597001b1129db351aad9c57fe2409327916b8e718"},
+    {file = "filelock-3.12.2-py3-none-any.whl", hash = "sha256:cbb791cdea2a72f23da6ac5b5269ab0a0d161e9ef0100e653b69049a7706d1ec"},
+    {file = "filelock-3.12.2.tar.gz", hash = "sha256:002740518d8aa59a26b0c76e10fb8c6e15eae825d34b6fdf670333fd7b938d81"},
 ]
 
 [package.extras]
-docs = ["furo (>=2023.3.27)", "sphinx (>=6.1.3)", "sphinx-autodoc-typehints (>=1.23,!=1.23.4)"]
-testing = ["covdefaults (>=2.3)", "coverage (>=7.2.3)", "diff-cover (>=7.5)", "pytest (>=7.3.1)", "pytest-cov (>=4)", "pytest-mock (>=3.10)", "pytest-timeout (>=2.1)"]
-
-[[package]]
-name = "flake8"
-version = "5.0.4"
-description = "the modular source code checker: pep8 pyflakes and co"
-optional = false
-python-versions = ">=3.6.1"
-files = [
-    {file = "flake8-5.0.4-py2.py3-none-any.whl", hash = "sha256:7a1cf6b73744f5806ab95e526f6f0d8c01c66d7bbe349562d22dfca20610b248"},
-    {file = "flake8-5.0.4.tar.gz", hash = "sha256:6fbe320aad8d6b95cec8b8e47bc933004678dc63095be98528b7bdd2a9f510db"},
-]
-
-[package.dependencies]
-importlib-metadata = {version = ">=1.1.0,<4.3", markers = "python_version < \"3.8\""}
-mccabe = ">=0.7.0,<0.8.0"
-pycodestyle = ">=2.9.0,<2.10.0"
-pyflakes = ">=2.5.0,<2.6.0"
-
-[[package]]
-name = "flake8"
-version = "6.0.0"
-description = "the modular source code checker: pep8 pyflakes and co"
-optional = false
-python-versions = ">=3.8.1"
-files = [
-    {file = "flake8-6.0.0-py2.py3-none-any.whl", hash = "sha256:3833794e27ff64ea4e9cf5d410082a8b97ff1a06c16aa3d2027339cd0f1195c7"},
-    {file = "flake8-6.0.0.tar.gz", hash = "sha256:c61007e76655af75e6785a931f452915b371dc48f56efd765247c8fe68f2b181"},
-]
-
-[package.dependencies]
-mccabe = ">=0.7.0,<0.8.0"
-pycodestyle = ">=2.10.0,<2.11.0"
-pyflakes = ">=3.0.0,<3.1.0"
-
-[[package]]
-name = "flake8-bandit"
-version = "4.1.1"
-description = "Automated security testing with bandit and flake8."
-optional = false
-python-versions = ">=3.6"
-files = [
-    {file = "flake8_bandit-4.1.1-py3-none-any.whl", hash = "sha256:4c8a53eb48f23d4ef1e59293657181a3c989d0077c9952717e98a0eace43e06d"},
-    {file = "flake8_bandit-4.1.1.tar.gz", hash = "sha256:068e09287189cbfd7f986e92605adea2067630b75380c6b5733dab7d87f9a84e"},
-]
-
-[package.dependencies]
-bandit = ">=1.7.3"
-flake8 = ">=5.0.0"
+docs = ["furo (>=2023.5.20)", "sphinx (>=7.0.1)", "sphinx-autodoc-typehints (>=1.23,!=1.23.4)"]
+testing = ["covdefaults (>=2.3)", "coverage (>=7.2.7)", "diff-cover (>=7.5)", "pytest (>=7.3.1)", "pytest-cov (>=4.1)", "pytest-mock (>=3.10)", "pytest-timeout (>=2.1)"]
 
 [[package]]
-name = "flake8-bugbear"
-version = "23.3.12"
-description = "A plugin for flake8 finding likely bugs and design problems in your program. Contains warnings that don't belong in pyflakes and pycodestyle."
+name = "filelock"
+version = "3.13.1"
+description = "A platform independent file lock."
 optional = false
-python-versions = ">=3.7"
+python-versions = ">=3.8"
 files = [
-    {file = "flake8-bugbear-23.3.12.tar.gz", hash = "sha256:e3e7f74c8a49ad3794a7183353026dabd68c74030d5f46571f84c1fb0eb79363"},
-    {file = "flake8_bugbear-23.3.12-py3-none-any.whl", hash = "sha256:beb5c7efcd7ccc2039ef66a77bb8db925e7be3531ff1cb4d0b7030d0e2113d72"},
+    {file = "filelock-3.13.1-py3-none-any.whl", hash = "sha256:57dbda9b35157b05fb3e58ee91448612eb674172fab98ee235ccb0b5bee19a1c"},
+    {file = "filelock-3.13.1.tar.gz", hash = "sha256:521f5f56c50f8426f5e03ad3b281b490a87ef15bc6c526f168290f0c7148d44e"},
 ]
 
-[package.dependencies]
-attrs = ">=19.2.0"
-flake8 = ">=3.0.0"
-
 [package.extras]
-dev = ["coverage", "hypothesis", "hypothesmith (>=0.2)", "pre-commit", "pytest", "tox"]
-
-[[package]]
-name = "flake8-bugbear"
-version = "23.5.9"
-description = "A plugin for flake8 finding likely bugs and design problems in your program. Contains warnings that don't belong in pyflakes and pycodestyle."
-optional = false
-python-versions = ">=3.8.1"
-files = [
-    {file = "flake8-bugbear-23.5.9.tar.gz", hash = "sha256:695c84a5d7da54eb35d79a7354dbaf3aaba80de32250608868aa1c85534b2a86"},
-    {file = "flake8_bugbear-23.5.9-py3-none-any.whl", hash = "sha256:631fa927fbc799e8ca636b849dd7dfc304812287137b6ecb3277821f028bee40"},
-]
-
-[package.dependencies]
-attrs = ">=19.2.0"
-flake8 = ">=6.0.0"
-
-[package.extras]
-dev = ["coverage", "hypothesis", "hypothesmith (>=0.2)", "pre-commit", "pytest", "tox"]
-
-[[package]]
-name = "gitdb"
-version = "4.0.10"
-description = "Git Object Database"
-optional = false
-python-versions = ">=3.7"
-files = [
-    {file = "gitdb-4.0.10-py3-none-any.whl", hash = "sha256:c286cf298426064079ed96a9e4a9d39e7f3e9bf15ba60701e95f5492f28415c7"},
-    {file = "gitdb-4.0.10.tar.gz", hash = "sha256:6eb990b69df4e15bad899ea868dc46572c3f75339735663b81de79b06f17eb9a"},
-]
-
-[package.dependencies]
-smmap = ">=3.0.1,<6"
-
-[[package]]
-name = "gitpython"
-version = "3.1.31"
-description = "GitPython is a Python library used to interact with Git repositories"
-optional = false
-python-versions = ">=3.7"
-files = [
-    {file = "GitPython-3.1.31-py3-none-any.whl", hash = "sha256:f04893614f6aa713a60cbbe1e6a97403ef633103cdd0ef5eb6efe0deb98dbe8d"},
-    {file = "GitPython-3.1.31.tar.gz", hash = "sha256:8ce3bcf69adfdf7c7d503e78fd3b1c492af782d58893b650adb2ac8912ddd573"},
-]
-
-[package.dependencies]
-gitdb = ">=4.0.1,<5"
-typing-extensions = {version = ">=3.7.4.3", markers = "python_version < \"3.8\""}
+docs = ["furo (>=2023.9.10)", "sphinx (>=7.2.6)", "sphinx-autodoc-typehints (>=1.24)"]
+testing = ["covdefaults (>=2.3)", "coverage (>=7.3.2)", "diff-cover (>=8)", "pytest (>=7.4.3)", "pytest-cov (>=4.1)", "pytest-mock (>=3.12)", "pytest-timeout (>=2.2)"]
+typing = ["typing-extensions (>=4.8)"]
 
 [[package]]
 name = "idna"
-version = "3.4"
+version = "3.6"
 description = "Internationalized Domain Names in Applications (IDNA)"
 optional = false
 python-versions = ">=3.5"
 files = [
-    {file = "idna-3.4-py3-none-any.whl", hash = "sha256:90b77e79eaa3eba6de819a0c442c0b4ceefc341a7a2ab77d7562bf49f425c5c2"},
-    {file = "idna-3.4.tar.gz", hash = "sha256:814f528e8dead7d329833b91c5faa87d60bf71824cd12a7530b5526063d02cb4"},
+    {file = "idna-3.6-py3-none-any.whl", hash = "sha256:c05567e9c24a6b9faaa835c4821bad0590fbb9d5779e7caa6e1cc4978e7eb24f"},
+    {file = "idna-3.6.tar.gz", hash = "sha256:9ecdbbd083b06798ae1e86adcbfe8ab1479cf864e4ee30fe4e46a003d12491ca"},
 ]
 
 [[package]]
 name = "imagesize"
 version = "1.4.1"
 description = "Getting image size from png/jpeg/jpeg2000/gif file"
 optional = false
@@ -554,264 +355,240 @@
 files = [
     {file = "imagesize-1.4.1-py2.py3-none-any.whl", hash = "sha256:0d8d18d08f840c19d0ee7ca1fd82490fdc3729b7ac93f49870406ddde8ef8d8b"},
     {file = "imagesize-1.4.1.tar.gz", hash = "sha256:69150444affb9cb0d5cc5a92b3676f0b2fb7cd9ae39e947a5e11a36b4497cd4a"},
 ]
 
 [[package]]
 name = "importlib-metadata"
-version = "4.2.0"
+version = "6.7.0"
 description = "Read metadata from Python packages"
 optional = false
-python-versions = ">=3.6"
+python-versions = ">=3.7"
 files = [
-    {file = "importlib_metadata-4.2.0-py3-none-any.whl", hash = "sha256:057e92c15bc8d9e8109738a48db0ccb31b4d9d5cfbee5a8670879a30be66304b"},
-    {file = "importlib_metadata-4.2.0.tar.gz", hash = "sha256:b7e52a1f8dec14a75ea73e0891f3060099ca1d8e6a462a4dff11c3e119ea1b31"},
+    {file = "importlib_metadata-6.7.0-py3-none-any.whl", hash = "sha256:cb52082e659e97afc5dac71e79de97d8681de3aa07ff18578330904a9d18e5b5"},
+    {file = "importlib_metadata-6.7.0.tar.gz", hash = "sha256:1aaf550d4f73e5d6783e7acb77aec43d49da8017410afae93822cc9cca98c4d4"},
 ]
 
 [package.dependencies]
 typing-extensions = {version = ">=3.6.4", markers = "python_version < \"3.8\""}
 zipp = ">=0.5"
 
 [package.extras]
-docs = ["jaraco.packaging (>=8.2)", "rst.linker (>=1.9)", "sphinx"]
-testing = ["flufl.flake8", "importlib-resources (>=1.3)", "packaging", "pep517", "pyfakefs", "pytest (>=4.6)", "pytest-black (>=0.3.7)", "pytest-checkdocs (>=2.4)", "pytest-cov", "pytest-enabler (>=1.0.1)", "pytest-flake8", "pytest-mypy"]
+docs = ["furo", "jaraco.packaging (>=9)", "jaraco.tidelift (>=1.4)", "rst.linker (>=1.9)", "sphinx (>=3.5)", "sphinx-lint"]
+perf = ["ipython"]
+testing = ["flufl.flake8", "importlib-resources (>=1.3)", "packaging", "pyfakefs", "pytest (>=6)", "pytest-black (>=0.3.7)", "pytest-checkdocs (>=2.4)", "pytest-cov", "pytest-enabler (>=1.3)", "pytest-mypy (>=0.9.1)", "pytest-perf (>=0.9.2)", "pytest-ruff"]
 
 [[package]]
 name = "importlib-metadata"
-version = "6.6.0"
+version = "7.0.1"
 description = "Read metadata from Python packages"
 optional = false
-python-versions = ">=3.7"
+python-versions = ">=3.8"
 files = [
-    {file = "importlib_metadata-6.6.0-py3-none-any.whl", hash = "sha256:43dd286a2cd8995d5eaef7fee2066340423b818ed3fd70adf0bad5f1fac53fed"},
-    {file = "importlib_metadata-6.6.0.tar.gz", hash = "sha256:92501cdf9cc66ebd3e612f1b4f0c0765dfa42f0fa38ffb319b6bd84dd675d705"},
+    {file = "importlib_metadata-7.0.1-py3-none-any.whl", hash = "sha256:4805911c3a4ec7c3966410053e9ec6a1fecd629117df5adee56dfc9432a1081e"},
+    {file = "importlib_metadata-7.0.1.tar.gz", hash = "sha256:f238736bb06590ae52ac1fab06a3a9ef1d8dce2b7a35b5ab329371d6c8f5d2cc"},
 ]
 
 [package.dependencies]
-typing-extensions = {version = ">=3.6.4", markers = "python_version < \"3.8\""}
 zipp = ">=0.5"
 
 [package.extras]
-docs = ["furo", "jaraco.packaging (>=9)", "jaraco.tidelift (>=1.4)", "rst.linker (>=1.9)", "sphinx (>=3.5)", "sphinx-lint"]
+docs = ["furo", "jaraco.packaging (>=9.3)", "jaraco.tidelift (>=1.4)", "rst.linker (>=1.9)", "sphinx (<7.2.5)", "sphinx (>=3.5)", "sphinx-lint"]
 perf = ["ipython"]
-testing = ["flake8 (<5)", "flufl.flake8", "importlib-resources (>=1.3)", "packaging", "pyfakefs", "pytest (>=6)", "pytest-black (>=0.3.7)", "pytest-checkdocs (>=2.4)", "pytest-cov", "pytest-enabler (>=1.3)", "pytest-flake8", "pytest-mypy (>=0.9.1)", "pytest-perf (>=0.9.2)"]
+testing = ["flufl.flake8", "importlib-resources (>=1.3)", "packaging", "pyfakefs", "pytest (>=6)", "pytest-black (>=0.3.7)", "pytest-checkdocs (>=2.4)", "pytest-cov", "pytest-enabler (>=2.2)", "pytest-mypy (>=0.9.1)", "pytest-perf (>=0.9.2)", "pytest-ruff"]
 
 [[package]]
 name = "iniconfig"
 version = "2.0.0"
 description = "brain-dead simple config-ini parsing"
 optional = false
 python-versions = ">=3.7"
 files = [
     {file = "iniconfig-2.0.0-py3-none-any.whl", hash = "sha256:b6a85871a79d2e3b22d2d1b94ac2824226a63c6b741c88f7ae975f18b6778374"},
     {file = "iniconfig-2.0.0.tar.gz", hash = "sha256:2d91e135bf72d31a410b17c16da610a82cb55f6b0477d1a902134b24a455b8b3"},
 ]
 
 [[package]]
-name = "isort"
-version = "5.11.5"
-description = "A Python utility / library to sort Python imports."
-optional = false
-python-versions = ">=3.7.0"
-files = [
-    {file = "isort-5.11.5-py3-none-any.whl", hash = "sha256:ba1d72fb2595a01c7895a5128f9585a5cc4b6d395f1c8d514989b9a7eb2a8746"},
-    {file = "isort-5.11.5.tar.gz", hash = "sha256:6be1f76a507cb2ecf16c7cf14a37e41609ca082330be4e3436a18ef74add55db"},
-]
-
-[package.extras]
-colors = ["colorama (>=0.4.3,<0.5.0)"]
-pipfile-deprecated-finder = ["pip-shims (>=0.5.2)", "pipreqs", "requirementslib"]
-plugins = ["setuptools"]
-requirements-deprecated-finder = ["pip-api", "pipreqs"]
-
-[[package]]
-name = "isort"
-version = "5.12.0"
-description = "A Python utility / library to sort Python imports."
-optional = false
-python-versions = ">=3.8.0"
-files = [
-    {file = "isort-5.12.0-py3-none-any.whl", hash = "sha256:f84c2818376e66cf843d497486ea8fed8700b340f308f076c6fb1229dff318b6"},
-    {file = "isort-5.12.0.tar.gz", hash = "sha256:8bef7dde241278824a6d83f44a544709b065191b95b6e50894bdc722fcba0504"},
-]
-
-[package.extras]
-colors = ["colorama (>=0.4.3)"]
-pipfile-deprecated-finder = ["pip-shims (>=0.5.2)", "pipreqs", "requirementslib"]
-plugins = ["setuptools"]
-requirements-deprecated-finder = ["pip-api", "pipreqs"]
-
-[[package]]
 name = "jinja2"
-version = "3.1.2"
+version = "3.1.3"
 description = "A very fast and expressive template engine."
 optional = false
 python-versions = ">=3.7"
 files = [
-    {file = "Jinja2-3.1.2-py3-none-any.whl", hash = "sha256:6088930bfe239f0e6710546ab9c19c9ef35e29792895fed6e6e31a023a182a61"},
-    {file = "Jinja2-3.1.2.tar.gz", hash = "sha256:31351a702a408a9e7595a8fc6150fc3f43bb6bf7e319770cbc0db9df9437e852"},
+    {file = "Jinja2-3.1.3-py3-none-any.whl", hash = "sha256:7d6d50dd97d52cbc355597bd845fabfbac3f551e1f99619e39a35ce8c370b5fa"},
+    {file = "Jinja2-3.1.3.tar.gz", hash = "sha256:ac8bd6544d4bb2c9792bf3a159e80bba8fda7f07e81bc3aed565432d5925ba90"},
 ]
 
 [package.dependencies]
 MarkupSafe = ">=2.0"
 
 [package.extras]
 i18n = ["Babel (>=2.7)"]
 
 [[package]]
-name = "markdown-it-py"
-version = "2.2.0"
-description = "Python port of markdown-it. Markdown parsing, done right!"
-optional = false
-python-versions = ">=3.7"
-files = [
-    {file = "markdown-it-py-2.2.0.tar.gz", hash = "sha256:7c9a5e412688bc771c67432cbfebcdd686c93ce6484913dccf06cb5a0bea35a1"},
-    {file = "markdown_it_py-2.2.0-py3-none-any.whl", hash = "sha256:5a35f8d1870171d9acc47b99612dc146129b631baf04970128b568f190d0cc30"},
-]
-
-[package.dependencies]
-mdurl = ">=0.1,<1.0"
-typing_extensions = {version = ">=3.7.4", markers = "python_version < \"3.8\""}
-
-[package.extras]
-benchmarking = ["psutil", "pytest", "pytest-benchmark"]
-code-style = ["pre-commit (>=3.0,<4.0)"]
-compare = ["commonmark (>=0.9,<1.0)", "markdown (>=3.4,<4.0)", "mistletoe (>=1.0,<2.0)", "mistune (>=2.0,<3.0)", "panflute (>=2.3,<3.0)"]
-linkify = ["linkify-it-py (>=1,<3)"]
-plugins = ["mdit-py-plugins"]
-profiling = ["gprof2dot"]
-rtd = ["attrs", "myst-parser", "pyyaml", "sphinx", "sphinx-copybutton", "sphinx-design", "sphinx_book_theme"]
-testing = ["coverage", "pytest", "pytest-cov", "pytest-regressions"]
-
-[[package]]
 name = "markupsafe"
-version = "2.1.3"
+version = "2.1.5"
 description = "Safely add untrusted strings to HTML/XML markup."
 optional = false
 python-versions = ">=3.7"
 files = [
-    {file = "MarkupSafe-2.1.3-cp310-cp310-macosx_10_9_universal2.whl", hash = "sha256:cd0f502fe016460680cd20aaa5a76d241d6f35a1c3350c474bac1273803893fa"},
-    {file = "MarkupSafe-2.1.3-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:e09031c87a1e51556fdcb46e5bd4f59dfb743061cf93c4d6831bf894f125eb57"},
-    {file = "MarkupSafe-2.1.3-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:68e78619a61ecf91e76aa3e6e8e33fc4894a2bebe93410754bd28fce0a8a4f9f"},
-    {file = "MarkupSafe-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:65c1a9bcdadc6c28eecee2c119465aebff8f7a584dd719facdd9e825ec61ab52"},
-    {file = "MarkupSafe-2.1.3-cp310-cp310-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:525808b8019e36eb524b8c68acdd63a37e75714eac50e988180b169d64480a00"},
-    {file = "MarkupSafe-2.1.3-cp310-cp310-musllinux_1_1_aarch64.whl", hash = "sha256:962f82a3086483f5e5f64dbad880d31038b698494799b097bc59c2edf392fce6"},
-    {file = "MarkupSafe-2.1.3-cp310-cp310-musllinux_1_1_i686.whl", hash = "sha256:aa7bd130efab1c280bed0f45501b7c8795f9fdbeb02e965371bbef3523627779"},
-    {file = "MarkupSafe-2.1.3-cp310-cp310-musllinux_1_1_x86_64.whl", hash = "sha256:c9c804664ebe8f83a211cace637506669e7890fec1b4195b505c214e50dd4eb7"},
-    {file = "MarkupSafe-2.1.3-cp310-cp310-win32.whl", hash = "sha256:10bbfe99883db80bdbaff2dcf681dfc6533a614f700da1287707e8a5d78a8431"},
-    {file = "MarkupSafe-2.1.3-cp310-cp310-win_amd64.whl", hash = "sha256:1577735524cdad32f9f694208aa75e422adba74f1baee7551620e43a3141f559"},
-    {file = "MarkupSafe-2.1.3-cp311-cp311-macosx_10_9_universal2.whl", hash = "sha256:ad9e82fb8f09ade1c3e1b996a6337afac2b8b9e365f926f5a61aacc71adc5b3c"},
-    {file = "MarkupSafe-2.1.3-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:3c0fae6c3be832a0a0473ac912810b2877c8cb9d76ca48de1ed31e1c68386575"},
-    {file = "MarkupSafe-2.1.3-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:b076b6226fb84157e3f7c971a47ff3a679d837cf338547532ab866c57930dbee"},
-    {file = "MarkupSafe-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:bfce63a9e7834b12b87c64d6b155fdd9b3b96191b6bd334bf37db7ff1fe457f2"},
-    {file = "MarkupSafe-2.1.3-cp311-cp311-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:338ae27d6b8745585f87218a3f23f1512dbf52c26c28e322dbe54bcede54ccb9"},
-    {file = "MarkupSafe-2.1.3-cp311-cp311-musllinux_1_1_aarch64.whl", hash = "sha256:e4dd52d80b8c83fdce44e12478ad2e85c64ea965e75d66dbeafb0a3e77308fcc"},
-    {file = "MarkupSafe-2.1.3-cp311-cp311-musllinux_1_1_i686.whl", hash = "sha256:df0be2b576a7abbf737b1575f048c23fb1d769f267ec4358296f31c2479db8f9"},
-    {file = "MarkupSafe-2.1.3-cp311-cp311-musllinux_1_1_x86_64.whl", hash = "sha256:5bbe06f8eeafd38e5d0a4894ffec89378b6c6a625ff57e3028921f8ff59318ac"},
-    {file = "MarkupSafe-2.1.3-cp311-cp311-win32.whl", hash = "sha256:dd15ff04ffd7e05ffcb7fe79f1b98041b8ea30ae9234aed2a9168b5797c3effb"},
-    {file = "MarkupSafe-2.1.3-cp311-cp311-win_amd64.whl", hash = "sha256:134da1eca9ec0ae528110ccc9e48041e0828d79f24121a1a146161103c76e686"},
-    {file = "MarkupSafe-2.1.3-cp37-cp37m-macosx_10_9_x86_64.whl", hash = "sha256:8e254ae696c88d98da6555f5ace2279cf7cd5b3f52be2b5cf97feafe883b58d2"},
-    {file = "MarkupSafe-2.1.3-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:cb0932dc158471523c9637e807d9bfb93e06a95cbf010f1a38b98623b929ef2b"},
-    {file = "MarkupSafe-2.1.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:9402b03f1a1b4dc4c19845e5c749e3ab82d5078d16a2a4c2cd2df62d57bb0707"},
-    {file = "MarkupSafe-2.1.3-cp37-cp37m-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:ca379055a47383d02a5400cb0d110cef0a776fc644cda797db0c5696cfd7e18e"},
-    {file = "MarkupSafe-2.1.3-cp37-cp37m-musllinux_1_1_aarch64.whl", hash = "sha256:b7ff0f54cb4ff66dd38bebd335a38e2c22c41a8ee45aa608efc890ac3e3931bc"},
-    {file = "MarkupSafe-2.1.3-cp37-cp37m-musllinux_1_1_i686.whl", hash = "sha256:c011a4149cfbcf9f03994ec2edffcb8b1dc2d2aede7ca243746df97a5d41ce48"},
-    {file = "MarkupSafe-2.1.3-cp37-cp37m-musllinux_1_1_x86_64.whl", hash = "sha256:56d9f2ecac662ca1611d183feb03a3fa4406469dafe241673d521dd5ae92a155"},
-    {file = "MarkupSafe-2.1.3-cp37-cp37m-win32.whl", hash = "sha256:8758846a7e80910096950b67071243da3e5a20ed2546e6392603c096778d48e0"},
-    {file = "MarkupSafe-2.1.3-cp37-cp37m-win_amd64.whl", hash = "sha256:787003c0ddb00500e49a10f2844fac87aa6ce977b90b0feaaf9de23c22508b24"},
-    {file = "MarkupSafe-2.1.3-cp38-cp38-macosx_10_9_universal2.whl", hash = "sha256:2ef12179d3a291be237280175b542c07a36e7f60718296278d8593d21ca937d4"},
-    {file = "MarkupSafe-2.1.3-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:2c1b19b3aaacc6e57b7e25710ff571c24d6c3613a45e905b1fde04d691b98ee0"},
-    {file = "MarkupSafe-2.1.3-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:8afafd99945ead6e075b973fefa56379c5b5c53fd8937dad92c662da5d8fd5ee"},
-    {file = "MarkupSafe-2.1.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:8c41976a29d078bb235fea9b2ecd3da465df42a562910f9022f1a03107bd02be"},
-    {file = "MarkupSafe-2.1.3-cp38-cp38-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:d080e0a5eb2529460b30190fcfcc4199bd7f827663f858a226a81bc27beaa97e"},
-    {file = "MarkupSafe-2.1.3-cp38-cp38-musllinux_1_1_aarch64.whl", hash = "sha256:69c0f17e9f5a7afdf2cc9fb2d1ce6aabdb3bafb7f38017c0b77862bcec2bbad8"},
-    {file = "MarkupSafe-2.1.3-cp38-cp38-musllinux_1_1_i686.whl", hash = "sha256:504b320cd4b7eff6f968eddf81127112db685e81f7e36e75f9f84f0df46041c3"},
-    {file = "MarkupSafe-2.1.3-cp38-cp38-musllinux_1_1_x86_64.whl", hash = "sha256:42de32b22b6b804f42c5d98be4f7e5e977ecdd9ee9b660fda1a3edf03b11792d"},
-    {file = "MarkupSafe-2.1.3-cp38-cp38-win32.whl", hash = "sha256:ceb01949af7121f9fc39f7d27f91be8546f3fb112c608bc4029aef0bab86a2a5"},
-    {file = "MarkupSafe-2.1.3-cp38-cp38-win_amd64.whl", hash = "sha256:1b40069d487e7edb2676d3fbdb2b0829ffa2cd63a2ec26c4938b2d34391b4ecc"},
-    {file = "MarkupSafe-2.1.3-cp39-cp39-macosx_10_9_universal2.whl", hash = "sha256:8023faf4e01efadfa183e863fefde0046de576c6f14659e8782065bcece22198"},
-    {file = "MarkupSafe-2.1.3-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:6b2b56950d93e41f33b4223ead100ea0fe11f8e6ee5f641eb753ce4b77a7042b"},
-    {file = "MarkupSafe-2.1.3-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:9dcdfd0eaf283af041973bff14a2e143b8bd64e069f4c383416ecd79a81aab58"},
-    {file = "MarkupSafe-2.1.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:05fb21170423db021895e1ea1e1f3ab3adb85d1c2333cbc2310f2a26bc77272e"},
-    {file = "MarkupSafe-2.1.3-cp39-cp39-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:282c2cb35b5b673bbcadb33a585408104df04f14b2d9b01d4c345a3b92861c2c"},
-    {file = "MarkupSafe-2.1.3-cp39-cp39-musllinux_1_1_aarch64.whl", hash = "sha256:ab4a0df41e7c16a1392727727e7998a467472d0ad65f3ad5e6e765015df08636"},
-    {file = "MarkupSafe-2.1.3-cp39-cp39-musllinux_1_1_i686.whl", hash = "sha256:7ef3cb2ebbf91e330e3bb937efada0edd9003683db6b57bb108c4001f37a02ea"},
-    {file = "MarkupSafe-2.1.3-cp39-cp39-musllinux_1_1_x86_64.whl", hash = "sha256:0a4e4a1aff6c7ac4cd55792abf96c915634c2b97e3cc1c7129578aa68ebd754e"},
-    {file = "MarkupSafe-2.1.3-cp39-cp39-win32.whl", hash = "sha256:fec21693218efe39aa7f8599346e90c705afa52c5b31ae019b2e57e8f6542bb2"},
-    {file = "MarkupSafe-2.1.3-cp39-cp39-win_amd64.whl", hash = "sha256:3fd4abcb888d15a94f32b75d8fd18ee162ca0c064f35b11134be77050296d6ba"},
-    {file = "MarkupSafe-2.1.3.tar.gz", hash = "sha256:af598ed32d6ae86f1b747b82783958b1a4ab8f617b06fe68795c7f026abbdcad"},
-]
-
-[[package]]
-name = "mccabe"
-version = "0.7.0"
-description = "McCabe checker, plugin for flake8"
-optional = false
-python-versions = ">=3.6"
-files = [
-    {file = "mccabe-0.7.0-py2.py3-none-any.whl", hash = "sha256:6c2d30ab6be0e4a46919781807b4f0d834ebdd6c6e3dca0bda5a15f863427b6e"},
-    {file = "mccabe-0.7.0.tar.gz", hash = "sha256:348e0240c33b60bbdf4e523192ef919f28cb2c3d7d5c7794f74009290f236325"},
+    {file = "MarkupSafe-2.1.5-cp310-cp310-macosx_10_9_universal2.whl", hash = "sha256:a17a92de5231666cfbe003f0e4b9b3a7ae3afb1ec2845aadc2bacc93ff85febc"},
+    {file = "MarkupSafe-2.1.5-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:72b6be590cc35924b02c78ef34b467da4ba07e4e0f0454a2c5907f473fc50ce5"},
+    {file = "MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:e61659ba32cf2cf1481e575d0462554625196a1f2fc06a1c777d3f48e8865d46"},
+    {file = "MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:2174c595a0d73a3080ca3257b40096db99799265e1c27cc5a610743acd86d62f"},
+    {file = "MarkupSafe-2.1.5-cp310-cp310-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:ae2ad8ae6ebee9d2d94b17fb62763125f3f374c25618198f40cbb8b525411900"},
+    {file = "MarkupSafe-2.1.5-cp310-cp310-musllinux_1_1_aarch64.whl", hash = "sha256:075202fa5b72c86ad32dc7d0b56024ebdbcf2048c0ba09f1cde31bfdd57bcfff"},
+    {file = "MarkupSafe-2.1.5-cp310-cp310-musllinux_1_1_i686.whl", hash = "sha256:598e3276b64aff0e7b3451b72e94fa3c238d452e7ddcd893c3ab324717456bad"},
+    {file = "MarkupSafe-2.1.5-cp310-cp310-musllinux_1_1_x86_64.whl", hash = "sha256:fce659a462a1be54d2ffcacea5e3ba2d74daa74f30f5f143fe0c58636e355fdd"},
+    {file = "MarkupSafe-2.1.5-cp310-cp310-win32.whl", hash = "sha256:d9fad5155d72433c921b782e58892377c44bd6252b5af2f67f16b194987338a4"},
+    {file = "MarkupSafe-2.1.5-cp310-cp310-win_amd64.whl", hash = "sha256:bf50cd79a75d181c9181df03572cdce0fbb75cc353bc350712073108cba98de5"},
+    {file = "MarkupSafe-2.1.5-cp311-cp311-macosx_10_9_universal2.whl", hash = "sha256:629ddd2ca402ae6dbedfceeba9c46d5f7b2a61d9749597d4307f943ef198fc1f"},
+    {file = "MarkupSafe-2.1.5-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:5b7b716f97b52c5a14bffdf688f971b2d5ef4029127f1ad7a513973cfd818df2"},
+    {file = "MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:6ec585f69cec0aa07d945b20805be741395e28ac1627333b1c5b0105962ffced"},
+    {file = "MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:b91c037585eba9095565a3556f611e3cbfaa42ca1e865f7b8015fe5c7336d5a5"},
+    {file = "MarkupSafe-2.1.5-cp311-cp311-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:7502934a33b54030eaf1194c21c692a534196063db72176b0c4028e140f8f32c"},
+    {file = "MarkupSafe-2.1.5-cp311-cp311-musllinux_1_1_aarch64.whl", hash = "sha256:0e397ac966fdf721b2c528cf028494e86172b4feba51d65f81ffd65c63798f3f"},
+    {file = "MarkupSafe-2.1.5-cp311-cp311-musllinux_1_1_i686.whl", hash = "sha256:c061bb86a71b42465156a3ee7bd58c8c2ceacdbeb95d05a99893e08b8467359a"},
+    {file = "MarkupSafe-2.1.5-cp311-cp311-musllinux_1_1_x86_64.whl", hash = "sha256:3a57fdd7ce31c7ff06cdfbf31dafa96cc533c21e443d57f5b1ecc6cdc668ec7f"},
+    {file = "MarkupSafe-2.1.5-cp311-cp311-win32.whl", hash = "sha256:397081c1a0bfb5124355710fe79478cdbeb39626492b15d399526ae53422b906"},
+    {file = "MarkupSafe-2.1.5-cp311-cp311-win_amd64.whl", hash = "sha256:2b7c57a4dfc4f16f7142221afe5ba4e093e09e728ca65c51f5620c9aaeb9a617"},
+    {file = "MarkupSafe-2.1.5-cp312-cp312-macosx_10_9_universal2.whl", hash = "sha256:8dec4936e9c3100156f8a2dc89c4b88d5c435175ff03413b443469c7c8c5f4d1"},
+    {file = "MarkupSafe-2.1.5-cp312-cp312-macosx_10_9_x86_64.whl", hash = "sha256:3c6b973f22eb18a789b1460b4b91bf04ae3f0c4234a0a6aa6b0a92f6f7b951d4"},
+    {file = "MarkupSafe-2.1.5-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:ac07bad82163452a6884fe8fa0963fb98c2346ba78d779ec06bd7a6262132aee"},
+    {file = "MarkupSafe-2.1.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:f5dfb42c4604dddc8e4305050aa6deb084540643ed5804d7455b5df8fe16f5e5"},
+    {file = "MarkupSafe-2.1.5-cp312-cp312-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:ea3d8a3d18833cf4304cd2fc9cbb1efe188ca9b5efef2bdac7adc20594a0e46b"},
+    {file = "MarkupSafe-2.1.5-cp312-cp312-musllinux_1_1_aarch64.whl", hash = "sha256:d050b3361367a06d752db6ead6e7edeb0009be66bc3bae0ee9d97fb326badc2a"},
+    {file = "MarkupSafe-2.1.5-cp312-cp312-musllinux_1_1_i686.whl", hash = "sha256:bec0a414d016ac1a18862a519e54b2fd0fc8bbfd6890376898a6c0891dd82e9f"},
+    {file = "MarkupSafe-2.1.5-cp312-cp312-musllinux_1_1_x86_64.whl", hash = "sha256:58c98fee265677f63a4385256a6d7683ab1832f3ddd1e66fe948d5880c21a169"},
+    {file = "MarkupSafe-2.1.5-cp312-cp312-win32.whl", hash = "sha256:8590b4ae07a35970728874632fed7bd57b26b0102df2d2b233b6d9d82f6c62ad"},
+    {file = "MarkupSafe-2.1.5-cp312-cp312-win_amd64.whl", hash = "sha256:823b65d8706e32ad2df51ed89496147a42a2a6e01c13cfb6ffb8b1e92bc910bb"},
+    {file = "MarkupSafe-2.1.5-cp37-cp37m-macosx_10_9_x86_64.whl", hash = "sha256:c8b29db45f8fe46ad280a7294f5c3ec36dbac9491f2d1c17345be8e69cc5928f"},
+    {file = "MarkupSafe-2.1.5-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:ec6a563cff360b50eed26f13adc43e61bc0c04d94b8be985e6fb24b81f6dcfdf"},
+    {file = "MarkupSafe-2.1.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:a549b9c31bec33820e885335b451286e2969a2d9e24879f83fe904a5ce59d70a"},
+    {file = "MarkupSafe-2.1.5-cp37-cp37m-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:4f11aa001c540f62c6166c7726f71f7573b52c68c31f014c25cc7901deea0b52"},
+    {file = "MarkupSafe-2.1.5-cp37-cp37m-musllinux_1_1_aarch64.whl", hash = "sha256:7b2e5a267c855eea6b4283940daa6e88a285f5f2a67f2220203786dfa59b37e9"},
+    {file = "MarkupSafe-2.1.5-cp37-cp37m-musllinux_1_1_i686.whl", hash = "sha256:2d2d793e36e230fd32babe143b04cec8a8b3eb8a3122d2aceb4a371e6b09b8df"},
+    {file = "MarkupSafe-2.1.5-cp37-cp37m-musllinux_1_1_x86_64.whl", hash = "sha256:ce409136744f6521e39fd8e2a24c53fa18ad67aa5bc7c2cf83645cce5b5c4e50"},
+    {file = "MarkupSafe-2.1.5-cp37-cp37m-win32.whl", hash = "sha256:4096e9de5c6fdf43fb4f04c26fb114f61ef0bf2e5604b6ee3019d51b69e8c371"},
+    {file = "MarkupSafe-2.1.5-cp37-cp37m-win_amd64.whl", hash = "sha256:4275d846e41ecefa46e2015117a9f491e57a71ddd59bbead77e904dc02b1bed2"},
+    {file = "MarkupSafe-2.1.5-cp38-cp38-macosx_10_9_universal2.whl", hash = "sha256:656f7526c69fac7f600bd1f400991cc282b417d17539a1b228617081106feb4a"},
+    {file = "MarkupSafe-2.1.5-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:97cafb1f3cbcd3fd2b6fbfb99ae11cdb14deea0736fc2b0952ee177f2b813a46"},
+    {file = "MarkupSafe-2.1.5-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:1f3fbcb7ef1f16e48246f704ab79d79da8a46891e2da03f8783a5b6fa41a9532"},
+    {file = "MarkupSafe-2.1.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:fa9db3f79de01457b03d4f01b34cf91bc0048eb2c3846ff26f66687c2f6d16ab"},
+    {file = "MarkupSafe-2.1.5-cp38-cp38-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:ffee1f21e5ef0d712f9033568f8344d5da8cc2869dbd08d87c84656e6a2d2f68"},
+    {file = "MarkupSafe-2.1.5-cp38-cp38-musllinux_1_1_aarch64.whl", hash = "sha256:5dedb4db619ba5a2787a94d877bc8ffc0566f92a01c0ef214865e54ecc9ee5e0"},
+    {file = "MarkupSafe-2.1.5-cp38-cp38-musllinux_1_1_i686.whl", hash = "sha256:30b600cf0a7ac9234b2638fbc0fb6158ba5bdcdf46aeb631ead21248b9affbc4"},
+    {file = "MarkupSafe-2.1.5-cp38-cp38-musllinux_1_1_x86_64.whl", hash = "sha256:8dd717634f5a044f860435c1d8c16a270ddf0ef8588d4887037c5028b859b0c3"},
+    {file = "MarkupSafe-2.1.5-cp38-cp38-win32.whl", hash = "sha256:daa4ee5a243f0f20d528d939d06670a298dd39b1ad5f8a72a4275124a7819eff"},
+    {file = "MarkupSafe-2.1.5-cp38-cp38-win_amd64.whl", hash = "sha256:619bc166c4f2de5caa5a633b8b7326fbe98e0ccbfacabd87268a2b15ff73a029"},
+    {file = "MarkupSafe-2.1.5-cp39-cp39-macosx_10_9_universal2.whl", hash = "sha256:7a68b554d356a91cce1236aa7682dc01df0edba8d043fd1ce607c49dd3c1edcf"},
+    {file = "MarkupSafe-2.1.5-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:db0b55e0f3cc0be60c1f19efdde9a637c32740486004f20d1cff53c3c0ece4d2"},
+    {file = "MarkupSafe-2.1.5-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:3e53af139f8579a6d5f7b76549125f0d94d7e630761a2111bc431fd820e163b8"},
+    {file = "MarkupSafe-2.1.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:17b950fccb810b3293638215058e432159d2b71005c74371d784862b7e4683f3"},
+    {file = "MarkupSafe-2.1.5-cp39-cp39-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:4c31f53cdae6ecfa91a77820e8b151dba54ab528ba65dfd235c80b086d68a465"},
+    {file = "MarkupSafe-2.1.5-cp39-cp39-musllinux_1_1_aarch64.whl", hash = "sha256:bff1b4290a66b490a2f4719358c0cdcd9bafb6b8f061e45c7a2460866bf50c2e"},
+    {file = "MarkupSafe-2.1.5-cp39-cp39-musllinux_1_1_i686.whl", hash = "sha256:bc1667f8b83f48511b94671e0e441401371dfd0f0a795c7daa4a3cd1dde55bea"},
+    {file = "MarkupSafe-2.1.5-cp39-cp39-musllinux_1_1_x86_64.whl", hash = "sha256:5049256f536511ee3f7e1b3f87d1d1209d327e818e6ae1365e8653d7e3abb6a6"},
+    {file = "MarkupSafe-2.1.5-cp39-cp39-win32.whl", hash = "sha256:00e046b6dd71aa03a41079792f8473dc494d564611a8f89bbbd7cb93295ebdcf"},
+    {file = "MarkupSafe-2.1.5-cp39-cp39-win_amd64.whl", hash = "sha256:fa173ec60341d6bb97a89f5ea19c85c5643c1e7dedebc22f5181eb73573142c5"},
+    {file = "MarkupSafe-2.1.5.tar.gz", hash = "sha256:d283d37a890ba4c1ae73ffadf8046435c76e7bc2247bbb63c00bd1a709c6544b"},
 ]
 
 [[package]]
-name = "mdurl"
-version = "0.1.2"
-description = "Markdown URL utilities"
+name = "mypy"
+version = "1.4.1"
+description = "Optional static typing for Python"
 optional = false
 python-versions = ">=3.7"
 files = [
-    {file = "mdurl-0.1.2-py3-none-any.whl", hash = "sha256:84008a41e51615a49fc9966191ff91509e3c40b939176e643fd50a5c2196b8f8"},
-    {file = "mdurl-0.1.2.tar.gz", hash = "sha256:bb413d29f5eea38f31dd4754dd7377d4465116fb207585f97bf925588687c1ba"},
+    {file = "mypy-1.4.1-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:566e72b0cd6598503e48ea610e0052d1b8168e60a46e0bfd34b3acf2d57f96a8"},
+    {file = "mypy-1.4.1-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:ca637024ca67ab24a7fd6f65d280572c3794665eaf5edcc7e90a866544076878"},
+    {file = "mypy-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:0dde1d180cd84f0624c5dcaaa89c89775550a675aff96b5848de78fb11adabcd"},
+    {file = "mypy-1.4.1-cp310-cp310-musllinux_1_1_x86_64.whl", hash = "sha256:8c4d8e89aa7de683e2056a581ce63c46a0c41e31bd2b6d34144e2c80f5ea53dc"},
+    {file = "mypy-1.4.1-cp310-cp310-win_amd64.whl", hash = "sha256:bfdca17c36ae01a21274a3c387a63aa1aafe72bff976522886869ef131b937f1"},
+    {file = "mypy-1.4.1-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:7549fbf655e5825d787bbc9ecf6028731973f78088fbca3a1f4145c39ef09462"},
+    {file = "mypy-1.4.1-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:98324ec3ecf12296e6422939e54763faedbfcc502ea4a4c38502082711867258"},
+    {file = "mypy-1.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:141dedfdbfe8a04142881ff30ce6e6653c9685b354876b12e4fe6c78598b45e2"},
+    {file = "mypy-1.4.1-cp311-cp311-musllinux_1_1_x86_64.whl", hash = "sha256:8207b7105829eca6f3d774f64a904190bb2231de91b8b186d21ffd98005f14a7"},
+    {file = "mypy-1.4.1-cp311-cp311-win_amd64.whl", hash = "sha256:16f0db5b641ba159eff72cff08edc3875f2b62b2fa2bc24f68c1e7a4e8232d01"},
+    {file = "mypy-1.4.1-cp37-cp37m-macosx_10_9_x86_64.whl", hash = "sha256:470c969bb3f9a9efcedbadcd19a74ffb34a25f8e6b0e02dae7c0e71f8372f97b"},
+    {file = "mypy-1.4.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:e5952d2d18b79f7dc25e62e014fe5a23eb1a3d2bc66318df8988a01b1a037c5b"},
+    {file = "mypy-1.4.1-cp37-cp37m-musllinux_1_1_x86_64.whl", hash = "sha256:190b6bab0302cec4e9e6767d3eb66085aef2a1cc98fe04936d8a42ed2ba77bb7"},
+    {file = "mypy-1.4.1-cp37-cp37m-win_amd64.whl", hash = "sha256:9d40652cc4fe33871ad3338581dca3297ff5f2213d0df345bcfbde5162abf0c9"},
+    {file = "mypy-1.4.1-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:01fd2e9f85622d981fd9063bfaef1aed6e336eaacca00892cd2d82801ab7c042"},
+    {file = "mypy-1.4.1-cp38-cp38-macosx_11_0_arm64.whl", hash = "sha256:2460a58faeea905aeb1b9b36f5065f2dc9a9c6e4c992a6499a2360c6c74ceca3"},
+    {file = "mypy-1.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:a2746d69a8196698146a3dbe29104f9eb6a2a4d8a27878d92169a6c0b74435b6"},
+    {file = "mypy-1.4.1-cp38-cp38-musllinux_1_1_x86_64.whl", hash = "sha256:ae704dcfaa180ff7c4cfbad23e74321a2b774f92ca77fd94ce1049175a21c97f"},
+    {file = "mypy-1.4.1-cp38-cp38-win_amd64.whl", hash = "sha256:43d24f6437925ce50139a310a64b2ab048cb2d3694c84c71c3f2a1626d8101dc"},
+    {file = "mypy-1.4.1-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:c482e1246726616088532b5e964e39765b6d1520791348e6c9dc3af25b233828"},
+    {file = "mypy-1.4.1-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:43b592511672017f5b1a483527fd2684347fdffc041c9ef53428c8dc530f79a3"},
+    {file = "mypy-1.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:34a9239d5b3502c17f07fd7c0b2ae6b7dd7d7f6af35fbb5072c6208e76295816"},
+    {file = "mypy-1.4.1-cp39-cp39-musllinux_1_1_x86_64.whl", hash = "sha256:5703097c4936bbb9e9bce41478c8d08edd2865e177dc4c52be759f81ee4dd26c"},
+    {file = "mypy-1.4.1-cp39-cp39-win_amd64.whl", hash = "sha256:e02d700ec8d9b1859790c0475df4e4092c7bf3272a4fd2c9f33d87fac4427b8f"},
+    {file = "mypy-1.4.1-py3-none-any.whl", hash = "sha256:45d32cec14e7b97af848bddd97d85ea4f0db4d5a149ed9676caa4eb2f7402bb4"},
+    {file = "mypy-1.4.1.tar.gz", hash = "sha256:9bbcd9ab8ea1f2e1c8031c21445b511442cc45c89951e49bbf852cbb70755b1b"},
 ]
 
+[package.dependencies]
+mypy-extensions = ">=1.0.0"
+tomli = {version = ">=1.1.0", markers = "python_version < \"3.11\""}
+typed-ast = {version = ">=1.4.0,<2", markers = "python_version < \"3.8\""}
+typing-extensions = ">=4.1.0"
+
+[package.extras]
+dmypy = ["psutil (>=4.0)"]
+install-types = ["pip"]
+python2 = ["typed-ast (>=1.4.0,<2)"]
+reports = ["lxml"]
+
 [[package]]
 name = "mypy"
-version = "1.3.0"
+version = "1.8.0"
 description = "Optional static typing for Python"
 optional = false
-python-versions = ">=3.7"
+python-versions = ">=3.8"
 files = [
-    {file = "mypy-1.3.0-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:c1eb485cea53f4f5284e5baf92902cd0088b24984f4209e25981cc359d64448d"},
-    {file = "mypy-1.3.0-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:4c99c3ecf223cf2952638da9cd82793d8f3c0c5fa8b6ae2b2d9ed1e1ff51ba85"},
-    {file = "mypy-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:550a8b3a19bb6589679a7c3c31f64312e7ff482a816c96e0cecec9ad3a7564dd"},
-    {file = "mypy-1.3.0-cp310-cp310-musllinux_1_1_x86_64.whl", hash = "sha256:cbc07246253b9e3d7d74c9ff948cd0fd7a71afcc2b77c7f0a59c26e9395cb152"},
-    {file = "mypy-1.3.0-cp310-cp310-win_amd64.whl", hash = "sha256:a22435632710a4fcf8acf86cbd0d69f68ac389a3892cb23fbad176d1cddaf228"},
-    {file = "mypy-1.3.0-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:6e33bb8b2613614a33dff70565f4c803f889ebd2f859466e42b46e1df76018dd"},
-    {file = "mypy-1.3.0-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:7d23370d2a6b7a71dc65d1266f9a34e4cde9e8e21511322415db4b26f46f6b8c"},
-    {file = "mypy-1.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:658fe7b674769a0770d4b26cb4d6f005e88a442fe82446f020be8e5f5efb2fae"},
-    {file = "mypy-1.3.0-cp311-cp311-musllinux_1_1_x86_64.whl", hash = "sha256:6e42d29e324cdda61daaec2336c42512e59c7c375340bd202efa1fe0f7b8f8ca"},
-    {file = "mypy-1.3.0-cp311-cp311-win_amd64.whl", hash = "sha256:d0b6c62206e04061e27009481cb0ec966f7d6172b5b936f3ead3d74f29fe3dcf"},
-    {file = "mypy-1.3.0-cp37-cp37m-macosx_10_9_x86_64.whl", hash = "sha256:76ec771e2342f1b558c36d49900dfe81d140361dd0d2df6cd71b3db1be155409"},
-    {file = "mypy-1.3.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:ebc95f8386314272bbc817026f8ce8f4f0d2ef7ae44f947c4664efac9adec929"},
-    {file = "mypy-1.3.0-cp37-cp37m-musllinux_1_1_x86_64.whl", hash = "sha256:faff86aa10c1aa4a10e1a301de160f3d8fc8703b88c7e98de46b531ff1276a9a"},
-    {file = "mypy-1.3.0-cp37-cp37m-win_amd64.whl", hash = "sha256:8c5979d0deb27e0f4479bee18ea0f83732a893e81b78e62e2dda3e7e518c92ee"},
-    {file = "mypy-1.3.0-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:c5d2cc54175bab47011b09688b418db71403aefad07cbcd62d44010543fc143f"},
-    {file = "mypy-1.3.0-cp38-cp38-macosx_11_0_arm64.whl", hash = "sha256:87df44954c31d86df96c8bd6e80dfcd773473e877ac6176a8e29898bfb3501cb"},
-    {file = "mypy-1.3.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:473117e310febe632ddf10e745a355714e771ffe534f06db40702775056614c4"},
-    {file = "mypy-1.3.0-cp38-cp38-musllinux_1_1_x86_64.whl", hash = "sha256:74bc9b6e0e79808bf8678d7678b2ae3736ea72d56eede3820bd3849823e7f305"},
-    {file = "mypy-1.3.0-cp38-cp38-win_amd64.whl", hash = "sha256:44797d031a41516fcf5cbfa652265bb994e53e51994c1bd649ffcd0c3a7eccbf"},
-    {file = "mypy-1.3.0-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:ddae0f39ca146972ff6bb4399f3b2943884a774b8771ea0a8f50e971f5ea5ba8"},
-    {file = "mypy-1.3.0-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:1c4c42c60a8103ead4c1c060ac3cdd3ff01e18fddce6f1016e08939647a0e703"},
-    {file = "mypy-1.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:e86c2c6852f62f8f2b24cb7a613ebe8e0c7dc1402c61d36a609174f63e0ff017"},
-    {file = "mypy-1.3.0-cp39-cp39-musllinux_1_1_x86_64.whl", hash = "sha256:f9dca1e257d4cc129517779226753dbefb4f2266c4eaad610fc15c6a7e14283e"},
-    {file = "mypy-1.3.0-cp39-cp39-win_amd64.whl", hash = "sha256:95d8d31a7713510685b05fbb18d6ac287a56c8f6554d88c19e73f724a445448a"},
-    {file = "mypy-1.3.0-py3-none-any.whl", hash = "sha256:a8763e72d5d9574d45ce5881962bc8e9046bf7b375b0abf031f3e6811732a897"},
-    {file = "mypy-1.3.0.tar.gz", hash = "sha256:e1f4d16e296f5135624b34e8fb741eb0eadedca90862405b1f1fde2040b9bd11"},
+    {file = "mypy-1.8.0-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:485a8942f671120f76afffff70f259e1cd0f0cfe08f81c05d8816d958d4577d3"},
+    {file = "mypy-1.8.0-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:df9824ac11deaf007443e7ed2a4a26bebff98d2bc43c6da21b2b64185da011c4"},
+    {file = "mypy-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:2afecd6354bbfb6e0160f4e4ad9ba6e4e003b767dd80d85516e71f2e955ab50d"},
+    {file = "mypy-1.8.0-cp310-cp310-musllinux_1_1_x86_64.whl", hash = "sha256:8963b83d53ee733a6e4196954502b33567ad07dfd74851f32be18eb932fb1cb9"},
+    {file = "mypy-1.8.0-cp310-cp310-win_amd64.whl", hash = "sha256:e46f44b54ebddbeedbd3d5b289a893219065ef805d95094d16a0af6630f5d410"},
+    {file = "mypy-1.8.0-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:855fe27b80375e5c5878492f0729540db47b186509c98dae341254c8f45f42ae"},
+    {file = "mypy-1.8.0-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:4c886c6cce2d070bd7df4ec4a05a13ee20c0aa60cb587e8d1265b6c03cf91da3"},
+    {file = "mypy-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:d19c413b3c07cbecf1f991e2221746b0d2a9410b59cb3f4fb9557f0365a1a817"},
+    {file = "mypy-1.8.0-cp311-cp311-musllinux_1_1_x86_64.whl", hash = "sha256:9261ed810972061388918c83c3f5cd46079d875026ba97380f3e3978a72f503d"},
+    {file = "mypy-1.8.0-cp311-cp311-win_amd64.whl", hash = "sha256:51720c776d148bad2372ca21ca29256ed483aa9a4cdefefcef49006dff2a6835"},
+    {file = "mypy-1.8.0-cp312-cp312-macosx_10_9_x86_64.whl", hash = "sha256:52825b01f5c4c1c4eb0db253ec09c7aa17e1a7304d247c48b6f3599ef40db8bd"},
+    {file = "mypy-1.8.0-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:f5ac9a4eeb1ec0f1ccdc6f326bcdb464de5f80eb07fb38b5ddd7b0de6bc61e55"},
+    {file = "mypy-1.8.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:afe3fe972c645b4632c563d3f3eff1cdca2fa058f730df2b93a35e3b0c538218"},
+    {file = "mypy-1.8.0-cp312-cp312-musllinux_1_1_x86_64.whl", hash = "sha256:42c6680d256ab35637ef88891c6bd02514ccb7e1122133ac96055ff458f93fc3"},
+    {file = "mypy-1.8.0-cp312-cp312-win_amd64.whl", hash = "sha256:720a5ca70e136b675af3af63db533c1c8c9181314d207568bbe79051f122669e"},
+    {file = "mypy-1.8.0-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:028cf9f2cae89e202d7b6593cd98db6759379f17a319b5faf4f9978d7084cdc6"},
+    {file = "mypy-1.8.0-cp38-cp38-macosx_11_0_arm64.whl", hash = "sha256:4e6d97288757e1ddba10dd9549ac27982e3e74a49d8d0179fc14d4365c7add66"},
+    {file = "mypy-1.8.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:7f1478736fcebb90f97e40aff11a5f253af890c845ee0c850fe80aa060a267c6"},
+    {file = "mypy-1.8.0-cp38-cp38-musllinux_1_1_x86_64.whl", hash = "sha256:42419861b43e6962a649068a61f4a4839205a3ef525b858377a960b9e2de6e0d"},
+    {file = "mypy-1.8.0-cp38-cp38-win_amd64.whl", hash = "sha256:2b5b6c721bd4aabaadead3a5e6fa85c11c6c795e0c81a7215776ef8afc66de02"},
+    {file = "mypy-1.8.0-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:5c1538c38584029352878a0466f03a8ee7547d7bd9f641f57a0f3017a7c905b8"},
+    {file = "mypy-1.8.0-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:4ef4be7baf08a203170f29e89d79064463b7fc7a0908b9d0d5114e8009c3a259"},
+    {file = "mypy-1.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:7178def594014aa6c35a8ff411cf37d682f428b3b5617ca79029d8ae72f5402b"},
+    {file = "mypy-1.8.0-cp39-cp39-musllinux_1_1_x86_64.whl", hash = "sha256:ab3c84fa13c04aeeeabb2a7f67a25ef5d77ac9d6486ff33ded762ef353aa5592"},
+    {file = "mypy-1.8.0-cp39-cp39-win_amd64.whl", hash = "sha256:99b00bc72855812a60d253420d8a2eae839b0afa4938f09f4d2aa9bb4654263a"},
+    {file = "mypy-1.8.0-py3-none-any.whl", hash = "sha256:538fd81bb5e430cc1381a443971c0475582ff9f434c16cd46d2c66763ce85d9d"},
+    {file = "mypy-1.8.0.tar.gz", hash = "sha256:6ff8b244d7085a0b425b56d327b480c3b29cafbd2eff27316a004f9a7391ae07"},
 ]
 
 [package.dependencies]
 mypy-extensions = ">=1.0.0"
 tomli = {version = ">=1.1.0", markers = "python_version < \"3.11\""}
-typed-ast = {version = ">=1.4.0,<2", markers = "python_version < \"3.8\""}
-typing-extensions = ">=3.10"
+typing-extensions = ">=4.1.0"
 
 [package.extras]
 dmypy = ["psutil (>=4.0)"]
 install-types = ["pip"]
-python2 = ["typed-ast (>=1.4.0,<2)"]
+mypyc = ["setuptools (>=50)"]
 reports = ["lxml"]
 
 [[package]]
 name = "mypy-extensions"
 version = "1.0.0"
 description = "Type system extensions for programs checked with the mypy type checker."
 optional = false
@@ -819,77 +596,85 @@
 files = [
     {file = "mypy_extensions-1.0.0-py3-none-any.whl", hash = "sha256:4392f6c0eb8a5668a69e23d168ffa70f0be9ccfd32b5cc2d26a34ae5b844552d"},
     {file = "mypy_extensions-1.0.0.tar.gz", hash = "sha256:75dbf8955dc00442a438fc4d0666508a9a97b6bd41aa2f0ffe9d2f2725af0782"},
 ]
 
 [[package]]
 name = "packaging"
-version = "23.1"
+version = "23.2"
 description = "Core utilities for Python packages"
 optional = false
 python-versions = ">=3.7"
 files = [
-    {file = "packaging-23.1-py3-none-any.whl", hash = "sha256:994793af429502c4ea2ebf6bf664629d07c1a9fe974af92966e4b8d2df7edc61"},
-    {file = "packaging-23.1.tar.gz", hash = "sha256:a392980d2b6cffa644431898be54b0045151319d1e7ec34f0cfed48767dd334f"},
+    {file = "packaging-23.2-py3-none-any.whl", hash = "sha256:8c491190033a9af7e1d931d0b5dacc2ef47509b34dd0de67ed209b5203fc88c7"},
+    {file = "packaging-23.2.tar.gz", hash = "sha256:048fb0e9405036518eaaf48a55953c750c11e1a1b68e0dd1a9d62ed0c092cfc5"},
 ]
 
 [[package]]
-name = "pathspec"
-version = "0.11.1"
-description = "Utility library for gitignore style pattern matching of file paths."
+name = "platformdirs"
+version = "4.0.0"
+description = "A small Python package for determining appropriate platform-specific dirs, e.g. a \"user data dir\"."
 optional = false
 python-versions = ">=3.7"
 files = [
-    {file = "pathspec-0.11.1-py3-none-any.whl", hash = "sha256:d8af70af76652554bd134c22b3e8a1cc46ed7d91edcdd721ef1a0c51a84a5293"},
-    {file = "pathspec-0.11.1.tar.gz", hash = "sha256:2798de800fa92780e33acca925945e9a19a133b715067cf165b8866c15a31687"},
+    {file = "platformdirs-4.0.0-py3-none-any.whl", hash = "sha256:118c954d7e949b35437270383a3f2531e99dd93cf7ce4dc8340d3356d30f173b"},
+    {file = "platformdirs-4.0.0.tar.gz", hash = "sha256:cb633b2bcf10c51af60beb0ab06d2f1d69064b43abf4c185ca6b28865f3f9731"},
 ]
 
+[package.dependencies]
+typing-extensions = {version = ">=4.7.1", markers = "python_version < \"3.8\""}
+
+[package.extras]
+docs = ["furo (>=2023.7.26)", "proselint (>=0.13)", "sphinx (>=7.1.1)", "sphinx-autodoc-typehints (>=1.24)"]
+test = ["appdirs (==1.4.4)", "covdefaults (>=2.3)", "pytest (>=7.4)", "pytest-cov (>=4.1)", "pytest-mock (>=3.11.1)"]
+
 [[package]]
-name = "pbr"
-version = "5.11.1"
-description = "Python Build Reasonableness"
+name = "platformdirs"
+version = "4.2.0"
+description = "A small Python package for determining appropriate platform-specific dirs, e.g. a \"user data dir\"."
 optional = false
-python-versions = ">=2.6"
+python-versions = ">=3.8"
 files = [
-    {file = "pbr-5.11.1-py2.py3-none-any.whl", hash = "sha256:567f09558bae2b3ab53cb3c1e2e33e726ff3338e7bae3db5dc954b3a44eef12b"},
-    {file = "pbr-5.11.1.tar.gz", hash = "sha256:aefc51675b0b533d56bb5fd1c8c6c0522fe31896679882e1c4c63d5e4a0fccb3"},
+    {file = "platformdirs-4.2.0-py3-none-any.whl", hash = "sha256:0614df2a2f37e1a662acbd8e2b25b92ccf8632929bc6d43467e17fe89c75e068"},
+    {file = "platformdirs-4.2.0.tar.gz", hash = "sha256:ef0cc731df711022c174543cb70a9b5bd22e5a9337c8624ef2c2ceb8ddad8768"},
 ]
 
+[package.extras]
+docs = ["furo (>=2023.9.10)", "proselint (>=0.13)", "sphinx (>=7.2.6)", "sphinx-autodoc-typehints (>=1.25.2)"]
+test = ["appdirs (==1.4.4)", "covdefaults (>=2.3)", "pytest (>=7.4.3)", "pytest-cov (>=4.1)", "pytest-mock (>=3.12)"]
+
 [[package]]
-name = "platformdirs"
-version = "3.5.1"
-description = "A small Python package for determining appropriate platform-specific dirs, e.g. a \"user data dir\"."
+name = "pluggy"
+version = "1.2.0"
+description = "plugin and hook calling mechanisms for python"
 optional = false
 python-versions = ">=3.7"
 files = [
-    {file = "platformdirs-3.5.1-py3-none-any.whl", hash = "sha256:e2378146f1964972c03c085bb5662ae80b2b8c06226c54b2ff4aa9483e8a13a5"},
-    {file = "platformdirs-3.5.1.tar.gz", hash = "sha256:412dae91f52a6f84830f39a8078cecd0e866cb72294a5c66808e74d5e88d251f"},
+    {file = "pluggy-1.2.0-py3-none-any.whl", hash = "sha256:c2fd55a7d7a3863cba1a013e4e2414658b1d07b6bc57b3919e0c63c9abb99849"},
+    {file = "pluggy-1.2.0.tar.gz", hash = "sha256:d12f0c4b579b15f5e054301bb226ee85eeeba08ffec228092f8defbaa3a4c4b3"},
 ]
 
 [package.dependencies]
-typing-extensions = {version = ">=4.5", markers = "python_version < \"3.8\""}
+importlib-metadata = {version = ">=0.12", markers = "python_version < \"3.8\""}
 
 [package.extras]
-docs = ["furo (>=2023.3.27)", "proselint (>=0.13)", "sphinx (>=6.2.1)", "sphinx-autodoc-typehints (>=1.23,!=1.23.4)"]
-test = ["appdirs (==1.4.4)", "covdefaults (>=2.3)", "pytest (>=7.3.1)", "pytest-cov (>=4)", "pytest-mock (>=3.10)"]
+dev = ["pre-commit", "tox"]
+testing = ["pytest", "pytest-benchmark"]
 
 [[package]]
 name = "pluggy"
-version = "1.0.0"
+version = "1.4.0"
 description = "plugin and hook calling mechanisms for python"
 optional = false
-python-versions = ">=3.6"
+python-versions = ">=3.8"
 files = [
-    {file = "pluggy-1.0.0-py2.py3-none-any.whl", hash = "sha256:74134bbf457f031a36d68416e1509f34bd5ccc019f0bcc952c7b909d06b37bd3"},
-    {file = "pluggy-1.0.0.tar.gz", hash = "sha256:4224373bacce55f955a878bf9cfa763c1e360858e330072059e10bad68531159"},
+    {file = "pluggy-1.4.0-py3-none-any.whl", hash = "sha256:7db9f7b503d67d1c5b95f59773ebb58a8c1c288129a88665838012cfb07b8981"},
+    {file = "pluggy-1.4.0.tar.gz", hash = "sha256:8c85c2876142a764e5b7548e7d9a0e0ddb46f5185161049a79b7e974454223be"},
 ]
 
-[package.dependencies]
-importlib-metadata = {version = ">=0.12", markers = "python_version < \"3.8\""}
-
 [package.extras]
 dev = ["pre-commit", "tox"]
 testing = ["pytest", "pytest-benchmark"]
 
 [[package]]
 name = "py"
 version = "1.11.0"
@@ -909,133 +694,130 @@
 python-versions = "*"
 files = [
     {file = "py-cpuinfo-9.0.0.tar.gz", hash = "sha256:3cdbbf3fac90dc6f118bfd64384f309edeadd902d7c8fb17f02ffa1fc3f49690"},
     {file = "py_cpuinfo-9.0.0-py3-none-any.whl", hash = "sha256:859625bc251f64e21f077d099d4162689c762b5d6a4c3c97553d56241c9674d5"},
 ]
 
 [[package]]
-name = "pycodestyle"
-version = "2.9.1"
-description = "Python style guide checker"
-optional = false
-python-versions = ">=3.6"
-files = [
-    {file = "pycodestyle-2.9.1-py2.py3-none-any.whl", hash = "sha256:d1735fc58b418fd7c5f658d28d943854f8a849b01a5d0a1e6f3f3fdd0166804b"},
-    {file = "pycodestyle-2.9.1.tar.gz", hash = "sha256:2c9607871d58c76354b697b42f5d57e1ada7d261c261efac224b664affdc5785"},
-]
-
-[[package]]
-name = "pycodestyle"
-version = "2.10.0"
-description = "Python style guide checker"
-optional = false
-python-versions = ">=3.6"
-files = [
-    {file = "pycodestyle-2.10.0-py2.py3-none-any.whl", hash = "sha256:8a4eaf0d0495c7395bdab3589ac2db602797d76207242c17d470186815706610"},
-    {file = "pycodestyle-2.10.0.tar.gz", hash = "sha256:347187bdb476329d98f695c213d7295a846d1152ff4fe9bacb8a9590b8ee7053"},
-]
-
-[[package]]
-name = "pyflakes"
-version = "2.5.0"
-description = "passive checker of Python programs"
-optional = false
-python-versions = ">=3.6"
-files = [
-    {file = "pyflakes-2.5.0-py2.py3-none-any.whl", hash = "sha256:4579f67d887f804e67edb544428f264b7b24f435b263c4614f384135cea553d2"},
-    {file = "pyflakes-2.5.0.tar.gz", hash = "sha256:491feb020dca48ccc562a8c0cbe8df07ee13078df59813b83959cbdada312ea3"},
-]
-
-[[package]]
-name = "pyflakes"
-version = "3.0.1"
-description = "passive checker of Python programs"
-optional = false
-python-versions = ">=3.6"
-files = [
-    {file = "pyflakes-3.0.1-py2.py3-none-any.whl", hash = "sha256:ec55bf7fe21fff7f1ad2f7da62363d749e2a470500eab1b555334b67aa1ef8cf"},
-    {file = "pyflakes-3.0.1.tar.gz", hash = "sha256:ec8b276a6b60bd80defed25add7e439881c19e64850afd9b346283d4165fd0fd"},
-]
-
-[[package]]
 name = "pygments"
-version = "2.15.1"
+version = "2.17.2"
 description = "Pygments is a syntax highlighting package written in Python."
 optional = false
 python-versions = ">=3.7"
 files = [
-    {file = "Pygments-2.15.1-py3-none-any.whl", hash = "sha256:db2db3deb4b4179f399a09054b023b6a586b76499d36965813c71aa8ed7b5fd1"},
-    {file = "Pygments-2.15.1.tar.gz", hash = "sha256:8ace4d3c1dd481894b2005f560ead0f9f19ee64fe983366be1a21e171d12775c"},
+    {file = "pygments-2.17.2-py3-none-any.whl", hash = "sha256:b27c2826c47d0f3219f29554824c30c5e8945175d888647acd804ddd04af846c"},
+    {file = "pygments-2.17.2.tar.gz", hash = "sha256:da46cec9fd2de5be3a8a784f434e4c4ab670b4ff54d605c4c2717e9d49c4c367"},
 ]
 
 [package.extras]
 plugins = ["importlib-metadata"]
+windows-terminal = ["colorama (>=0.4.6)"]
 
 [[package]]
 name = "pyproject-api"
-version = "1.5.1"
+version = "1.6.1"
 description = "API to interact with the python pyproject.toml based projects"
 optional = false
-python-versions = ">=3.7"
+python-versions = ">=3.8"
 files = [
-    {file = "pyproject_api-1.5.1-py3-none-any.whl", hash = "sha256:4698a3777c2e0f6b624f8a4599131e2a25376d90fe8d146d7ac74c67c6f97c43"},
-    {file = "pyproject_api-1.5.1.tar.gz", hash = "sha256:435f46547a9ff22cf4208ee274fca3e2869aeb062a4834adfc99a4dd64af3cf9"},
+    {file = "pyproject_api-1.6.1-py3-none-any.whl", hash = "sha256:4c0116d60476b0786c88692cf4e325a9814965e2469c5998b830bba16b183675"},
+    {file = "pyproject_api-1.6.1.tar.gz", hash = "sha256:1817dc018adc0d1ff9ca1ed8c60e1623d5aaca40814b953af14a9cf9a5cae538"},
 ]
 
 [package.dependencies]
-packaging = ">=23"
+packaging = ">=23.1"
 tomli = {version = ">=2.0.1", markers = "python_version < \"3.11\""}
 
 [package.extras]
-docs = ["furo (>=2022.12.7)", "sphinx (>=6.1.3)", "sphinx-autodoc-typehints (>=1.22,!=1.23.4)"]
-testing = ["covdefaults (>=2.2.2)", "importlib-metadata (>=6)", "pytest (>=7.2.1)", "pytest-cov (>=4)", "pytest-mock (>=3.10)", "virtualenv (>=20.17.1)", "wheel (>=0.38.4)"]
+docs = ["furo (>=2023.8.19)", "sphinx (<7.2)", "sphinx-autodoc-typehints (>=1.24)"]
+testing = ["covdefaults (>=2.3)", "pytest (>=7.4)", "pytest-cov (>=4.1)", "pytest-mock (>=3.11.1)", "setuptools (>=68.1.2)", "wheel (>=0.41.2)"]
 
 [[package]]
 name = "pytest"
-version = "7.3.1"
+version = "7.4.4"
 description = "pytest: simple powerful testing with Python"
 optional = false
 python-versions = ">=3.7"
 files = [
-    {file = "pytest-7.3.1-py3-none-any.whl", hash = "sha256:3799fa815351fea3a5e96ac7e503a96fa51cc9942c3753cda7651b93c1cfa362"},
-    {file = "pytest-7.3.1.tar.gz", hash = "sha256:434afafd78b1d78ed0addf160ad2b77a30d35d4bdf8af234fe621919d9ed15e3"},
+    {file = "pytest-7.4.4-py3-none-any.whl", hash = "sha256:b090cdf5ed60bf4c45261be03239c2c1c22df034fbffe691abe93cd80cea01d8"},
+    {file = "pytest-7.4.4.tar.gz", hash = "sha256:2cf0005922c6ace4a3e2ec8b4080eb0d9753fdc93107415332f50ce9e7994280"},
 ]
 
 [package.dependencies]
 colorama = {version = "*", markers = "sys_platform == \"win32\""}
 exceptiongroup = {version = ">=1.0.0rc8", markers = "python_version < \"3.11\""}
 importlib-metadata = {version = ">=0.12", markers = "python_version < \"3.8\""}
 iniconfig = "*"
 packaging = "*"
 pluggy = ">=0.12,<2.0"
 tomli = {version = ">=1.0.0", markers = "python_version < \"3.11\""}
 
 [package.extras]
-testing = ["argcomplete", "attrs (>=19.2.0)", "hypothesis (>=3.56)", "mock", "nose", "pygments (>=2.7.2)", "requests", "xmlschema"]
+testing = ["argcomplete", "attrs (>=19.2.0)", "hypothesis (>=3.56)", "mock", "nose", "pygments (>=2.7.2)", "requests", "setuptools", "xmlschema"]
+
+[[package]]
+name = "pytest"
+version = "8.0.1"
+description = "pytest: simple powerful testing with Python"
+optional = false
+python-versions = ">=3.8"
+files = [
+    {file = "pytest-8.0.1-py3-none-any.whl", hash = "sha256:3e4f16fe1c0a9dc9d9389161c127c3edc5d810c38d6793042fb81d9f48a59fca"},
+    {file = "pytest-8.0.1.tar.gz", hash = "sha256:267f6563751877d772019b13aacbe4e860d73fe8f651f28112e9ac37de7513ae"},
+]
+
+[package.dependencies]
+colorama = {version = "*", markers = "sys_platform == \"win32\""}
+exceptiongroup = {version = ">=1.0.0rc8", markers = "python_version < \"3.11\""}
+iniconfig = "*"
+packaging = "*"
+pluggy = ">=1.3.0,<2.0"
+tomli = {version = ">=1.0.0", markers = "python_version < \"3.11\""}
+
+[package.extras]
+testing = ["argcomplete", "attrs (>=19.2.0)", "hypothesis (>=3.56)", "mock", "nose", "pygments (>=2.7.2)", "requests", "setuptools", "xmlschema"]
 
 [[package]]
 name = "pytest-asyncio"
-version = "0.21.0"
+version = "0.21.1"
 description = "Pytest support for asyncio"
 optional = false
 python-versions = ">=3.7"
 files = [
-    {file = "pytest-asyncio-0.21.0.tar.gz", hash = "sha256:2b38a496aef56f56b0e87557ec313e11e1ab9276fc3863f6a7be0f1d0e415e1b"},
-    {file = "pytest_asyncio-0.21.0-py3-none-any.whl", hash = "sha256:f2b3366b7cd501a4056858bd39349d5af19742aed2d81660b7998b6341c7eb9c"},
+    {file = "pytest-asyncio-0.21.1.tar.gz", hash = "sha256:40a7eae6dded22c7b604986855ea48400ab15b069ae38116e8c01238e9eeb64d"},
+    {file = "pytest_asyncio-0.21.1-py3-none-any.whl", hash = "sha256:8666c1c8ac02631d7c51ba282e0c69a8a452b211ffedf2599099845da5c5c37b"},
 ]
 
 [package.dependencies]
 pytest = ">=7.0.0"
 typing-extensions = {version = ">=3.7.2", markers = "python_version < \"3.8\""}
 
 [package.extras]
 docs = ["sphinx (>=5.3)", "sphinx-rtd-theme (>=1.0)"]
 testing = ["coverage (>=6.2)", "flaky (>=3.5.0)", "hypothesis (>=5.7.1)", "mypy (>=0.931)", "pytest-trio (>=0.7.0)"]
 
 [[package]]
+name = "pytest-asyncio"
+version = "0.23.5"
+description = "Pytest support for asyncio"
+optional = false
+python-versions = ">=3.8"
+files = [
+    {file = "pytest-asyncio-0.23.5.tar.gz", hash = "sha256:3a048872a9c4ba14c3e90cc1aa20cbc2def7d01c7c8db3777ec281ba9c057675"},
+    {file = "pytest_asyncio-0.23.5-py3-none-any.whl", hash = "sha256:4e7093259ba018d58ede7d5315131d21923a60f8a6e9ee266ce1589685c89eac"},
+]
+
+[package.dependencies]
+pytest = ">=7.0.0,<9"
+
+[package.extras]
+docs = ["sphinx (>=5.3)", "sphinx-rtd-theme (>=1.0)"]
+testing = ["coverage (>=6.2)", "hypothesis (>=5.7.1)"]
+
+[[package]]
 name = "pytest-benchmark"
 version = "4.0.0"
 description = "A ``pytest`` fixture for benchmarking code. It will group the tests into rounds that are calibrated to the chosen timer."
 optional = false
 python-versions = ">=3.7"
 files = [
     {file = "pytest-benchmark-4.0.0.tar.gz", hash = "sha256:fb0785b83efe599a6a956361c0691ae1dbb5318018561af10f3e915caa0048d1"},
@@ -1067,98 +849,49 @@
 pytest = ">=4.6"
 
 [package.extras]
 testing = ["fields", "hunter", "process-tests", "pytest-xdist", "six", "virtualenv"]
 
 [[package]]
 name = "pytest-describe"
-version = "2.1.0"
+version = "2.2.0"
 description = "Describe-style plugin for pytest"
 optional = false
 python-versions = ">=3.7"
 files = [
-    {file = "pytest-describe-2.1.0.tar.gz", hash = "sha256:0630c95ac4942ab8dcd8e766236f86436b4984896db0c059fc234fef66fe9732"},
-    {file = "pytest_describe-2.1.0-py3-none-any.whl", hash = "sha256:3ea587839363a91ea24e35e442dae46b56bd91d670e63b755e002b0adfc7a7b2"},
+    {file = "pytest-describe-2.2.0.tar.gz", hash = "sha256:39bb05eb90f2497d9ca342ef9a0b7fa5bada7e58505aec33f66d661d631955b7"},
+    {file = "pytest_describe-2.2.0-py3-none-any.whl", hash = "sha256:bd9e2c73acb4b9522a8400823d98f5b6a081667d3bfd7243a8598336896b544d"},
 ]
 
 [package.dependencies]
-pytest = ">=4.6,<8"
+pytest = ">=4.6,<9"
 
 [[package]]
 name = "pytest-timeout"
-version = "2.1.0"
+version = "2.2.0"
 description = "pytest plugin to abort hanging tests"
 optional = false
-python-versions = ">=3.6"
+python-versions = ">=3.7"
 files = [
-    {file = "pytest-timeout-2.1.0.tar.gz", hash = "sha256:c07ca07404c612f8abbe22294b23c368e2e5104b521c1790195561f37e1ac3d9"},
-    {file = "pytest_timeout-2.1.0-py3-none-any.whl", hash = "sha256:f6f50101443ce70ad325ceb4473c4255e9d74e3c7cd0ef827309dfa4c0d975c6"},
+    {file = "pytest-timeout-2.2.0.tar.gz", hash = "sha256:3b0b95dabf3cb50bac9ef5ca912fa0cfc286526af17afc806824df20c2f72c90"},
+    {file = "pytest_timeout-2.2.0-py3-none-any.whl", hash = "sha256:bde531e096466f49398a59f2dde76fa78429a09a12411466f88a07213e220de2"},
 ]
 
 [package.dependencies]
 pytest = ">=5.0.0"
 
 [[package]]
 name = "pytz"
-version = "2023.3"
+version = "2024.1"
 description = "World timezone definitions, modern and historical"
 optional = false
 python-versions = "*"
 files = [
-    {file = "pytz-2023.3-py2.py3-none-any.whl", hash = "sha256:a151b3abb88eda1d4e34a9814df37de2a80e301e68ba0fd856fb9b46bfbbbffb"},
-    {file = "pytz-2023.3.tar.gz", hash = "sha256:1d8ce29db189191fb55338ee6d0387d82ab59f3d00eac103412d64e0ebd0c588"},
-]
-
-[[package]]
-name = "pyyaml"
-version = "6.0"
-description = "YAML parser and emitter for Python"
-optional = false
-python-versions = ">=3.6"
-files = [
-    {file = "PyYAML-6.0-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:d4db7c7aef085872ef65a8fd7d6d09a14ae91f691dec3e87ee5ee0539d516f53"},
-    {file = "PyYAML-6.0-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:9df7ed3b3d2e0ecfe09e14741b857df43adb5a3ddadc919a2d94fbdf78fea53c"},
-    {file = "PyYAML-6.0-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:77f396e6ef4c73fdc33a9157446466f1cff553d979bd00ecb64385760c6babdc"},
-    {file = "PyYAML-6.0-cp310-cp310-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:a80a78046a72361de73f8f395f1f1e49f956c6be882eed58505a15f3e430962b"},
-    {file = "PyYAML-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl", hash = "sha256:f84fbc98b019fef2ee9a1cb3ce93e3187a6df0b2538a651bfb890254ba9f90b5"},
-    {file = "PyYAML-6.0-cp310-cp310-win32.whl", hash = "sha256:2cd5df3de48857ed0544b34e2d40e9fac445930039f3cfe4bcc592a1f836d513"},
-    {file = "PyYAML-6.0-cp310-cp310-win_amd64.whl", hash = "sha256:daf496c58a8c52083df09b80c860005194014c3698698d1a57cbcfa182142a3a"},
-    {file = "PyYAML-6.0-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:d4b0ba9512519522b118090257be113b9468d804b19d63c71dbcf4a48fa32358"},
-    {file = "PyYAML-6.0-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:81957921f441d50af23654aa6c5e5eaf9b06aba7f0a19c18a538dc7ef291c5a1"},
-    {file = "PyYAML-6.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:afa17f5bc4d1b10afd4466fd3a44dc0e245382deca5b3c353d8b757f9e3ecb8d"},
-    {file = "PyYAML-6.0-cp311-cp311-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:dbad0e9d368bb989f4515da330b88a057617d16b6a8245084f1b05400f24609f"},
-    {file = "PyYAML-6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:432557aa2c09802be39460360ddffd48156e30721f5e8d917f01d31694216782"},
-    {file = "PyYAML-6.0-cp311-cp311-win32.whl", hash = "sha256:bfaef573a63ba8923503d27530362590ff4f576c626d86a9fed95822a8255fd7"},
-    {file = "PyYAML-6.0-cp311-cp311-win_amd64.whl", hash = "sha256:01b45c0191e6d66c470b6cf1b9531a771a83c1c4208272ead47a3ae4f2f603bf"},
-    {file = "PyYAML-6.0-cp36-cp36m-macosx_10_9_x86_64.whl", hash = "sha256:897b80890765f037df3403d22bab41627ca8811ae55e9a722fd0392850ec4d86"},
-    {file = "PyYAML-6.0-cp36-cp36m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:50602afada6d6cbfad699b0c7bb50d5ccffa7e46a3d738092afddc1f9758427f"},
-    {file = "PyYAML-6.0-cp36-cp36m-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:48c346915c114f5fdb3ead70312bd042a953a8ce5c7106d5bfb1a5254e47da92"},
-    {file = "PyYAML-6.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl", hash = "sha256:98c4d36e99714e55cfbaaee6dd5badbc9a1ec339ebfc3b1f52e293aee6bb71a4"},
-    {file = "PyYAML-6.0-cp36-cp36m-win32.whl", hash = "sha256:0283c35a6a9fbf047493e3a0ce8d79ef5030852c51e9d911a27badfde0605293"},
-    {file = "PyYAML-6.0-cp36-cp36m-win_amd64.whl", hash = "sha256:07751360502caac1c067a8132d150cf3d61339af5691fe9e87803040dbc5db57"},
-    {file = "PyYAML-6.0-cp37-cp37m-macosx_10_9_x86_64.whl", hash = "sha256:819b3830a1543db06c4d4b865e70ded25be52a2e0631ccd2f6a47a2822f2fd7c"},
-    {file = "PyYAML-6.0-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:473f9edb243cb1935ab5a084eb238d842fb8f404ed2193a915d1784b5a6b5fc0"},
-    {file = "PyYAML-6.0-cp37-cp37m-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:0ce82d761c532fe4ec3f87fc45688bdd3a4c1dc5e0b4a19814b9009a29baefd4"},
-    {file = "PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl", hash = "sha256:231710d57adfd809ef5d34183b8ed1eeae3f76459c18fb4a0b373ad56bedcdd9"},
-    {file = "PyYAML-6.0-cp37-cp37m-win32.whl", hash = "sha256:c5687b8d43cf58545ade1fe3e055f70eac7a5a1a0bf42824308d868289a95737"},
-    {file = "PyYAML-6.0-cp37-cp37m-win_amd64.whl", hash = "sha256:d15a181d1ecd0d4270dc32edb46f7cb7733c7c508857278d3d378d14d606db2d"},
-    {file = "PyYAML-6.0-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:0b4624f379dab24d3725ffde76559cff63d9ec94e1736b556dacdfebe5ab6d4b"},
-    {file = "PyYAML-6.0-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:213c60cd50106436cc818accf5baa1aba61c0189ff610f64f4a3e8c6726218ba"},
-    {file = "PyYAML-6.0-cp38-cp38-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:9fa600030013c4de8165339db93d182b9431076eb98eb40ee068700c9c813e34"},
-    {file = "PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl", hash = "sha256:277a0ef2981ca40581a47093e9e2d13b3f1fbbeffae064c1d21bfceba2030287"},
-    {file = "PyYAML-6.0-cp38-cp38-win32.whl", hash = "sha256:d4eccecf9adf6fbcc6861a38015c2a64f38b9d94838ac1810a9023a0609e1b78"},
-    {file = "PyYAML-6.0-cp38-cp38-win_amd64.whl", hash = "sha256:1e4747bc279b4f613a09eb64bba2ba602d8a6664c6ce6396a4d0cd413a50ce07"},
-    {file = "PyYAML-6.0-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:055d937d65826939cb044fc8c9b08889e8c743fdc6a32b33e2390f66013e449b"},
-    {file = "PyYAML-6.0-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:e61ceaab6f49fb8bdfaa0f92c4b57bcfbea54c09277b1b4f7ac376bfb7a7c174"},
-    {file = "PyYAML-6.0-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:d67d839ede4ed1b28a4e8909735fc992a923cdb84e618544973d7dfc71540803"},
-    {file = "PyYAML-6.0-cp39-cp39-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:cba8c411ef271aa037d7357a2bc8f9ee8b58b9965831d9e51baf703280dc73d3"},
-    {file = "PyYAML-6.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl", hash = "sha256:40527857252b61eacd1d9af500c3337ba8deb8fc298940291486c465c8b46ec0"},
-    {file = "PyYAML-6.0-cp39-cp39-win32.whl", hash = "sha256:b5b9eccad747aabaaffbc6064800670f0c297e52c12754eb1d976c57e4f74dcb"},
-    {file = "PyYAML-6.0-cp39-cp39-win_amd64.whl", hash = "sha256:b3d267842bf12586ba6c734f89d1f5b871df0273157918b0ccefa29deb05c21c"},
-    {file = "PyYAML-6.0.tar.gz", hash = "sha256:68fb519c14306fec9720a2a5b45bc9f0c8d1b9c72adf45c37baedfcd949c35a2"},
+    {file = "pytz-2024.1-py2.py3-none-any.whl", hash = "sha256:328171f4e3623139da4983451950b28e95ac706e13f3f2630a879749e7a8b319"},
+    {file = "pytz-2024.1.tar.gz", hash = "sha256:2a29735ea9c18baf14b448846bde5a48030ed267578472d8955cd0e7443a9812"},
 ]
 
 [[package]]
 name = "requests"
 version = "2.31.0"
 description = "Python HTTP for Humans."
 optional = false
@@ -1175,132 +908,112 @@
 urllib3 = ">=1.21.1,<3"
 
 [package.extras]
 socks = ["PySocks (>=1.5.6,!=1.5.7)"]
 use-chardet-on-py3 = ["chardet (>=3.0.2,<6)"]
 
 [[package]]
-name = "rich"
-version = "13.4.1"
-description = "Render rich text, tables, progress bars, syntax highlighting, markdown and more to the terminal"
-optional = false
-python-versions = ">=3.7.0"
-files = [
-    {file = "rich-13.4.1-py3-none-any.whl", hash = "sha256:d204aadb50b936bf6b1a695385429d192bc1fdaf3e8b907e8e26f4c4e4b5bf75"},
-    {file = "rich-13.4.1.tar.gz", hash = "sha256:76f6b65ea7e5c5d924ba80e322231d7cb5b5981aa60bfc1e694f1bc097fe6fe1"},
-]
-
-[package.dependencies]
-markdown-it-py = ">=2.2.0,<3.0.0"
-pygments = ">=2.13.0,<3.0.0"
-typing-extensions = {version = ">=4.0.0,<5.0", markers = "python_version < \"3.9\""}
-
-[package.extras]
-jupyter = ["ipywidgets (>=7.5.1,<9)"]
-
-[[package]]
-name = "setuptools"
-version = "67.8.0"
-description = "Easily download, build, install, upgrade, and uninstall Python packages"
+name = "ruff"
+version = "0.2.1"
+description = "An extremely fast Python linter and code formatter, written in Rust."
 optional = false
 python-versions = ">=3.7"
 files = [
-    {file = "setuptools-67.8.0-py3-none-any.whl", hash = "sha256:5df61bf30bb10c6f756eb19e7c9f3b473051f48db77fddbe06ff2ca307df9a6f"},
-    {file = "setuptools-67.8.0.tar.gz", hash = "sha256:62642358adc77ffa87233bc4d2354c4b2682d214048f500964dbe760ccedf102"},
+    {file = "ruff-0.2.1-py3-none-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl", hash = "sha256:dd81b911d28925e7e8b323e8d06951554655021df8dd4ac3045d7212ac4ba080"},
+    {file = "ruff-0.2.1-py3-none-macosx_10_12_x86_64.whl", hash = "sha256:dc586724a95b7d980aa17f671e173df00f0a2eef23f8babbeee663229a938fec"},
+    {file = "ruff-0.2.1-py3-none-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:c92db7101ef5bfc18e96777ed7bc7c822d545fa5977e90a585accac43d22f18a"},
+    {file = "ruff-0.2.1-py3-none-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:13471684694d41ae0f1e8e3a7497e14cd57ccb7dd72ae08d56a159d6c9c3e30e"},
+    {file = "ruff-0.2.1-py3-none-manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:a11567e20ea39d1f51aebd778685582d4c56ccb082c1161ffc10f79bebe6df35"},
+    {file = "ruff-0.2.1-py3-none-manylinux_2_17_ppc64.manylinux2014_ppc64.whl", hash = "sha256:00a818e2db63659570403e44383ab03c529c2b9678ba4ba6c105af7854008105"},
+    {file = "ruff-0.2.1-py3-none-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:be60592f9d218b52f03384d1325efa9d3b41e4c4d55ea022cd548547cc42cd2b"},
+    {file = "ruff-0.2.1-py3-none-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:fbd2288890b88e8aab4499e55148805b58ec711053588cc2f0196a44f6e3d855"},
+    {file = "ruff-0.2.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:f3ef052283da7dec1987bba8d8733051c2325654641dfe5877a4022108098683"},
+    {file = "ruff-0.2.1-py3-none-musllinux_1_2_aarch64.whl", hash = "sha256:7022d66366d6fded4ba3889f73cd791c2d5621b2ccf34befc752cb0df70f5fad"},
+    {file = "ruff-0.2.1-py3-none-musllinux_1_2_armv7l.whl", hash = "sha256:0a725823cb2a3f08ee743a534cb6935727d9e47409e4ad72c10a3faf042ad5ba"},
+    {file = "ruff-0.2.1-py3-none-musllinux_1_2_i686.whl", hash = "sha256:0034d5b6323e6e8fe91b2a1e55b02d92d0b582d2953a2b37a67a2d7dedbb7acc"},
+    {file = "ruff-0.2.1-py3-none-musllinux_1_2_x86_64.whl", hash = "sha256:e5cb5526d69bb9143c2e4d2a115d08ffca3d8e0fddc84925a7b54931c96f5c02"},
+    {file = "ruff-0.2.1-py3-none-win32.whl", hash = "sha256:6b95ac9ce49b4fb390634d46d6ece32ace3acdd52814671ccaf20b7f60adb232"},
+    {file = "ruff-0.2.1-py3-none-win_amd64.whl", hash = "sha256:e3affdcbc2afb6f5bd0eb3130139ceedc5e3f28d206fe49f63073cb9e65988e0"},
+    {file = "ruff-0.2.1-py3-none-win_arm64.whl", hash = "sha256:efababa8e12330aa94a53e90a81eb6e2d55f348bc2e71adbf17d9cad23c03ee6"},
+    {file = "ruff-0.2.1.tar.gz", hash = "sha256:3b42b5d8677cd0c72b99fcaf068ffc62abb5a19e71b4a3b9cfa50658a0af02f1"},
 ]
 
-[package.extras]
-docs = ["furo", "jaraco.packaging (>=9)", "jaraco.tidelift (>=1.4)", "pygments-github-lexers (==0.0.5)", "rst.linker (>=1.9)", "sphinx (>=3.5)", "sphinx-favicon", "sphinx-hoverxref (<2)", "sphinx-inline-tabs", "sphinx-lint", "sphinx-notfound-page (==0.8.3)", "sphinx-reredirects", "sphinxcontrib-towncrier"]
-testing = ["build[virtualenv]", "filelock (>=3.4.0)", "flake8-2020", "ini2toml[lite] (>=0.9)", "jaraco.envs (>=2.2)", "jaraco.path (>=3.2.0)", "pip (>=19.1)", "pip-run (>=8.8)", "pytest (>=6)", "pytest-black (>=0.3.7)", "pytest-checkdocs (>=2.4)", "pytest-cov", "pytest-enabler (>=1.3)", "pytest-mypy (>=0.9.1)", "pytest-perf", "pytest-ruff", "pytest-timeout", "pytest-xdist", "tomli-w (>=1.0.0)", "virtualenv (>=13.0.0)", "wheel"]
-testing-integration = ["build[virtualenv]", "filelock (>=3.4.0)", "jaraco.envs (>=2.2)", "jaraco.path (>=3.2.0)", "pytest", "pytest-enabler", "pytest-xdist", "tomli", "virtualenv (>=13.0.0)", "wheel"]
-
 [[package]]
 name = "six"
 version = "1.16.0"
 description = "Python 2 and 3 compatibility utilities"
 optional = false
 python-versions = ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*"
 files = [
     {file = "six-1.16.0-py2.py3-none-any.whl", hash = "sha256:8abb2f1d86890a2dfb989f9a77cfcfd3e47c2a354b01111771326f8aa26e0254"},
     {file = "six-1.16.0.tar.gz", hash = "sha256:1e61c37477a1626458e36f7b1d82aa5c9b094fa4802892072e49de9c60c4c926"},
 ]
 
 [[package]]
-name = "smmap"
-version = "5.0.0"
-description = "A pure Python implementation of a sliding window memory map manager"
-optional = false
-python-versions = ">=3.6"
-files = [
-    {file = "smmap-5.0.0-py3-none-any.whl", hash = "sha256:2aba19d6a040e78d8b09de5c57e96207b09ed71d8e55ce0959eeee6c8e190d94"},
-    {file = "smmap-5.0.0.tar.gz", hash = "sha256:c840e62059cd3be204b0c9c9f74be2c09d5648eddd4580d9314c3ecde0b30936"},
-]
-
-[[package]]
 name = "snowballstemmer"
 version = "2.2.0"
 description = "This package provides 29 stemmers for 28 languages generated from Snowball algorithms."
 optional = false
 python-versions = "*"
 files = [
     {file = "snowballstemmer-2.2.0-py2.py3-none-any.whl", hash = "sha256:c8e1716e83cc398ae16824e5572ae04e0d9fc2c6b985fb0f900f5f0c96ecba1a"},
     {file = "snowballstemmer-2.2.0.tar.gz", hash = "sha256:09b16deb8547d3412ad7b590689584cd0fe25ec8db3be37788be3810cbf19cb1"},
 ]
 
 [[package]]
 name = "sphinx"
-version = "4.3.2"
+version = "5.3.0"
 description = "Python documentation generator"
 optional = false
 python-versions = ">=3.6"
 files = [
-    {file = "Sphinx-4.3.2-py3-none-any.whl", hash = "sha256:6a11ea5dd0bdb197f9c2abc2e0ce73e01340464feaece525e64036546d24c851"},
-    {file = "Sphinx-4.3.2.tar.gz", hash = "sha256:0a8836751a68306b3fe97ecbe44db786f8479c3bf4b80e3a7f5c838657b4698c"},
+    {file = "Sphinx-5.3.0.tar.gz", hash = "sha256:51026de0a9ff9fc13c05d74913ad66047e104f56a129ff73e174eb5c3ee794b5"},
+    {file = "sphinx-5.3.0-py3-none-any.whl", hash = "sha256:060ca5c9f7ba57a08a1219e547b269fadf125ae25b06b9fa7f66768efb652d6d"},
 ]
 
 [package.dependencies]
 alabaster = ">=0.7,<0.8"
-babel = ">=1.3"
-colorama = {version = ">=0.3.5", markers = "sys_platform == \"win32\""}
-docutils = ">=0.14,<0.18"
-imagesize = "*"
-Jinja2 = ">=2.3"
-packaging = "*"
-Pygments = ">=2.0"
+babel = ">=2.9"
+colorama = {version = ">=0.4.5", markers = "sys_platform == \"win32\""}
+docutils = ">=0.14,<0.20"
+imagesize = ">=1.3"
+importlib-metadata = {version = ">=4.8", markers = "python_version < \"3.10\""}
+Jinja2 = ">=3.0"
+packaging = ">=21.0"
+Pygments = ">=2.12"
 requests = ">=2.5.0"
-setuptools = "*"
-snowballstemmer = ">=1.1"
+snowballstemmer = ">=2.0"
 sphinxcontrib-applehelp = "*"
 sphinxcontrib-devhelp = "*"
 sphinxcontrib-htmlhelp = ">=2.0.0"
 sphinxcontrib-jsmath = "*"
 sphinxcontrib-qthelp = "*"
 sphinxcontrib-serializinghtml = ">=1.1.5"
 
 [package.extras]
 docs = ["sphinxcontrib-websupport"]
-lint = ["docutils-stubs", "flake8 (>=3.5.0)", "isort", "mypy (>=0.920)", "types-pkg-resources", "types-requests", "types-typed-ast"]
-test = ["cython", "html5lib", "pytest", "pytest-cov", "typed-ast"]
+lint = ["docutils-stubs", "flake8 (>=3.5.0)", "flake8-bugbear", "flake8-comprehensions", "flake8-simplify", "isort", "mypy (>=0.981)", "sphinx-lint", "types-requests", "types-typed-ast"]
+test = ["cython", "html5lib", "pytest (>=4.6)", "typed_ast"]
 
 [[package]]
 name = "sphinx"
-version = "6.2.1"
+version = "7.1.2"
 description = "Python documentation generator"
 optional = false
 python-versions = ">=3.8"
 files = [
-    {file = "Sphinx-6.2.1.tar.gz", hash = "sha256:6d56a34697bb749ffa0152feafc4b19836c755d90a7c59b72bc7dfd371b9cc6b"},
-    {file = "sphinx-6.2.1-py3-none-any.whl", hash = "sha256:97787ff1fa3256a3eef9eda523a63dbf299f7b47e053cfcf684a1c2a8380c912"},
+    {file = "sphinx-7.1.2-py3-none-any.whl", hash = "sha256:d170a81825b2fcacb6dfd5a0d7f578a053e45d3f2b153fecc948c37344eb4cbe"},
+    {file = "sphinx-7.1.2.tar.gz", hash = "sha256:780f4d32f1d7d1126576e0e5ecc19dc32ab76cd24e950228dcf7b1f6d3d9e22f"},
 ]
 
 [package.dependencies]
 alabaster = ">=0.7,<0.8"
 babel = ">=2.9"
 colorama = {version = ">=0.4.5", markers = "sys_platform == \"win32\""}
-docutils = ">=0.18.1,<0.20"
+docutils = ">=0.18.1,<0.21"
 imagesize = ">=1.3"
 importlib-metadata = {version = ">=4.8", markers = "python_version < \"3.10\""}
 Jinja2 = ">=3.0"
 packaging = ">=21.0"
 Pygments = ">=2.13"
 requests = ">=2.25.0"
 snowballstemmer = ">=2.0"
@@ -1314,27 +1027,27 @@
 [package.extras]
 docs = ["sphinxcontrib-websupport"]
 lint = ["docutils-stubs", "flake8 (>=3.5.0)", "flake8-simplify", "isort", "mypy (>=0.990)", "ruff", "sphinx-lint", "types-requests"]
 test = ["cython", "filelock", "html5lib", "pytest (>=4.6)"]
 
 [[package]]
 name = "sphinx-rtd-theme"
-version = "1.2.1"
+version = "2.0.0"
 description = "Read the Docs theme for Sphinx"
 optional = false
-python-versions = "!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*,!=3.5.*,>=2.7"
+python-versions = ">=3.6"
 files = [
-    {file = "sphinx_rtd_theme-1.2.1-py2.py3-none-any.whl", hash = "sha256:2cc9351176cbf91944ce44cefd4fab6c3b76ac53aa9e15d6db45a3229ad7f866"},
-    {file = "sphinx_rtd_theme-1.2.1.tar.gz", hash = "sha256:cf9a7dc0352cf179c538891cb28d6fad6391117d4e21c891776ab41dd6c8ff70"},
+    {file = "sphinx_rtd_theme-2.0.0-py2.py3-none-any.whl", hash = "sha256:ec93d0856dc280cf3aee9a4c9807c60e027c7f7b461b77aeffed682e68f0e586"},
+    {file = "sphinx_rtd_theme-2.0.0.tar.gz", hash = "sha256:bd5d7b80622406762073a04ef8fadc5f9151261563d47027de09910ce03afe6b"},
 ]
 
 [package.dependencies]
-docutils = "<0.19"
-sphinx = ">=1.6,<7"
-sphinxcontrib-jquery = {version = ">=2.0.0,<3.0.0 || >3.0.0", markers = "python_version > \"3\""}
+docutils = "<0.21"
+sphinx = ">=5,<8"
+sphinxcontrib-jquery = ">=4,<5"
 
 [package.extras]
 dev = ["bump2version", "sphinxcontrib-httpdomain", "transifex-client", "wheel"]
 
 [[package]]
 name = "sphinxcontrib-applehelp"
 version = "1.0.2"
@@ -1465,29 +1178,14 @@
 ]
 
 [package.extras]
 lint = ["docutils-stubs", "flake8", "mypy"]
 test = ["pytest"]
 
 [[package]]
-name = "stevedore"
-version = "3.5.2"
-description = "Manage dynamic plugins for Python applications"
-optional = false
-python-versions = ">=3.6"
-files = [
-    {file = "stevedore-3.5.2-py3-none-any.whl", hash = "sha256:fa2630e3d0ad3e22d4914aff2501445815b9a4467a6edc49387c667a38faf5bf"},
-    {file = "stevedore-3.5.2.tar.gz", hash = "sha256:cf99f41fc0d5a4f185ca4d3d42b03be9011b0a1ec1a4ea1a282be1b4b306dcc2"},
-]
-
-[package.dependencies]
-importlib-metadata = {version = ">=1.7.0", markers = "python_version < \"3.8\""}
-pbr = ">=2.0.0,<2.1.0 || >2.1.0"
-
-[[package]]
 name = "tomli"
 version = "2.0.1"
 description = "A lil' TOML parser"
 optional = false
 python-versions = ">=3.7"
 files = [
     {file = "tomli-2.0.1-py3-none-any.whl", hash = "sha256:939de3e7a6161af0c887ef91b7d41a53e7c5a1ca976325f429cb46ea9bc30ecc"},
@@ -1518,141 +1216,165 @@
 
 [package.extras]
 docs = ["pygments-github-lexers (>=0.0.5)", "sphinx (>=2.0.0)", "sphinxcontrib-autoprogram (>=0.1.5)", "towncrier (>=18.5.0)"]
 testing = ["flaky (>=3.4.0)", "freezegun (>=0.3.11)", "pathlib2 (>=2.3.3)", "psutil (>=5.6.1)", "pytest (>=4.0.0)", "pytest-cov (>=2.5.1)", "pytest-mock (>=1.10.0)", "pytest-randomly (>=1.0.0)"]
 
 [[package]]
 name = "tox"
-version = "4.5.2"
+version = "4.13.0"
 description = "tox is a generic virtualenv management and test command line tool"
 optional = false
-python-versions = ">=3.7"
+python-versions = ">=3.8"
 files = [
-    {file = "tox-4.5.2-py3-none-any.whl", hash = "sha256:f1a9541b292aa0449f6c7bb67dc0073f25f9086413c3922fe47f5168cbf7b2f4"},
-    {file = "tox-4.5.2.tar.gz", hash = "sha256:ad87fb7a10ef476afb6eb7e408808057f42976ef0d30ad5fe023099ba493ce58"},
+    {file = "tox-4.13.0-py3-none-any.whl", hash = "sha256:1143c7e2489c68026a55d3d4ae84c02c449f073b28e62f80e3e440a3b72a4afa"},
+    {file = "tox-4.13.0.tar.gz", hash = "sha256:dd789a554c16c4b532924ba393c92fc8991323c4b3d466712bfecc8c9b9f24f7"},
 ]
 
 [package.dependencies]
-cachetools = ">=5.3"
-chardet = ">=5.1"
+cachetools = ">=5.3.2"
+chardet = ">=5.2"
 colorama = ">=0.4.6"
-filelock = ">=3.12"
-packaging = ">=23.1"
-platformdirs = ">=3.5.1"
-pluggy = ">=1"
-pyproject-api = ">=1.5.1"
+filelock = ">=3.13.1"
+packaging = ">=23.2"
+platformdirs = ">=4.1"
+pluggy = ">=1.3"
+pyproject-api = ">=1.6.1"
 tomli = {version = ">=2.0.1", markers = "python_version < \"3.11\""}
-virtualenv = ">=20.23"
+virtualenv = ">=20.25"
 
 [package.extras]
-docs = ["furo (>=2023.5.20)", "sphinx (>=7.0.1)", "sphinx-argparse-cli (>=1.11)", "sphinx-autodoc-typehints (>=1.23,!=1.23.4)", "sphinx-copybutton (>=0.5.2)", "sphinx-inline-tabs (>=2023.4.21)", "sphinxcontrib-towncrier (>=0.2.1a0)", "towncrier (>=22.12)"]
-testing = ["build[virtualenv] (>=0.10)", "covdefaults (>=2.3)", "devpi-process (>=0.3)", "diff-cover (>=7.5)", "distlib (>=0.3.6)", "flaky (>=3.7)", "hatch-vcs (>=0.3)", "hatchling (>=1.17)", "psutil (>=5.9.5)", "pytest (>=7.3.1)", "pytest-cov (>=4.1)", "pytest-mock (>=3.10)", "pytest-xdist (>=3.3.1)", "re-assert (>=1.1)", "time-machine (>=2.9)", "wheel (>=0.40)"]
+docs = ["furo (>=2023.9.10)", "sphinx (>=7.2.6)", "sphinx-argparse-cli (>=1.11.1)", "sphinx-autodoc-typehints (>=1.25.2)", "sphinx-copybutton (>=0.5.2)", "sphinx-inline-tabs (>=2023.4.21)", "sphinxcontrib-towncrier (>=0.2.1a0)", "towncrier (>=23.11)"]
+testing = ["build[virtualenv] (>=1.0.3)", "covdefaults (>=2.3)", "detect-test-pollution (>=1.2)", "devpi-process (>=1)", "diff-cover (>=8.0.2)", "distlib (>=0.3.8)", "flaky (>=3.7)", "hatch-vcs (>=0.4)", "hatchling (>=1.21)", "psutil (>=5.9.7)", "pytest (>=7.4.4)", "pytest-cov (>=4.1)", "pytest-mock (>=3.12)", "pytest-xdist (>=3.5)", "re-assert (>=1.1)", "time-machine (>=2.13)", "wheel (>=0.42)"]
 
 [[package]]
 name = "typed-ast"
-version = "1.5.4"
+version = "1.5.5"
 description = "a fork of Python 2 and 3 ast modules with type comment support"
 optional = false
 python-versions = ">=3.6"
 files = [
-    {file = "typed_ast-1.5.4-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:669dd0c4167f6f2cd9f57041e03c3c2ebf9063d0757dc89f79ba1daa2bfca9d4"},
-    {file = "typed_ast-1.5.4-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:211260621ab1cd7324e0798d6be953d00b74e0428382991adfddb352252f1d62"},
-    {file = "typed_ast-1.5.4-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:267e3f78697a6c00c689c03db4876dd1efdfea2f251a5ad6555e82a26847b4ac"},
-    {file = "typed_ast-1.5.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl", hash = "sha256:c542eeda69212fa10a7ada75e668876fdec5f856cd3d06829e6aa64ad17c8dfe"},
-    {file = "typed_ast-1.5.4-cp310-cp310-win_amd64.whl", hash = "sha256:a9916d2bb8865f973824fb47436fa45e1ebf2efd920f2b9f99342cb7fab93f72"},
-    {file = "typed_ast-1.5.4-cp36-cp36m-macosx_10_9_x86_64.whl", hash = "sha256:79b1e0869db7c830ba6a981d58711c88b6677506e648496b1f64ac7d15633aec"},
-    {file = "typed_ast-1.5.4-cp36-cp36m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:a94d55d142c9265f4ea46fab70977a1944ecae359ae867397757d836ea5a3f47"},
-    {file = "typed_ast-1.5.4-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl", hash = "sha256:183afdf0ec5b1b211724dfef3d2cad2d767cbefac291f24d69b00546c1837fb6"},
-    {file = "typed_ast-1.5.4-cp36-cp36m-win_amd64.whl", hash = "sha256:639c5f0b21776605dd6c9dbe592d5228f021404dafd377e2b7ac046b0349b1a1"},
-    {file = "typed_ast-1.5.4-cp37-cp37m-macosx_10_9_x86_64.whl", hash = "sha256:cf4afcfac006ece570e32d6fa90ab74a17245b83dfd6655a6f68568098345ff6"},
-    {file = "typed_ast-1.5.4-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:ed855bbe3eb3715fca349c80174cfcfd699c2f9de574d40527b8429acae23a66"},
-    {file = "typed_ast-1.5.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl", hash = "sha256:6778e1b2f81dfc7bc58e4b259363b83d2e509a65198e85d5700dfae4c6c8ff1c"},
-    {file = "typed_ast-1.5.4-cp37-cp37m-win_amd64.whl", hash = "sha256:0261195c2062caf107831e92a76764c81227dae162c4f75192c0d489faf751a2"},
-    {file = "typed_ast-1.5.4-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:2efae9db7a8c05ad5547d522e7dbe62c83d838d3906a3716d1478b6c1d61388d"},
-    {file = "typed_ast-1.5.4-cp38-cp38-macosx_11_0_arm64.whl", hash = "sha256:7d5d014b7daa8b0bf2eaef684295acae12b036d79f54178b92a2b6a56f92278f"},
-    {file = "typed_ast-1.5.4-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:370788a63915e82fd6f212865a596a0fefcbb7d408bbbb13dea723d971ed8bdc"},
-    {file = "typed_ast-1.5.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl", hash = "sha256:4e964b4ff86550a7a7d56345c7864b18f403f5bd7380edf44a3c1fb4ee7ac6c6"},
-    {file = "typed_ast-1.5.4-cp38-cp38-win_amd64.whl", hash = "sha256:683407d92dc953c8a7347119596f0b0e6c55eb98ebebd9b23437501b28dcbb8e"},
-    {file = "typed_ast-1.5.4-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:4879da6c9b73443f97e731b617184a596ac1235fe91f98d279a7af36c796da35"},
-    {file = "typed_ast-1.5.4-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:3e123d878ba170397916557d31c8f589951e353cc95fb7f24f6bb69adc1a8a97"},
-    {file = "typed_ast-1.5.4-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:ebd9d7f80ccf7a82ac5f88c521115cc55d84e35bf8b446fcd7836eb6b98929a3"},
-    {file = "typed_ast-1.5.4-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl", hash = "sha256:98f80dee3c03455e92796b58b98ff6ca0b2a6f652120c263efdba4d6c5e58f72"},
-    {file = "typed_ast-1.5.4-cp39-cp39-win_amd64.whl", hash = "sha256:0fdbcf2fef0ca421a3f5912555804296f0b0960f0418c440f5d6d3abb549f3e1"},
-    {file = "typed_ast-1.5.4.tar.gz", hash = "sha256:39e21ceb7388e4bb37f4c679d72707ed46c2fbf2a5609b8b8ebc4b067d977df2"},
+    {file = "typed_ast-1.5.5-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:4bc1efe0ce3ffb74784e06460f01a223ac1f6ab31c6bc0376a21184bf5aabe3b"},
+    {file = "typed_ast-1.5.5-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:5f7a8c46a8b333f71abd61d7ab9255440d4a588f34a21f126bbfc95f6049e686"},
+    {file = "typed_ast-1.5.5-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:597fc66b4162f959ee6a96b978c0435bd63791e31e4f410622d19f1686d5e769"},
+    {file = "typed_ast-1.5.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:d41b7a686ce653e06c2609075d397ebd5b969d821b9797d029fccd71fdec8e04"},
+    {file = "typed_ast-1.5.5-cp310-cp310-musllinux_1_1_aarch64.whl", hash = "sha256:5fe83a9a44c4ce67c796a1b466c270c1272e176603d5e06f6afbc101a572859d"},
+    {file = "typed_ast-1.5.5-cp310-cp310-musllinux_1_1_x86_64.whl", hash = "sha256:d5c0c112a74c0e5db2c75882a0adf3133adedcdbfd8cf7c9d6ed77365ab90a1d"},
+    {file = "typed_ast-1.5.5-cp310-cp310-win_amd64.whl", hash = "sha256:e1a976ed4cc2d71bb073e1b2a250892a6e968ff02aa14c1f40eba4f365ffec02"},
+    {file = "typed_ast-1.5.5-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:c631da9710271cb67b08bd3f3813b7af7f4c69c319b75475436fcab8c3d21bee"},
+    {file = "typed_ast-1.5.5-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:b445c2abfecab89a932b20bd8261488d574591173d07827c1eda32c457358b18"},
+    {file = "typed_ast-1.5.5-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:cc95ffaaab2be3b25eb938779e43f513e0e538a84dd14a5d844b8f2932593d88"},
+    {file = "typed_ast-1.5.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:61443214d9b4c660dcf4b5307f15c12cb30bdfe9588ce6158f4a005baeb167b2"},
+    {file = "typed_ast-1.5.5-cp311-cp311-musllinux_1_1_aarch64.whl", hash = "sha256:6eb936d107e4d474940469e8ec5b380c9b329b5f08b78282d46baeebd3692dc9"},
+    {file = "typed_ast-1.5.5-cp311-cp311-musllinux_1_1_x86_64.whl", hash = "sha256:e48bf27022897577d8479eaed64701ecaf0467182448bd95759883300ca818c8"},
+    {file = "typed_ast-1.5.5-cp311-cp311-win_amd64.whl", hash = "sha256:83509f9324011c9a39faaef0922c6f720f9623afe3fe220b6d0b15638247206b"},
+    {file = "typed_ast-1.5.5-cp36-cp36m-macosx_10_9_x86_64.whl", hash = "sha256:44f214394fc1af23ca6d4e9e744804d890045d1643dd7e8229951e0ef39429b5"},
+    {file = "typed_ast-1.5.5-cp36-cp36m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:118c1ce46ce58fda78503eae14b7664163aa735b620b64b5b725453696f2a35c"},
+    {file = "typed_ast-1.5.5-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:be4919b808efa61101456e87f2d4c75b228f4e52618621c77f1ddcaae15904fa"},
+    {file = "typed_ast-1.5.5-cp36-cp36m-musllinux_1_1_aarch64.whl", hash = "sha256:fc2b8c4e1bc5cd96c1a823a885e6b158f8451cf6f5530e1829390b4d27d0807f"},
+    {file = "typed_ast-1.5.5-cp36-cp36m-musllinux_1_1_x86_64.whl", hash = "sha256:16f7313e0a08c7de57f2998c85e2a69a642e97cb32f87eb65fbfe88381a5e44d"},
+    {file = "typed_ast-1.5.5-cp36-cp36m-win_amd64.whl", hash = "sha256:2b946ef8c04f77230489f75b4b5a4a6f24c078be4aed241cfabe9cbf4156e7e5"},
+    {file = "typed_ast-1.5.5-cp37-cp37m-macosx_10_9_x86_64.whl", hash = "sha256:2188bc33d85951ea4ddad55d2b35598b2709d122c11c75cffd529fbc9965508e"},
+    {file = "typed_ast-1.5.5-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:0635900d16ae133cab3b26c607586131269f88266954eb04ec31535c9a12ef1e"},
+    {file = "typed_ast-1.5.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:57bfc3cf35a0f2fdf0a88a3044aafaec1d2f24d8ae8cd87c4f58d615fb5b6311"},
+    {file = "typed_ast-1.5.5-cp37-cp37m-musllinux_1_1_aarch64.whl", hash = "sha256:fe58ef6a764de7b4b36edfc8592641f56e69b7163bba9f9c8089838ee596bfb2"},
+    {file = "typed_ast-1.5.5-cp37-cp37m-musllinux_1_1_x86_64.whl", hash = "sha256:d09d930c2d1d621f717bb217bf1fe2584616febb5138d9b3e8cdd26506c3f6d4"},
+    {file = "typed_ast-1.5.5-cp37-cp37m-win_amd64.whl", hash = "sha256:d40c10326893ecab8a80a53039164a224984339b2c32a6baf55ecbd5b1df6431"},
+    {file = "typed_ast-1.5.5-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:fd946abf3c31fb50eee07451a6aedbfff912fcd13cf357363f5b4e834cc5e71a"},
+    {file = "typed_ast-1.5.5-cp38-cp38-macosx_11_0_arm64.whl", hash = "sha256:ed4a1a42df8a3dfb6b40c3d2de109e935949f2f66b19703eafade03173f8f437"},
+    {file = "typed_ast-1.5.5-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:045f9930a1550d9352464e5149710d56a2aed23a2ffe78946478f7b5416f1ede"},
+    {file = "typed_ast-1.5.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:381eed9c95484ceef5ced626355fdc0765ab51d8553fec08661dce654a935db4"},
+    {file = "typed_ast-1.5.5-cp38-cp38-musllinux_1_1_aarch64.whl", hash = "sha256:bfd39a41c0ef6f31684daff53befddae608f9daf6957140228a08e51f312d7e6"},
+    {file = "typed_ast-1.5.5-cp38-cp38-musllinux_1_1_x86_64.whl", hash = "sha256:8c524eb3024edcc04e288db9541fe1f438f82d281e591c548903d5b77ad1ddd4"},
+    {file = "typed_ast-1.5.5-cp38-cp38-win_amd64.whl", hash = "sha256:7f58fabdde8dcbe764cef5e1a7fcb440f2463c1bbbec1cf2a86ca7bc1f95184b"},
+    {file = "typed_ast-1.5.5-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:042eb665ff6bf020dd2243307d11ed626306b82812aba21836096d229fdc6a10"},
+    {file = "typed_ast-1.5.5-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:622e4a006472b05cf6ef7f9f2636edc51bda670b7bbffa18d26b255269d3d814"},
+    {file = "typed_ast-1.5.5-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:1efebbbf4604ad1283e963e8915daa240cb4bf5067053cf2f0baadc4d4fb51b8"},
+    {file = "typed_ast-1.5.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:f0aefdd66f1784c58f65b502b6cf8b121544680456d1cebbd300c2c813899274"},
+    {file = "typed_ast-1.5.5-cp39-cp39-musllinux_1_1_aarch64.whl", hash = "sha256:48074261a842acf825af1968cd912f6f21357316080ebaca5f19abbb11690c8a"},
+    {file = "typed_ast-1.5.5-cp39-cp39-musllinux_1_1_x86_64.whl", hash = "sha256:429ae404f69dc94b9361bb62291885894b7c6fb4640d561179548c849f8492ba"},
+    {file = "typed_ast-1.5.5-cp39-cp39-win_amd64.whl", hash = "sha256:335f22ccb244da2b5c296e6f96b06ee9bed46526db0de38d2f0e5a6597b81155"},
+    {file = "typed_ast-1.5.5.tar.gz", hash = "sha256:94282f7a354f36ef5dbce0ef3467ebf6a258e370ab33d5b40c249fa996e590dd"},
 ]
 
 [[package]]
 name = "typing-extensions"
-version = "4.6.3"
+version = "4.7.1"
 description = "Backported and Experimental Type Hints for Python 3.7+"
 optional = false
 python-versions = ">=3.7"
 files = [
-    {file = "typing_extensions-4.6.3-py3-none-any.whl", hash = "sha256:88a4153d8505aabbb4e13aacb7c486c2b4a33ca3b3f807914a9b4c844c471c26"},
-    {file = "typing_extensions-4.6.3.tar.gz", hash = "sha256:d91d5919357fe7f681a9f2b5b4cb2a5f1ef0a1e9f59c4d8ff0d3491e05c0ffd5"},
+    {file = "typing_extensions-4.7.1-py3-none-any.whl", hash = "sha256:440d5dd3af93b060174bf433bccd69b0babc3b15b1a8dca43789fd7f61514b36"},
+    {file = "typing_extensions-4.7.1.tar.gz", hash = "sha256:b75ddc264f0ba5615db7ba217daeb99701ad295353c45f9e95963337ceeeffb2"},
+]
+
+[[package]]
+name = "typing-extensions"
+version = "4.9.0"
+description = "Backported and Experimental Type Hints for Python 3.8+"
+optional = false
+python-versions = ">=3.8"
+files = [
+    {file = "typing_extensions-4.9.0-py3-none-any.whl", hash = "sha256:af72aea155e91adfc61c3ae9e0e342dbc0cba726d6cba4b6c72c1f34e47291cd"},
+    {file = "typing_extensions-4.9.0.tar.gz", hash = "sha256:23478f88c37f27d76ac8aee6c905017a143b0b1b886c3c9f66bc2fd94f9f5783"},
 ]
 
 [[package]]
 name = "urllib3"
-version = "2.0.2"
+version = "2.0.7"
 description = "HTTP library with thread-safe connection pooling, file post, and more."
 optional = false
 python-versions = ">=3.7"
 files = [
-    {file = "urllib3-2.0.2-py3-none-any.whl", hash = "sha256:d055c2f9d38dc53c808f6fdc8eab7360b6fdbbde02340ed25cfbcd817c62469e"},
-    {file = "urllib3-2.0.2.tar.gz", hash = "sha256:61717a1095d7e155cdb737ac7bb2f4324a858a1e2e6466f6d03ff630ca68d3cc"},
+    {file = "urllib3-2.0.7-py3-none-any.whl", hash = "sha256:fdb6d215c776278489906c2f8916e6e7d4f5a9b602ccbcfdf7f016fc8da0596e"},
+    {file = "urllib3-2.0.7.tar.gz", hash = "sha256:c97dfde1f7bd43a71c8d2a58e369e9b2bf692d1334ea9f9cae55add7d0dd0f84"},
 ]
 
 [package.extras]
 brotli = ["brotli (>=1.0.9)", "brotlicffi (>=0.8.0)"]
 secure = ["certifi", "cryptography (>=1.9)", "idna (>=2.0.0)", "pyopenssl (>=17.1.0)", "urllib3-secure-extra"]
 socks = ["pysocks (>=1.5.6,!=1.5.7,<2.0)"]
 zstd = ["zstandard (>=0.18.0)"]
 
 [[package]]
-name = "virtualenv"
-version = "20.4.7"
-description = "Virtual Python Environment builder"
+name = "urllib3"
+version = "2.2.0"
+description = "HTTP library with thread-safe connection pooling, file post, and more."
 optional = false
-python-versions = "!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,>=2.7"
+python-versions = ">=3.8"
 files = [
-    {file = "virtualenv-20.4.7-py2.py3-none-any.whl", hash = "sha256:2b0126166ea7c9c3661f5b8e06773d28f83322de7a3ff7d06f0aed18c9de6a76"},
-    {file = "virtualenv-20.4.7.tar.gz", hash = "sha256:14fdf849f80dbb29a4eb6caa9875d476ee2a5cf76a5f5415fa2f1606010ab467"},
+    {file = "urllib3-2.2.0-py3-none-any.whl", hash = "sha256:ce3711610ddce217e6d113a2732fafad960a03fd0318c91faa79481e35c11224"},
+    {file = "urllib3-2.2.0.tar.gz", hash = "sha256:051d961ad0c62a94e50ecf1af379c3aba230c66c710493493560c0c223c49f20"},
 ]
 
-[package.dependencies]
-appdirs = ">=1.4.3,<2"
-distlib = ">=0.3.1,<1"
-filelock = ">=3.0.0,<4"
-importlib-metadata = {version = ">=0.12", markers = "python_version < \"3.8\""}
-six = ">=1.9.0,<2"
-
 [package.extras]
-docs = ["proselint (>=0.10.2)", "sphinx (>=3)", "sphinx-argparse (>=0.2.5)", "sphinx-rtd-theme (>=0.4.3)", "towncrier (>=19.9.0rc1)"]
-testing = ["coverage (>=4)", "coverage-enable-subprocess (>=1)", "flaky (>=3)", "packaging (>=20.0)", "pytest (>=4)", "pytest-env (>=0.6.2)", "pytest-freezegun (>=0.4.1)", "pytest-mock (>=2)", "pytest-randomly (>=1)", "pytest-timeout (>=1)", "xonsh (>=0.9.16)"]
+brotli = ["brotli (>=1.0.9)", "brotlicffi (>=0.8.0)"]
+h2 = ["h2 (>=4,<5)"]
+socks = ["pysocks (>=1.5.6,!=1.5.7,<2.0)"]
+zstd = ["zstandard (>=0.18.0)"]
 
 [[package]]
 name = "virtualenv"
-version = "20.23.0"
+version = "20.25.0"
 description = "Virtual Python Environment builder"
 optional = false
 python-versions = ">=3.7"
 files = [
-    {file = "virtualenv-20.23.0-py3-none-any.whl", hash = "sha256:6abec7670e5802a528357fdc75b26b9f57d5d92f29c5462ba0fbe45feacc685e"},
-    {file = "virtualenv-20.23.0.tar.gz", hash = "sha256:a85caa554ced0c0afbd0d638e7e2d7b5f92d23478d05d17a76daeac8f279f924"},
+    {file = "virtualenv-20.25.0-py3-none-any.whl", hash = "sha256:4238949c5ffe6876362d9c0180fc6c3a824a7b12b80604eeb8085f2ed7460de3"},
+    {file = "virtualenv-20.25.0.tar.gz", hash = "sha256:bf51c0d9c7dd63ea8e44086fa1e4fb1093a31e963b86959257378aef020e1f1b"},
 ]
 
 [package.dependencies]
-distlib = ">=0.3.6,<1"
-filelock = ">=3.11,<4"
-platformdirs = ">=3.2,<4"
+distlib = ">=0.3.7,<1"
+filelock = ">=3.12.2,<4"
+importlib-metadata = {version = ">=6.6", markers = "python_version < \"3.8\""}
+platformdirs = ">=3.9.1,<5"
 
 [package.extras]
-docs = ["furo (>=2023.3.27)", "proselint (>=0.13)", "sphinx (>=6.1.3)", "sphinx-argparse (>=0.4)", "sphinxcontrib-towncrier (>=0.2.1a0)", "towncrier (>=22.12)"]
-test = ["covdefaults (>=2.3)", "coverage (>=7.2.3)", "coverage-enable-subprocess (>=1)", "flaky (>=3.7)", "packaging (>=23.1)", "pytest (>=7.3.1)", "pytest-env (>=0.8.1)", "pytest-freezegun (>=0.4.2)", "pytest-mock (>=3.10)", "pytest-randomly (>=3.12)", "pytest-timeout (>=2.1)", "setuptools (>=67.7.1)", "time-machine (>=2.9)"]
+docs = ["furo (>=2023.7.26)", "proselint (>=0.13)", "sphinx (>=7.1.2)", "sphinx-argparse (>=0.4)", "sphinxcontrib-towncrier (>=0.2.1a0)", "towncrier (>=23.6)"]
+test = ["covdefaults (>=2.3)", "coverage (>=7.2.7)", "coverage-enable-subprocess (>=1)", "flaky (>=3.7)", "packaging (>=23.1)", "pytest (>=7.4)", "pytest-env (>=0.8.2)", "pytest-freezer (>=0.4.8)", "pytest-mock (>=3.11.1)", "pytest-randomly (>=3.12)", "pytest-timeout (>=2.1)", "setuptools (>=68)", "time-machine (>=2.10)"]
 
 [[package]]
 name = "zipp"
 version = "3.15.0"
 description = "Backport of pathlib-compatible object wrapper for zip files"
 optional = false
 python-versions = ">=3.7"
@@ -1661,11 +1383,26 @@
     {file = "zipp-3.15.0.tar.gz", hash = "sha256:112929ad649da941c23de50f356a2b5570c954b65150642bccdd66bf194d224b"},
 ]
 
 [package.extras]
 docs = ["furo", "jaraco.packaging (>=9)", "jaraco.tidelift (>=1.4)", "rst.linker (>=1.9)", "sphinx (>=3.5)", "sphinx-lint"]
 testing = ["big-O", "flake8 (<5)", "jaraco.functools", "jaraco.itertools", "more-itertools", "pytest (>=6)", "pytest-black (>=0.3.7)", "pytest-checkdocs (>=2.4)", "pytest-cov", "pytest-enabler (>=1.3)", "pytest-flake8", "pytest-mypy (>=0.9.1)"]
 
+[[package]]
+name = "zipp"
+version = "3.17.0"
+description = "Backport of pathlib-compatible object wrapper for zip files"
+optional = false
+python-versions = ">=3.8"
+files = [
+    {file = "zipp-3.17.0-py3-none-any.whl", hash = "sha256:0e923e726174922dce09c53c59ad483ff7bbb8e572e00c7f7c46b88556409f31"},
+    {file = "zipp-3.17.0.tar.gz", hash = "sha256:84e64a1c28cf7e91ed2078bb8cc8c259cb19b76942096c8d7b84947690cabaf0"},
+]
+
+[package.extras]
+docs = ["furo", "jaraco.packaging (>=9.3)", "jaraco.tidelift (>=1.4)", "rst.linker (>=1.9)", "sphinx (<7.2.5)", "sphinx (>=3.5)", "sphinx-lint"]
+testing = ["big-O", "jaraco.functools", "jaraco.itertools", "more-itertools", "pytest (>=6)", "pytest-black (>=0.3.7)", "pytest-checkdocs (>=2.4)", "pytest-cov", "pytest-enabler (>=2.2)", "pytest-ignore-flaky", "pytest-mypy (>=0.9.1)", "pytest-ruff"]
+
 [metadata]
 lock-version = "2.0"
 python-versions = "^3.7"
-content-hash = "07e28b85afe797b936dde14b570501b255d800339a459c680b80c7abfd83ed3f"
+content-hash = "b78e75f3de0aa66a09e5f2d319fc43cc3201402707385827a1ddee81c22941ad"
```

### Comparing `graphql_core-3.3.0a3/src/graphql/__init__.py` & `graphql_core-3.3.0a4/src/graphql/__init__.py`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/src/graphql/error/graphql_error.py` & `graphql_core-3.3.0a4/src/graphql/error/graphql_error.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,27 +1,28 @@
+"""GraphQL Error"""
+
 from sys import exc_info
 from typing import TYPE_CHECKING, Any, Collection, Dict, List, Optional, Union
 
-
 try:
     from typing import TypedDict
 except ImportError:  # Python < 3.8
     from typing_extensions import TypedDict
 try:
     from typing import TypeAlias
 except ImportError:  # Python < 3.10
     from typing_extensions import TypeAlias
 
 if TYPE_CHECKING:
-    from ..language.ast import Node  # noqa: F401
-    from ..language.location import (  # noqa: F401
+    from ..language.ast import Node
+    from ..language.location import (
         FormattedSourceLocation,
         SourceLocation,
     )
-    from ..language.source import Source  # noqa: F401
+    from ..language.source import Source
 
 __all__ = ["GraphQLError", "GraphQLErrorExtensions", "GraphQLFormattedError"]
 
 
 # Custom extensions
 GraphQLErrorExtensions: TypeAlias = Dict[str, Any]
 # Use a unique identifier name for your extension, for example the name of
@@ -123,14 +124,15 @@
         nodes: Union[Collection["Node"], "Node", None] = None,
         source: Optional["Source"] = None,
         positions: Optional[Collection[int]] = None,
         path: Optional[Collection[Union[str, int]]] = None,
         original_error: Optional[Exception] = None,
         extensions: Optional[GraphQLErrorExtensions] = None,
     ) -> None:
+        """Initialize a GraphQLError."""
         super().__init__(message)
         self.message = message
 
         if path and not isinstance(path, list):
             path = list(path)
         self.path = path or None  # type: ignore
         self.original_error = original_error
@@ -197,15 +199,15 @@
             args.append(f"locations={self.locations!r}")
         if self.path:
             args.append(f"path={self.path!r}")
         if self.extensions:
             args.append(f"extensions={self.extensions!r}")
         return f"{self.__class__.__name__}({', '.join(args)})"
 
-    def __eq__(self, other: Any) -> bool:
+    def __eq__(self, other: object) -> bool:
         return (
             isinstance(other, GraphQLError)
             and self.__class__ == other.__class__
             and all(
                 getattr(self, slot) == getattr(other, slot)
                 for slot in self.__slots__
                 if slot != "original_error"
@@ -216,15 +218,15 @@
             and all(
                 slot in self.__slots__ and getattr(self, slot) == other.get(slot)
                 for slot in other
                 if slot != "original_error"
             )
         )
 
-    def __ne__(self, other: Any) -> bool:
+    def __ne__(self, other: object) -> bool:
         return not self == other
 
     @property
     def formatted(self) -> GraphQLFormattedError:
         """Get error formatted according to the specification.
 
         Given a GraphQLError, format it according to the rules described by the
```

### Comparing `graphql_core-3.3.0a3/src/graphql/execution/__init__.py` & `graphql_core-3.3.0a4/src/graphql/execution/__init__.py`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/src/graphql/execution/async_iterables.py` & `graphql_core-3.3.0a4/src/graphql/execution/async_iterables.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,43 +1,43 @@
+"""Helpers for async iterables"""
+
 from __future__ import annotations  # Python < 3.10
 
 from contextlib import AbstractAsyncContextManager
 from typing import (
-    Any,
     AsyncGenerator,
     AsyncIterable,
     Awaitable,
     Callable,
     TypeVar,
     Union,
 )
 
-
 __all__ = ["aclosing", "flatten_async_iterable", "map_async_iterable"]
 
 T = TypeVar("T")
 V = TypeVar("V")
 
 AsyncIterableOrGenerator = Union[AsyncGenerator[T, None], AsyncIterable[T]]
 
 
-class aclosing(AbstractAsyncContextManager):
+class aclosing(AbstractAsyncContextManager):  # noqa: N801
     """Async context manager for safely finalizing an async iterator or generator.
 
     Contrary to the function available via the standard library, this one silently
     ignores the case that custom iterators have no aclose() method.
     """
 
     def __init__(self, iterable: AsyncIterableOrGenerator[T]) -> None:
         self.iterable = iterable
 
     async def __aenter__(self) -> AsyncIterableOrGenerator[T]:
         return self.iterable
 
-    async def __aexit__(self, *_exc_info: Any) -> None:
+    async def __aexit__(self, *_exc_info: object) -> None:
         try:
             aclose = self.iterable.aclose  # type: ignore
         except AttributeError:
             pass  # do not complain if the iterator has no aclose() method
         else:
             await aclose()
 
@@ -63,11 +63,10 @@
     """Map an AsyncIterable over a callback function.
 
     Given an AsyncIterable and an async callback function, return an AsyncGenerator
     that produces values mapped via calling the callback function.
     If the inner iterator supports an `aclose()` method, it will be called when
     the generator finishes or closes.
     """
-
     async with aclosing(iterable) as items:  # type: ignore
         async for item in items:
             yield await callback(item)
```

### Comparing `graphql_core-3.3.0a3/src/graphql/execution/collect_fields.py` & `graphql_core-3.3.0a4/src/graphql/execution/collect_fields.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,7 +1,9 @@
+"""Collect fields"""
+
 from collections import defaultdict
 from typing import Any, Dict, List, NamedTuple, Optional, Set, Union
 
 from ..language import (
     FieldNode,
     FragmentDefinitionNode,
     FragmentSpreadNode,
@@ -15,15 +17,14 @@
     GraphQLSchema,
     GraphQLSkipDirective,
     is_abstract_type,
 )
 from ..utilities.type_from_ast import type_from_ast
 from .values import get_directive_values
 
-
 __all__ = ["collect_fields", "collect_subfields", "FieldsAndPatches"]
 
 
 class PatchFields(NamedTuple):
     """Optionally labelled set of fields to be used as a patch."""
 
     label: Optional[str]
@@ -260,9 +261,9 @@
     if is_abstract_type(conditional_type):
         # noinspection PyTypeChecker
         return schema.is_sub_type(conditional_type, type_)
     return False
 
 
 def get_field_entry_key(node: FieldNode) -> str:
-    """Implements the logic to compute the key of a given field's entry"""
+    """Implement the logic to compute the key of a given field's entry"""
     return node.alias.value if node.alias else node.name.value
```

### Comparing `graphql_core-3.3.0a3/src/graphql/execution/execute.py` & `graphql_core-3.3.0a4/src/graphql/execution/execute.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,7 +1,9 @@
+"""GraphQL execution"""
+
 from __future__ import annotations  # Python < 3.10
 
 from asyncio import Event, as_completed, ensure_future, gather, shield, sleep, wait_for
 from collections.abc import Mapping
 from contextlib import suppress
 from typing import (
     Any,
@@ -9,26 +11,26 @@
     AsyncIterable,
     AsyncIterator,
     Awaitable,
     Callable,
     Dict,
     Generator,
     Iterable,
+    Iterator,
     List,
     NamedTuple,
     Optional,
     Sequence,
     Set,
     Tuple,
     Type,
     Union,
     cast,
 )
 
-
 try:
     from typing import TypedDict
 except ImportError:  # Python < 3.8
     from typing_extensions import TypedDict
 try:
     from typing import TypeAlias, TypeGuard
 except ImportError:  # Python < 3.10
@@ -43,17 +45,23 @@
 from ..language import (
     DocumentNode,
     FieldNode,
     FragmentDefinitionNode,
     OperationDefinitionNode,
     OperationType,
 )
-from ..pyutils import AwaitableOrValue, Path, Undefined, async_reduce, inspect
+from ..pyutils import (
+    AwaitableOrValue,
+    Path,
+    Undefined,
+    async_reduce,
+    inspect,
+    is_iterable,
+)
 from ..pyutils import is_awaitable as default_is_awaitable
-from ..pyutils import is_iterable
 from ..type import (
     GraphQLAbstractType,
     GraphQLField,
     GraphQLFieldResolver,
     GraphQLLeafType,
     GraphQLList,
     GraphQLObjectType,
@@ -70,23 +78,21 @@
     is_object_type,
 )
 from .async_iterables import flatten_async_iterable, map_async_iterable
 from .collect_fields import FieldsAndPatches, collect_fields, collect_subfields
 from .middleware import MiddlewareManager
 from .values import get_argument_values, get_directive_values, get_variable_values
 
-
 ASYNC_DELAY = 1 / 512  # wait time in seconds for deferring execution
 
-
 try:  # pragma: no cover
-    anext
+    anext  # noqa: B018
 except NameError:  # pragma: no cover (Python < 3.10)
     # noinspection PyShadowingBuiltins
-    async def anext(iterator: AsyncIterator) -> Any:
+    async def anext(iterator: AsyncIterator) -> Any:  # noqa: A001
         """Return the next item from an async iterator."""
         return await iterator.__anext__()
 
 
 __all__ = [
     "ASYNC_DELAY",
     "create_source_event_stream",
@@ -160,56 +166,58 @@
     extensions: Optional[Dict[str, Any]]
 
     def __init__(
         self,
         data: Optional[Dict[str, Any]] = None,
         errors: Optional[List[GraphQLError]] = None,
         extensions: Optional[Dict[str, Any]] = None,
-    ):
+    ) -> None:
         self.data = data
         self.errors = errors
         self.extensions = extensions
 
     def __repr__(self) -> str:
         name = self.__class__.__name__
         ext = "" if self.extensions is None else f", extensions={self.extensions}"
         return f"{name}(data={self.data!r}, errors={self.errors!r}{ext})"
 
-    def __iter__(self) -> Iterable[Any]:
+    def __iter__(self) -> Iterator[Any]:
         return iter((self.data, self.errors))
 
     @property
     def formatted(self) -> FormattedExecutionResult:
         """Get execution result formatted according to the specification."""
         formatted: FormattedExecutionResult = {"data": self.data}
         if self.errors is not None:
             formatted["errors"] = [error.formatted for error in self.errors]
         if self.extensions is not None:
             formatted["extensions"] = self.extensions
         return formatted
 
-    def __eq__(self, other: Any) -> bool:
+    def __eq__(self, other: object) -> bool:
         if isinstance(other, dict):
             if "extensions" not in other:
-                return other == dict(data=self.data, errors=self.errors)
-            return other == dict(
-                data=self.data, errors=self.errors, extensions=self.extensions
-            )
+                return other == {"data": self.data, "errors": self.errors}
+            return other == {
+                "data": self.data,
+                "errors": self.errors,
+                "extensions": self.extensions,
+            }
         if isinstance(other, tuple):
             if len(other) == 2:
                 return other == (self.data, self.errors)
             return other == (self.data, self.errors, self.extensions)
         return (
             isinstance(other, self.__class__)
             and other.data == self.data
             and other.errors == self.errors
             and other.extensions == self.extensions
         )
 
-    def __ne__(self, other: Any) -> bool:
+    def __ne__(self, other: object) -> bool:
         return not self == other
 
 
 class FormattedIncrementalDeferResult(TypedDict, total=False):
     """Formatted incremental deferred execution result"""
 
     data: Optional[Dict[str, Any]]
@@ -233,15 +241,15 @@
     def __init__(
         self,
         data: Optional[Dict[str, Any]] = None,
         errors: Optional[List[GraphQLError]] = None,
         path: Optional[List[Union[str, int]]] = None,
         label: Optional[str] = None,
         extensions: Optional[Dict[str, Any]] = None,
-    ):
+    ) -> None:
         self.data = data
         self.errors = errors
         self.path = path
         self.label = label
         self.extensions = extensions
 
     def __repr__(self) -> str:
@@ -265,15 +273,15 @@
             formatted["path"] = self.path
         if self.label is not None:
             formatted["label"] = self.label
         if self.extensions is not None:
             formatted["extensions"] = self.extensions
         return formatted
 
-    def __eq__(self, other: Any) -> bool:
+    def __eq__(self, other: object) -> bool:
         if isinstance(other, dict):
             return (
                 other.get("data") == self.data
                 and other.get("errors") == self.errors
                 and ("path" not in other or other["path"] == self.path)
                 and ("label" not in other or other["label"] == self.label)
                 and (
@@ -294,15 +302,15 @@
             and other.data == self.data
             and other.errors == self.errors
             and other.path == self.path
             and other.label == self.label
             and other.extensions == self.extensions
         )
 
-    def __ne__(self, other: Any) -> bool:
+    def __ne__(self, other: object) -> bool:
         return not self == other
 
 
 class FormattedIncrementalStreamResult(TypedDict, total=False):
     """Formatted incremental stream execution result"""
 
     items: Optional[List[Any]]
@@ -326,15 +334,15 @@
     def __init__(
         self,
         items: Optional[List[Any]] = None,
         errors: Optional[List[GraphQLError]] = None,
         path: Optional[List[Union[str, int]]] = None,
         label: Optional[str] = None,
         extensions: Optional[Dict[str, Any]] = None,
-    ):
+    ) -> None:
         self.items = items
         self.errors = errors
         self.path = path
         self.label = label
         self.extensions = extensions
 
     def __repr__(self) -> str:
@@ -358,15 +366,15 @@
             formatted["path"] = self.path
         if self.label is not None:
             formatted["label"] = self.label
         if self.extensions is not None:
             formatted["extensions"] = self.extensions
         return formatted
 
-    def __eq__(self, other: Any) -> bool:
+    def __eq__(self, other: object) -> bool:
         if isinstance(other, dict):
             return (
                 other.get("items") == self.items
                 and other.get("errors") == self.errors
                 and ("path" not in other or other["path"] == self.path)
                 and ("label" not in other or other["label"] == self.label)
                 and (
@@ -387,15 +395,15 @@
             and other.items == self.items
             and other.errors == self.errors
             and other.path == self.path
             and other.label == self.label
             and other.extensions == self.extensions
         )
 
-    def __ne__(self, other: Any) -> bool:
+    def __ne__(self, other: object) -> bool:
         return not self == other
 
 
 FormattedIncrementalResult = Union[
     FormattedIncrementalDeferResult, FormattedIncrementalStreamResult
 ]
 
@@ -430,15 +438,15 @@
     def __init__(
         self,
         data: Optional[Dict[str, Any]] = None,
         errors: Optional[List[GraphQLError]] = None,
         incremental: Optional[Sequence[IncrementalResult]] = None,
         has_next: bool = False,
         extensions: Optional[Dict[str, Any]] = None,
-    ):
+    ) -> None:
         self.data = data
         self.errors = errors
         self.incremental = incremental
         self.has_next = has_next
         self.extensions = extensions
 
     def __repr__(self) -> str:
@@ -461,15 +469,15 @@
         if self.incremental:
             formatted["incremental"] = [result.formatted for result in self.incremental]
         formatted["hasNext"] = self.has_next
         if self.extensions is not None:
             formatted["extensions"] = self.extensions
         return formatted
 
-    def __eq__(self, other: Any) -> bool:
+    def __eq__(self, other: object) -> bool:
         if isinstance(other, dict):
             return (
                 other.get("data") == self.data
                 and other.get("errors") == self.errors
                 and (
                     "incremental" not in other
                     or other["incremental"] == self.incremental
@@ -497,15 +505,15 @@
             and other.data == self.data
             and other.errors == self.errors
             and other.incremental == self.incremental
             and other.has_next == self.has_next
             and other.extensions == self.extensions
         )
 
-    def __ne__(self, other: Any) -> bool:
+    def __ne__(self, other: object) -> bool:
         return not self == other
 
 
 class FormattedSubsequentIncrementalExecutionResult(TypedDict, total=False):
     """Formatted subsequent incremental execution result"""
 
     incremental: List[FormattedIncrementalResult]
@@ -554,15 +562,15 @@
         if self.incremental:
             formatted["incremental"] = [result.formatted for result in self.incremental]
         formatted["hasNext"] = self.has_next
         if self.extensions is not None:
             formatted["extensions"] = self.extensions
         return formatted
 
-    def __eq__(self, other: Any) -> bool:
+    def __eq__(self, other: object) -> bool:
         if isinstance(other, dict):
             return (
                 ("incremental" not in other or other["incremental"] == self.incremental)
                 and ("hasNext" in other and other["hasNext"] == self.has_next)
                 and (
                     "extensions" not in other or other["extensions"] == self.extensions
                 )
@@ -581,15 +589,15 @@
         return (
             isinstance(other, self.__class__)
             and other.incremental == self.incremental
             and other.has_next == self.has_next
             and other.extensions == self.extensions
         )
 
-    def __ne__(self, other: Any) -> bool:
+    def __ne__(self, other: object) -> bool:
         return not self == other
 
 
 class StreamArguments(NamedTuple):
     """Arguments of the stream directive"""
 
     initial_count: int
@@ -695,19 +703,20 @@
         middleware_manager: Optional[MiddlewareManager] = None
         if middleware is not None:
             if isinstance(middleware, (list, tuple)):
                 middleware_manager = MiddlewareManager(*middleware)
             elif isinstance(middleware, MiddlewareManager):
                 middleware_manager = middleware
             else:
-                raise TypeError(
+                msg = (
                     "Middleware must be passed as a list or tuple of functions"
                     " or objects, or as a single MiddlewareManager object."
                     f" Got {inspect(middleware)} instead."
                 )
+                raise TypeError(msg)
 
         for definition in document.definitions:
             if isinstance(definition, OperationDefinitionNode):
                 if operation_name is None:
                     if operation:
                         return [
                             GraphQLError(
@@ -793,19 +802,19 @@
 
         Implements the "Executing operations" section of the spec.
         """
         schema = self.schema
         operation = self.operation
         root_type = schema.get_root_type(operation.operation)
         if root_type is None:
-            raise GraphQLError(
+            msg = (
                 "Schema is not configured to execute"
-                f" {operation.operation.value} operation.",
-                operation,
+                f" {operation.operation.value} operation."
             )
+            raise GraphQLError(msg, operation)
 
         root_fields, patches = collect_fields(
             schema,
             self.fragments,
             self.variable_values,
             root_type,
             operation.selection_set,
@@ -813,17 +822,15 @@
 
         root_value = self.root_value
         # noinspection PyTypeChecker
         result = (
             self.execute_fields_serially
             if operation.operation == OperationType.MUTATION
             else self.execute_fields
-        )(
-            root_type, root_value, None, root_fields
-        )  # type: ignore
+        )(root_type, root_value, None, root_fields)  # type: ignore
 
         for patch in patches:
             label, patch_fields = patch
             self.execute_deferred_fragment(
                 root_type, root_value, patch_fields, label, None
             )
 
@@ -958,68 +965,53 @@
             args = get_argument_values(field_def, field_nodes[0], self.variable_values)
 
             # Note that contrary to the JavaScript implementation, we pass the context
             # value as part of the resolve info.
             result = resolve_fn(source, info, **args)
 
             if self.is_awaitable(result):
-                # noinspection PyShadowingNames
-                async def await_result() -> Any:
-                    try:
-                        completed = self.complete_value(
-                            return_type,
-                            field_nodes,
-                            info,
-                            path,
-                            await result,
-                            async_payload_record,
-                        )
-                        if self.is_awaitable(completed):
-                            return await completed
-                        return completed
-                    except Exception as raw_error:
-                        error = located_error(raw_error, field_nodes, path.as_list())
-                        handle_field_error(error, return_type, errors)
-                        return None
-
-                return await_result()
+                return self.complete_awaitable_value(
+                    return_type, field_nodes, info, path, result, async_payload_record
+                )
 
             completed = self.complete_value(
                 return_type, field_nodes, info, path, result, async_payload_record
             )
             if self.is_awaitable(completed):
                 # noinspection PyShadowingNames
                 async def await_completed() -> Any:
                     try:
                         return await completed
                     except Exception as raw_error:
                         error = located_error(raw_error, field_nodes, path.as_list())
                         handle_field_error(error, return_type, errors)
-                        self.filter_subsequent_payloads(path)
+                        self.filter_subsequent_payloads(path, async_payload_record)
                         return None
 
                 return await_completed()
 
-            return completed
         except Exception as raw_error:
             error = located_error(raw_error, field_nodes, path.as_list())
             handle_field_error(error, return_type, errors)
-            self.filter_subsequent_payloads(path)
+            self.filter_subsequent_payloads(path, async_payload_record)
             return None
 
+        return completed
+
     def build_resolve_info(
         self,
         field_def: GraphQLField,
         field_nodes: List[FieldNode],
         parent_type: GraphQLObjectType,
         path: Path,
     ) -> GraphQLResolveInfo:
         """Build the GraphQLResolveInfo object.
 
-        For internal use only."""
+        For internal use only.
+        """
         # The resolve function's first argument is a collection of information about
         # the current execution state.
         return GraphQLResolveInfo(
             field_nodes[0].name.value,
             field_nodes,
             field_def.type,
             parent_type,
@@ -1076,18 +1068,19 @@
                 field_nodes,
                 info,
                 path,
                 result,
                 async_payload_record,
             )
             if completed is None:
-                raise TypeError(
+                msg = (
                     "Cannot return null for non-nullable field"
                     f" {info.parent_type.name}.{info.field_name}."
                 )
+                raise TypeError(msg)
             return completed
 
         # If result value is null or undefined then return null.
         if result is None or result is Undefined:
             return None
 
         # If field type is List, complete each item in the list with inner type
@@ -1111,18 +1104,51 @@
         # If field type is Object, execute and complete all sub-selections.
         if is_object_type(return_type):
             return self.complete_object_value(
                 return_type, field_nodes, info, path, result, async_payload_record
             )
 
         # Not reachable. All possible output types have been considered.
-        raise TypeError(  # pragma: no cover
+        msg = (
             "Cannot complete value of unexpected output type:"
             f" '{inspect(return_type)}'."
-        )
+        )  # pragma: no cover
+        raise TypeError(msg)  # pragma: no cover
+
+    async def complete_awaitable_value(
+        self,
+        return_type: GraphQLOutputType,
+        field_nodes: List[FieldNode],
+        info: GraphQLResolveInfo,
+        path: Path,
+        result: Any,
+        async_payload_record: Optional[AsyncPayloadRecord] = None,
+    ) -> Any:
+        """Complete an awaitable value."""
+        try:
+            resolved = await result
+            completed = self.complete_value(
+                return_type,
+                field_nodes,
+                info,
+                path,
+                resolved,
+                async_payload_record,
+            )
+            if self.is_awaitable(completed):
+                completed = await completed
+        except Exception as raw_error:
+            errors = (
+                async_payload_record.errors if async_payload_record else self.errors
+            )
+            error = located_error(raw_error, field_nodes, path.as_list())
+            handle_field_error(error, return_type, errors)
+            self.filter_subsequent_payloads(path, async_payload_record)
+            completed = None
+        return completed
 
     def get_stream_values(
         self, field_nodes: List[FieldNode], path: Path
     ) -> Optional[StreamArguments]:
         """Get stream values.
 
         Returns an object containing the `@stream` arguments if a field should be
@@ -1140,15 +1166,16 @@
         )
 
         if not stream or stream.get("if") is False:
             return None
 
         initial_count = stream.get("initialCount")
         if initial_count is None or initial_count < 0:
-            raise ValueError("initialCount must be a positive integer")
+            msg = "initialCount must be a positive integer"
+            raise ValueError(msg)
 
         label = stream.get("label")
         return StreamArguments(initial_count=initial_count, label=label)
 
     async def complete_async_iterator_value(
         self,
         item_type: GraphQLOutputType,
@@ -1156,32 +1183,31 @@
         info: GraphQLResolveInfo,
         path: Path,
         iterator: AsyncIterator[Any],
         async_payload_record: Optional[AsyncPayloadRecord],
     ) -> List[Any]:
         """Complete an async iterator.
 
-        Complete a async iterator value by completing the result and calling
+        Complete an async iterator value by completing the result and calling
         recursively until all the results are completed.
         """
         errors = async_payload_record.errors if async_payload_record else self.errors
         stream = self.get_stream_values(field_nodes, path)
-        is_awaitable = self.is_awaitable
+        complete_list_item_value = self.complete_list_item_value
         awaitable_indices: List[int] = []
         append_awaitable = awaitable_indices.append
         completed_results: List[Any] = []
-        append_result = completed_results.append
         index = 0
         while True:
             if (
                 stream
                 and isinstance(stream.initial_count, int)
                 and index >= stream.initial_count
             ):
-                try:
+                with suppress(TimeoutError):
                     await wait_for(
                         shield(
                             self.execute_stream_iterator(
                                 index,
                                 iterator,
                                 field_nodes,
                                 info,
@@ -1189,45 +1215,39 @@
                                 path,
                                 stream.label,
                                 async_payload_record,
                             )
                         ),
                         timeout=ASYNC_DELAY,
                     )
-                except TimeoutError:
-                    pass
                 break
 
-            field_path = path.add_key(index, None)
+            item_path = path.add_key(index, None)
             try:
                 try:
                     value = await anext(iterator)
                 except StopAsyncIteration:
                     break
-                try:
-                    completed_item = self.complete_value(
-                        item_type,
-                        field_nodes,
-                        info,
-                        field_path,
-                        value,
-                        async_payload_record,
-                    )
-                    if is_awaitable(completed_item):
-                        append_awaitable(index)
-                    append_result(completed_item)
-                except Exception as raw_error:
-                    append_result(None)
-                    error = located_error(raw_error, field_nodes, field_path.as_list())
-                    handle_field_error(error, item_type, errors)
             except Exception as raw_error:
-                append_result(None)
-                error = located_error(raw_error, field_nodes, field_path.as_list())
+                error = located_error(raw_error, field_nodes, item_path.as_list())
                 handle_field_error(error, item_type, errors)
+                completed_results.append(None)
                 break
+            if complete_list_item_value(
+                value,
+                completed_results,
+                errors,
+                item_type,
+                field_nodes,
+                info,
+                item_path,
+                async_payload_record,
+            ):
+                append_awaitable(index)
+
             index += 1
 
         if not awaitable_indices:
             return completed_results
 
         if len(awaitable_indices) == 1:
             # If there is only one index, avoid the overhead of parallelization.
@@ -1263,35 +1283,34 @@
             iterator = result.__aiter__()
 
             return self.complete_async_iterator_value(
                 item_type, field_nodes, info, path, iterator, async_payload_record
             )
 
         if not is_iterable(result):
-            raise GraphQLError(
+            msg = (
                 "Expected Iterable, but did not find one for field"
                 f" '{info.parent_type.name}.{info.field_name}'."
             )
+            raise GraphQLError(msg)
 
         stream = self.get_stream_values(field_nodes, path)
 
         # This is specified as a simple map, however we're optimizing the path where
         # the list contains no coroutine objects by avoiding creating another coroutine
         # object.
-        is_awaitable = self.is_awaitable
+        complete_list_item_value = self.complete_list_item_value
         awaitable_indices: List[int] = []
         append_awaitable = awaitable_indices.append
         previous_async_payload_record = async_payload_record
         completed_results: List[Any] = []
-        append_result = completed_results.append
         for index, item in enumerate(result):
             # No need to modify the info object containing the path, since from here on
             # it is not ever accessed by resolver functions.
             item_path = path.add_key(index, None)
-            completed_item: AwaitableOrValue[Any]
 
             if (
                 stream
                 and isinstance(stream.initial_count, int)
                 and index >= stream.initial_count
             ):
                 previous_async_payload_record = self.execute_stream_field(
@@ -1301,71 +1320,26 @@
                     field_nodes,
                     info,
                     item_type,
                     stream.label,
                     previous_async_payload_record,
                 )
                 continue
-            if is_awaitable(item):
-                # noinspection PyShadowingNames
-                async def await_completed(item: Any, item_path: Path) -> Any:
-                    try:
-                        completed = self.complete_value(
-                            item_type,
-                            field_nodes,
-                            info,
-                            item_path,
-                            await item,
-                            async_payload_record,
-                        )
-                        if is_awaitable(completed):
-                            return await completed
-                        return completed
-                    except Exception as raw_error:
-                        error = located_error(
-                            raw_error, field_nodes, item_path.as_list()
-                        )
-                        handle_field_error(error, item_type, errors)
-                        self.filter_subsequent_payloads(item_path)
-                        return None
-
-                completed_item = await_completed(item, item_path)
-            else:
-                try:
-                    completed_item = self.complete_value(
-                        item_type,
-                        field_nodes,
-                        info,
-                        item_path,
-                        item,
-                        async_payload_record,
-                    )
-                    if is_awaitable(completed_item):
-                        # noinspection PyShadowingNames
-                        async def await_completed(item: Any, item_path: Path) -> Any:
-                            try:
-                                return await item
-                            except Exception as raw_error:
-                                error = located_error(
-                                    raw_error, field_nodes, item_path.as_list()
-                                )
-                                handle_field_error(error, item_type, errors)
-                                self.filter_subsequent_payloads(item_path)
-                                return None
-
-                        completed_item = await_completed(completed_item, item_path)
-                except Exception as raw_error:
-                    error = located_error(raw_error, field_nodes, item_path.as_list())
-                    handle_field_error(error, item_type, errors)
-                    self.filter_subsequent_payloads(item_path)
-                    completed_item = None
 
-            if is_awaitable(completed_item):
+            if complete_list_item_value(
+                item,
+                completed_results,
+                errors,
+                item_type,
+                field_nodes,
+                info,
+                item_path,
+                async_payload_record,
+            ):
                 append_awaitable(index)
-            append_result(completed_item)
 
         if not awaitable_indices:
             return completed_results
 
         # noinspection PyShadowingNames
         async def get_completed_results() -> List[Any]:
             if len(awaitable_indices) == 1:
@@ -1380,27 +1354,90 @@
                     ),
                 ):
                     completed_results[index] = result
             return completed_results
 
         return get_completed_results()
 
+    def complete_list_item_value(
+        self,
+        item: Any,
+        complete_results: List[Any],
+        errors: List[GraphQLError],
+        item_type: GraphQLOutputType,
+        field_nodes: List[FieldNode],
+        info: GraphQLResolveInfo,
+        item_path: Path,
+        async_payload_record: Optional[AsyncPayloadRecord],
+    ) -> bool:
+        """Complete a list item value by adding it to the completed results.
+
+        Returns True if the value is awaitable.
+        """
+        is_awaitable = self.is_awaitable
+
+        if is_awaitable(item):
+            complete_results.append(
+                self.complete_awaitable_value(
+                    item_type, field_nodes, info, item_path, item, async_payload_record
+                )
+            )
+            return True
+
+        try:
+            completed_item = self.complete_value(
+                item_type,
+                field_nodes,
+                info,
+                item_path,
+                item,
+                async_payload_record,
+            )
+
+            if is_awaitable(completed_item):
+                # noinspection PyShadowingNames
+                async def await_completed() -> Any:
+                    try:
+                        return await completed_item
+                    except Exception as raw_error:
+                        error = located_error(
+                            raw_error, field_nodes, item_path.as_list()
+                        )
+                        handle_field_error(error, item_type, errors)
+                        self.filter_subsequent_payloads(item_path, async_payload_record)
+                        return None
+
+                complete_results.append(await_completed())
+                return True
+
+            complete_results.append(completed_item)
+
+        except Exception as raw_error:
+            error = located_error(raw_error, field_nodes, item_path.as_list())
+            handle_field_error(error, item_type, errors)
+            self.filter_subsequent_payloads(item_path, async_payload_record)
+            complete_results.append(None)
+
+        return False
+
     @staticmethod
     def complete_leaf_value(return_type: GraphQLLeafType, result: Any) -> Any:
         """Complete a leaf value.
 
         Complete a Scalar or Enum by serializing to a valid value, returning null if
         serialization is not possible.
         """
         serialized_result = return_type.serialize(result)
         if serialized_result is Undefined or serialized_result is None:
-            raise TypeError(
+            msg = (
                 f"Expected `{inspect(return_type)}.serialize({inspect(result)})`"
-                f" to return non-nullable value, returned: {inspect(serialized_result)}"
+                " to return non-nullable value, returned:"
+                f" {inspect(serialized_result)}"
             )
+            raise TypeError(msg)
         return serialized_result
 
     def complete_abstract_value(
         self,
         return_type: GraphQLAbstractType,
         field_nodes: List[FieldNode],
         info: GraphQLResolveInfo,
@@ -1456,62 +1493,64 @@
         self,
         runtime_type_name: Any,
         return_type: GraphQLAbstractType,
         field_nodes: List[FieldNode],
         info: GraphQLResolveInfo,
         result: Any,
     ) -> GraphQLObjectType:
+        """Ensure that the given type is valid at runtime."""
         if runtime_type_name is None:
-            raise GraphQLError(
+            msg = (
                 f"Abstract type '{return_type.name}' must resolve"
                 " to an Object type at runtime"
                 f" for field '{info.parent_type.name}.{info.field_name}'."
                 f" Either the '{return_type.name}' type should provide"
                 " a 'resolve_type' function or each possible type should provide"
-                " an 'is_type_of' function.",
-                field_nodes,
+                " an 'is_type_of' function."
             )
+            raise GraphQLError(msg, field_nodes)
 
         if is_object_type(runtime_type_name):  # pragma: no cover
-            raise GraphQLError(
+            msg = (
                 "Support for returning GraphQLObjectType from resolve_type was"
                 " removed in GraphQL-core 3.2, please return type name instead."
             )
+            raise GraphQLError(msg)
 
         if not isinstance(runtime_type_name, str):
-            raise GraphQLError(
+            msg = (
                 f"Abstract type '{return_type.name}' must resolve"
                 " to an Object type at runtime"
                 f" for field '{info.parent_type.name}.{info.field_name}' with value"
-                f" {inspect(result)}, received '{inspect(runtime_type_name)}'.",
-                field_nodes,
+                f" {inspect(result)}, received '{inspect(runtime_type_name)}'."
             )
+            raise GraphQLError(msg, field_nodes)
 
         runtime_type = self.schema.get_type(runtime_type_name)
 
         if runtime_type is None:
-            raise GraphQLError(
+            msg = (
                 f"Abstract type '{return_type.name}' was resolved to a type"
-                f" '{runtime_type_name}' that does not exist inside the schema.",
-                field_nodes,
+                f" '{runtime_type_name}' that does not exist inside the schema."
             )
+            raise GraphQLError(msg, field_nodes)
 
         if not is_object_type(runtime_type):
-            raise GraphQLError(
+            msg = (
                 f"Abstract type '{return_type.name}' was resolved"
-                f" to a non-object type '{runtime_type_name}'.",
-                field_nodes,
+                f" to a non-object type '{runtime_type_name}'."
             )
+            raise GraphQLError(msg, field_nodes)
 
         if not self.schema.is_sub_type(return_type, runtime_type):
-            raise GraphQLError(
+            msg = (
                 f"Runtime Object type '{runtime_type.name}' is not a possible"
-                f" type for '{return_type.name}'.",
-                field_nodes,
+                f" type for '{return_type.name}'."
             )
+            raise GraphQLError(msg, field_nodes)
 
         # noinspection PyTypeChecker
         return runtime_type
 
     def complete_object_value(
         self,
         return_type: GraphQLObjectType,
@@ -1552,15 +1591,15 @@
         self,
         return_type: GraphQLObjectType,
         field_nodes: List[FieldNode],
         path: Path,
         result: Any,
         async_payload_record: Optional[AsyncPayloadRecord],
     ) -> AwaitableOrValue[Dict[str, Any]]:
-        # Collect sub-fields to execute to complete this value.
+        """Collect sub-fields to execute to complete this value."""
         sub_field_nodes, sub_patches = self.collect_subfields(return_type, field_nodes)
 
         sub_fields = self.execute_fields(
             return_type, result, path, sub_field_nodes, async_payload_record
         )
 
         for sub_patch in sub_patches:
@@ -1593,15 +1632,15 @@
         # Therefore, we use the ids of the field_nodes as keys. Note that we do not
         # use the id of the list, since we want to hit the cache for all lists of
         # the same nodes, not only for the same list of nodes. Also, the list id may
         # even be reused, in which case we would get wrong results from the cache.
         key = (
             (return_type, id(field_nodes[0]))
             if len(field_nodes) == 1  # optimize most frequent case
-            else tuple((return_type, *map(id, field_nodes)))
+            else (return_type, *map(id, field_nodes))
         )
         sub_fields_and_patches = cache.get(key)
         if sub_fields_and_patches is None:
             sub_fields_and_patches = collect_subfields(
                 self.schema,
                 self.fragments,
                 self.variable_values,
@@ -1609,40 +1648,37 @@
                 field_nodes,
             )
             cache[key] = sub_fields_and_patches
         return sub_fields_and_patches
 
     def map_source_to_response(
         self, result_or_stream: Union[ExecutionResult, AsyncIterable[Any]]
-    ) -> AwaitableOrValue[
-        Union[
-            AsyncGenerator[
-                Union[
-                    ExecutionResult,
-                    InitialIncrementalExecutionResult,
-                    SubsequentIncrementalExecutionResult,
-                ],
-                None,
+    ) -> Union[
+        AsyncGenerator[
+            Union[
+                ExecutionResult,
+                InitialIncrementalExecutionResult,
+                SubsequentIncrementalExecutionResult,
             ],
-            ExecutionResult,
-        ]
+            None,
+        ],
+        ExecutionResult,
     ]:
         """Map source result to response.
 
         For each payload yielded from a subscription,
         map it over the normal GraphQL :func:`~graphql.execution.execute` function,
         with ``payload`` as the ``root_value``.
         This implements the "MapSourceToResponseEvent" algorithm
         described in the GraphQL specification.
         The :func:`~graphql.execution.execute` function provides
         the "ExecuteSubscriptionEvent" algorithm,
         as it is nearly identical to the "ExecuteQuery" algorithm,
         for which :func:`~graphql.execution.execute` is also used.
         """
-
         if not isinstance(result_or_stream, AsyncIterable):
             return result_or_stream  # pragma: no cover
 
         async def callback(payload: Any) -> AsyncGenerator:
             result = execute_impl(self.build_per_event_execution_context(payload))
             return ensure_async_iterable(
                 await result if self.is_awaitable(result) else result  # type: ignore
@@ -1655,24 +1691,25 @@
         parent_type: GraphQLObjectType,
         source_value: Any,
         fields: Dict[str, List[FieldNode]],
         label: Optional[str] = None,
         path: Optional[Path] = None,
         parent_context: Optional[AsyncPayloadRecord] = None,
     ) -> None:
+        """Execute deferred fragment."""
         async_payload_record = DeferredFragmentRecord(label, path, parent_context, self)
         try:
             awaitable_or_data = self.execute_fields(
                 parent_type, source_value, path, fields, async_payload_record
             )
 
             if self.is_awaitable(awaitable_or_data):
 
                 async def await_data(
-                    awaitable: Awaitable[Dict[str, Any]]
+                    awaitable: Awaitable[Dict[str, Any]],
                 ) -> Optional[Dict[str, Any]]:
                     # noinspection PyShadowingNames
 
                     try:
                         return await awaitable
                     except GraphQLError as error:
                         async_payload_record.errors.append(error)
@@ -1692,206 +1729,205 @@
         item: AwaitableOrValue[Any],
         field_nodes: List[FieldNode],
         info: GraphQLResolveInfo,
         item_type: GraphQLOutputType,
         label: Optional[str] = None,
         parent_context: Optional[AsyncPayloadRecord] = None,
     ) -> AsyncPayloadRecord:
+        """Execute stream field."""
+        is_awaitable = self.is_awaitable
         async_payload_record = StreamRecord(
             label, item_path, None, parent_context, self
         )
         completed_item: Any
-        try:
-            try:
-                if self.is_awaitable(item):
 
-                    async def await_completed_item() -> Any:
-                        completed = self.complete_value(
+        if is_awaitable(item):
+            # noinspection PyShadowingNames
+            async def await_completed_items() -> Optional[List[Any]]:
+                try:
+                    return [
+                        await self.complete_awaitable_value(
                             item_type,
                             field_nodes,
                             info,
                             item_path,
-                            await item,
+                            item,
                             async_payload_record,
                         )
-                        return (
-                            await completed
-                            if self.is_awaitable(completed)
-                            else completed
-                        )
+                    ]
+                except GraphQLError as error:
+                    async_payload_record.errors.append(error)
+                    self.filter_subsequent_payloads(path, async_payload_record)
+                    return None
 
-                    completed_item = await_completed_item()
+            async_payload_record.add_items(await_completed_items())
+            return async_payload_record
 
-                else:
-                    completed_item = self.complete_value(
-                        item_type,
-                        field_nodes,
-                        info,
-                        item_path,
-                        item,
-                        async_payload_record,
-                    )
+        try:
+            try:
+                completed_item = self.complete_value(
+                    item_type,
+                    field_nodes,
+                    info,
+                    item_path,
+                    item,
+                    async_payload_record,
+                )
 
-                if self.is_awaitable(completed_item):
+                completed_items: Any
 
-                    async def await_completed_item() -> Any:
+                if is_awaitable(completed_item):
+                    # noinspection PyShadowingNames
+                    async def await_completed_items() -> Optional[List[Any]]:
                         # noinspection PyShadowingNames
                         try:
-                            return await completed_item
-                        except Exception as raw_error:
-                            # noinspection PyShadowingNames
-                            error = located_error(
-                                raw_error, field_nodes, item_path.as_list()
-                            )
-                            handle_field_error(
-                                error, item_type, async_payload_record.errors
-                            )
-                            self.filter_subsequent_payloads(
-                                item_path, async_payload_record
-                            )
+                            try:
+                                return [await completed_item]
+                            except Exception as raw_error:  # pragma: no cover
+                                # noinspection PyShadowingNames
+                                error = located_error(
+                                    raw_error, field_nodes, item_path.as_list()
+                                )
+                                handle_field_error(
+                                    error, item_type, async_payload_record.errors
+                                )
+                                self.filter_subsequent_payloads(
+                                    item_path, async_payload_record
+                                )
+                                return [None]
+                        except GraphQLError as error:  # pragma: no cover
+                            async_payload_record.errors.append(error)
+                            self.filter_subsequent_payloads(path, async_payload_record)
                             return None
 
-                    complete_item = await_completed_item()
-
+                    completed_items = await_completed_items()
                 else:
-                    complete_item = completed_item
+                    completed_items = [completed_item]
+
             except Exception as raw_error:
                 error = located_error(raw_error, field_nodes, item_path.as_list())
                 handle_field_error(error, item_type, async_payload_record.errors)
-                self.filter_subsequent_payloads(  # pragma: no cover
-                    item_path, async_payload_record
-                )
-                complete_item = None  # pragma: no cover
+                self.filter_subsequent_payloads(item_path, async_payload_record)
+                completed_items = [None]
 
         except GraphQLError as error:
             async_payload_record.errors.append(error)
             self.filter_subsequent_payloads(item_path, async_payload_record)
-            async_payload_record.add_items(None)
-            return async_payload_record
-
-        completed_items: AwaitableOrValue[Optional[List[Any]]]
-        if self.is_awaitable(complete_item):
-
-            async def await_completed_items() -> Optional[List[Any]]:
-                # noinspection PyShadowingNames
-                try:
-                    return [await complete_item]  # type: ignore
-                except GraphQLError as error:
-                    async_payload_record.errors.append(error)
-                    self.filter_subsequent_payloads(path, async_payload_record)
-                    return None
-
-            completed_items = await_completed_items()
-        else:
-            completed_items = [complete_item]
+            completed_items = None
 
         async_payload_record.add_items(completed_items)
         return async_payload_record
 
     async def execute_stream_iterator_item(
         self,
         iterator: AsyncIterator[Any],
         field_nodes: List[FieldNode],
         info: GraphQLResolveInfo,
         item_type: GraphQLOutputType,
         async_payload_record: StreamRecord,
-        field_path: Path,
+        item_path: Path,
     ) -> Any:
+        """Execute stream iterator item."""
         if iterator in self._canceled_iterators:
             raise StopAsyncIteration
         try:
             item = await anext(iterator)
             completed_item = self.complete_value(
-                item_type, field_nodes, info, field_path, item, async_payload_record
+                item_type, field_nodes, info, item_path, item, async_payload_record
             )
 
             return (
                 await completed_item
                 if self.is_awaitable(completed_item)
                 else completed_item
             )
 
         except StopAsyncIteration as raw_error:
             async_payload_record.set_is_completed_iterator()
             raise StopAsyncIteration from raw_error
 
         except Exception as raw_error:
-            error = located_error(raw_error, field_nodes, field_path.as_list())
+            error = located_error(raw_error, field_nodes, item_path.as_list())
             handle_field_error(error, item_type, async_payload_record.errors)
-            self.filter_subsequent_payloads(field_path, async_payload_record)
+            self.filter_subsequent_payloads(item_path, async_payload_record)
 
     async def execute_stream_iterator(
         self,
         initial_index: int,
         iterator: AsyncIterator[Any],
         field_modes: List[FieldNode],
         info: GraphQLResolveInfo,
         item_type: GraphQLOutputType,
-        path: Optional[Path],
-        label: Optional[str],
-        parent_context: Optional[AsyncPayloadRecord],
+        path: Path,
+        label: Optional[str] = None,
+        parent_context: Optional[AsyncPayloadRecord] = None,
     ) -> None:
+        """Execute stream iterator."""
         index = initial_index
         previous_async_payload_record = parent_context
 
         while True:
-            field_path = Path(path, index, None)
+            item_path = Path(path, index, None)
             async_payload_record = StreamRecord(
-                label, field_path, iterator, previous_async_payload_record, self
-            )
-
-            awaitable_data = self.execute_stream_iterator_item(
-                iterator, field_modes, info, item_type, async_payload_record, field_path
+                label, item_path, iterator, previous_async_payload_record, self
             )
 
             try:
-                data = await awaitable_data
+                data = await self.execute_stream_iterator_item(
+                    iterator,
+                    field_modes,
+                    info,
+                    item_type,
+                    async_payload_record,
+                    item_path,
+                )
             except StopAsyncIteration:
                 if async_payload_record.errors:
                     async_payload_record.add_items(None)  # pragma: no cover
                 else:
                     del self.subsequent_payloads[async_payload_record]
                 break
             except GraphQLError as error:
-                # entire stream has errored and bubbled upwards
+                async_payload_record.errors.append(error)
                 self.filter_subsequent_payloads(path, async_payload_record)
+                async_payload_record.add_items(None)
                 if iterator:  # pragma: no cover else
                     with suppress(Exception):
                         await iterator.aclose()  # type: ignore
                     # running generators cannot be closed since Python 3.8,
                     # so we need to remember that this iterator is already canceled
                     self._canceled_iterators.add(iterator)
-                async_payload_record.add_items(None)
-                async_payload_record.errors.append(error)
                 break
 
             async_payload_record.add_items([data])
 
             previous_async_payload_record = async_payload_record
             index += 1
 
     def filter_subsequent_payloads(
         self,
-        null_path: Optional[Path] = None,
+        null_path: Path,
         current_async_record: Optional[AsyncPayloadRecord] = None,
     ) -> None:
-        null_path_list = null_path.as_list() if null_path else []
+        """Filter subsequent payloads."""
+        null_path_list = null_path.as_list()
         for async_record in list(self.subsequent_payloads):
             if async_record is current_async_record:
                 # don't remove payload from where error originates
                 continue
             if async_record.path[: len(null_path_list)] != null_path_list:
                 # async_record points to a path unaffected by this payload
                 continue
             # async_record path points to nulled error field
             if isinstance(async_record, StreamRecord) and async_record.iterator:
                 self._canceled_iterators.add(async_record.iterator)
             del self.subsequent_payloads[async_record]
 
     def get_completed_incremental_results(self) -> List[IncrementalResult]:
+        """Get completed incremental results."""
         incremental_results: List[IncrementalResult] = []
         append_result = incremental_results.append
         subsequent_payloads = list(self.subsequent_payloads)
         for async_payload_record in subsequent_payloads:
             incremental_result: IncrementalResult
             if not async_payload_record.completed.is_set():
                 continue
@@ -1923,14 +1959,15 @@
             append_result(incremental_result)
 
         return incremental_results
 
     async def yield_subsequent_payloads(
         self,
     ) -> AsyncGenerator[SubsequentIncrementalExecutionResult, None]:
+        """Yield subsequent payloads."""
         payloads = self.subsequent_payloads
         has_next = bool(payloads)
 
         while has_next:
             for awaitable in as_completed(payloads):
                 await awaitable
 
@@ -1999,15 +2036,15 @@
     )
     if isinstance(result, ExecutionResult):
         return result
     if isinstance(result, ExperimentalIncrementalExecutionResults):
         raise GraphQLError(UNEXPECTED_MULTIPLE_PAYLOADS)
 
     async def await_result() -> Any:
-        awaited_result = await result  # type: ignore
+        awaited_result = await result
         if isinstance(awaited_result, ExecutionResult):
             return awaited_result
         return ExecutionResult(
             None, errors=[GraphQLError(UNEXPECTED_MULTIPLE_PAYLOADS)]
         )
 
     return await_result()
@@ -2084,46 +2121,47 @@
         result = context.execute_operation()
 
         if context.is_awaitable(result):
             # noinspection PyShadowingNames
             async def await_result() -> Any:
                 try:
                     initial_result = build_response(
-                        await result, errors  # type: ignore
+                        await result,  # type: ignore
+                        errors,
                     )
                     if context.subsequent_payloads:
                         return ExperimentalIncrementalExecutionResults(
                             initial_result=InitialIncrementalExecutionResult(
                                 initial_result.data,
                                 initial_result.errors,
                                 has_next=True,
                             ),
                             subsequent_results=context.yield_subsequent_payloads(),
                         )
-                    return initial_result
                 except GraphQLError as error:
                     errors.append(error)
                     return build_response(None, errors)
+                return initial_result
 
             return await_result()
 
         initial_result = build_response(result, errors)  # type: ignore
         if context.subsequent_payloads:
             return ExperimentalIncrementalExecutionResults(
                 initial_result=InitialIncrementalExecutionResult(
                     initial_result.data,
                     initial_result.errors,
                     has_next=True,
                 ),
                 subsequent_results=context.yield_subsequent_payloads(),
             )
-        return initial_result
     except GraphQLError as error:
         errors.append(error)
         return build_response(None, errors)
+    return initial_result
 
 
 def assume_not_awaitable(_value: Any) -> bool:
     """Replacement for is_awaitable if everything is assumed to be synchronous."""
     return False
 
 
@@ -2172,15 +2210,16 @@
 
     # Assert that the execution was synchronous.
     if default_is_awaitable(result) or isinstance(
         result, ExperimentalIncrementalExecutionResults
     ):
         if default_is_awaitable(result):
             ensure_future(cast(Awaitable[ExecutionResult], result)).cancel()
-        raise RuntimeError("GraphQL execution failed to complete synchronously.")
+        msg = "GraphQL execution failed to complete synchronously."
+        raise RuntimeError(msg)
 
     return cast(ExecutionResult, result)
 
 
 def handle_field_error(
     error: GraphQLError, return_type: GraphQLOutputType, errors: List[GraphQLError]
 ) -> None:
@@ -2188,15 +2227,14 @@
     # If the field type is non-nullable, then it is resolved without any protection
     # from errors, however it still properly locates the error.
     if is_non_null_type(return_type):
         raise error
     # Otherwise, error protection is applied, logging the error and resolving a
     # null value for this field if one is encountered.
     errors.append(error)
-    return None
 
 
 def invalid_return_type_error(
     return_type: GraphQLObjectType, result: Any, field_nodes: List[FieldNode]
 ) -> GraphQLError:
     """Create a GraphQLError for an invalid return type."""
     return GraphQLError(
@@ -2347,30 +2385,30 @@
 
     if isinstance(result, ExecutionResult):
         return result
     if isinstance(result, AsyncIterable):
         return map_async_iterable(result, ensure_single_execution_result)
 
     async def await_result() -> Union[AsyncIterator[ExecutionResult], ExecutionResult]:
-        result_or_iterable = await result  # type: ignore
+        result_or_iterable = await result
         if isinstance(result_or_iterable, AsyncIterable):
             return map_async_iterable(
                 result_or_iterable, ensure_single_execution_result
             )
         return result_or_iterable
 
     return await_result()
 
 
 async def ensure_single_execution_result(
     result: Union[
         ExecutionResult,
         InitialIncrementalExecutionResult,
         SubsequentIncrementalExecutionResult,
-    ]
+    ],
 ) -> ExecutionResult:
     """Ensure that the given result does not use incremental delivery."""
     if not isinstance(result, ExecutionResult):
         return ExecutionResult(
             None, errors=[GraphQLError(UNEXPECTED_MULTIPLE_PAYLOADS)]
         )
     return result
@@ -2455,17 +2493,15 @@
 
     if context.is_awaitable(result_or_stream):
         # noinspection PyShadowingNames
         async def await_result() -> Any:
             awaited_result_or_stream = await result_or_stream  # type: ignore
             if isinstance(awaited_result_or_stream, ExecutionResult):
                 return awaited_result_or_stream
-            return context.map_source_to_response(  # type: ignore
-                awaited_result_or_stream
-            )
+            return context.map_source_to_response(awaited_result_or_stream)
 
         return await_result()
 
     if isinstance(result_or_stream, ExecutionResult):
         return result_or_stream
 
     return context.map_source_to_response(result_or_stream)  # type: ignore
@@ -2574,35 +2610,32 @@
 def execute_subscription(
     context: ExecutionContext,
 ) -> AwaitableOrValue[AsyncIterable[Any]]:
     schema = context.schema
 
     root_type = schema.subscription_type
     if root_type is None:
-        raise GraphQLError(
-            "Schema is not configured to execute subscription operation.",
-            context.operation,
-        )
+        msg = "Schema is not configured to execute subscription operation."
+        raise GraphQLError(msg, context.operation)
 
     root_fields = collect_fields(
         schema,
         context.fragments,
         context.variable_values,
         root_type,
         context.operation.selection_set,
     ).fields
     first_root_field = next(iter(root_fields.items()))
     response_name, field_nodes = first_root_field
     field_name = field_nodes[0].name.value
     field_def = schema.get_field(root_type, field_name)
 
     if not field_def:
-        raise GraphQLError(
-            f"The subscription field '{field_name}' is not defined.", field_nodes
-        )
+        msg = f"The subscription field '{field_name}' is not defined."
+        raise GraphQLError(msg, field_nodes)
 
     path = Path(None, response_name, root_type.name)
     info = context.build_resolve_info(field_def, field_nodes, root_type, path)
 
     # Implements the "ResolveFieldEventStream" algorithm from GraphQL specification.
     # It differs from "ResolveFieldValue" due to providing a different `resolveFn`.
 
@@ -2618,34 +2651,35 @@
         result = resolve_fn(context.root_value, info, **args)
         if context.is_awaitable(result):
             # noinspection PyShadowingNames
             async def await_result() -> AsyncIterable[Any]:
                 try:
                     return assert_event_stream(await result)
                 except Exception as error:
-                    raise located_error(error, field_nodes, path.as_list())
+                    raise located_error(error, field_nodes, path.as_list()) from error
 
             return await_result()
 
         return assert_event_stream(result)
 
     except Exception as error:
-        raise located_error(error, field_nodes, path.as_list())
+        raise located_error(error, field_nodes, path.as_list()) from error
 
 
 def assert_event_stream(result: Any) -> AsyncIterable:
     if isinstance(result, Exception):
         raise result
 
     # Assert field returned an event stream, otherwise yield an error.
     if not isinstance(result, AsyncIterable):
-        raise GraphQLError(
+        msg = (
             "Subscription field must return AsyncIterable."
             f" Received: {inspect(result)}."
         )
+        raise GraphQLError(msg)
 
     return result
 
 
 class DeferredFragmentRecord:
     """A record collecting data marked with the defer directive"""
 
@@ -2687,14 +2721,15 @@
             args.append("data")
         return f"{name}({', '.join(args)})"
 
     def __await__(self) -> Generator[Any, None, Optional[Dict[str, Any]]]:
         return self.wait().__await__()
 
     async def wait(self) -> Optional[Dict[str, Any]]:
+        """Wait until data is ready."""
         if self.parent_context:
             await self.parent_context.completed.wait()
         _data = self._data
         try:
             data = (
                 await _data  # type: ignore
                 if self._context.is_awaitable(_data)
@@ -2703,14 +2738,15 @@
         finally:
             await sleep(ASYNC_DELAY)  # always defer completion a little bit
             self.data = data
             self.completed.set()
         return data
 
     def add_data(self, data: AwaitableOrValue[Optional[Dict[str, Any]]]) -> None:
+        """Add data to the record."""
         self._data = data
         self._data_added.set()
 
 
 class StreamRecord:
     """A record collecting items marked with the stream directive"""
 
@@ -2757,14 +2793,15 @@
             args.append("items")
         return f"{name}({', '.join(args)})"
 
     def __await__(self) -> Generator[Any, None, Optional[List[str]]]:
         return self.wait().__await__()
 
     async def wait(self) -> Optional[List[str]]:
+        """Wait until data is ready."""
         await self._items_added.wait()
         if self.parent_context:
             await self.parent_context.completed.wait()
         _items = self._items
         try:
             items = (
                 await _items  # type: ignore
@@ -2774,16 +2811,18 @@
         finally:
             await sleep(ASYNC_DELAY)  # always defer completion a little bit
             self.items = items
             self.completed.set()
         return items
 
     def add_items(self, items: AwaitableOrValue[Optional[List[Any]]]) -> None:
+        """Add items to the record."""
         self._items = items
         self._items_added.set()
 
     def set_is_completed_iterator(self) -> None:
+        """Mark as completed."""
         self.is_completed_iterator = True
         self._items_added.set()
 
 
 AsyncPayloadRecord = Union[DeferredFragmentRecord, StreamRecord]
```

### Comparing `graphql_core-3.3.0a3/src/graphql/execution/middleware.py` & `graphql_core-3.3.0a4/src/graphql/execution/middleware.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,12 +1,13 @@
+"""Middleware manager"""
+
 from functools import partial, reduce
 from inspect import isfunction
 from typing import Any, Callable, Dict, Iterator, List, Optional, Tuple
 
-
 try:
     from typing import TypeAlias
 except ImportError:  # Python < 3.10
     from typing_extensions import TypeAlias
 
 
 __all__ = ["MiddlewareManager"]
@@ -28,15 +29,15 @@
 
     # allow custom attributes (not used internally)
     __slots__ = "__dict__", "middlewares", "_middleware_resolvers", "_cached_resolvers"
 
     _cached_resolvers: Dict[GraphQLFieldResolver, GraphQLFieldResolver]
     _middleware_resolvers: Optional[List[Callable]]
 
-    def __init__(self, *middlewares: Any):
+    def __init__(self, *middlewares: Any) -> None:
         self.middlewares = middlewares
         self._middleware_resolvers = (
             list(get_middleware_resolvers(middlewares)) if middlewares else None
         )
         self._cached_resolvers = {}
 
     def get_field_resolver(
```

### Comparing `graphql_core-3.3.0a3/src/graphql/execution/values.py` & `graphql_core-3.3.0a4/src/graphql/execution/values.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,7 +1,9 @@
+"""Helpers for handling values"""
+
 from typing import Any, Callable, Collection, Dict, List, Optional, Union
 
 from ..error import GraphQLError
 from ..language import (
     DirectiveNode,
     EnumValueDefinitionNode,
     ExecutableDefinitionNode,
@@ -25,24 +27,21 @@
     is_input_type,
     is_non_null_type,
 )
 from ..utilities.coerce_input_value import coerce_input_value
 from ..utilities.type_from_ast import type_from_ast
 from ..utilities.value_from_ast import value_from_ast
 
-
 try:
     from typing import TypeAlias
 except ImportError:  # Python < 3.10
     from typing_extensions import TypeAlias
 
-
 __all__ = ["get_argument_values", "get_directive_values", "get_variable_values"]
 
-
 CoercedVariableValues: TypeAlias = Union[List[GraphQLError], Dict[str, Any]]
 
 
 def get_variable_values(
     schema: GraphQLSchema,
     var_def_nodes: Collection[VariableDefinitionNode],
     inputs: Dict[str, Any],
@@ -54,18 +53,19 @@
     variable definitions and arbitrary input. If the input cannot be parsed to match
     the variable definitions, a GraphQLError will be raised.
     """
     errors: List[GraphQLError] = []
 
     def on_error(error: GraphQLError) -> None:
         if max_errors is not None and len(errors) >= max_errors:
-            raise GraphQLError(
+            msg = (
                 "Too many errors processing variables,"
                 " error limit reached. Execution aborted."
             )
+            raise GraphQLError(msg)
         errors.append(error)
 
     try:
         coerced = coerce_variable_values(schema, var_def_nodes, inputs, on_error)
         if not errors:
             return coerced
     except GraphQLError as e:
@@ -125,24 +125,22 @@
             )
             continue
 
         def on_input_value_error(
             path: List[Union[str, int]], invalid_value: Any, error: GraphQLError
         ) -> None:
             invalid_str = inspect(invalid_value)
-            prefix = (
-                f"Variable '${var_name}' got invalid value {invalid_str}"  # noqa: B023
-            )
+            prefix = f"Variable '${var_name}' got invalid value {invalid_str}"  # noqa: B023
             if path:
                 prefix += f" at '{var_name}{print_path_list(path)}'"  # noqa: B023
             on_error(
                 GraphQLError(
                     prefix + "; " + error.message,
                     var_def_node,  # noqa: B023
-                    original_error=error.original_error,
+                    original_error=error,
                 )
             )
 
         coerced_values[var_name] = coerce_input_value(
             value, var_type, on_input_value_error
         )
 
@@ -166,54 +164,50 @@
         arg_type = arg_def.type
         argument_node = arg_node_map.get(name)
 
         if argument_node is None:
             if arg_def.default_value is not Undefined:
                 coerced_values[arg_def.out_name or name] = arg_def.default_value
             elif is_non_null_type(arg_type):  # pragma: no cover else
-                raise GraphQLError(
+                msg = (
                     f"Argument '{name}' of required type '{arg_type}'"
-                    " was not provided.",
-                    node,
+                    " was not provided."
                 )
+                raise GraphQLError(msg, node)
             continue  # pragma: no cover
 
         value_node = argument_node.value
         is_null = isinstance(argument_node.value, NullValueNode)
 
         if isinstance(value_node, VariableNode):
             variable_name = value_node.name.value
             if variable_values is None or variable_name not in variable_values:
                 if arg_def.default_value is not Undefined:
                     coerced_values[arg_def.out_name or name] = arg_def.default_value
                 elif is_non_null_type(arg_type):  # pragma: no cover else
-                    raise GraphQLError(
+                    msg = (
                         f"Argument '{name}' of required type '{arg_type}'"
                         f" was provided the variable '${variable_name}'"
-                        " which was not provided a runtime value.",
-                        value_node,
+                        " which was not provided a runtime value."
                     )
+                    raise GraphQLError(msg, value_node)
                 continue  # pragma: no cover
             is_null = variable_values[variable_name] is None
 
         if is_null and is_non_null_type(arg_type):
-            raise GraphQLError(
-                f"Argument '{name}' of non-null type '{arg_type}' must not be null.",
-                value_node,
-            )
+            msg = f"Argument '{name}' of non-null type '{arg_type}' must not be null."
+            raise GraphQLError(msg, value_node)
 
         coerced_value = value_from_ast(value_node, arg_type, variable_values)
         if coerced_value is Undefined:
             # Note: `values_of_correct_type` validation should catch this before
             # execution. This is a runtime check to ensure execution does not
             # continue with an invalid argument value.
-            raise GraphQLError(
-                f"Argument '{name}' has invalid value {print_ast(value_node)}.",
-                value_node,
-            )
+            msg = f"Argument '{name}' has invalid value {print_ast(value_node)}."
+            raise GraphQLError(msg, value_node)
         coerced_values[arg_def.out_name or name] = coerced_value
 
     return coerced_values
 
 
 NodeWithDirective: TypeAlias = Union[
     EnumValueDefinitionNode,
```

### Comparing `graphql_core-3.3.0a3/src/graphql/graphql.py` & `graphql_core-3.3.0a4/src/graphql/graphql.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,7 +1,9 @@
+"""Execute a GraphQL operation"""
+
 from asyncio import ensure_future
 from typing import Any, Awaitable, Callable, Dict, Optional, Type, Union, cast
 
 from .error import GraphQLError
 from .execution import ExecutionContext, ExecutionResult, Middleware, execute
 from .language import Source, parse
 from .pyutils import AwaitableOrValue
@@ -9,15 +11,14 @@
 from .type import (
     GraphQLFieldResolver,
     GraphQLSchema,
     GraphQLTypeResolver,
     validate_schema,
 )
 
-
 __all__ = ["graphql", "graphql_sync"]
 
 
 async def graphql(
     schema: GraphQLSchema,
     source: Union[str, Source],
     root_value: Any = None,
@@ -143,15 +144,16 @@
         execution_context_class,
         is_awaitable,
     )
 
     # Assert that the execution was synchronous.
     if default_is_awaitable(result):
         ensure_future(cast(Awaitable[ExecutionResult], result)).cancel()
-        raise RuntimeError("GraphQL execution failed to complete synchronously.")
+        msg = "GraphQL execution failed to complete synchronously."
+        raise RuntimeError(msg)
 
     return cast(ExecutionResult, result)
 
 
 def graphql_impl(
     schema: GraphQLSchema,
     source: Union[str, Source],
```

### Comparing `graphql_core-3.3.0a3/src/graphql/language/__init__.py` & `graphql_core-3.3.0a4/src/graphql/language/__init__.py`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/src/graphql/language/ast.py` & `graphql_core-3.3.0a4/src/graphql/language/ast.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,23 +1,26 @@
+"""GraphQL Abstract Syntax Tree"""
+
 from __future__ import annotations  # Python < 3.10
 
 from copy import copy, deepcopy
 from enum import Enum
-from typing import Any, Dict, List, Optional, Tuple, Union
-
-from ..pyutils import camel_to_snake
-from .source import Source
-from .token_kind import TokenKind
-
+from typing import TYPE_CHECKING, Any, Dict, List, Optional, Tuple, Union
 
 try:
     from typing import TypeAlias
 except ImportError:  # Python < 3.10
     from typing_extensions import TypeAlias
 
+from ..pyutils import camel_to_snake
+
+if TYPE_CHECKING:
+    from .source import Source
+    from .token_kind import TokenKind
+
 
 __all__ = [
     "Location",
     "Token",
     "Node",
     "NameNode",
     "DocumentNode",
@@ -127,25 +130,25 @@
     def __repr__(self) -> str:
         """Print a simplified form when appearing in repr() or inspect()."""
         return f"<Token {self.desc} {self.line}:{self.column}>"
 
     def __inspect__(self) -> str:
         return repr(self)
 
-    def __eq__(self, other: Any) -> bool:
+    def __eq__(self, other: object) -> bool:
         if isinstance(other, Token):
             return (
                 self.kind == other.kind
                 and self.start == other.start
                 and self.end == other.end
                 and self.line == other.line
                 and self.column == other.column
                 and self.value == other.value
             )
-        elif isinstance(other, str):
+        if isinstance(other, str):
             return other == self.desc
         return False
 
     def __hash__(self) -> int:
         return hash(
             (self.kind, self.start, self.end, self.line, self.column, self.value)
         )
@@ -225,22 +228,22 @@
     def __repr__(self) -> str:
         """Print a simplified form when appearing in repr() or inspect()."""
         return f"<Location {self.start}:{self.end}>"
 
     def __inspect__(self) -> str:
         return repr(self)
 
-    def __eq__(self, other: Any) -> bool:
+    def __eq__(self, other: object) -> bool:
         if isinstance(other, Location):
             return self.start == other.start and self.end == other.end
-        elif isinstance(other, (list, tuple)) and len(other) == 2:
+        if isinstance(other, (list, tuple)) and len(other) == 2:
             return self.start == other[0] and self.end == other[1]
         return False
 
-    def __ne__(self, other: Any) -> bool:
+    def __ne__(self, other: object) -> bool:
         return not self == other
 
     def __hash__(self) -> int:
         return hash((self.start, self.end))
 
 
 class OperationType(Enum):
@@ -367,15 +370,15 @@
             if name:
                 rep += f"(name={name.value!r})"
         loc = getattr(self, "loc", None)
         if loc:
             rep += f" at {loc}"
         return rep
 
-    def __eq__(self, other: Any) -> bool:
+    def __eq__(self, other: object) -> bool:
         """Test whether two nodes are equal (recursively)."""
         return (
             isinstance(other, Node)
             and self.__class__ == other.__class__
             and all(getattr(self, key) == getattr(other, key) for key in self.keys)
         )
 
@@ -421,14 +424,15 @@
         for base in cls.__bases__:
             # noinspection PyUnresolvedReferences
             keys.extend(base.keys)  # type: ignore
         keys.extend(cls.__slots__)
         cls.keys = tuple(keys)
 
     def to_dict(self, locations: bool = False) -> Dict:
+        """Concert node to a dictionary."""
         from ..utilities import ast_to_dict
 
         return ast_to_dict(self, locations)
 
 
 # Name
 
@@ -498,15 +502,15 @@
     # and may be changed or removed in the future.
     nullability_assertion: NullabilityAssertionNode
     selection_set: Optional[SelectionSetNode]
 
 
 class NullabilityAssertionNode(Node):
     __slots__ = ("nullability_assertion",)
-    nullability_assertion: Optional["NullabilityAssertionNode"]
+    nullability_assertion: Optional[NullabilityAssertionNode]
 
 
 class ListNullabilityOperatorNode(NullabilityAssertionNode):
     pass
 
 
 class NonNullAssertionNode(NullabilityAssertionNode):
```

### Comparing `graphql_core-3.3.0a3/src/graphql/language/block_string.py` & `graphql_core-3.3.0a4/src/graphql/language/block_string.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,11 +1,12 @@
+"""Helpers for block strings"""
+
 from sys import maxsize
 from typing import Collection, List
 
-
 __all__ = [
     "dedent_block_string_lines",
     "is_printable_as_block_string",
     "print_block_string",
 ]
```

### Comparing `graphql_core-3.3.0a3/src/graphql/language/character_classes.py` & `graphql_core-3.3.0a4/src/graphql/language/character_classes.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,7 +1,9 @@
+"""Character classes"""
+
 __all__ = ["is_digit", "is_letter", "is_name_start", "is_name_continue"]
 
 
 def is_digit(char: str) -> bool:
     """Check whether char is a digit
 
     For internal use by the lexer only.
```

### Comparing `graphql_core-3.3.0a3/src/graphql/language/directive_locations.py` & `graphql_core-3.3.0a4/src/graphql/language/directive_locations.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,9 +1,10 @@
-from enum import Enum
+"""Directive locations"""
 
+from enum import Enum
 
 __all__ = ["DirectiveLocation"]
 
 
 class DirectiveLocation(Enum):
     """The enum type representing the directive location values."""
```

### Comparing `graphql_core-3.3.0a3/src/graphql/language/lexer.py` & `graphql_core-3.3.0a4/src/graphql/language/lexer.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,17 +1,18 @@
+"""GraphQL Lexer"""
+
 from typing import List, NamedTuple, Optional
 
 from ..error import GraphQLSyntaxError
 from .ast import Token
 from .block_string import dedent_block_string_lines
 from .character_classes import is_digit, is_name_continue, is_name_start
 from .source import Source
 from .token_kind import TokenKind
 
-
 __all__ = ["Lexer", "is_punctuator_token_kind"]
 
 
 class EscapeSequence(NamedTuple):
     """The string value and lexed size of an escape sequence."""
 
     value: str
@@ -23,15 +24,15 @@
 
     A Lexer is a stateful stream generator in that every time it is advanced, it returns
     the next token in the Source. Assuming the source lexes, the final Token emitted by
     the lexer will be of kind EOF, after which the lexer will repeatedly return the same
     EOF token whenever called.
     """
 
-    def __init__(self, source: Source):
+    def __init__(self, source: Source) -> None:
         """Given a Source object, initialize a Lexer for that source."""
         self.source = source
         self.token = self.last_token = Token(TokenKind.SOF, 0, 0, 0, 0)
         self.line, self.line_start = 1, 0
 
     def advance(self) -> Token:
         """Advance the token stream to the next non-ignored token."""
@@ -103,20 +104,20 @@
 
         while position < body_length:
             char = body[position]  # SourceCharacter
 
             if char in " \t,\ufeff":
                 position += 1
                 continue
-            elif char == "\n":
+            if char == "\n":
                 position += 1
                 self.line += 1
                 self.line_start = position
                 continue
-            elif char == "\r":
+            if char == "\r":
                 if body[position + 1 : position + 2] == "\n":
                     position += 2
                 else:
                     position += 1
                 self.line += 1
                 self.line_start = position
                 continue
@@ -135,17 +136,16 @@
 
             if is_digit(char) or char == "-":
                 return self.read_number(position, char)
 
             if is_name_start(char):
                 return self.read_name(position)
 
-            if char == ".":
-                if body[position + 1 : position + 3] == "..":
-                    return self.create_token(TokenKind.SPREAD, position, position + 3)
+            if char == "." and body[position + 1 : position + 3] == "..":
+                return self.create_token(TokenKind.SPREAD, position, position + 3)
 
             message = (
                 "Unexpected single quote character ('),"
                 ' did you mean to use a double quote (")?'
                 if char == "'"
                 else (
                     f"Unexpected character: {self.print_code_point_at(position)}."
@@ -310,14 +310,15 @@
                     "Invalid character within String:"
                     f" {self.print_code_point_at(position)}.",
                 )
 
         raise GraphQLSyntaxError(self.source, position, "Unterminated string.")
 
     def read_escaped_unicode_variable_width(self, position: int) -> EscapeSequence:
+        """Read escaped unicode with variable width"""
         body = self.source.body
         point = 0
         size = 3
         max_size = min(12, len(body) - position)
         # Cannot be larger than 12 chars (\u{00000000}).
         while size < max_size:
             char = body[position + size]
@@ -337,40 +338,41 @@
         raise GraphQLSyntaxError(
             self.source,
             position,
             f"Invalid Unicode escape sequence: '{body[position: position + size]}'.",
         )
 
     def read_escaped_unicode_fixed_width(self, position: int) -> EscapeSequence:
+        """Read escaped unicode with fixed width"""
         body = self.source.body
         code = read_16_bit_hex_code(body, position + 2)
 
         if 0 <= code <= 0xD7FF or 0xE000 <= code <= 0x10FFFF:
             return EscapeSequence(chr(code), 6)
 
         # GraphQL allows JSON-style surrogate pair escape sequences, but only when
         # a valid pair is formed.
-        if 0xD800 <= code <= 0xDBFF:
-            if body[position + 6 : position + 8] == "\\u":
-                trailing_code = read_16_bit_hex_code(body, position + 8)
-                if 0xDC00 <= trailing_code <= 0xDFFF:
-                    return EscapeSequence(
-                        (chr(code) + chr(trailing_code))
-                        .encode("utf-16", "surrogatepass")
-                        .decode("utf-16"),
-                        12,
-                    )
+        if 0xD800 <= code <= 0xDBFF and body[position + 6 : position + 8] == "\\u":
+            trailing_code = read_16_bit_hex_code(body, position + 8)
+            if 0xDC00 <= trailing_code <= 0xDFFF:
+                return EscapeSequence(
+                    (chr(code) + chr(trailing_code))
+                    .encode("utf-16", "surrogatepass")
+                    .decode("utf-16"),
+                    12,
+                )
 
         raise GraphQLSyntaxError(
             self.source,
             position,
             f"Invalid Unicode escape sequence: '{body[position: position + 6]}'.",
         )
 
     def read_escaped_character(self, position: int) -> EscapeSequence:
+        """Read escaped character sequence"""
         body = self.source.body
         value = _ESCAPED_CHARS.get(body[position + 1])
         if value:
             return EscapeSequence(value, 2)
         raise GraphQLSyntaxError(
             self.source,
             position,
@@ -540,17 +542,17 @@
     'A' becomes 10, 'F' becomes 15
     'a' becomes 10, 'f' becomes 15
 
     Returns -1 if the provided character code was not a valid hexadecimal digit.
     """
     if "0" <= char <= "9":
         return ord(char) - 48
-    elif "A" <= char <= "F":
+    if "A" <= char <= "F":
         return ord(char) - 55
-    elif "a" <= char <= "f":
+    if "a" <= char <= "f":
         return ord(char) - 87
     return -1
 
 
 def is_unicode_scalar_value(char: str) -> bool:
     """Check whether this is a Unicode scalar value.
 
@@ -558,16 +560,15 @@
     points. In other words, the inclusive ranges of values 0x0000 to 0xD7FF and
     0xE000 to 0x10FFFF.
     """
     return "\x00" <= char <= "\ud7ff" or "\ue000" <= char <= "\U0010ffff"
 
 
 def is_supplementary_code_point(body: str, location: int) -> bool:
-    """
-    Check whether the current location is a supplementary code point.
+    """Check whether the current location is a supplementary code point.
 
     The GraphQL specification defines source text as a sequence of unicode scalar
     values (which Unicode defines to exclude surrogate code points).
     """
     try:
         return (
             "\ud800" <= body[location] <= "\udbff"
```

### Comparing `graphql_core-3.3.0a3/src/graphql/language/location.py` & `graphql_core-3.3.0a4/src/graphql/language/location.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,19 +1,20 @@
-from __future__ import annotations  # Python < 3.10
+"""Source locations"""
 
-from typing import TYPE_CHECKING, Any, NamedTuple
+from __future__ import annotations  # Python < 3.10
 
+from typing import TYPE_CHECKING, NamedTuple
 
 try:
     from typing import TypedDict
 except ImportError:  # Python < 3.8
     from typing_extensions import TypedDict
 
 if TYPE_CHECKING:
-    from .source import Source  # noqa: F401
+    from .source import Source
 
 __all__ = ["get_location", "SourceLocation", "FormattedSourceLocation"]
 
 
 class FormattedSourceLocation(TypedDict):
     """Formatted source location"""
 
@@ -25,25 +26,26 @@
     """Represents a location in a Source."""
 
     line: int
     column: int
 
     @property
     def formatted(self) -> FormattedSourceLocation:
-        return dict(line=self.line, column=self.column)
+        """Get formatted source location."""
+        return {"line": self.line, "column": self.column}
 
-    def __eq__(self, other: Any) -> bool:
+    def __eq__(self, other: object) -> bool:
         if isinstance(other, dict):
             return self.formatted == other
         return tuple(self) == other
 
-    def __ne__(self, other: Any) -> bool:
+    def __ne__(self, other: object) -> bool:
         return not self == other
 
 
-def get_location(source: "Source", position: int) -> SourceLocation:
+def get_location(source: Source, position: int) -> SourceLocation:
     """Get the line and column for a character position in the source.
 
     Takes a Source and a UTF-8 character offset, and returns the corresponding line and
     column as a SourceLocation.
     """
     return source.get_location(position)
```

### Comparing `graphql_core-3.3.0a3/src/graphql/language/parser.py` & `graphql_core-3.3.0a4/src/graphql/language/parser.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,11 @@
+"""GraphQL parser"""
+
 from functools import partial
-from typing import Callable, Dict, List, Optional, TypeVar, Union, cast
+from typing import Callable, List, Mapping, Optional, TypeVar, Union, cast
 
 from ..error import GraphQLError, GraphQLSyntaxError
 from .ast import (
     ArgumentNode,
     BooleanValueNode,
     ConstArgumentNode,
     ConstDirectiveNode,
@@ -63,15 +65,14 @@
     VariableNode,
 )
 from .directive_locations import DirectiveLocation
 from .lexer import Lexer, is_punctuator_token_kind
 from .source import Source, is_source
 from .token_kind import TokenKind
 
-
 try:
     from typing import TypeAlias
 except ImportError:  # Python < 3.10
     from typing_extensions import TypeAlias
 
 
 __all__ = ["parse", "parse_type", "parse_value", "parse_const_value"]
@@ -136,15 +137,15 @@
     Note: this feature is experimental and may change or be removed in the future.
     """
     parser = Parser(
         source,
         no_location=no_location,
         max_tokens=max_tokens,
         allow_legacy_fragment_variables=allow_legacy_fragment_variables,
-        experimental_client_controlled_nullability=experimental_client_controlled_nullability,  # noqa
+        experimental_client_controlled_nullability=experimental_client_controlled_nullability,
     )
     return parser.parse_document()
 
 
 def parse_value(
     source: SourceType,
     no_location: bool = False,
@@ -246,15 +247,15 @@
     def __init__(
         self,
         source: SourceType,
         no_location: bool = False,
         max_tokens: Optional[int] = None,
         allow_legacy_fragment_variables: bool = False,
         experimental_client_controlled_nullability: bool = False,
-    ):
+    ) -> None:
         if not is_source(source):
             source = Source(cast(str, source))
 
         self._no_location = no_location
         self._max_tokens = max_tokens
         self._allow_legacy_fragment_variables = allow_legacy_fragment_variables
         self._experimental_client_controlled_nullability = (
@@ -274,26 +275,26 @@
         """Document: Definition+"""
         start = self._lexer.token
         return DocumentNode(
             definitions=self.many(TokenKind.SOF, self.parse_definition, TokenKind.EOF),
             loc=self.loc(start),
         )
 
-    _parse_type_system_definition_method_names: Dict[str, str] = {
+    _parse_type_system_definition_method_names: Mapping[str, str] = {
         "schema": "schema_definition",
         "scalar": "scalar_type_definition",
         "type": "object_type_definition",
         "interface": "interface_type_definition",
         "union": "union_type_definition",
         "enum": "enum_type_definition",
         "input": "input_object_type_definition",
         "directive": "directive_definition",
     }
 
-    _parse_other_definition_method_names: Dict[str, str] = {
+    _parse_other_definition_method_names: Mapping[str, str] = {
         **dict.fromkeys(("query", "mutation", "subscription"), "operation_definition"),
         "fragment": "fragment_definition",
         "extend": "type_system_extension",
     }
 
     def parse_definition(self) -> DefinitionNode:
         """Definition: ExecutableDefinition or TypeSystemDefinition/Extension
@@ -363,16 +364,16 @@
         )
 
     def parse_operation_type(self) -> OperationType:
         """OperationType: one of query mutation subscription"""
         operation_token = self.expect_token(TokenKind.NAME)
         try:
             return OperationType(operation_token.value)
-        except ValueError:
-            raise self.unexpected(operation_token)
+        except ValueError as error:
+            raise self.unexpected(operation_token) from error
 
     def parse_variable_definitions(self) -> List[VariableDefinitionNode]:
         """VariableDefinitions: (VariableDefinition+)"""
         return self.optional_many(
             TokenKind.PAREN_L, self.parse_variable_definition, TokenKind.PAREN_R
         )
 
@@ -542,15 +543,15 @@
     def parse_type_condition(self) -> NamedTypeNode:
         """TypeCondition: NamedType"""
         self.expect_keyword("on")
         return self.parse_named_type()
 
     # Implement the parsing rules in the Values section.
 
-    _parse_value_literal_method_names: Dict[TokenKind, str] = {
+    _parse_value_literal_method_names: Mapping[TokenKind, str] = {
         TokenKind.BRACKET_L: "list",
         TokenKind.BRACE_L: "object",
         TokenKind.INT: "int",
         TokenKind.FLOAT: "float",
         TokenKind.STRING: "string_literal",
         TokenKind.BLOCK_STRING: "string_literal",
         TokenKind.NAME: "named_values",
@@ -681,15 +682,15 @@
     def parse_named_type(self) -> NamedTypeNode:
         """NamedType: Name"""
         start = self._lexer.token
         return NamedTypeNode(name=self.parse_name(), loc=self.loc(start))
 
     # Implement the parsing rules in the Type Definition section.
 
-    _parse_type_extension_method_names: Dict[str, str] = {
+    _parse_type_extension_method_names: Mapping[str, str] = {
         "schema": "schema_extension",
         "scalar": "scalar_type_extension",
         "type": "object_type_extension",
         "interface": "interface_type_extension",
         "union": "union_type_extension",
         "enum": "enum_type_extension",
         "input": "input_object_type_extension",
@@ -1248,15 +1249,15 @@
         max_tokens = self._max_tokens
         if max_tokens is not None and token.kind is not TokenKind.EOF:
             self._token_counter += 1
             if self._token_counter > max_tokens:
                 raise GraphQLSyntaxError(
                     self._lexer.source,
                     token.start,
-                    f"Document contains more that {max_tokens} tokens."
+                    f"Document contains more than {max_tokens} tokens."
                     " Parsing aborted.",
                 )
 
 
 def get_token_desc(token: Token) -> str:
     """Describe a token as a string for debugging."""
     value = token.value
```

### Comparing `graphql_core-3.3.0a3/src/graphql/language/predicates.py` & `graphql_core-3.3.0a4/src/graphql/language/predicates.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,7 +1,9 @@
+"""Predicates for GraphQL nodes"""
+
 from typing import Union
 
 from .ast import (
     DefinitionNode,
     ExecutableDefinitionNode,
     ListValueNode,
     Node,
@@ -13,15 +15,14 @@
     TypeExtensionNode,
     TypeNode,
     TypeSystemDefinitionNode,
     ValueNode,
     VariableNode,
 )
 
-
 try:
     from typing import TypeGuard
 except ImportError:  # Python < 3.10
     from typing_extensions import TypeGuard
 
 
 __all__ = [
```

### Comparing `graphql_core-3.3.0a3/src/graphql/language/print_location.py` & `graphql_core-3.3.0a4/src/graphql/language/print_location.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,15 +1,16 @@
+"""Print location in GraphQL source"""
+
 import re
 from typing import Optional, Tuple, cast
 
 from .ast import Location
 from .location import SourceLocation, get_location
 from .source import Source
 
-
 __all__ = ["print_location", "print_source_location"]
 
 
 def print_location(location: Location) -> str:
     """Render a helpful description of the location in the GraphQL Source document."""
     return print_source_location(
         location.source, get_location(location.source, location.start)
```

### Comparing `graphql_core-3.3.0a3/src/graphql/language/print_string.py` & `graphql_core-3.3.0a4/src/graphql/language/print_string.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,14 +1,16 @@
+"""Print a string as a GraphQL expression."""
+
 __all__ = ["print_string"]
 
 
 def print_string(s: str) -> str:
-    """Print a string as a GraphQL StringValue literal.
+    r"""Print a string as a GraphQL StringValue literal.
 
-    Replaces control characters and excluded characters (" U+0022 and \\ U+005C)
+    Replaces control characters and excluded characters (" U+0022 and \ U+005C)
     with escape sequences.
     """
     if not isinstance(s, str):
         s = str(s)
     return f'"{s.translate(escape_sequences)}"'
```

### Comparing `graphql_core-3.3.0a3/src/graphql/language/printer.py` & `graphql_core-3.3.0a4/src/graphql/language/printer.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,15 +1,16 @@
+"""Print AST"""
+
 from typing import Any, Collection, Optional
 
 from ..language.ast import Node, OperationType
 from .block_string import print_block_string
 from .print_string import print_string
 from .visitor import Visitor, visit
 
-
 try:
     from typing import TypeAlias
 except ImportError:  # Python < 3.10
     from typing_extensions import TypeAlias
 
 
 __all__ = ["print_ast"]
```

### Comparing `graphql_core-3.3.0a3/src/graphql/language/source.py` & `graphql_core-3.3.0a4/src/graphql/language/source.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,18 +1,18 @@
+"""GraphQL source input"""
+
 from typing import Any
 
 from .location import SourceLocation
 
-
 try:
     from typing import TypeGuard
 except ImportError:  # Python < 3.10
     from typing_extensions import TypeGuard
 
-
 __all__ = ["Source", "is_source"]
 
 DEFAULT_NAME = "GraphQL request"
 DEFAULT_SOURCE_LOCATION = SourceLocation(1, 1)
 
 
 class Source:
@@ -37,42 +37,41 @@
         The ``line`` and ``column`` attributes in ``location_offset`` are 1-indexed.
         """
         self.body = body
         self.name = name
         if not isinstance(location_offset, SourceLocation):
             location_offset = SourceLocation._make(location_offset)
         if location_offset.line <= 0:
-            raise ValueError(
-                "line in location_offset is 1-indexed and must be positive."
-            )
+            msg = "line in location_offset is 1-indexed and must be positive."
+            raise ValueError(msg)
         if location_offset.column <= 0:
-            raise ValueError(
-                "column in location_offset is 1-indexed and must be positive."
-            )
+            msg = "column in location_offset is 1-indexed and must be positive."
+            raise ValueError(msg)
         self.location_offset = location_offset
 
     def get_location(self, position: int) -> SourceLocation:
+        """Get source location."""
         lines = self.body[:position].splitlines()
         if lines:
             line = len(lines)
             column = len(lines[-1]) + 1
         else:
             line = 1
             column = 1
         return SourceLocation(line, column)
 
     def __repr__(self) -> str:
         return f"<{self.__class__.__name__} name={self.name!r}>"
 
-    def __eq__(self, other: Any) -> bool:
+    def __eq__(self, other: object) -> bool:
         return (isinstance(other, Source) and other.body == self.body) or (
             isinstance(other, str) and other == self.body
         )
 
-    def __ne__(self, other: Any) -> bool:
+    def __ne__(self, other: object) -> bool:
         return not self == other
 
 
 def is_source(source: Any) -> TypeGuard[Source]:
     """Test if the given value is a Source object.
 
     For internal use only.
```

### Comparing `graphql_core-3.3.0a3/src/graphql/language/visitor.py` & `graphql_core-3.3.0a4/src/graphql/language/visitor.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,7 +1,9 @@
+"""AST Visitor"""
+
 from copy import copy
 from enum import Enum
 from typing import (
     Any,
     Callable,
     Collection,
     Dict,
@@ -12,15 +14,14 @@
     Union,
 )
 
 from ..pyutils import inspect, snake_to_camel
 from . import ast
 from .ast import QUERY_DOCUMENT_KEYS, Node
 
-
 try:
     from typing import TypeAlias
 except ImportError:  # Python < 3.10
     from typing_extensions import TypeAlias
 
 
 __all__ = [
@@ -119,24 +120,25 @@
         for attr in cls.__dict__:
             if attr.startswith("_"):
                 continue
             attr_kind = attr.split("_", 1)
             if len(attr_kind) < 2:
                 kind: Optional[str] = None
             else:
-                attr, kind = attr_kind
+                attr, kind = attr_kind  # noqa: PLW2901
             if attr in ("enter", "leave") and kind:
                 name = snake_to_camel(kind) + "Node"
                 node_cls = getattr(ast, name, None)
                 if (
                     not node_cls
                     or not isinstance(node_cls, type)
                     or not issubclass(node_cls, Node)
                 ):
-                    raise TypeError(f"Invalid AST node kind: {kind}.")
+                    msg = f"Invalid AST node kind: {kind}."
+                    raise TypeError(msg)
 
     def __init__(self) -> None:
         self.enter_leave_map = {}
 
     def get_enter_leave_for_kind(self, kind: str) -> EnterLeaveVisitor:
         """Given a node kind, return the EnterLeaveVisitor for that kind."""
         try:
@@ -181,17 +183,19 @@
     and a new version of the AST with the changes applied will be returned from the
     visit function.
 
     To customize the node attributes to be used for traversal, you can provide a
     dictionary visitor_keys mapping node kinds to node attributes.
     """
     if not isinstance(root, Node):
-        raise TypeError(f"Not an AST Node: {inspect(root)}.")
+        msg = f"Not an AST Node: {inspect(root)}."
+        raise TypeError(msg)
     if not isinstance(visitor, Visitor):
-        raise TypeError(f"Not an AST Visitor: {inspect(visitor)}.")
+        msg = f"Not an AST Visitor: {inspect(visitor)}."
+        raise TypeError(msg)
     if visitor_keys is None:
         visitor_keys = QUERY_DOCUMENT_KEYS
 
     stack: Any = None
     in_array = False
     keys: Tuple[Node, ...] = (root,)
     idx = -1
@@ -246,15 +250,16 @@
                 continue
             path_append(key)
 
         if isinstance(node, tuple):
             result = None
         else:
             if not isinstance(node, Node):
-                raise TypeError(f"Invalid AST Node: {inspect(node)}.")
+                msg = f"Invalid AST Node: {inspect(node)}."
+                raise TypeError(msg)
             enter_leave = visitor.get_enter_leave_for_kind(node.kind)
             visit_fn = enter_leave.leave if is_leaving else enter_leave.enter
             if visit_fn:
                 result = visit_fn(node, key, parent, path, ancestors)
 
                 if result is BREAK or result is True:
                     break
@@ -304,15 +309,15 @@
     """A Visitor which delegates to many visitors to run in parallel.
 
     Each visitor will be visited for each node before moving on.
 
     If a prior visitor edits a node, no following visitors will see that node.
     """
 
-    def __init__(self, visitors: Collection[Visitor]):
+    def __init__(self, visitors: Collection[Visitor]) -> None:
         """Create a new visitor from the given list of parallel visitors."""
         super().__init__()
         self.visitors = visitors
         self.skipping: List[Any] = [None] * len(visitors)
 
     def get_enter_leave_for_kind(self, kind: str) -> EnterLeaveVisitor:
         """Given a node kind, return the EnterLeaveVisitor for that kind."""
@@ -330,23 +335,22 @@
                 leave_list.append(leave)
 
             if has_visitor:
 
                 def enter(node: Node, *args: Any) -> Optional[VisitorAction]:
                     skipping = self.skipping
                     for i, fn in enumerate(enter_list):
-                        if not skipping[i]:
-                            if fn:
-                                result = fn(node, *args)
-                                if result is SKIP or result is False:
-                                    skipping[i] = node
-                                elif result is BREAK or result is True:
-                                    skipping[i] = BREAK
-                                elif result is not None:
-                                    return result
+                        if not skipping[i] and fn:
+                            result = fn(node, *args)
+                            if result is SKIP or result is False:
+                                skipping[i] = node
+                            elif result is BREAK or result is True:
+                                skipping[i] = BREAK
+                            elif result is not None:
+                                return result
                     return None
 
                 def leave(node: Node, *args: Any) -> Optional[VisitorAction]:
                     skipping = self.skipping
                     for i, fn in enumerate(leave_list):
                         if not skipping[i]:
                             if fn:
```

### Comparing `graphql_core-3.3.0a3/src/graphql/pyutils/__init__.py` & `graphql_core-3.3.0a4/src/graphql/pyutils/__init__.py`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/src/graphql/pyutils/async_reduce.py` & `graphql_core-3.3.0a4/src/graphql/pyutils/async_reduce.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,13 +1,14 @@
+"""Reduce awaitable values"""
+
 from typing import Any, Awaitable, Callable, Collection, TypeVar, cast
 
 from .awaitable_or_value import AwaitableOrValue
 from .is_awaitable import is_awaitable as default_is_awaitable
 
-
 __all__ = ["async_reduce"]
 
 T = TypeVar("T")
 U = TypeVar("U")
 
 
 def async_reduce(
```

### Comparing `graphql_core-3.3.0a3/src/graphql/pyutils/cached_property.py` & `graphql_core-3.3.0a4/src/graphql/pyutils/cached_property.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,9 +1,10 @@
-from typing import TYPE_CHECKING, Any, Callable
+"""Cached properties"""
 
+from typing import TYPE_CHECKING, Any, Callable
 
 if TYPE_CHECKING:
     standard_cached_property = None
 else:
     try:
         from functools import cached_property as standard_cached_property
     except ImportError:  # Python < 3.8
```

### Comparing `graphql_core-3.3.0a3/src/graphql/pyutils/convert_case.py` & `graphql_core-3.3.0a4/src/graphql/pyutils/convert_case.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,12 +1,13 @@
+"""Conversion between camel and snake case"""
+
 # uses code from https://github.com/daveoncode/python-string-utils
 
 import re
 
-
 __all__ = ["camel_to_snake", "snake_to_camel"]
 
 _re_camel_to_snake = re.compile(r"([a-z]|[A-Z0-9]+)(?=[A-Z])")
 _re_snake_to_camel = re.compile(r"(_)([a-z\d])")
 
 
 def camel_to_snake(s: str) -> str:
```

### Comparing `graphql_core-3.3.0a3/src/graphql/pyutils/description.py` & `graphql_core-3.3.0a4/src/graphql/pyutils/description.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,53 +1,57 @@
-from typing import Any, Tuple, Union
+"""Human-readable descriptions"""
 
+from typing import Any, Tuple, Union
 
 __all__ = [
     "Description",
     "is_description",
     "register_description",
     "unregister_description",
 ]
 
 
 class Description:
-    """Type checker for human readable descriptions.
+    """Type checker for human-readable descriptions.
 
     By default, only ordinary strings are accepted as descriptions,
     but you can register() other classes that will also be allowed,
     e.g. to support lazy string objects that are evaluated only at runtime.
     If you register(object), any object will be allowed as description.
     """
 
     bases: Union[type, Tuple[type, ...]] = str
 
     @classmethod
     def isinstance(cls, obj: Any) -> bool:
+        """Check whether this is an instance of a description."""
         return isinstance(obj, cls.bases)
 
     @classmethod
     def register(cls, base: type) -> None:
         """Register a class that shall be accepted as a description."""
         if not isinstance(base, type):
-            raise TypeError("Only types can be registered.")
+            msg = "Only types can be registered."
+            raise TypeError(msg)
         if base is object:
             cls.bases = object
         elif cls.bases is object:
             cls.bases = base
         elif not isinstance(cls.bases, tuple):
             if base is not cls.bases:
                 cls.bases = (cls.bases, base)
         elif base not in cls.bases:
             cls.bases += (base,)
 
     @classmethod
     def unregister(cls, base: type) -> None:
         """Unregister a class that shall no more be accepted as a description."""
         if not isinstance(base, type):
-            raise TypeError("Only types can be unregistered.")
+            msg = "Only types can be unregistered."
+            raise TypeError(msg)
         if isinstance(cls.bases, tuple):
             if base in cls.bases:
                 cls.bases = tuple(b for b in cls.bases if b is not base)
             if not cls.bases:
                 cls.bases = object
             elif len(cls.bases) == 1:
                 cls.bases = cls.bases[0]
```

### Comparing `graphql_core-3.3.0a3/src/graphql/pyutils/did_you_mean.py` & `graphql_core-3.3.0a4/src/graphql/pyutils/did_you_mean.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,12 +1,13 @@
+"""Generating suggestions"""
+
 from typing import Optional, Sequence
 
 from .format_list import or_list
 
-
 __all__ = ["did_you_mean"]
 
 MAX_LENGTH = 5
 
 
 def did_you_mean(suggestions: Sequence[str], sub_message: Optional[str] = None) -> str:
     """Given [ A, B, C ] return ' Did you mean A, B, or C?'"""
```

### Comparing `graphql_core-3.3.0a3/src/graphql/pyutils/format_list.py` & `graphql_core-3.3.0a4/src/graphql/pyutils/format_list.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,9 +1,10 @@
-from typing import Sequence
+"""List formatting"""
 
+from typing import Sequence
 
 __all__ = ["or_list", "and_list"]
 
 
 def or_list(items: Sequence[str]) -> str:
     """Given [ A, B, C ] return 'A, B, or C'."""
     return format_list("or", items)
@@ -13,15 +14,16 @@
     """Given [ A, B, C ] return 'A, B, and C'."""
     return format_list("and", items)
 
 
 def format_list(conjunction: str, items: Sequence[str]) -> str:
     """Given [ A, B, C ] return 'A, B, (conjunction) C'"""
     if not items:
-        raise ValueError("Missing list items to be formatted.")
+        msg = "Missing list items to be formatted."
+        raise ValueError(msg)
 
     n = len(items)
     if n == 1:
         return items[0]
     if n == 2:
         return f"{items[0]} {conjunction} {items[1]}"
```

### Comparing `graphql_core-3.3.0a3/src/graphql/pyutils/inspect.py` & `graphql_core-3.3.0a4/src/graphql/pyutils/inspect.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,7 +1,9 @@
+"""Value inspection for error messages"""
+
 from inspect import (
     isasyncgen,
     isasyncgenfunction,
     isclass,
     iscoroutine,
     iscoroutinefunction,
     isfunction,
@@ -9,15 +11,14 @@
     isgeneratorfunction,
     ismethod,
 )
 from typing import Any, List
 
 from .undefined import Undefined
 
-
 __all__ = ["inspect"]
 
 max_recursive_depth = 2
 max_str_size = 240
 max_list_size = 10
 
 
@@ -80,28 +81,26 @@
                     return f"({s},)"
                 return f"({s})"
             if isinstance(value, (dict, set)):
                 return "{" + s + "}"
             if isinstance(value, frozenset):
                 return f"frozenset({{{s}}})"
             return f"[{s}]"
-    else:
-        # handle collections that are nested too deep
-        if isinstance(value, (list, tuple, dict, set, frozenset)):
-            if not value:
-                return repr(value)
-            if isinstance(value, list):
-                return "[...]"
-            if isinstance(value, tuple):
-                return "(...)"
-            if isinstance(value, dict):
-                return "{...}"
-            if isinstance(value, set):
-                return "set(...)"
-            return "frozenset(...)"
+    elif isinstance(value, (list, tuple, dict, set, frozenset)):
+        if not value:
+            return repr(value)
+        if isinstance(value, list):
+            return "[...]"
+        if isinstance(value, tuple):
+            return "(...)"
+        if isinstance(value, dict):
+            return "{...}"
+        if isinstance(value, set):
+            return "set(...)"
+        return "frozenset(...)"
     if isinstance(value, Exception):
         type_ = "exception"
         value = type(value)
     elif isclass(value):
         type_ = "exception class" if issubclass(value, Exception) else "class"
     elif ismethod(value):
         type_ = "method"
@@ -137,23 +136,23 @@
                 GraphQLWrappingType,
             ),
         ):
             return str(value)
         try:
             name = type(value).__name__
             if not name or "<" in name or ">" in name:
-                raise AttributeError
+                raise AttributeError  # noqa: TRY301
         except AttributeError:
             return "<object>"
         else:
             return f"<{name} instance>"
     try:
         name = value.__name__
         if not name or "<" in name or ">" in name:
-            raise AttributeError
+            raise AttributeError  # noqa: TRY301
     except AttributeError:
         return f"<{type_}>"
     else:
         return f"<{type_} {name}>"
 
 
 def trunc_str(s: str) -> str:
```

### Comparing `graphql_core-3.3.0a3/src/graphql/pyutils/is_awaitable.py` & `graphql_core-3.3.0a4/src/graphql/pyutils/is_awaitable.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,12 +1,13 @@
+"""Check whether objects are awaitable"""
+
 import inspect
 from types import CoroutineType, GeneratorType
 from typing import Any, Awaitable
 
-
 try:
     from typing import TypeGuard
 except ImportError:  # Python < 3.10
     from typing_extensions import TypeGuard
 
 
 __all__ = ["is_awaitable"]
```

### Comparing `graphql_core-3.3.0a3/src/graphql/pyutils/is_iterable.py` & `graphql_core-3.3.0a4/src/graphql/pyutils/is_iterable.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,10 +1,11 @@
-from array import array
-from typing import Any, ByteString, Collection, Iterable, Mapping, Text, ValuesView
+"""Check whether objects are iterable"""
 
+from array import array
+from typing import Any, Collection, Iterable, Mapping, ValuesView
 
 try:
     from typing import TypeGuard
 except ImportError:  # Python < 3.10
     from typing_extensions import TypeGuard
 
 
@@ -15,15 +16,15 @@
     collection_types.append(ValuesView)
 if not issubclass(array, Collection):  # PyPy <= 7.3.9
     collection_types.append(array)
 collection_types = (
     collection_types[0] if len(collection_types) == 1 else tuple(collection_types)
 )
 iterable_types: Any = Iterable
-not_iterable_types: Any = (ByteString, Mapping, Text)
+not_iterable_types: Any = (bytearray, bytes, str, memoryview, Mapping)
 
 
 def is_collection(value: Any) -> TypeGuard[Collection]:
     """Check if value is a collection, but not a string or a mapping."""
     return isinstance(value, collection_types) and not isinstance(
         value, not_iterable_types
     )
```

### Comparing `graphql_core-3.3.0a3/src/graphql/pyutils/path.py` & `graphql_core-3.3.0a4/src/graphql/pyutils/path.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,12 +1,13 @@
+"""Path of indices"""
+
 from __future__ import annotations  # Python < 3.10
 
 from typing import Any, List, NamedTuple, Optional, Union
 
-
 __all__ = ["Path"]
 
 
 class Path(NamedTuple):
     """A generic path of string or integer indices"""
 
     prev: Any  # Optional['Path'] (python/mypy/issues/731)
```

### Comparing `graphql_core-3.3.0a3/src/graphql/pyutils/simple_pub_sub.py` & `graphql_core-3.3.0a4/src/graphql/pyutils/simple_pub_sub.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,15 +1,16 @@
+"""Simple public-subscribe system"""
+
 from __future__ import annotations  # Python < 3.10
 
 from asyncio import Future, Queue, create_task, get_running_loop, sleep
 from typing import Any, AsyncIterator, Callable, Optional, Set
 
 from .is_awaitable import is_awaitable
 
-
 __all__ = ["SimplePubSub", "SimplePubSubIterator"]
 
 
 class SimplePubSub:
     """A very simple publish-subscript system.
 
     Creates an AsyncIterator from an EventEmitter.
@@ -23,24 +24,27 @@
         self.subscribers = set()
 
     def emit(self, event: Any) -> bool:
         """Emit an event."""
         for subscriber in self.subscribers:
             result = subscriber(event)
             if is_awaitable(result):
-                create_task(result)  # type: ignore
+                create_task(result)  # type: ignore # noqa: RUF006
         return bool(self.subscribers)
 
     def get_subscriber(
         self, transform: Optional[Callable] = None
     ) -> SimplePubSubIterator:
+        """Return subscriber iterator"""
         return SimplePubSubIterator(self, transform)
 
 
 class SimplePubSubIterator(AsyncIterator):
+    """Async iterator used for subscriptions."""
+
     def __init__(self, pubsub: SimplePubSub, transform: Optional[Callable]) -> None:
         self.pubsub = pubsub
         self.transform = transform
         self.pull_queue: Queue[Future] = Queue()
         self.push_queue: Queue[Any] = Queue()
         self.listening = True
         pubsub.subscribers.add(self.push_value)
@@ -55,25 +59,28 @@
         if not self.push_queue.empty():
             return await self.push_queue.get()
         future = get_running_loop().create_future()
         await self.pull_queue.put(future)
         return future
 
     async def aclose(self) -> None:
+        """Close the iterator."""
         if self.listening:
             await self.empty_queue()
 
     async def empty_queue(self) -> None:
+        """Empty the queue."""
         self.listening = False
         self.pubsub.subscribers.remove(self.push_value)
         while not self.pull_queue.empty():
             future = await self.pull_queue.get()
             future.cancel()
         while not self.push_queue.empty():
             await self.push_queue.get()
 
     async def push_value(self, event: Any) -> None:
+        """Push a new value."""
         value = event if self.transform is None else self.transform(event)
         if self.pull_queue.empty():
             await self.push_queue.put(value)
         else:
             (await self.pull_queue.get()).set_result(value)
```

### Comparing `graphql_core-3.3.0a3/src/graphql/pyutils/suggestion_list.py` & `graphql_core-3.3.0a4/src/graphql/pyutils/suggestion_list.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,12 +1,13 @@
+"""List with suggestions"""
+
 from typing import Collection, List, Optional
 
 from .natural_compare import natural_comparison_key
 
-
 __all__ = ["suggestion_list"]
 
 
 def suggestion_list(input_: str, options: Collection[str]) -> List[str]:
     """Get list with suggestions for a given input.
 
     Given an invalid input string and list of valid options, returns a filtered list
@@ -42,15 +43,15 @@
     """
 
     _input: str
     _input_lower_case: str
     _input_list: List[int]
     _rows: List[List[int]]
 
-    def __init__(self, input_: str):
+    def __init__(self, input_: str) -> None:
         self._input = input_
         self._input_lower_case = input_.lower()
         row_size = len(input_) + 1
         self._input_list = list(map(ord, self._input_lower_case))
 
         self._rows = [[0] * row_size, [0] * row_size, [0] * row_size]
```

### Comparing `graphql_core-3.3.0a3/src/graphql/pyutils/undefined.py` & `graphql_core-3.3.0a4/src/graphql/pyutils/undefined.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,22 +1,24 @@
+"""The Undefined value"""
+
 from __future__ import annotations  # Python < 3.10
 
 import warnings
-from typing import Any, Optional
-
+from typing import Optional
 
 __all__ = ["Undefined", "UndefinedType"]
 
 
 class UndefinedType:
     """Auxiliary class for creating the Undefined singleton."""
 
     _instance: Optional[UndefinedType] = None
 
     def __new__(cls) -> UndefinedType:
+        """Create the Undefined singleton."""
         if cls._instance is None:
             cls._instance = super().__new__(cls)
         else:
             warnings.warn("Redefinition of 'Undefined'", RuntimeWarning, stacklevel=2)
         return cls._instance
 
     def __reduce__(self) -> str:
@@ -29,18 +31,18 @@
 
     def __hash__(self) -> int:
         return hash(UndefinedType)
 
     def __bool__(self) -> bool:
         return False
 
-    def __eq__(self, other: Any) -> bool:
+    def __eq__(self, other: object) -> bool:
         return other is Undefined or other is None
 
-    def __ne__(self, other: Any) -> bool:
+    def __ne__(self, other: object) -> bool:
         return not self == other
 
 
 # Used to indicate undefined or invalid values (like "undefined" in JavaScript):
 Undefined = UndefinedType()
 
 Undefined.__doc__ = """Symbol for undefined values
```

### Comparing `graphql_core-3.3.0a3/src/graphql/type/__init__.py` & `graphql_core-3.3.0a4/src/graphql/type/__init__.py`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/src/graphql/type/assert_name.py` & `graphql_core-3.3.0a4/src/graphql/type/assert_name.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,30 +1,35 @@
+"""Assertions for naming conventions"""
+
 from ..error import GraphQLError
 from ..language.character_classes import is_name_continue, is_name_start
 
-
 __all__ = ["assert_name", "assert_enum_value_name"]
 
 
 def assert_name(name: str) -> str:
     """Uphold the spec rules about naming."""
     if name is None:
-        raise TypeError("Must provide name.")
+        msg = "Must provide name."
+        raise TypeError(msg)
     if not isinstance(name, str):
-        raise TypeError("Expected name to be a string.")
+        msg = "Expected name to be a string."
+        raise TypeError(msg)
     if not name:
-        raise GraphQLError("Expected name to be a non-empty string.")
+        msg = "Expected name to be a non-empty string."
+        raise GraphQLError(msg)
     if not all(is_name_continue(char) for char in name[1:]):
-        raise GraphQLError(
-            f"Names must only contain [_a-zA-Z0-9] but {name!r} does not."
-        )
+        msg = f"Names must only contain [_a-zA-Z0-9] but {name!r} does not."
+        raise GraphQLError(msg)
     if not is_name_start(name[0]):
-        raise GraphQLError(f"Names must start with [_a-zA-Z] but {name!r} does not.")
+        msg = f"Names must start with [_a-zA-Z] but {name!r} does not."
+        raise GraphQLError(msg)
     return name
 
 
 def assert_enum_value_name(name: str) -> str:
     """Uphold the spec rules about naming enum values."""
     assert_name(name)
     if name in {"true", "false", "null"}:
-        raise GraphQLError(f"Enum values cannot be named: {name}.")
+        msg = f"Enum values cannot be named: {name}."
+        raise GraphQLError(msg)
     return name
```

### Comparing `graphql_core-3.3.0a3/src/graphql/type/definition.py` & `graphql_core-3.3.0a4/src/graphql/type/definition.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,7 +1,9 @@
+"""GraphQL type definitions."""
+
 from __future__ import annotations  # Python < 3.10
 
 from enum import Enum
 from typing import (
     TYPE_CHECKING,
     Any,
     Callable,
@@ -54,27 +56,25 @@
     did_you_mean,
     inspect,
     suggestion_list,
 )
 from ..utilities.value_from_ast_untyped import value_from_ast_untyped
 from .assert_name import assert_enum_value_name, assert_name
 
-
 try:
     from typing import TypedDict
 except ImportError:  # Python < 3.8
     from typing_extensions import TypedDict
 try:
     from typing import TypeAlias, TypeGuard
 except ImportError:  # Python < 3.10
     from typing_extensions import TypeAlias, TypeGuard
 
 if TYPE_CHECKING:
-    from .schema import GraphQLSchema  # noqa: F401
-
+    from .schema import GraphQLSchema
 
 __all__ = [
     "is_type",
     "is_scalar_type",
     "is_object_type",
     "is_interface_type",
     "is_union_type",
@@ -174,26 +174,29 @@
     # properties slower or more complicated.
 
 
 # There are predicates for each kind of GraphQL type.
 
 
 def is_type(type_: Any) -> TypeGuard[GraphQLType]:
+    """Check whether this is a GraphQL type."""
     return isinstance(type_, GraphQLType)
 
 
 def assert_type(type_: Any) -> GraphQLType:
+    """Assert that this is a GraphQL type."""
     if not is_type(type_):
-        raise TypeError(f"Expected {type_} to be a GraphQL type.")
+        msg = f"Expected {type_} to be a GraphQL type."
+        raise TypeError(msg)
     return type_
 
 
 # These types wrap and modify other types
 
-GT = TypeVar("GT", bound=GraphQLType, covariant=True)
+GT = TypeVar("GT", bound=GraphQLType, covariant=True)  # noqa: PLC0105
 
 
 class GraphQLWrappingType(GraphQLType, Generic[GT]):
     """Base class for all GraphQL wrapping types"""
 
     of_type: GT
 
@@ -201,24 +204,29 @@
         self.of_type = type_
 
     def __repr__(self) -> str:
         return f"<{self.__class__.__name__} {self.of_type!r}>"
 
 
 def is_wrapping_type(type_: Any) -> TypeGuard[GraphQLWrappingType]:
+    """Check whether this is a GraphQL wrapping type."""
     return isinstance(type_, GraphQLWrappingType)
 
 
 def assert_wrapping_type(type_: Any) -> GraphQLWrappingType:
+    """Assert that this is a GraphQL wrapping type."""
     if not is_wrapping_type(type_):
-        raise TypeError(f"Expected {type_} to be a GraphQL wrapping type.")
+        msg = f"Expected {type_} to be a GraphQL wrapping type."
+        raise TypeError(msg)
     return type_
 
 
 class GraphQLNamedTypeKwargs(TypedDict, total=False):
+    """Arguments for GraphQL named types"""
+
     name: str
     description: Optional[str]
     extensions: Dict[str, Any]
     # unfortunately, we cannot make the following more specific, because they are
     # used by subclasses with different node types and typed dicts cannot be refined
     ast_node: Optional[Any]
     extension_ast_nodes: Tuple[Any, ...]
@@ -229,19 +237,21 @@
 
     name: str
     description: Optional[str]
     extensions: Dict[str, Any]
     ast_node: Optional[TypeDefinitionNode]
     extension_ast_nodes: Tuple[TypeExtensionNode, ...]
 
-    reserved_types: Dict[str, GraphQLNamedType] = {}
+    reserved_types: Mapping[str, GraphQLNamedType] = {}
 
     def __new__(cls, name: str, *_args: Any, **_kwargs: Any) -> GraphQLNamedType:
+        """Create a GraphQL named type."""
         if name in cls.reserved_types:
-            raise TypeError(f"Redefinition of reserved type {name!r}")
+            msg = f"Redefinition of reserved type {name!r}"
+            raise TypeError(msg)
         return super().__new__(cls)
 
     def __reduce__(self) -> Tuple[Callable, Tuple]:
         return self._get_instance, (self.name, tuple(self.to_kwargs().items()))
 
     @classmethod
     def _get_instance(cls, name: str, args: Tuple) -> GraphQLNamedType:
@@ -270,14 +280,15 @@
     def __repr__(self) -> str:
         return f"<{self.__class__.__name__} {self.name!r}>"
 
     def __str__(self) -> str:
         return self.name
 
     def to_kwargs(self) -> GraphQLNamedTypeKwargs:
+        """Get corresponding arguments."""
         return GraphQLNamedTypeKwargs(
             name=self.name,
             description=self.description,
             extensions=self.extensions,
             ast_node=self.ast_node,
             extension_ast_nodes=self.extension_ast_nodes,
         )
@@ -306,14 +317,16 @@
 GraphQLScalarValueParser: TypeAlias = Callable[[Any], Any]
 GraphQLScalarLiteralParser: TypeAlias = Callable[
     [ValueNode, Optional[Dict[str, Any]]], Any
 ]
 
 
 class GraphQLScalarTypeKwargs(GraphQLNamedTypeKwargs, total=False):
+    """Arguments for GraphQL scalar types"""
+
     serialize: Optional[GraphQLScalarSerializer]
     parse_value: Optional[GraphQLScalarValueParser]
     parse_literal: Optional[GraphQLScalarLiteralParser]
     specified_by_url: Optional[str]
 
 
 class GraphQLScalarType(GraphQLNamedType):
@@ -370,20 +383,20 @@
 
         if serialize is not None:
             self.serialize = serialize  # type: ignore
         if parse_value is not None:
             self.parse_value = parse_value  # type: ignore
         if parse_literal is not None:
             self.parse_literal = parse_literal  # type: ignore
-        if parse_literal is not None:
-            if parse_value is None:
-                raise TypeError(
-                    f"{name} must provide"
-                    " both 'parse_value' and 'parse_literal' functions."
-                )
+        if parse_literal is not None and parse_value is None:
+            msg = (
+                f"{name} must provide"
+                " both 'parse_value' and 'parse_literal' functions."
+            )
+            raise TypeError(msg)
         self.specified_by_url = specified_by_url
 
     def __repr__(self) -> str:
         return f"<{self.__class__.__name__} {self.name!r}>"
 
     def __str__(self) -> str:
         return self.name
@@ -413,14 +426,15 @@
 
         This default method uses the parse_value method and should be replaced
         with a more specific version when creating a scalar type.
         """
         return self.parse_value(value_from_ast_untyped(node, variables))
 
     def to_kwargs(self) -> GraphQLScalarTypeKwargs:
+        """Get corresponding arguments."""
         # noinspection PyArgumentList
         return GraphQLScalarTypeKwargs(  # type: ignore
             super().to_kwargs(),
             serialize=None
             if self.serialize is GraphQLScalarType.serialize
             else self.serialize,
             parse_value=None
@@ -434,27 +448,32 @@
         )
 
     def __copy__(self) -> GraphQLScalarType:  # pragma: no cover
         return self.__class__(**self.to_kwargs())
 
 
 def is_scalar_type(type_: Any) -> TypeGuard[GraphQLScalarType]:
+    """Check whether this is a GraphQL scalar type."""
     return isinstance(type_, GraphQLScalarType)
 
 
 def assert_scalar_type(type_: Any) -> GraphQLScalarType:
+    """Assert that this is a GraphQL scalar type."""
     if not is_scalar_type(type_):
-        raise TypeError(f"Expected {type_} to be a GraphQL Scalar type.")
+        msg = f"Expected {type_} to be a GraphQL Scalar type."
+        raise TypeError(msg)
     return type_
 
 
 GraphQLArgumentMap: TypeAlias = Dict[str, "GraphQLArgument"]
 
 
 class GraphQLFieldKwargs(TypedDict, total=False):
+    """Arguments for GraphQL fields"""
+
     type_: GraphQLOutputType
     args: Optional[GraphQLArgumentMap]
     resolve: Optional[GraphQLFieldResolver]
     subscribe: Optional[GraphQLFieldResolver]
     description: Optional[str]
     deprecation_reason: Optional[str]
     extensions: Dict[str, Any]
@@ -504,26 +523,27 @@
 
     def __repr__(self) -> str:
         return f"<{self.__class__.__name__} {self.type!r}>"
 
     def __str__(self) -> str:
         return f"Field: {self.type}"
 
-    def __eq__(self, other: Any) -> bool:
+    def __eq__(self, other: object) -> bool:
         return self is other or (
             isinstance(other, GraphQLField)
             and self.type == other.type
             and self.args == other.args
             and self.resolve == other.resolve
             and self.description == other.description
             and self.deprecation_reason == other.deprecation_reason
             and self.extensions == other.extensions
         )
 
     def to_kwargs(self) -> GraphQLFieldKwargs:
+        """Get corresponding arguments."""
         return GraphQLFieldKwargs(
             type_=self.type,
             args=self.args.copy() if self.args else None,
             resolve=self.resolve,
             subscribe=self.subscribe,
             deprecation_reason=self.deprecation_reason,
             description=self.description,
@@ -546,15 +566,15 @@
     """
 
     field_name: str
     field_nodes: List[FieldNode]
     return_type: GraphQLOutputType
     parent_type: GraphQLObjectType
     path: Path
-    schema: "GraphQLSchema"
+    schema: GraphQLSchema
     fragments: Dict[str, FragmentDefinitionNode]
     root_value: Any
     operation: OperationDefinitionNode
     variable_values: Dict[str, Any]
     context: Any
     is_awaitable: Callable[[Any], bool]
 
@@ -580,14 +600,16 @@
     [Any, GraphQLResolveInfo], AwaitableOrValue[bool]
 ]
 
 GraphQLFieldMap: TypeAlias = Dict[str, GraphQLField]
 
 
 class GraphQLArgumentKwargs(TypedDict, total=False):
+    """Python arguments for GraphQL arguments"""
+
     type_: GraphQLInputType
     default_value: Any
     description: Optional[str]
     deprecation_reason: Optional[str]
     out_name: Optional[str]
     extensions: Dict[str, Any]
     ast_node: Optional[InputValueDefinitionNode]
@@ -618,26 +640,27 @@
         self.default_value = default_value
         self.description = description
         self.deprecation_reason = deprecation_reason
         self.out_name = out_name
         self.extensions = extensions or {}
         self.ast_node = ast_node
 
-    def __eq__(self, other: Any) -> bool:
+    def __eq__(self, other: object) -> bool:
         return self is other or (
             isinstance(other, GraphQLArgument)
             and self.type == other.type
             and self.default_value == other.default_value
             and self.description == other.description
             and self.deprecation_reason == other.deprecation_reason
             and self.out_name == other.out_name
             and self.extensions == other.extensions
         )
 
     def to_kwargs(self) -> GraphQLArgumentKwargs:
+        """Get corresponding arguments."""
         return GraphQLArgumentKwargs(
             type_=self.type,
             default_value=self.default_value,
             description=self.description,
             deprecation_reason=self.deprecation_reason,
             out_name=self.out_name,
             extensions=self.extensions,
@@ -645,18 +668,21 @@
         )
 
     def __copy__(self) -> GraphQLArgument:  # pragma: no cover
         return self.__class__(**self.to_kwargs())
 
 
 def is_required_argument(arg: GraphQLArgument) -> bool:
+    """Check whether the argument is required."""
     return is_non_null_type(arg.type) and arg.default_value is Undefined
 
 
 class GraphQLObjectTypeKwargs(GraphQLNamedTypeKwargs, total=False):
+    """Arguments for GraphQL object types"""
+
     fields: GraphQLFieldMap
     interfaces: Tuple[GraphQLInterfaceType, ...]
     is_type_of: Optional[GraphQLIsTypeOfFn]
 
 
 class GraphQLObjectType(GraphQLNamedType):
     """Object Type Definition
@@ -709,14 +735,15 @@
             extension_ast_nodes=extension_ast_nodes,
         )
         self._fields = fields
         self._interfaces = interfaces
         self.is_type_of = is_type_of
 
     def to_kwargs(self) -> GraphQLObjectTypeKwargs:
+        """Get corresponding arguments."""
         # noinspection PyArgumentList
         return GraphQLObjectTypeKwargs(  # type: ignore
             super().to_kwargs(),
             fields=self.fields.copy(),
             interfaces=self.interfaces,
             is_type_of=self.is_type_of,
         )
@@ -725,48 +752,55 @@
         return self.__class__(**self.to_kwargs())
 
     @cached_property
     def fields(self) -> GraphQLFieldMap:
         """Get provided fields, wrapping them as GraphQLFields if needed."""
         try:
             fields = resolve_thunk(self._fields)
-        except Exception as error:
+        except Exception as error:  # noqa: BLE001
             cls = GraphQLError if isinstance(error, GraphQLError) else TypeError
-            raise cls(f"{self.name} fields cannot be resolved. {error}") from error
+            msg = f"{self.name} fields cannot be resolved. {error}"
+            raise cls(msg) from error
         return {
             assert_name(name): value
             if isinstance(value, GraphQLField)
             else GraphQLField(value)  # type: ignore
             for name, value in fields.items()
         }
 
     @cached_property
     def interfaces(self) -> Tuple[GraphQLInterfaceType, ...]:
         """Get provided interfaces."""
         try:
             interfaces: Collection[GraphQLInterfaceType] = resolve_thunk(
                 self._interfaces  # type: ignore
             )
-        except Exception as error:
+        except Exception as error:  # noqa: BLE001
             cls = GraphQLError if isinstance(error, GraphQLError) else TypeError
-            raise cls(f"{self.name} interfaces cannot be resolved. {error}") from error
+            msg = f"{self.name} interfaces cannot be resolved. {error}"
+            raise cls(msg) from error
         return tuple(interfaces) if interfaces else ()
 
 
 def is_object_type(type_: Any) -> TypeGuard[GraphQLObjectType]:
+    """Check whether this is a graphql object type"""
     return isinstance(type_, GraphQLObjectType)
 
 
 def assert_object_type(type_: Any) -> GraphQLObjectType:
+    """Assume that this is a graphql object type"""
     if not is_object_type(type_):
-        raise TypeError(f"Expected {type_} to be a GraphQL Object type.")
+        msg = f"Expected {type_} to be a GraphQL Object type."
+        raise TypeError(msg)
     return type_
 
 
 class GraphQLInterfaceTypeKwargs(GraphQLNamedTypeKwargs, total=False):
+    """Arguments for GraphQL interface types"""
+
     fields: GraphQLFieldMap
     interfaces: Tuple[GraphQLInterfaceType, ...]
     resolve_type: Optional[GraphQLTypeResolver]
 
 
 class GraphQLInterfaceType(GraphQLNamedType):
     """Interface Type Definition
@@ -806,14 +840,15 @@
             extension_ast_nodes=extension_ast_nodes,
         )
         self._fields = fields
         self._interfaces = interfaces
         self.resolve_type = resolve_type
 
     def to_kwargs(self) -> GraphQLInterfaceTypeKwargs:
+        """Get corresponding arguments."""
         # noinspection PyArgumentList
         return GraphQLInterfaceTypeKwargs(  # type: ignore
             super().to_kwargs(),
             fields=self.fields.copy(),
             interfaces=self.interfaces,
             resolve_type=self.resolve_type,
         )
@@ -822,48 +857,55 @@
         return self.__class__(**self.to_kwargs())
 
     @cached_property
     def fields(self) -> GraphQLFieldMap:
         """Get provided fields, wrapping them as GraphQLFields if needed."""
         try:
             fields = resolve_thunk(self._fields)
-        except Exception as error:
+        except Exception as error:  # noqa: BLE001
             cls = GraphQLError if isinstance(error, GraphQLError) else TypeError
-            raise cls(f"{self.name} fields cannot be resolved. {error}") from error
+            msg = f"{self.name} fields cannot be resolved. {error}"
+            raise cls(msg) from error
         return {
             assert_name(name): value
             if isinstance(value, GraphQLField)
             else GraphQLField(value)  # type: ignore
             for name, value in fields.items()
         }
 
     @cached_property
     def interfaces(self) -> Tuple[GraphQLInterfaceType, ...]:
         """Get provided interfaces."""
         try:
             interfaces: Collection[GraphQLInterfaceType] = resolve_thunk(
                 self._interfaces  # type: ignore
             )
-        except Exception as error:
+        except Exception as error:  # noqa: BLE001
             cls = GraphQLError if isinstance(error, GraphQLError) else TypeError
-            raise cls(f"{self.name} interfaces cannot be resolved. {error}") from error
+            msg = f"{self.name} interfaces cannot be resolved. {error}"
+            raise cls(msg) from error
         return tuple(interfaces) if interfaces else ()
 
 
 def is_interface_type(type_: Any) -> TypeGuard[GraphQLInterfaceType]:
+    """Check whether this is a GraphQL interface type."""
     return isinstance(type_, GraphQLInterfaceType)
 
 
 def assert_interface_type(type_: Any) -> GraphQLInterfaceType:
+    """Assert that this is a GraphQL interface type."""
     if not is_interface_type(type_):
-        raise TypeError(f"Expected {type_} to be a GraphQL Interface type.")
+        msg = f"Expected {type_} to be a GraphQL Interface type."
+        raise TypeError(msg)
     return type_
 
 
 class GraphQLUnionTypeKwargs(GraphQLNamedTypeKwargs, total=False):
+    """Arguments for GraphQL union types"""
+
     types: Tuple[GraphQLObjectType, ...]
     resolve_type: Optional[GraphQLTypeResolver]
 
 
 class GraphQLUnionType(GraphQLNamedType):
     """Union Type Definition
 
@@ -903,47 +945,54 @@
             ast_node=ast_node,
             extension_ast_nodes=extension_ast_nodes,
         )
         self._types = types
         self.resolve_type = resolve_type
 
     def to_kwargs(self) -> GraphQLUnionTypeKwargs:
+        """Get corresponding arguments."""
         # noinspection PyArgumentList
         return GraphQLUnionTypeKwargs(  # type: ignore
             super().to_kwargs(), types=self.types, resolve_type=self.resolve_type
         )
 
     def __copy__(self) -> GraphQLUnionType:  # pragma: no cover
         return self.__class__(**self.to_kwargs())
 
     @cached_property
     def types(self) -> Tuple[GraphQLObjectType, ...]:
         """Get provided types."""
         try:
             types: Collection[GraphQLObjectType] = resolve_thunk(self._types)
-        except Exception as error:
+        except Exception as error:  # noqa: BLE001
             cls = GraphQLError if isinstance(error, GraphQLError) else TypeError
-            raise cls(f"{self.name} types cannot be resolved. {error}") from error
+            msg = f"{self.name} types cannot be resolved. {error}"
+            raise cls(msg) from error
         return tuple(types) if types else ()
 
 
 def is_union_type(type_: Any) -> TypeGuard[GraphQLUnionType]:
+    """Check whether this is a GraphQL union type."""
     return isinstance(type_, GraphQLUnionType)
 
 
 def assert_union_type(type_: Any) -> GraphQLUnionType:
+    """Assert that this is a GraphQL union type."""
     if not is_union_type(type_):
-        raise TypeError(f"Expected {type_} to be a GraphQL Union type.")
+        msg = f"Expected {type_} to be a GraphQL Union type."
+        raise TypeError(msg)
     return type_
 
 
 GraphQLEnumValueMap: TypeAlias = Dict[str, "GraphQLEnumValue"]
 
 
 class GraphQLEnumTypeKwargs(GraphQLNamedTypeKwargs, total=False):
+    """Arguments for GraphQL enum types"""
+
     values: GraphQLEnumValueMap
     names_as_values: Optional[bool]
 
 
 class GraphQLEnumType(GraphQLNamedType):
     """Enum Type Definition
 
@@ -1002,21 +1051,21 @@
         try:  # check for enum
             values = cast(Enum, values).__members__  # type: ignore
         except AttributeError:
             if not isinstance(values, Mapping) or not all(
                 isinstance(name, str) for name in values
             ):
                 try:
-                    # noinspection PyTypeChecker
-                    values = dict(values)  # type: ignore
-                except (TypeError, ValueError):
-                    raise TypeError(
+                    values = dict(values)
+                except (TypeError, ValueError) as error:
+                    msg = (
                         f"{name} values must be an Enum or a mapping"
                         " with value names as keys."
                     )
+                    raise TypeError(msg) from error
             values = cast(Dict[str, Any], values)
         else:
             values = cast(Dict[str, Enum], values)
             if names_as_values is False:
                 values = {key: value.value for key, value in values.items()}
             elif names_as_values is True:
                 values = {key: key for key in values}
@@ -1025,14 +1074,15 @@
             if isinstance(value, GraphQLEnumValue)
             else GraphQLEnumValue(value)
             for key, value in values.items()
         }
         self.values = values
 
     def to_kwargs(self) -> GraphQLEnumTypeKwargs:
+        """Get corresponding arguments."""
         # noinspection PyArgumentList
         return GraphQLEnumTypeKwargs(  # type: ignore
             super().to_kwargs(), values=self.values.copy()
         )
 
     def __copy__(self) -> GraphQLEnumType:  # pragma: no cover
         return self.__class__(**self.to_kwargs())
@@ -1049,89 +1099,101 @@
                 if value not in lookup:
                     lookup[value] = name
             except TypeError:
                 pass  # ignore unhashable values
         return lookup
 
     def serialize(self, output_value: Any) -> str:
+        """Serialize an output value."""
         try:
             return self._value_lookup[output_value]
         except KeyError:  # hashable value not found
             pass
         except TypeError:  # unhashable value, we need to scan all values
             for enum_name, enum_value in self.values.items():
                 if enum_value.value == output_value:
                     return enum_name
-        raise GraphQLError(
-            f"Enum '{self.name}' cannot represent value: {inspect(output_value)}"
-        )
+        msg = f"Enum '{self.name}' cannot represent value: {inspect(output_value)}"
+        raise GraphQLError(msg)
 
     def parse_value(self, input_value: str) -> Any:
+        """Parse an enum value."""
         if isinstance(input_value, str):
             try:
                 enum_value = self.values[input_value]
-            except KeyError:
-                raise GraphQLError(
+            except KeyError as error:
+                msg = (
                     f"Value '{input_value}' does not exist in '{self.name}' enum."
                     + did_you_mean_enum_value(self, input_value)
                 )
+                raise GraphQLError(msg) from error
             return enum_value.value
         value_str = inspect(input_value)
-        raise GraphQLError(
+        msg = (
             f"Enum '{self.name}' cannot represent non-string value: {value_str}."
             + did_you_mean_enum_value(self, value_str)
         )
+        raise GraphQLError(msg)
 
     def parse_literal(
         self, value_node: ValueNode, _variables: Optional[Dict[str, Any]] = None
     ) -> Any:
+        """Parse literal value."""
         # Note: variables will be resolved before calling this method.
         if isinstance(value_node, EnumValueNode):
             try:
                 enum_value = self.values[value_node.value]
-            except KeyError:
+            except KeyError as error:
                 value_str = print_ast(value_node)
-                raise GraphQLError(
+                msg = (
                     f"Value '{value_str}' does not exist in '{self.name}' enum."
-                    + did_you_mean_enum_value(self, value_str),
-                    value_node,
+                    + did_you_mean_enum_value(self, value_str)
                 )
+                raise GraphQLError(msg, value_node) from error
             return enum_value.value
         value_str = print_ast(value_node)
-        raise GraphQLError(
+        msg = (
             f"Enum '{self.name}' cannot represent non-enum value: {value_str}."
-            + did_you_mean_enum_value(self, value_str),
-            value_node,
+            + did_you_mean_enum_value(self, value_str)
         )
+        raise GraphQLError(msg, value_node)
 
 
 def is_enum_type(type_: Any) -> TypeGuard[GraphQLEnumType]:
+    """Check whether this is a GraphQL enum type."""
     return isinstance(type_, GraphQLEnumType)
 
 
 def assert_enum_type(type_: Any) -> GraphQLEnumType:
+    """Assert that this is a GraphQL enum type."""
     if not is_enum_type(type_):
-        raise TypeError(f"Expected {type_} to be a GraphQL Enum type.")
+        msg = f"Expected {type_} to be a GraphQL Enum type."
+        raise TypeError(msg)
     return type_
 
 
 def did_you_mean_enum_value(enum_type: GraphQLEnumType, unknown_value_str: str) -> str:
+    """Return suggestions for enum value."""
     suggested_values = suggestion_list(unknown_value_str, enum_type.values)
     return did_you_mean(suggested_values, "the enum value")
 
 
 class GraphQLEnumValueKwargs(TypedDict, total=False):
+    """Arguments for GraphQL enum values"""
+
     value: Any
     description: Optional[str]
     deprecation_reason: Optional[str]
     extensions: Dict[str, Any]
     ast_node: Optional[EnumValueDefinitionNode]
 
 
 class GraphQLEnumValue:
+    """A GraphQL enum value."""
+
     value: Any
     description: Optional[str]
     deprecation_reason: Optional[str]
     extensions: Dict[str, Any]
     ast_node: Optional[EnumValueDefinitionNode]
 
     def __init__(
@@ -1144,24 +1206,25 @@
     ) -> None:
         self.value = value
         self.description = description
         self.deprecation_reason = deprecation_reason
         self.extensions = extensions or {}
         self.ast_node = ast_node
 
-    def __eq__(self, other: Any) -> bool:
+    def __eq__(self, other: object) -> bool:
         return self is other or (
             isinstance(other, GraphQLEnumValue)
             and self.value == other.value
             and self.description == other.description
             and self.deprecation_reason == other.deprecation_reason
             and self.extensions == other.extensions
         )
 
     def to_kwargs(self) -> GraphQLEnumValueKwargs:
+        """Get corresponding arguments."""
         return GraphQLEnumValueKwargs(
             value=self.value,
             description=self.description,
             deprecation_reason=self.deprecation_reason,
             extensions=self.extensions,
             ast_node=self.ast_node,
         )
@@ -1171,14 +1234,16 @@
 
 
 GraphQLInputFieldMap: TypeAlias = Dict[str, "GraphQLInputField"]
 GraphQLInputFieldOutType = Callable[[Dict[str, Any]], Any]
 
 
 class GraphQLInputObjectTypeKwargs(GraphQLNamedTypeKwargs, total=False):
+    """Arguments for GraphQL input object types"""
+
     fields: GraphQLInputFieldMap
     out_type: Optional[GraphQLInputFieldOutType]
 
 
 class GraphQLInputObjectType(GraphQLNamedType):
     """Input Object Type Definition
 
@@ -1233,14 +1298,15 @@
         """Transform outbound values (this is an extension of GraphQL.js).
 
         This default implementation passes values unaltered as dictionaries.
         """
         return value
 
     def to_kwargs(self) -> GraphQLInputObjectTypeKwargs:
+        """Get corresponding arguments."""
         # noinspection PyArgumentList
         return GraphQLInputObjectTypeKwargs(  # type: ignore
             super().to_kwargs(),
             fields=self.fields.copy(),
             out_type=None
             if self.out_type is GraphQLInputObjectType.out_type
             else self.out_type,
@@ -1250,36 +1316,42 @@
         return self.__class__(**self.to_kwargs())
 
     @cached_property
     def fields(self) -> GraphQLInputFieldMap:
         """Get provided fields, wrap them as GraphQLInputField if needed."""
         try:
             fields = resolve_thunk(self._fields)
-        except Exception as error:
+        except Exception as error:  # noqa: BLE001
             cls = GraphQLError if isinstance(error, GraphQLError) else TypeError
-            raise cls(f"{self.name} fields cannot be resolved. {error}") from error
+            msg = f"{self.name} fields cannot be resolved. {error}"
+            raise cls(msg) from error
         return {
             assert_name(name): value
             if isinstance(value, GraphQLInputField)
             else GraphQLInputField(value)  # type: ignore
             for name, value in fields.items()
         }
 
 
 def is_input_object_type(type_: Any) -> TypeGuard[GraphQLInputObjectType]:
+    """Check whether this is a GraphQL input type."""
     return isinstance(type_, GraphQLInputObjectType)
 
 
 def assert_input_object_type(type_: Any) -> GraphQLInputObjectType:
+    """Assert that this is a GraphQL input type."""
     if not is_input_object_type(type_):
-        raise TypeError(f"Expected {type_} to be a GraphQL Input Object type.")
+        msg = f"Expected {type_} to be a GraphQL Input Object type."
+        raise TypeError(msg)
     return type_
 
 
 class GraphQLInputFieldKwargs(TypedDict, total=False):
+    """Arguments for GraphQL input fields"""
+
     type_: GraphQLInputType
     default_value: Any
     description: Optional[str]
     deprecation_reason: Optional[str]
     out_name: Optional[str]
     extensions: Dict[str, Any]
     ast_node: Optional[InputValueDefinitionNode]
@@ -1310,26 +1382,27 @@
         self.default_value = default_value
         self.description = description
         self.deprecation_reason = deprecation_reason
         self.out_name = out_name
         self.extensions = extensions or {}
         self.ast_node = ast_node
 
-    def __eq__(self, other: Any) -> bool:
+    def __eq__(self, other: object) -> bool:
         return self is other or (
             isinstance(other, GraphQLInputField)
             and self.type == other.type
             and self.default_value == other.default_value
             and self.description == other.description
             and self.deprecation_reason == other.deprecation_reason
             and self.extensions == other.extensions
             and self.out_name == other.out_name
         )
 
     def to_kwargs(self) -> GraphQLInputFieldKwargs:
+        """Get corresponding arguments."""
         return GraphQLInputFieldKwargs(
             type_=self.type,
             default_value=self.default_value,
             description=self.description,
             deprecation_reason=self.deprecation_reason,
             out_name=self.out_name,
             extensions=self.extensions,
@@ -1337,14 +1410,15 @@
         )
 
     def __copy__(self) -> GraphQLInputField:  # pragma: no cover
         return self.__class__(**self.to_kwargs())
 
 
 def is_required_input_field(field: GraphQLInputField) -> bool:
+    """Check whether this is input field is required."""
     return is_non_null_type(field.type) and field.default_value is Undefined
 
 
 # Wrapper types
 
 
 class GraphQLList(GraphQLWrappingType[GT]):
@@ -1370,24 +1444,27 @@
         super().__init__(type_=type_)
 
     def __str__(self) -> str:
         return f"[{self.of_type}]"
 
 
 def is_list_type(type_: Any) -> TypeGuard[GraphQLList]:
+    """Check whether this is a GraphQL list type."""
     return isinstance(type_, GraphQLList)
 
 
 def assert_list_type(type_: Any) -> GraphQLList:
+    """Assert that this is a GraphQL list type."""
     if not is_list_type(type_):
-        raise TypeError(f"Expected {type_} to be a GraphQL List type.")
+        msg = f"Expected {type_} to be a GraphQL List type."
+        raise TypeError(msg)
     return type_
 
 
-GNT = TypeVar("GNT", bound="GraphQLNullableType", covariant=True)
+GNT = TypeVar("GNT", bound="GraphQLNullableType", covariant=True)  # noqa: PLC0105
 
 
 class GraphQLNonNull(GraphQLWrappingType[GNT]):
     """Non-Null Type Wrapper
 
     A non-null is a wrapping type which points to another type. Non-null types enforce
     that their values are never null and can ensure an error is raised if this ever
@@ -1402,15 +1479,15 @@
             fields = {
                 'id': GraphQLField(GraphQLNonNull(GraphQLString()))
             }
 
     Note: the enforcement of non-nullability occurs within the executor.
     """
 
-    def __init__(self, type_: GNT):
+    def __init__(self, type_: GNT) -> None:
         super().__init__(type_=type_)
 
     def __str__(self) -> str:
         return f"{self.of_type}!"
 
 
 # These types can all accept null as a value.
@@ -1421,30 +1498,28 @@
     GraphQLInterfaceType,
     GraphQLUnionType,
     GraphQLEnumType,
     GraphQLInputObjectType,
     GraphQLList,
 ]
 
-
 # These types may be used as input types for arguments and directives.
 
 GraphQLNullableInputType: TypeAlias = Union[
     GraphQLScalarType,
     GraphQLEnumType,
     GraphQLInputObjectType,
     # actually GraphQLList[GraphQLInputType], but we can't recurse
     GraphQLList,
 ]
 
 GraphQLInputType: TypeAlias = Union[
     GraphQLNullableInputType, GraphQLNonNull[GraphQLNullableInputType]
 ]
 
-
 # These types may be used as output types as the result of fields.
 
 GraphQLNullableOutputType: TypeAlias = Union[
     GraphQLScalarType,
     GraphQLObjectType,
     GraphQLInterfaceType,
     GraphQLUnionType,
@@ -1458,55 +1533,65 @@
 ]
 
 
 # Predicates and Assertions
 
 
 def is_input_type(type_: Any) -> TypeGuard[GraphQLInputType]:
+    """Check whether this is a GraphQL input type."""
     return isinstance(
         type_, (GraphQLScalarType, GraphQLEnumType, GraphQLInputObjectType)
     ) or (isinstance(type_, GraphQLWrappingType) and is_input_type(type_.of_type))
 
 
 def assert_input_type(type_: Any) -> GraphQLInputType:
+    """Assert that this is a GraphQL input type."""
     if not is_input_type(type_):
-        raise TypeError(f"Expected {type_} to be a GraphQL input type.")
+        msg = f"Expected {type_} to be a GraphQL input type."
+        raise TypeError(msg)
     return type_
 
 
 def is_output_type(type_: Any) -> TypeGuard[GraphQLOutputType]:
+    """Check whether this is a GraphQL output type."""
     return isinstance(
         type_,
         (
             GraphQLScalarType,
             GraphQLObjectType,
             GraphQLInterfaceType,
             GraphQLUnionType,
             GraphQLEnumType,
         ),
     ) or (isinstance(type_, GraphQLWrappingType) and is_output_type(type_.of_type))
 
 
 def assert_output_type(type_: Any) -> GraphQLOutputType:
+    """Assert that this is a GraphQL output type."""
     if not is_output_type(type_):
-        raise TypeError(f"Expected {type_} to be a GraphQL output type.")
+        msg = f"Expected {type_} to be a GraphQL output type."
+        raise TypeError(msg)
     return type_
 
 
 def is_non_null_type(type_: Any) -> TypeGuard[GraphQLNonNull]:
+    """Check whether this is a non-null GraphQL type."""
     return isinstance(type_, GraphQLNonNull)
 
 
 def assert_non_null_type(type_: Any) -> GraphQLNonNull:
+    """Assert that this is a non-null GraphQL type."""
     if not is_non_null_type(type_):
-        raise TypeError(f"Expected {type_} to be a GraphQL Non-Null type.")
+        msg = f"Expected {type_} to be a GraphQL Non-Null type."
+        raise TypeError(msg)
     return type_
 
 
 def is_nullable_type(type_: Any) -> TypeGuard[GraphQLNullableType]:
+    """Check whether this is a nullable GraphQL type."""
     return isinstance(
         type_,
         (
             GraphQLScalarType,
             GraphQLObjectType,
             GraphQLInterfaceType,
             GraphQLUnionType,
@@ -1514,16 +1599,18 @@
             GraphQLInputObjectType,
             GraphQLList,
         ),
     )
 
 
 def assert_nullable_type(type_: Any) -> GraphQLNullableType:
+    """Assert that this is a nullable GraphQL type."""
     if not is_nullable_type(type_):
-        raise TypeError(f"Expected {type_} to be a GraphQL nullable type.")
+        msg = f"Expected {type_} to be a GraphQL nullable type."
+        raise TypeError(msg)
     return type_
 
 
 @overload
 def get_nullable_type(type_: None) -> None:
     ...
 
@@ -1535,15 +1622,15 @@
 
 @overload
 def get_nullable_type(type_: GraphQLNonNull) -> GraphQLNullableType:
     ...
 
 
 def get_nullable_type(
-    type_: Optional[Union[GraphQLNullableType, GraphQLNonNull]]
+    type_: Optional[Union[GraphQLNullableType, GraphQLNonNull]],
 ) -> Optional[GraphQLNullableType]:
     """Unwrap possible non-null type"""
     if is_non_null_type(type_):
         type_ = type_.of_type
     return cast(Optional[GraphQLNullableType], type_)
 
 
@@ -1559,20 +1646,23 @@
     GraphQLInterfaceType,
     GraphQLUnionType,
     GraphQLEnumType,
 ]
 
 
 def is_named_type(type_: Any) -> TypeGuard[GraphQLNamedType]:
+    """Check whether this is a named GraphQL type."""
     return isinstance(type_, GraphQLNamedType)
 
 
 def assert_named_type(type_: Any) -> GraphQLNamedType:
+    """Assert that this is a named GraphQL type."""
     if not is_named_type(type_):
-        raise TypeError(f"Expected {type_} to be a GraphQL named type.")
+        msg = f"Expected {type_} to be a GraphQL named type."
+        raise TypeError(msg)
     return type_
 
 
 @overload
 def get_named_type(type_: None) -> None:
     ...
 
@@ -1594,48 +1684,57 @@
 
 # These types may describe types which may be leaf values.
 
 GraphQLLeafType: TypeAlias = Union[GraphQLScalarType, GraphQLEnumType]
 
 
 def is_leaf_type(type_: Any) -> TypeGuard[GraphQLLeafType]:
+    """Check whether this is a GraphQL leaf type."""
     return isinstance(type_, (GraphQLScalarType, GraphQLEnumType))
 
 
 def assert_leaf_type(type_: Any) -> GraphQLLeafType:
+    """Assert that this is a GraphQL leaf type."""
     if not is_leaf_type(type_):
-        raise TypeError(f"Expected {type_} to be a GraphQL leaf type.")
+        msg = f"Expected {type_} to be a GraphQL leaf type."
+        raise TypeError(msg)
     return type_
 
 
 # These types may describe the parent context of a selection set.
 
 GraphQLCompositeType: TypeAlias = Union[
     GraphQLObjectType, GraphQLInterfaceType, GraphQLUnionType
 ]
 
 
 def is_composite_type(type_: Any) -> TypeGuard[GraphQLCompositeType]:
+    """Check whether this is a GraphQL composite type."""
     return isinstance(
         type_, (GraphQLObjectType, GraphQLInterfaceType, GraphQLUnionType)
     )
 
 
-def assert_composite_type(type_: Any) -> GraphQLType:
+def assert_composite_type(type_: Any) -> GraphQLCompositeType:
+    """Assert that this is a GraphQL composite type."""
     if not is_composite_type(type_):
-        raise TypeError(f"Expected {type_} to be a GraphQL composite type.")
+        msg = f"Expected {type_} to be a GraphQL composite type."
+        raise TypeError(msg)
     return type_
 
 
 # These types may describe abstract types.
 
 GraphQLAbstractType: TypeAlias = Union[GraphQLInterfaceType, GraphQLUnionType]
 
 
 def is_abstract_type(type_: Any) -> TypeGuard[GraphQLAbstractType]:
+    """Check whether this is a GraphQL abstract type."""
     return isinstance(type_, (GraphQLInterfaceType, GraphQLUnionType))
 
 
 def assert_abstract_type(type_: Any) -> GraphQLAbstractType:
+    """Assert that this is a GraphQL abstract type."""
     if not is_abstract_type(type_):
-        raise TypeError(f"Expected {type_} to be a GraphQL composite type.")
+        msg = f"Expected {type_} to be a GraphQL composite type."
+        raise TypeError(msg)
     return type_
```

### Comparing `graphql_core-3.3.0a3/src/graphql/type/directives.py` & `graphql_core-3.3.0a4/src/graphql/type/directives.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,18 +1,19 @@
+"""GraphQL directives"""
+
 from __future__ import annotations  # Python < 3.10
 
 from typing import Any, Collection, Dict, Optional, Tuple, cast
 
 from ..language import DirectiveLocation, ast
 from ..pyutils import inspect
 from .assert_name import assert_name
 from .definition import GraphQLArgument, GraphQLInputType, GraphQLNonNull
 from .scalars import GraphQLBoolean, GraphQLInt, GraphQLString
 
-
 try:
     from typing import TypedDict
 except ImportError:  # Python < 3.8
     from typing_extensions import TypedDict
 try:
     from typing import TypeGuard
 except ImportError:  # Python < 3.10
@@ -33,14 +34,16 @@
     "GraphQLSpecifiedByDirective",
     "DirectiveLocation",
     "DEFAULT_DEPRECATION_REASON",
 ]
 
 
 class GraphQLDirectiveKwargs(TypedDict, total=False):
+    """Arguments for GraphQL directives"""
+
     name: str
     locations: Tuple[DirectiveLocation, ...]
     args: Dict[str, GraphQLArgument]
     is_repeatable: bool
     description: Optional[str]
     extensions: Dict[str, Any]
     ast_node: Optional[ast.DirectiveDefinitionNode]
@@ -75,19 +78,20 @@
         try:
             locations = tuple(
                 value
                 if isinstance(value, DirectiveLocation)
                 else DirectiveLocation[cast(str, value)]
                 for value in locations
             )
-        except (KeyError, TypeError):
-            raise TypeError(
+        except (KeyError, TypeError) as error:
+            msg = (
                 f"{name} locations must be specified"
                 " as a collection of DirectiveLocation enum values."
             )
+            raise TypeError(msg) from error
         if args:
             args = {
                 assert_name(name): value
                 if isinstance(value, GraphQLArgument)
                 else GraphQLArgument(cast(GraphQLInputType, value))
                 for name, value in args.items()
             }
@@ -103,26 +107,27 @@
 
     def __str__(self) -> str:
         return f"@{self.name}"
 
     def __repr__(self) -> str:
         return f"<{self.__class__.__name__}({self})>"
 
-    def __eq__(self, other: Any) -> bool:
+    def __eq__(self, other: object) -> bool:
         return self is other or (
             isinstance(other, GraphQLDirective)
             and self.name == other.name
             and self.locations == other.locations
             and self.args == other.args
             and self.is_repeatable == other.is_repeatable
             and self.description == other.description
             and self.extensions == other.extensions
         )
 
     def to_kwargs(self) -> GraphQLDirectiveKwargs:
+        """Get corresponding arguments."""
         return GraphQLDirectiveKwargs(
             name=self.name,
             locations=self.locations,
             args=self.args,
             is_repeatable=self.is_repeatable,
             description=self.description,
             extensions=self.extensions,
@@ -130,21 +135,23 @@
         )
 
     def __copy__(self) -> GraphQLDirective:  # pragma: no cover
         return self.__class__(**self.to_kwargs())
 
 
 def is_directive(directive: Any) -> TypeGuard[GraphQLDirective]:
-    """Test if the given value is a GraphQL directive."""
+    """Check whether this is a GraphQL directive."""
     return isinstance(directive, GraphQLDirective)
 
 
 def assert_directive(directive: Any) -> GraphQLDirective:
+    """Assert that this is a GraphQL directive."""
     if not is_directive(directive):
-        raise TypeError(f"Expected {inspect(directive)} to be a GraphQL directive.")
+        msg = f"Expected {inspect(directive)} to be a GraphQL directive."
+        raise TypeError(msg)
     return directive
 
 
 # Used to conditionally include fields or fragments.
 GraphQLIncludeDirective = GraphQLDirective(
     name="include",
     locations=[
@@ -157,15 +164,14 @@
             GraphQLNonNull(GraphQLBoolean), description="Included when true."
         )
     },
     description="Directs the executor to include this field or fragment"
     " only when the `if` argument is true.",
 )
 
-
 # Used to conditionally skip (exclude) fields or fragments:
 GraphQLSkipDirective = GraphQLDirective(
     name="skip",
     locations=[
         DirectiveLocation.FIELD,
         DirectiveLocation.FRAGMENT_SPREAD,
         DirectiveLocation.INLINE_FRAGMENT,
@@ -212,15 +218,14 @@
             GraphQLInt,
             description="Number of items to return immediately",
             default_value=0,
         ),
     },
 )
 
-
 # Constant string used for default reason for a deprecation:
 DEFAULT_DEPRECATION_REASON = "No longer supported"
 
 # Used to declare element of a GraphQL schema as deprecated:
 GraphQLDeprecatedDirective = GraphQLDirective(
     name="deprecated",
     locations=[
@@ -252,15 +257,14 @@
             GraphQLNonNull(GraphQLString),
             description="The URL that specifies the behaviour of this scalar.",
         )
     },
     description="Exposes a URL that specifies the behaviour of this scalar.",
 )
 
-
 specified_directives: Tuple[GraphQLDirective, ...] = (
     GraphQLIncludeDirective,
     GraphQLSkipDirective,
     GraphQLDeprecatedDirective,
     GraphQLSpecifiedByDirective,
 )
 """A tuple with all directives from the GraphQL specification"""
```

### Comparing `graphql_core-3.3.0a3/src/graphql/type/introspection.py` & `graphql_core-3.3.0a4/src/graphql/type/introspection.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,7 +1,9 @@
+"""GraphQL introspection"""
+
 from enum import Enum
 from typing import Mapping
 
 from ..language import DirectiveLocation, print_ast
 from ..pyutils import inspect
 from .definition import (
     GraphQLArgument,
@@ -21,15 +23,14 @@
     is_non_null_type,
     is_object_type,
     is_scalar_type,
     is_union_type,
 )
 from .scalars import GraphQLBoolean, GraphQLString
 
-
 __all__ = [
     "SchemaMetaFieldDef",
     "TypeKind",
     "TypeMetaFieldDef",
     "TypeNameMetaFieldDef",
     "introspection_types",
     "is_introspection_type",
@@ -320,15 +321,16 @@
             return TypeKind.INPUT_OBJECT
         if is_list_type(type_):
             return TypeKind.LIST
         if is_non_null_type(type_):
             return TypeKind.NON_NULL
 
         # Not reachable. All possible types have been considered.
-        raise TypeError(f"Unexpected type: {inspect(type_)}.")  # pragma: no cover
+        msg = f"Unexpected type: {inspect(type_)}."  # pragma: no cover
+        raise TypeError(msg)  # pragma: no cover
 
     @staticmethod
     def name(type_, _info):
         return getattr(type_, "name", None)
 
     @staticmethod
     def description(type_, _info):
@@ -337,53 +339,60 @@
     @staticmethod
     def specified_by_url(type_, _info):
         return getattr(type_, "specified_by_url", None)
 
     # noinspection PyPep8Naming
     @staticmethod
     def fields(type_, _info, includeDeprecated=False):
-        if is_object_type(type_) or is_interface_type(type_):
-            items = type_.fields.items()
-            return (
-                list(items)
-                if includeDeprecated
-                else [item for item in items if item[1].deprecation_reason is None]
-            )
+        if not (is_object_type(type_) or is_interface_type(type_)):
+            return None
+        items = type_.fields.items()
+        return (
+            list(items)
+            if includeDeprecated
+            else [item for item in items if item[1].deprecation_reason is None]
+        )
 
     @staticmethod
     def interfaces(type_, _info):
-        if is_object_type(type_) or is_interface_type(type_):
-            return type_.interfaces
+        return (
+            type_.interfaces
+            if is_object_type(type_) or is_interface_type(type_)
+            else None
+        )
 
     @staticmethod
     def possible_types(type_, info):
-        if is_abstract_type(type_):
-            return info.schema.get_possible_types(type_)
+        return (
+            info.schema.get_possible_types(type_) if is_abstract_type(type_) else None
+        )
 
     # noinspection PyPep8Naming
     @staticmethod
     def enum_values(type_, _info, includeDeprecated=False):
-        if is_enum_type(type_):
-            items = type_.values.items()
-            return (
-                items
-                if includeDeprecated
-                else [item for item in items if item[1].deprecation_reason is None]
-            )
+        if not is_enum_type(type_):
+            return None
+        items = type_.values.items()
+        return (
+            items
+            if includeDeprecated
+            else [item for item in items if item[1].deprecation_reason is None]
+        )
 
     # noinspection PyPep8Naming
     @staticmethod
     def input_fields(type_, _info, includeDeprecated=False):
-        if is_input_object_type(type_):
-            items = type_.fields.items()
-            return (
-                items
-                if includeDeprecated
-                else [item for item in items if item[1].deprecation_reason is None]
-            )
+        if not is_input_object_type(type_):
+            return None
+        items = type_.fields.items()
+        return (
+            items
+            if includeDeprecated
+            else [item for item in items if item[1].deprecation_reason is None]
+        )
 
     @staticmethod
     def of_type(type_, _info):
         return getattr(type_, "of_type", None)
 
 
 _Type: GraphQLObjectType = GraphQLObjectType(
@@ -569,14 +578,16 @@
     " However an Enum value is returned in a JSON response as a"
     " string.",
     fields=EnumValueFields,
 )
 
 
 class TypeKind(Enum):
+    """Kinds of types"""
+
     SCALAR = "scalar"
     OBJECT = "object"
     INTERFACE = "interface"
     UNION = "union"
     ENUM = "enum"
     INPUT_OBJECT = "input object"
     LIST = "list"
@@ -683,8 +694,8 @@
 
 def is_introspection_type(type_: GraphQLNamedType) -> bool:
     """Check whether the given named GraphQL type is an introspection type."""
     return type_.name in introspection_types
 
 
 # register the introspection types to avoid redefinition
-GraphQLNamedType.reserved_types.update(introspection_types)
+GraphQLNamedType.reserved_types.update(introspection_types)  # type: ignore
```

### Comparing `graphql_core-3.3.0a3/src/graphql/type/scalars.py` & `graphql_core-3.3.0a4/src/graphql/type/scalars.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,7 +1,9 @@
+"""GraphQL scalar types"""
+
 from math import isfinite
 from typing import Any, Mapping
 
 from ..error import GraphQLError
 from ..language.ast import (
     BooleanValueNode,
     FloatValueNode,
@@ -9,21 +11,19 @@
     StringValueNode,
     ValueNode,
 )
 from ..language.printer import print_ast
 from ..pyutils import inspect
 from .definition import GraphQLNamedType, GraphQLScalarType
 
-
 try:
     from typing import TypeGuard
 except ImportError:  # Python < 3.10
     from typing_extensions import TypeGuard
 
-
 __all__ = [
     "is_specified_scalar_type",
     "specified_scalar_types",
     "GraphQLInt",
     "GraphQLFloat",
     "GraphQLString",
     "GraphQLBoolean",
@@ -51,65 +51,60 @@
         return 1 if output_value else 0
     try:
         if isinstance(output_value, int):
             num = output_value
         elif isinstance(output_value, float):
             num = int(output_value)
             if num != output_value:
-                raise ValueError
+                raise ValueError  # noqa: TRY301
         elif not output_value and isinstance(output_value, str):
             output_value = ""
-            raise ValueError
+            raise ValueError  # noqa: TRY301
         else:
             num = int(output_value)  # raises ValueError if not an integer
-    except (OverflowError, ValueError, TypeError):
-        raise GraphQLError(
-            "Int cannot represent non-integer value: " + inspect(output_value)
-        )
+    except (OverflowError, ValueError, TypeError) as error:
+        msg = "Int cannot represent non-integer value: " + inspect(output_value)
+        raise GraphQLError(msg) from error
     if not GRAPHQL_MIN_INT <= num <= GRAPHQL_MAX_INT:
-        raise GraphQLError(
-            "Int cannot represent non 32-bit signed integer value: "
-            + inspect(output_value)
+        msg = "Int cannot represent non 32-bit signed integer value: " + inspect(
+            output_value
         )
+        raise GraphQLError(msg)
     return num
 
 
 def coerce_int(input_value: Any) -> int:
     if not (
         isinstance(input_value, int) and not isinstance(input_value, bool)
     ) and not (
         isinstance(input_value, float)
         and isfinite(input_value)
         and int(input_value) == input_value
     ):
-        raise GraphQLError(
-            "Int cannot represent non-integer value: " + inspect(input_value)
-        )
+        msg = "Int cannot represent non-integer value: " + inspect(input_value)
+        raise GraphQLError(msg)
     if not GRAPHQL_MIN_INT <= input_value <= GRAPHQL_MAX_INT:
-        raise GraphQLError(
-            "Int cannot represent non 32-bit signed integer value: "
-            + inspect(input_value)
+        msg = "Int cannot represent non 32-bit signed integer value: " + inspect(
+            input_value
         )
+        raise GraphQLError(msg)
     return int(input_value)
 
 
 def parse_int_literal(value_node: ValueNode, _variables: Any = None) -> int:
     """Parse an integer value node in the AST."""
     if not isinstance(value_node, IntValueNode):
-        raise GraphQLError(
-            "Int cannot represent non-integer value: " + print_ast(value_node),
-            value_node,
-        )
+        msg = "Int cannot represent non-integer value: " + print_ast(value_node)
+        raise GraphQLError(msg, value_node)
     num = int(value_node.value)
     if not GRAPHQL_MIN_INT <= num <= GRAPHQL_MAX_INT:
-        raise GraphQLError(
-            "Int cannot represent non 32-bit signed integer value: "
-            + print_ast(value_node),
-            value_node,
+        msg = "Int cannot represent non 32-bit signed integer value: " + print_ast(
+            value_node
         )
+        raise GraphQLError(msg, value_node)
     return num
 
 
 GraphQLInt = GraphQLScalarType(
     name="Int",
     description="The `Int` scalar type represents"
     " non-fractional signed whole numeric values."
@@ -122,22 +117,21 @@
 
 def serialize_float(output_value: Any) -> float:
     if isinstance(output_value, bool):
         return 1 if output_value else 0
     try:
         if not output_value and isinstance(output_value, str):
             output_value = ""
-            raise ValueError
+            raise ValueError  # noqa: TRY301
         num = output_value if isinstance(output_value, float) else float(output_value)
         if not isfinite(num):
-            raise ValueError
-    except (ValueError, TypeError):
-        raise GraphQLError(
-            "Float cannot represent non numeric value: " + inspect(output_value)
-        )
+            raise ValueError  # noqa: TRY301
+    except (ValueError, TypeError) as error:
+        msg = "Float cannot represent non numeric value: " + inspect(output_value)
+        raise GraphQLError(msg) from error
     return num
 
 
 def coerce_float(input_value: Any) -> float:
     if not (
         isinstance(input_value, int) and not isinstance(input_value, bool)
     ) and not (isinstance(input_value, float) and isfinite(input_value)):
@@ -306,15 +300,14 @@
     ' input type, any string (such as `"4"`) or integer (such as'
     " `4`) input value will be accepted as an ID.",
     serialize=serialize_id,
     parse_value=coerce_id,
     parse_literal=parse_id_literal,
 )
 
-
 specified_scalar_types: Mapping[str, GraphQLScalarType] = {
     type_.name: type_
     for type_ in (
         GraphQLString,
         GraphQLInt,
         GraphQLFloat,
         GraphQLBoolean,
@@ -325,8 +318,8 @@
 
 def is_specified_scalar_type(type_: GraphQLNamedType) -> TypeGuard[GraphQLScalarType]:
     """Check whether the given named GraphQL type is a specified scalar type."""
     return type_.name in specified_scalar_types
 
 
 # register the scalar types to avoid redefinition
-GraphQLNamedType.reserved_types.update(specified_scalar_types)
+GraphQLNamedType.reserved_types.update(specified_scalar_types)  # type: ignore
```

### Comparing `graphql_core-3.3.0a3/src/graphql/type/schema.py` & `graphql_core-3.3.0a4/src/graphql/type/schema.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,14 +1,29 @@
+"""GraphQL schemas"""
+
 from __future__ import annotations  # Python < 3.10
 
 from copy import copy, deepcopy
-from typing import Any, Collection, Dict, List, NamedTuple, Optional, Set, Tuple, cast
+from typing import (
+    TYPE_CHECKING,
+    Any,
+    Collection,
+    Dict,
+    List,
+    NamedTuple,
+    Optional,
+    Set,
+    Tuple,
+    cast,
+)
+
+if TYPE_CHECKING:
+    from ..error import GraphQLError
+    from ..language import OperationType, ast
 
-from ..error import GraphQLError
-from ..language import OperationType, ast
 from ..pyutils import inspect
 from .definition import (
     GraphQLAbstractType,
     GraphQLCompositeType,
     GraphQLField,
     GraphQLInterfaceType,
     GraphQLNamedType,
@@ -25,37 +40,36 @@
 from .introspection import (
     SchemaMetaFieldDef,
     TypeMetaFieldDef,
     TypeNameMetaFieldDef,
     introspection_types,
 )
 
-
 try:
     from typing import TypedDict
 except ImportError:  # Python < 3.8
     from typing_extensions import TypedDict
 try:
     from typing import TypeAlias, TypeGuard
 except ImportError:  # Python < 3.10
     from typing_extensions import TypeAlias, TypeGuard
 
-
 __all__ = ["GraphQLSchema", "GraphQLSchemaKwargs", "is_schema", "assert_schema"]
 
-
 TypeMap: TypeAlias = Dict[str, GraphQLNamedType]
 
 
 class InterfaceImplementations(NamedTuple):
     objects: List[GraphQLObjectType]
     interfaces: List[GraphQLInterfaceType]
 
 
 class GraphQLSchemaKwargs(TypedDict, total=False):
+    """Arguments for GraphQL schemas"""
+
     query: Optional[GraphQLObjectType]
     mutation: Optional[GraphQLObjectType]
     subscription: Optional[GraphQLObjectType]
     types: Optional[Tuple[GraphQLNamedType, ...]]
     directives: Tuple[GraphQLDirective, ...]
     description: Optional[str]
     extensions: Dict[str, Any]
@@ -203,23 +217,25 @@
 
         for named_type in all_referenced_types:
             if not named_type:
                 continue
 
             type_name = getattr(named_type, "name", None)
             if not type_name:
-                raise TypeError(
+                msg = (
                     "One of the provided types for building the Schema"
-                    " is missing a name.",
+                    " is missing a name."
                 )
+                raise TypeError(msg)
             if type_name in type_map:
-                raise TypeError(
+                msg = (
                     "Schema must contain uniquely named types"
                     f" but contains multiple types named '{type_name}'."
                 )
+                raise TypeError(msg)
 
             type_map[type_name] = named_type
 
             if is_interface_type(named_type):
                 # Store implementations by interface.
                 for iface in named_type.interfaces:
                     if is_interface_type(iface):
@@ -241,14 +257,15 @@
                             implementations = implementations_map[
                                 iface.name
                             ] = InterfaceImplementations(objects=[], interfaces=[])
 
                         implementations.objects.append(named_type)
 
     def to_kwargs(self) -> GraphQLSchemaKwargs:
+        """Get corresponding arguments."""
         return GraphQLSchemaKwargs(
             query=self.query_type,
             mutation=self.mutation_type,
             subscription=self.subscription_type,
             types=tuple(self.type_map.values()) or None,
             directives=self.directives,
             description=self.description,
@@ -292,17 +309,19 @@
             extensions=deepcopy(self.extensions),
             ast_node=deepcopy(self.ast_node),
             extension_ast_nodes=deepcopy(self.extension_ast_nodes),
             assume_valid=True,
         )
 
     def get_root_type(self, operation: OperationType) -> Optional[GraphQLObjectType]:
+        """Get the root type."""
         return getattr(self, f"{operation.value}_type")
 
     def get_type(self, name: str) -> Optional[GraphQLNamedType]:
+        """Get the type with the given name."""
         return self.type_map.get(name)
 
     def get_possible_types(
         self, abstract_type: GraphQLAbstractType
     ) -> List[GraphQLObjectType]:
         """Get list of all possible concrete types for given abstract type."""
         return (
@@ -312,14 +331,15 @@
                 cast(GraphQLInterfaceType, abstract_type)
             ).objects
         )
 
     def get_implementations(
         self, interface_type: GraphQLInterfaceType
     ) -> InterfaceImplementations:
+        """Get implementations for the given interface type."""
         return self._implementations_map.get(
             interface_type.name, InterfaceImplementations(objects=[], interfaces=[])
         )
 
     def is_sub_type(
         self,
         abstract_type: GraphQLAbstractType,
@@ -341,14 +361,15 @@
                     add(type_.name)
                 for type_ in implementations.interfaces:
                     add(type_.name)
             self._sub_type_map[abstract_type.name] = types
         return maybe_sub_type.name in types
 
     def get_directive(self, name: str) -> Optional[GraphQLDirective]:
+        """Get the directive with the given name."""
         for directive in self.directives:
             if directive.name == name:
                 return directive
         return None
 
     def get_field(
         self, parent_type: GraphQLCompositeType, field_name: str
@@ -377,14 +398,15 @@
         try:
             return parent_type.fields[field_name]  # type: ignore
         except (AttributeError, KeyError):
             return None
 
     @property
     def validation_errors(self) -> Optional[List[GraphQLError]]:
+        """Get validation errors."""
         return self._validation_errors
 
 
 class TypeSet(Dict[GraphQLNamedType, None]):
     """An ordered set of types that can be collected starting from initial types."""
 
     @classmethod
@@ -414,21 +436,23 @@
                     collect_referenced_types(arg.type)
         elif is_input_object_type(named_type):
             for field in named_type.fields.values():
                 collect_referenced_types(field.type)
 
 
 def is_schema(schema: Any) -> TypeGuard[GraphQLSchema]:
-    """Test if the given value is a GraphQL schema."""
+    """Check whether this is a GraphQL schema."""
     return isinstance(schema, GraphQLSchema)
 
 
 def assert_schema(schema: Any) -> GraphQLSchema:
+    """Assert that this is a GraphQL schema."""
     if not is_schema(schema):
-        raise TypeError(f"Expected {inspect(schema)} to be a GraphQL schema.")
+        msg = f"Expected {inspect(schema)} to be a GraphQL schema."
+        raise TypeError(msg)
     return schema
 
 
 def remapped_type(type_: GraphQLType, type_map: TypeMap) -> GraphQLType:
     """Get a copy of the given type that uses this type map."""
     if is_wrapping_type(type_):
         return type_.__class__(remapped_type(type_.of_type, type_map))
@@ -445,21 +469,21 @@
     elif is_object_type(type_) or is_interface_type(type_):
         type_.interfaces = [
             type_map.get(interface_type.name, interface_type)
             for interface_type in type_.interfaces
         ]
         fields = type_.fields
         for field_name, field in fields.items():
-            field = copy(field)
+            field = copy(field)  # noqa: PLW2901
             field.type = remapped_type(field.type, type_map)
             args = field.args
             for arg_name, arg in args.items():
-                arg = copy(arg)
+                arg = copy(arg)  # noqa: PLW2901
                 arg.type = remapped_type(arg.type, type_map)
                 args[arg_name] = arg
             fields[field_name] = field
     elif is_input_object_type(type_):
         fields = type_.fields
         for field_name, field in fields.items():
-            field = copy(field)
+            field = copy(field)  # noqa: PLW2901
             field.type = remapped_type(field.type, type_map)
             fields[field_name] = field
```

### Comparing `graphql_core-3.3.0a3/src/graphql/type/validate.py` & `graphql_core-3.3.0a4/src/graphql/type/validate.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,7 +1,9 @@
+"""Schema validation"""
+
 from collections import defaultdict
 from operator import attrgetter, itemgetter
 from typing import Any, Collection, Dict, List, Optional, Set, Tuple, Union, cast
 
 from ..error import GraphQLError
 from ..language import (
     DirectiveNode,
@@ -33,15 +35,14 @@
     is_required_input_field,
     is_union_type,
 )
 from .directives import GraphQLDeprecatedDirective, is_directive
 from .introspection import is_introspection_type
 from .schema import GraphQLSchema, assert_schema
 
-
 __all__ = ["validate_schema", "assert_valid_schema"]
 
 
 def validate_schema(schema: GraphQLSchema) -> List[GraphQLError]:
     """Validate a GraphQL schema.
 
     Implements the "Type Validation" sub-sections of the specification's "Type System"
@@ -51,26 +52,26 @@
     list if no errors were encountered and the Schema is valid.
     """
     # First check to ensure the provided value is in fact a GraphQLSchema.
     assert_schema(schema)
 
     # If this Schema has already been validated, return the previous results.
     # noinspection PyProtectedMember
-    errors = schema._validation_errors
+    errors = schema._validation_errors  # noqa: SLF001
     if errors is None:
         # Validate the schema, producing a list of errors.
         context = SchemaValidationContext(schema)
         context.validate_root_types()
         context.validate_directives()
         context.validate_types()
 
         # Persist the results of validation before returning to ensure validation does
         # not run multiple times for this schema.
         errors = context.errors
-        schema._validation_errors = errors
+        schema._validation_errors = errors  # noqa: SLF001
 
     return errors
 
 
 def assert_valid_schema(schema: GraphQLSchema) -> None:
     """Utility function which asserts a schema is valid.
 
@@ -83,15 +84,15 @@
 
 class SchemaValidationContext:
     """Utility class providing a context for schema validation."""
 
     errors: List[GraphQLError]
     schema: GraphQLSchema
 
-    def __init__(self, schema: GraphQLSchema):
+    def __init__(self, schema: GraphQLSchema) -> None:
         self.errors = []
         self.schema = schema
 
     def report_error(
         self,
         message: str,
         nodes: Union[Optional[Node], Collection[Optional[Node]]] = None,
@@ -495,15 +496,15 @@
                         return operation_type.type
     return None
 
 
 class InputObjectCircularRefsValidator:
     """Modified copy of algorithm from validation.rules.NoFragmentCycles"""
 
-    def __init__(self, context: SchemaValidationContext):
+    def __init__(self, context: SchemaValidationContext) -> None:
         self.context = context
         # Tracks already visited types to maintain O(N) and to ensure that cycles
         # are not redundantly reported.
         self.visited_types: Set[str] = set()
         # Array of input fields used to produce meaningful errors
         self.field_path: List[Tuple[str, GraphQLInputField]] = []
         # Position in the type path
```

### Comparing `graphql_core-3.3.0a3/src/graphql/utilities/__init__.py` & `graphql_core-3.3.0a4/src/graphql/utilities/__init__.py`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/src/graphql/utilities/ast_from_value.py` & `graphql_core-3.3.0a4/src/graphql/utilities/ast_from_value.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,7 +1,9 @@
+"""GraphQL AST creation from Python"""
+
 import re
 from math import isfinite
 from typing import Any, Mapping, Optional
 
 from ..language import (
     BooleanValueNode,
     EnumValueNode,
@@ -22,15 +24,14 @@
     is_enum_type,
     is_input_object_type,
     is_leaf_type,
     is_list_type,
     is_non_null_type,
 )
 
-
 __all__ = ["ast_from_value"]
 
 _re_integer_string = re.compile("^-?(?:0|[1-9][0-9]*)$")
 
 
 def ast_from_value(value: Any, type_: GraphQLInputType) -> Optional[ValueNode]:
     """Produce a GraphQL Value AST given a Python object.
@@ -124,11 +125,13 @@
 
             # ID types can use Int literals.
             if type_ is GraphQLID and _re_integer_string.match(serialized):
                 return IntValueNode(value=serialized)
 
             return StringValueNode(value=serialized)
 
-        raise TypeError(f"Cannot convert value to AST: {inspect(serialized)}.")
+        msg = f"Cannot convert value to AST: {inspect(serialized)}."
+        raise TypeError(msg)
 
     # Not reachable. All possible input types have been considered.
-    raise TypeError(f"Unexpected input type: {inspect(type_)}.")
+    msg = f"Unexpected input type: {inspect(type_)}."  # pragma: no cover
+    raise TypeError(msg)  # pragma: no cover
```

### Comparing `graphql_core-3.3.0a3/src/graphql/utilities/ast_to_dict.py` & `graphql_core-3.3.0a4/src/graphql/utilities/ast_to_dict.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,13 +1,14 @@
+"""Python dictionary creation from GraphQL AST"""
+
 from typing import Any, Collection, Dict, List, Optional, overload
 
 from ..language import Node, OperationType
 from ..pyutils import is_iterable
 
-
 __all__ = ["ast_to_dict"]
 
 
 @overload
 def ast_to_dict(
     node: Node, locations: bool = False, cache: Optional[Dict[Node, Any]] = None
 ) -> Dict:
@@ -35,15 +36,14 @@
 def ast_to_dict(
     node: Any, locations: bool = False, cache: Optional[Dict[Node, Any]] = None
 ) -> Any:
     """Convert a language AST to a nested Python dictionary.
 
     Set `location` to True in order to get the locations as well.
     """
-
     """Convert a node to a nested Python dictionary."""
     if isinstance(node, Node):
         if cache is None:
             cache = {}
         elif node in cache:
             return cache[node]
         cache[node] = res = {}
@@ -52,14 +52,14 @@
                 key: ast_to_dict(getattr(node, key), locations, cache)
                 for key in ("kind",) + node.keys[1:]
             }
         )
         if locations:
             loc = node.loc
             if loc:
-                res["loc"] = dict(start=loc.start, end=loc.end)
+                res["loc"] = {"start": loc.start, "end": loc.end}
         return res
     if is_iterable(node):
         return [ast_to_dict(sub_node, locations, cache) for sub_node in node]
     if isinstance(node, OperationType):
         return node.value
     return node
```

### Comparing `graphql_core-3.3.0a3/src/graphql/utilities/build_ast_schema.py` & `graphql_core-3.3.0a4/src/graphql/utilities/build_ast_schema.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,19 +1,20 @@
+"""GraphQL Schema creation from GraphQL AST"""
+
 from typing import Union, cast
 
 from ..language import DocumentNode, Source, parse
 from ..type import (
     GraphQLObjectType,
     GraphQLSchema,
     GraphQLSchemaKwargs,
     specified_directives,
 )
 from .extend_schema import ExtendSchemaImpl
 
-
 __all__ = [
     "build_ast_schema",
     "build_schema",
 ]
 
 
 def build_ast_schema(
@@ -69,15 +70,15 @@
             elif type_name == "Mutation":
                 schema_kwargs["mutation"] = cast(GraphQLObjectType, type_)
             elif type_name == "Subscription":
                 schema_kwargs["subscription"] = cast(GraphQLObjectType, type_)
 
     # If specified directives were not explicitly declared, add them.
     directives = schema_kwargs["directives"]
-    directive_names = set(directive.name for directive in directives)
+    directive_names = {directive.name for directive in directives}
     missing_directives = []
     for directive in specified_directives:
         if directive.name not in directive_names:
             missing_directives.append(directive)
     if missing_directives:
         schema_kwargs["directives"] = directives + tuple(missing_directives)
```

### Comparing `graphql_core-3.3.0a3/src/graphql/utilities/build_client_schema.py` & `graphql_core-3.3.0a4/src/graphql/utilities/build_client_schema.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,7 +1,9 @@
+"""GraphQL client schema creation"""
+
 from itertools import chain
 from typing import Callable, Collection, Dict, List, Union, cast
 
 from ..language import DirectiveLocation, parse_value
 from ..pyutils import Undefined, inspect
 from ..type import (
     GraphQLArgument,
@@ -41,15 +43,14 @@
     IntrospectionScalarType,
     IntrospectionType,
     IntrospectionTypeRef,
     IntrospectionUnionType,
 )
 from .value_from_ast import value_from_ast
 
-
 __all__ = ["build_client_schema"]
 
 
 def build_client_schema(
     introspection: IntrospectionQuery, assume_valid: bool = False
 ) -> GraphQLSchema:
     """Build a GraphQLSchema for use by client tools.
@@ -64,55 +65,60 @@
     "errors" field of a server response before calling this function.
     """
     # Even though the `introspection` argument is typed, in most cases it's received
     # as an untyped value from the server, so we will do an additional check here.
     if not isinstance(introspection, dict) or not isinstance(
         introspection.get("__schema"), dict
     ):
-        raise TypeError(
+        msg = (
             "Invalid or incomplete introspection result. Ensure that you"
             " are passing the 'data' attribute of an introspection response"
             f" and no 'errors' were returned alongside: {inspect(introspection)}."
         )
+        raise TypeError(msg)
 
     # Get the schema from the introspection result.
     schema_introspection = introspection["__schema"]
 
     # Given a type reference in introspection, return the GraphQLType instance,
     # preferring cached instances before building new instances.
     def get_type(type_ref: IntrospectionTypeRef) -> GraphQLType:
         kind = type_ref.get("kind")
         if kind == TypeKind.LIST.name:
             item_ref = type_ref.get("ofType")
             if not item_ref:
-                raise TypeError("Decorated type deeper than introspection query.")
+                msg = "Decorated type deeper than introspection query."
+                raise TypeError(msg)
             item_ref = cast(IntrospectionTypeRef, item_ref)
             return GraphQLList(get_type(item_ref))
         if kind == TypeKind.NON_NULL.name:
             nullable_ref = type_ref.get("ofType")
             if not nullable_ref:
-                raise TypeError("Decorated type deeper than introspection query.")
+                msg = "Decorated type deeper than introspection query."
+                raise TypeError(msg)
             nullable_ref = cast(IntrospectionTypeRef, nullable_ref)
             nullable_type = get_type(nullable_ref)
             return GraphQLNonNull(assert_nullable_type(nullable_type))
         type_ref = cast(IntrospectionType, type_ref)
         return get_named_type(type_ref)
 
     def get_named_type(type_ref: IntrospectionType) -> GraphQLNamedType:
         type_name = type_ref.get("name")
         if not type_name:
-            raise TypeError(f"Unknown type reference: {inspect(type_ref)}.")
+            msg = f"Unknown type reference: {inspect(type_ref)}."
+            raise TypeError(msg)
 
         type_ = type_map.get(type_name)
         if not type_:
-            raise TypeError(
+            msg = (
                 f"Invalid or incomplete schema, unknown type: {type_name}."
                 " Ensure that a full introspection query is used in order"
                 " to build a client schema."
             )
+            raise TypeError(msg)
         return type_
 
     def get_object_type(type_ref: IntrospectionObjectType) -> GraphQLObjectType:
         return assert_object_type(get_type(type_ref))
 
     def get_interface_type(
         type_ref: IntrospectionInterfaceType,
@@ -121,19 +127,20 @@
 
     # Given a type's introspection result, construct the correct GraphQLType instance.
     def build_type(type_: IntrospectionType) -> GraphQLNamedType:
         if type_ and "name" in type_ and "kind" in type_:
             builder = type_builders.get(type_["kind"])
             if builder:  # pragma: no cover else
                 return builder(type_)
-        raise TypeError(
+        msg = (
             "Invalid or incomplete introspection result."
             " Ensure that a full introspection query is used in order"
             f" to build a client schema: {inspect(type_)}."
         )
+        raise TypeError(msg)
 
     def build_scalar_def(
         scalar_introspection: IntrospectionScalarType,
     ) -> GraphQLScalarType:
         name = scalar_introspection["name"]
         try:
             return cast(GraphQLScalarType, GraphQLScalarType.reserved_types[name])
@@ -151,18 +158,19 @@
     ) -> List[GraphQLInterfaceType]:
         maybe_interfaces = implementing_introspection.get("interfaces")
         if maybe_interfaces is None:
             # Temporary workaround until GraphQL ecosystem will fully support
             # 'interfaces' on interface types
             if implementing_introspection["kind"] == TypeKind.INTERFACE.name:
                 return []
-            raise TypeError(
+            msg = (
                 "Introspection result missing interfaces:"
                 f" {inspect(implementing_introspection)}."
             )
+            raise TypeError(msg)
         interfaces = cast(Collection[IntrospectionInterfaceType], maybe_interfaces)
         return [get_interface_type(interface) for interface in interfaces]
 
     def build_object_def(
         object_introspection: IntrospectionObjectType,
     ) -> GraphQLObjectType:
         name = object_introspection["name"]
@@ -187,31 +195,33 @@
         )
 
     def build_union_def(
         union_introspection: IntrospectionUnionType,
     ) -> GraphQLUnionType:
         maybe_possible_types = union_introspection.get("possibleTypes")
         if maybe_possible_types is None:
-            raise TypeError(
+            msg = (
                 "Introspection result missing possibleTypes:"
                 f" {inspect(union_introspection)}."
             )
+            raise TypeError(msg)
         possible_types = cast(Collection[IntrospectionObjectType], maybe_possible_types)
         return GraphQLUnionType(
             name=union_introspection["name"],
             description=union_introspection.get("description"),
             types=lambda: [get_object_type(type_) for type_ in possible_types],
         )
 
     def build_enum_def(enum_introspection: IntrospectionEnumType) -> GraphQLEnumType:
         if enum_introspection.get("enumValues") is None:
-            raise TypeError(
+            msg = (
                 "Introspection result missing enumValues:"
                 f" {inspect(enum_introspection)}."
             )
+            raise TypeError(msg)
         name = enum_introspection["name"]
         try:
             return cast(GraphQLEnumType, GraphQLEnumType.reserved_types[name])
         except KeyError:
             return GraphQLEnumType(
                 name=name,
                 description=enum_introspection.get("description"),
@@ -225,18 +235,19 @@
                 },
             )
 
     def build_input_object_def(
         input_object_introspection: IntrospectionInputObjectType,
     ) -> GraphQLInputObjectType:
         if input_object_introspection.get("inputFields") is None:
-            raise TypeError(
+            msg = (
                 "Introspection result missing inputFields:"
                 f" {inspect(input_object_introspection)}."
             )
+            raise TypeError(msg)
         return GraphQLInputObjectType(
             name=input_object_introspection["name"],
             description=input_object_introspection.get("description"),
             fields=lambda: build_input_value_def_map(
                 input_object_introspection["inputFields"]
             ),
         )
@@ -250,37 +261,39 @@
         TypeKind.INPUT_OBJECT.name: build_input_object_def,  # type: ignore
     }
 
     def build_field_def_map(
         type_introspection: Union[IntrospectionObjectType, IntrospectionInterfaceType],
     ) -> Dict[str, GraphQLField]:
         if type_introspection.get("fields") is None:
-            raise TypeError(
-                f"Introspection result missing fields: {type_introspection}."
-            )
+            msg = f"Introspection result missing fields: {type_introspection}."
+
+            raise TypeError(msg)
         return {
             field_introspection["name"]: build_field(field_introspection)
             for field_introspection in type_introspection["fields"]
         }
 
     def build_field(field_introspection: IntrospectionField) -> GraphQLField:
         type_introspection = cast(IntrospectionType, field_introspection["type"])
         type_ = get_type(type_introspection)
         if not is_output_type(type_):
-            raise TypeError(
+            msg = (
                 "Introspection must provide output type for fields,"
                 f" but received: {inspect(type_)}."
             )
+            raise TypeError(msg)
 
         args_introspection = field_introspection.get("args")
         if args_introspection is None:
-            raise TypeError(
+            msg = (
                 "Introspection result missing field args:"
                 f" {inspect(field_introspection)}."
             )
+            raise TypeError(msg)
 
         return GraphQLField(
             type_,
             args=build_argument_def_map(args_introspection),
             description=field_introspection.get("description"),
             deprecation_reason=field_introspection.get("deprecationReason"),
         )
@@ -295,18 +308,19 @@
 
     def build_argument(
         argument_introspection: IntrospectionInputValue,
     ) -> GraphQLArgument:
         type_introspection = cast(IntrospectionType, argument_introspection["type"])
         type_ = get_type(type_introspection)
         if not is_input_type(type_):
-            raise TypeError(
+            msg = (
                 "Introspection must provide input type for arguments,"
                 f" but received: {inspect(type_)}."
             )
+            raise TypeError(msg)
 
         default_value_introspection = argument_introspection.get("defaultValue")
         default_value = (
             Undefined
             if default_value_introspection is None
             else value_from_ast(parse_value(default_value_introspection), type_)
         )
@@ -329,18 +343,19 @@
 
     def build_input_value(
         input_value_introspection: IntrospectionInputValue,
     ) -> GraphQLInputField:
         type_introspection = cast(IntrospectionType, input_value_introspection["type"])
         type_ = get_type(type_introspection)
         if not is_input_type(type_):
-            raise TypeError(
+            msg = (
                 "Introspection must provide input type for input fields,"
                 f" but received: {inspect(type_)}."
             )
+            raise TypeError(msg)
 
         default_value_introspection = input_value_introspection.get("defaultValue")
         default_value = (
             Undefined
             if default_value_introspection is None
             else value_from_ast(parse_value(default_value_introspection), type_)
         )
@@ -351,23 +366,25 @@
             deprecation_reason=input_value_introspection.get("deprecationReason"),
         )
 
     def build_directive(
         directive_introspection: IntrospectionDirective,
     ) -> GraphQLDirective:
         if directive_introspection.get("args") is None:
-            raise TypeError(
+            msg = (
                 "Introspection result missing directive args:"
                 f" {inspect(directive_introspection)}."
             )
+            raise TypeError(msg)
         if directive_introspection.get("locations") is None:
-            raise TypeError(
+            msg = (
                 "Introspection result missing directive locations:"
                 f" {inspect(directive_introspection)}."
             )
+            raise TypeError(msg)
         return GraphQLDirective(
             name=directive_introspection["name"],
             description=directive_introspection.get("description"),
             is_repeatable=directive_introspection.get("isRepeatable", False),
             locations=list(
                 cast(
                     Collection[DirectiveLocation],
```

### Comparing `graphql_core-3.3.0a3/src/graphql/utilities/coerce_input_value.py` & `graphql_core-3.3.0a4/src/graphql/utilities/coerce_input_value.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,7 +1,9 @@
+"""Input value coercion"""
+
 from typing import Any, Callable, Dict, List, Optional, Union, cast
 
 from ..error import GraphQLError
 from ..pyutils import (
     Path,
     Undefined,
     did_you_mean,
@@ -15,15 +17,14 @@
     GraphQLScalarType,
     is_input_object_type,
     is_leaf_type,
     is_list_type,
     is_non_null_type,
 )
 
-
 try:
     from typing import TypeAlias
 except ImportError:  # Python < 3.10
     from typing_extensions import TypeAlias
 
 
 __all__ = ["coerce_input_value"]
@@ -135,15 +136,15 @@
         # to the original error.
         type_ = cast(GraphQLScalarType, type_)
         try:
             parse_result = type_.parse_value(input_value)
         except GraphQLError as error:
             on_error(path.as_list() if path else [], input_value, error)
             return Undefined
-        except Exception as error:
+        except Exception as error:  # noqa: BLE001
             on_error(
                 path.as_list() if path else [],
                 input_value,
                 GraphQLError(
                     f"Expected type '{type_.name}'. {error}", original_error=error
                 ),
             )
@@ -153,8 +154,9 @@
                 path.as_list() if path else [],
                 input_value,
                 GraphQLError(f"Expected type '{type_.name}'."),
             )
         return parse_result
 
     # Not reachable. All possible input types have been considered.
-    raise TypeError(f"Unexpected input type: {inspect(type_)}.")
+    msg = f"Unexpected input type: {inspect(type_)}."  # pragma: no cover
+    raise TypeError(msg)  # pragma: no cover
```

### Comparing `graphql_core-3.3.0a3/src/graphql/utilities/concat_ast.py` & `graphql_core-3.3.0a4/src/graphql/utilities/concat_ast.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,13 +1,14 @@
+"""AST concatenation"""
+
 from itertools import chain
 from typing import Collection
 
 from ..language.ast import DocumentNode
 
-
 __all__ = ["concat_ast"]
 
 
 def concat_ast(asts: Collection[DocumentNode]) -> DocumentNode:
     """Concat ASTs.
 
     Provided a collection of ASTs, presumably each from different files, concatenate
```

### Comparing `graphql_core-3.3.0a3/src/graphql/utilities/extend_schema.py` & `graphql_core-3.3.0a4/src/graphql/utilities/extend_schema.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,7 +1,9 @@
+"""GraphQL schema extension"""
+
 from collections import defaultdict
 from functools import partial
 from typing import (
     Any,
     Collection,
     DefaultDict,
     Dict,
@@ -84,15 +86,14 @@
     is_specified_directive,
     is_specified_scalar_type,
     is_union_type,
     specified_scalar_types,
 )
 from .value_from_ast import value_from_ast
 
-
 __all__ = [
     "extend_schema",
     "ExtendSchemaImpl",
 ]
 
 
 def extend_schema(
@@ -174,15 +175,15 @@
 
     For internal use only.
     """
 
     type_map: Dict[str, GraphQLNamedType]
     type_extensions: TypeExtensionsMap
 
-    def __init__(self, type_extensions: TypeExtensionsMap):
+    def __init__(self, type_extensions: TypeExtensionsMap) -> None:
         self.type_map = {}
         self.type_extensions = type_extensions
 
     @classmethod
     def extend_schema_args(
         cls,
         schema_kwargs: GraphQLSchemaKwargs,
@@ -254,40 +255,46 @@
             subscription=get_operation(OperationType.SUBSCRIPTION),  # type: ignore
             types=tuple(self.type_map.values()),
             directives=tuple(
                 self.replace_directive(directive)
                 for directive in schema_kwargs["directives"]
             )
             + tuple(self.build_directive(directive) for directive in directive_defs),
-            description=schema_def.description.value
-            if schema_def and schema_def.description
-            else None,
-            extensions={},
+            description=(
+                schema_def.description.value
+                if schema_def and schema_def.description
+                else None
+            )
+            or schema_kwargs["description"],
+            extensions=schema_kwargs["extensions"],
             ast_node=schema_def or schema_kwargs["ast_node"],
             extension_ast_nodes=schema_kwargs["extension_ast_nodes"]
             + tuple(schema_extensions),
             assume_valid=assume_valid,
         )
 
     # noinspection PyTypeChecker,PyUnresolvedReferences
     def replace_type(self, type_: GraphQLType) -> GraphQLType:
+        """Replace a GraphQL type."""
         if is_list_type(type_):
             return GraphQLList(self.replace_type(type_.of_type))
         if is_non_null_type(type_):
             return GraphQLNonNull(self.replace_type(type_.of_type))  # type: ignore
         return self.replace_named_type(type_)  # type: ignore
 
     def replace_named_type(self, type_: GraphQLNamedType) -> GraphQLNamedType:
+        """Replace a named GraphQL type."""
         # Note: While this could make early assertions to get the correctly
         # typed values below, that would throw immediately while type system
         # validation with validate_schema() will produce more actionable results.
         return self.type_map[type_.name]
 
     # noinspection PyShadowingNames
     def replace_directive(self, directive: GraphQLDirective) -> GraphQLDirective:
+        """Replace a GraphQL directive."""
         if is_specified_directive(directive):
             # Builtin directives are not extended.
             return directive
 
         kwargs = directive.to_kwargs()
         return GraphQLDirective(
             **merge_kwargs(
@@ -295,14 +302,15 @@
                 args={
                     name: self.extend_arg(arg) for name, arg in kwargs["args"].items()
                 },
             )
         )
 
     def extend_named_type(self, type_: GraphQLNamedType) -> GraphQLNamedType:
+        """Extend a named GraphQL type."""
         if is_introspection_type(type_) or is_specified_scalar_type(type_):
             # Builtin types are not extended.
             return type_
         if is_scalar_type(type_):
             return self.extend_scalar_type(type_)
         if is_object_type(type_):
             return self.extend_object_type(type_)
@@ -312,19 +320,21 @@
             return self.extend_union_type(type_)
         if is_enum_type(type_):
             return self.extend_enum_type(type_)
         if is_input_object_type(type_):
             return self.extend_input_object_type(type_)
 
         # Not reachable. All possible types have been considered.
-        raise TypeError(f"Unexpected type: {inspect(type_)}.")  # pragma: no cover
+        msg = f"Unexpected type: {inspect(type_)}."  # pragma: no cover
+        raise TypeError(msg)  # pragma: no cover
 
     def extend_input_object_type_fields(
         self, kwargs: Dict[str, Any], extensions: Tuple[Any, ...]
     ) -> GraphQLInputFieldMap:
+        """Extend GraphQL input object type fields."""
         return {
             **{
                 name: GraphQLInputField(
                     **merge_kwargs(
                         field.to_kwargs(),
                         type_=self.replace_type(field.type),
                     )
@@ -335,40 +345,43 @@
         }
 
     # noinspection PyShadowingNames
     def extend_input_object_type(
         self,
         type_: GraphQLInputObjectType,
     ) -> GraphQLInputObjectType:
+        """Extend a GraphQL input object type."""
         kwargs = type_.to_kwargs()
         extensions = tuple(self.type_extensions.input_object[kwargs["name"]])
 
         return GraphQLInputObjectType(
             **merge_kwargs(
                 kwargs,
                 fields=partial(
                     self.extend_input_object_type_fields, kwargs, extensions
                 ),
                 extension_ast_nodes=kwargs["extension_ast_nodes"] + extensions,
             )
         )
 
     def extend_enum_type(self, type_: GraphQLEnumType) -> GraphQLEnumType:
+        """Extend a GraphQL enum type."""
         kwargs = type_.to_kwargs()
         extensions = tuple(self.type_extensions.enum[kwargs["name"]])
 
         return GraphQLEnumType(
             **merge_kwargs(
                 kwargs,
                 values={**kwargs["values"], **self.build_enum_value_map(extensions)},
                 extension_ast_nodes=kwargs["extension_ast_nodes"] + extensions,
             )
         )
 
     def extend_scalar_type(self, type_: GraphQLScalarType) -> GraphQLScalarType:
+        """Extend a GraphQL scalar type."""
         kwargs = type_.to_kwargs()
         extensions = tuple(self.type_extensions.scalar[kwargs["name"]])
 
         specified_by_url = kwargs["specified_by_url"]
         for extension_node in extensions:
             specified_by_url = get_specified_by_url(extension_node) or specified_by_url
 
@@ -379,32 +392,35 @@
                 extension_ast_nodes=kwargs["extension_ast_nodes"] + extensions,
             )
         )
 
     def extend_object_type_interfaces(
         self, kwargs: Dict[str, Any], extensions: Tuple[Any, ...]
     ) -> List[GraphQLInterfaceType]:
+        """Extend a GraphQL object type interface."""
         return [
             cast(GraphQLInterfaceType, self.replace_named_type(interface))
             for interface in kwargs["interfaces"]
         ] + self.build_interfaces(extensions)
 
     def extend_object_type_fields(
         self, kwargs: Dict[str, Any], extensions: Tuple[Any, ...]
     ) -> GraphQLFieldMap:
+        """Extend GraphQL object type fields."""
         return {
             **{
                 name: self.extend_field(field)
                 for name, field in kwargs["fields"].items()
             },
             **self.build_field_map(extensions),
         }
 
     # noinspection PyShadowingNames
     def extend_object_type(self, type_: GraphQLObjectType) -> GraphQLObjectType:
+        """Extend a GraphQL object type."""
         kwargs = type_.to_kwargs()
         extensions = tuple(self.type_extensions.object[kwargs["name"]])
 
         return GraphQLObjectType(
             **merge_kwargs(
                 kwargs,
                 interfaces=partial(
@@ -414,34 +430,37 @@
                 extension_ast_nodes=kwargs["extension_ast_nodes"] + extensions,
             )
         )
 
     def extend_interface_type_interfaces(
         self, kwargs: Dict[str, Any], extensions: Tuple[Any, ...]
     ) -> List[GraphQLInterfaceType]:
+        """Extend GraphQL interface type interfaces."""
         return [
             cast(GraphQLInterfaceType, self.replace_named_type(interface))
             for interface in kwargs["interfaces"]
         ] + self.build_interfaces(extensions)
 
     def extend_interface_type_fields(
         self, kwargs: Dict[str, Any], extensions: Tuple[Any, ...]
     ) -> GraphQLFieldMap:
+        """Extend GraphQL interface type fields."""
         return {
             **{
                 name: self.extend_field(field)
                 for name, field in kwargs["fields"].items()
             },
             **self.build_field_map(extensions),
         }
 
     # noinspection PyShadowingNames
     def extend_interface_type(
         self, type_: GraphQLInterfaceType
     ) -> GraphQLInterfaceType:
+        """Extend a GraphQL interface type."""
         kwargs = type_.to_kwargs()
         extensions = tuple(self.type_extensions.interface[kwargs["name"]])
 
         return GraphQLInterfaceType(
             **merge_kwargs(
                 kwargs,
                 interfaces=partial(
@@ -451,81 +470,90 @@
                 extension_ast_nodes=kwargs["extension_ast_nodes"] + extensions,
             )
         )
 
     def extend_union_type_types(
         self, kwargs: Dict[str, Any], extensions: Tuple[Any, ...]
     ) -> List[GraphQLObjectType]:
+        """Extend types of a GraphQL union type."""
         return [
             cast(GraphQLObjectType, self.replace_named_type(member_type))
             for member_type in kwargs["types"]
         ] + self.build_union_types(extensions)
 
     def extend_union_type(self, type_: GraphQLUnionType) -> GraphQLUnionType:
+        """Extend a GraphQL union type."""
         kwargs = type_.to_kwargs()
         extensions = tuple(self.type_extensions.union[kwargs["name"]])
 
         return GraphQLUnionType(
             **merge_kwargs(
                 kwargs,
                 types=partial(self.extend_union_type_types, kwargs, extensions),
                 extension_ast_nodes=kwargs["extension_ast_nodes"] + extensions,
             ),
         )
 
     # noinspection PyShadowingNames
     def extend_field(self, field: GraphQLField) -> GraphQLField:
+        """Extend a GraphQL field."""
         return GraphQLField(
             **merge_kwargs(
                 field.to_kwargs(),
                 type_=self.replace_type(field.type),
                 args={name: self.extend_arg(arg) for name, arg in field.args.items()},
             )
         )
 
     def extend_arg(self, arg: GraphQLArgument) -> GraphQLArgument:
+        """Extend a GraphQL argument."""
         return GraphQLArgument(
             **merge_kwargs(
                 arg.to_kwargs(),
                 type_=self.replace_type(arg.type),
             )
         )
 
     # noinspection PyShadowingNames
     def get_operation_types(
         self, nodes: Collection[Union[SchemaDefinitionNode, SchemaExtensionNode]]
     ) -> Dict[OperationType, GraphQLNamedType]:
+        """Extend GraphQL operation types."""
         # Note: While this could make early assertions to get the correctly
         # typed values below, that would throw immediately while type system
         # validation with validate_schema() will produce more actionable results.
         return {
             operation_type.operation: self.get_named_type(operation_type.type)
             for node in nodes
             for operation_type in node.operation_types or []
         }
 
     # noinspection PyShadowingNames
     def get_named_type(self, node: NamedTypeNode) -> GraphQLNamedType:
+        """Get name GraphQL type for a given named type node."""
         name = node.name.value
         type_ = std_type_map.get(name) or self.type_map.get(name)
 
         if not type_:
-            raise TypeError(f"Unknown type: '{name}'.")
+            msg = f"Unknown type: '{name}'."
+            raise TypeError(msg)
         return type_
 
     def get_wrapped_type(self, node: TypeNode) -> GraphQLType:
+        """Get wrapped GraphQL type for a given type node."""
         if isinstance(node, ListTypeNode):
             return GraphQLList(self.get_wrapped_type(node.type))
         if isinstance(node, NonNullTypeNode):
             return GraphQLNonNull(
                 cast(GraphQLNullableType, self.get_wrapped_type(node.type))
             )
         return self.get_named_type(cast(NamedTypeNode, node))
 
     def build_directive(self, node: DirectiveDefinitionNode) -> GraphQLDirective:
+        """Build a GraphQL directive for a given directive definition node."""
         locations = [DirectiveLocation[node.value] for node in node.locations]
 
         return GraphQLDirective(
             name=node.name.value,
             description=node.description.value if node.description else None,
             locations=locations,
             is_repeatable=node.repeatable,
@@ -540,14 +568,15 @@
                 InterfaceTypeDefinitionNode,
                 InterfaceTypeExtensionNode,
                 ObjectTypeDefinitionNode,
                 ObjectTypeExtensionNode,
             ]
         ],
     ) -> GraphQLFieldMap:
+        """Build a GraphQL field map."""
         field_map: GraphQLFieldMap = {}
         for node in nodes:
             for field in node.fields or []:
                 # Note: While this could make assertions to get the correctly typed
                 # value, that would throw immediately while type system validation
                 # with validate_schema() will produce more actionable results.
                 field_map[field.name.value] = GraphQLField(
@@ -559,14 +588,15 @@
                 )
         return field_map
 
     def build_argument_map(
         self,
         args: Optional[Collection[InputValueDefinitionNode]],
     ) -> GraphQLArgumentMap:
+        """Build a GraphQL argument map."""
         arg_map: GraphQLArgumentMap = {}
         for arg in args or []:
             # Note: While this could make assertions to get the correctly typed
             # value, that would throw immediately while type system validation
             # with validate_schema() will produce more actionable results.
             type_ = cast(GraphQLInputType, self.get_wrapped_type(arg.type))
             arg_map[arg.name.value] = GraphQLArgument(
@@ -580,14 +610,15 @@
 
     def build_input_field_map(
         self,
         nodes: Collection[
             Union[InputObjectTypeDefinitionNode, InputObjectTypeExtensionNode]
         ],
     ) -> GraphQLInputFieldMap:
+        """Build a GraphQL input field map."""
         input_field_map: GraphQLInputFieldMap = {}
         for node in nodes:
             for field in node.fields or []:
                 # Note: While this could make assertions to get the correctly typed
                 # value, that would throw immediately while type system validation
                 # with validate_schema() will produce more actionable results.
                 type_ = cast(GraphQLInputType, self.get_wrapped_type(field.type))
@@ -598,16 +629,17 @@
                     deprecation_reason=get_deprecation_reason(field),
                     ast_node=field,
                 )
         return input_field_map
 
     @staticmethod
     def build_enum_value_map(
-        nodes: Collection[Union[EnumTypeDefinitionNode, EnumTypeExtensionNode]]
+        nodes: Collection[Union[EnumTypeDefinitionNode, EnumTypeExtensionNode]],
     ) -> GraphQLEnumValueMap:
+        """Build a GraphQL enum value map."""
         enum_value_map: GraphQLEnumValueMap = {}
         for node in nodes:
             for value in node.values or []:
                 # Note: While this could make assertions to get the correctly typed
                 # value, that would throw immediately while type system validation
                 # with validate_schema() will produce more actionable results.
                 value_name = value.name.value
@@ -626,39 +658,42 @@
                 InterfaceTypeDefinitionNode,
                 InterfaceTypeExtensionNode,
                 ObjectTypeDefinitionNode,
                 ObjectTypeExtensionNode,
             ]
         ],
     ) -> List[GraphQLInterfaceType]:
+        """Build GraphQL interface types for the given nodes."""
         # Note: While this could make assertions to get the correctly typed
         # value, that would throw immediately while type system validation
         # with validate_schema() will produce more actionable results.
         return [
             cast(GraphQLInterfaceType, self.get_named_type(type_))
             for node in nodes
             for type_ in node.interfaces or []
         ]
 
     def build_union_types(
         self,
         nodes: Collection[Union[UnionTypeDefinitionNode, UnionTypeExtensionNode]],
     ) -> List[GraphQLObjectType]:
+        """Build GraphQL object types for the given union type nodes."""
         # Note: While this could make assertions to get the correctly typed
         # value, that would throw immediately while type system validation
         # with validate_schema() will produce more actionable results.
         return [
             cast(GraphQLObjectType, self.get_named_type(type_))
             for node in nodes
             for type_ in node.types or []
         ]
 
     def build_object_type(
         self, ast_node: ObjectTypeDefinitionNode
     ) -> GraphQLObjectType:
+        """Build a GraphQL object type for the given object type definition node."""
         extension_nodes = self.type_extensions.object[ast_node.name.value]
         all_nodes: List[Union[ObjectTypeDefinitionNode, ObjectTypeExtensionNode]] = [
             ast_node,
             *extension_nodes,
         ]
         return GraphQLObjectType(
             name=ast_node.name.value,
@@ -669,42 +704,45 @@
             extension_ast_nodes=extension_nodes,
         )
 
     def build_interface_type(
         self,
         ast_node: InterfaceTypeDefinitionNode,
     ) -> GraphQLInterfaceType:
+        """Build a GraphQL interface type for the given type definition nodes."""
         extension_nodes = self.type_extensions.interface[ast_node.name.value]
         all_nodes: List[
             Union[InterfaceTypeDefinitionNode, InterfaceTypeExtensionNode]
         ] = [ast_node, *extension_nodes]
         return GraphQLInterfaceType(
             name=ast_node.name.value,
             description=ast_node.description.value if ast_node.description else None,
             interfaces=partial(self.build_interfaces, all_nodes),
             fields=partial(self.build_field_map, all_nodes),
             ast_node=ast_node,
             extension_ast_nodes=extension_nodes,
         )
 
     def build_enum_type(self, ast_node: EnumTypeDefinitionNode) -> GraphQLEnumType:
+        """Build a GraphQL enum type for the given enum type definition nodes."""
         extension_nodes = self.type_extensions.enum[ast_node.name.value]
         all_nodes: List[Union[EnumTypeDefinitionNode, EnumTypeExtensionNode]] = [
             ast_node,
             *extension_nodes,
         ]
         return GraphQLEnumType(
             name=ast_node.name.value,
             description=ast_node.description.value if ast_node.description else None,
             values=self.build_enum_value_map(all_nodes),
             ast_node=ast_node,
             extension_ast_nodes=extension_nodes,
         )
 
     def build_union_type(self, ast_node: UnionTypeDefinitionNode) -> GraphQLUnionType:
+        """Build a GraphQL union type for the given union type definition nodes."""
         extension_nodes = self.type_extensions.union[ast_node.name.value]
         all_nodes: List[Union[UnionTypeDefinitionNode, UnionTypeExtensionNode]] = [
             ast_node,
             *extension_nodes,
         ]
         return GraphQLUnionType(
             name=ast_node.name.value,
@@ -713,73 +751,77 @@
             ast_node=ast_node,
             extension_ast_nodes=extension_nodes,
         )
 
     def build_scalar_type(
         self, ast_node: ScalarTypeDefinitionNode
     ) -> GraphQLScalarType:
+        """Build a GraphQL scalar type for the given scalar type definition node."""
         extension_nodes = self.type_extensions.scalar[ast_node.name.value]
         return GraphQLScalarType(
             name=ast_node.name.value,
             description=ast_node.description.value if ast_node.description else None,
             specified_by_url=get_specified_by_url(ast_node),
             ast_node=ast_node,
             extension_ast_nodes=extension_nodes,
         )
 
     def build_input_object_type(
         self,
         ast_node: InputObjectTypeDefinitionNode,
     ) -> GraphQLInputObjectType:
+        """Build a GraphQL input object type for the given node."""
         extension_nodes = self.type_extensions.input_object[ast_node.name.value]
         all_nodes: List[
             Union[InputObjectTypeDefinitionNode, InputObjectTypeExtensionNode]
         ] = [ast_node, *extension_nodes]
         return GraphQLInputObjectType(
             name=ast_node.name.value,
             description=ast_node.description.value if ast_node.description else None,
             fields=partial(self.build_input_field_map, all_nodes),
             ast_node=ast_node,
             extension_ast_nodes=extension_nodes,
         )
 
     def build_type(self, ast_node: TypeDefinitionNode) -> GraphQLNamedType:
+        """Build a named GraphQL type for the given type definition node."""
         kind = ast_node.kind
         try:
             kind = kind.removesuffix("_definition")
         except AttributeError:  # pragma: no cover (Python < 3.9)
             if kind.endswith("_definition"):
                 kind = kind[:-11]
         try:
             build = getattr(self, f"build_{kind}")
-        except AttributeError:  # pragma: no cover
+        except AttributeError as error:  # pragma: no cover
             # Not reachable. All possible type definition nodes have been considered.
-            raise TypeError(  # pragma: no cover
+            msg = (  # pragma: no cover
                 f"Unexpected type definition node: {inspect(ast_node)}."
             )
+            raise TypeError(msg) from error  # pragma: no cover
         return build(ast_node)
 
 
 std_type_map: Mapping[str, Union[GraphQLNamedType, GraphQLObjectType]] = {
     **specified_scalar_types,
     **introspection_types,
 }
 
 
 def get_deprecation_reason(
-    node: Union[EnumValueDefinitionNode, FieldDefinitionNode, InputValueDefinitionNode]
+    node: Union[EnumValueDefinitionNode, FieldDefinitionNode, InputValueDefinitionNode],
 ) -> Optional[str]:
     """Given a field or enum value node, get deprecation reason as string."""
     from ..execution import get_directive_values
 
     deprecated = get_directive_values(GraphQLDeprecatedDirective, node)
     return deprecated["reason"] if deprecated else None
 
 
 def get_specified_by_url(
-    node: Union[ScalarTypeDefinitionNode, ScalarTypeExtensionNode]
+    node: Union[ScalarTypeDefinitionNode, ScalarTypeExtensionNode],
 ) -> Optional[str]:
     """Given a scalar node, return the string value for the specifiedByURL."""
     from ..execution import get_directive_values
 
     specified_by_url = get_directive_values(GraphQLSpecifiedByDirective, node)
     return specified_by_url["url"] if specified_by_url else None
```

### Comparing `graphql_core-3.3.0a3/src/graphql/utilities/find_breaking_changes.py` & `graphql_core-3.3.0a4/src/graphql/utilities/find_breaking_changes.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,7 +1,9 @@
+"""Find breaking changes between GraphQL schemas"""
+
 from enum import Enum
 from typing import Any, Collection, Dict, List, NamedTuple, Union
 
 from ..language import print_ast
 from ..pyutils import Undefined, inspect
 from ..type import (
     GraphQLEnumType,
@@ -26,15 +28,14 @@
     is_scalar_type,
     is_specified_scalar_type,
     is_union_type,
 )
 from ..utilities.sort_value_node import sort_value_node
 from .ast_from_value import ast_from_value
 
-
 try:
     from typing import TypeAlias
 except ImportError:  # Python < 3.10
     from typing_extensions import TypeAlias
 
 
 __all__ = [
@@ -44,14 +45,16 @@
     "DangerousChangeType",
     "find_breaking_changes",
     "find_dangerous_changes",
 ]
 
 
 class BreakingChangeType(Enum):
+    """Types of breaking changes"""
+
     TYPE_REMOVED = 10
     TYPE_CHANGED_KIND = 11
     TYPE_REMOVED_FROM_UNION = 20
     VALUE_REMOVED_FROM_ENUM = 21
     REQUIRED_INPUT_FIELD_ADDED = 22
     IMPLEMENTED_INTERFACE_REMOVED = 23
     FIELD_REMOVED = 30
@@ -63,28 +66,34 @@
     DIRECTIVE_ARG_REMOVED = 51
     REQUIRED_DIRECTIVE_ARG_ADDED = 52
     DIRECTIVE_REPEATABLE_REMOVED = 53
     DIRECTIVE_LOCATION_REMOVED = 54
 
 
 class DangerousChangeType(Enum):
+    """Types of dangerous changes"""
+
     VALUE_ADDED_TO_ENUM = 60
     TYPE_ADDED_TO_UNION = 61
     OPTIONAL_INPUT_FIELD_ADDED = 62
     OPTIONAL_ARG_ADDED = 63
     IMPLEMENTED_INTERFACE_ADDED = 64
     ARG_DEFAULT_VALUE_CHANGE = 65
 
 
 class BreakingChange(NamedTuple):
+    """Type and description of a breaking change"""
+
     type: BreakingChangeType
     description: str
 
 
 class DangerousChange(NamedTuple):
+    """Type and description of a dangerous change"""
+
     type: DangerousChangeType
     description: str
 
 
 Change: TypeAlias = Union[BreakingChange, DangerousChange]
 
 
@@ -201,20 +210,20 @@
     for type_name, (old_type, new_type) in types_diff.persisted.items():
         if is_enum_type(old_type) and is_enum_type(new_type):
             schema_changes.extend(find_enum_type_changes(old_type, new_type))
         elif is_union_type(old_type) and is_union_type(new_type):
             schema_changes.extend(find_union_type_changes(old_type, new_type))
         elif is_input_object_type(old_type) and is_input_object_type(new_type):
             schema_changes.extend(find_input_object_type_changes(old_type, new_type))
-        elif is_object_type(old_type) and is_object_type(new_type):
-            schema_changes.extend(find_field_changes(old_type, new_type))
-            schema_changes.extend(
-                find_implemented_interfaces_changes(old_type, new_type)
-            )
-        elif is_interface_type(old_type) and is_interface_type(new_type):
+        elif (
+            is_object_type(old_type)
+            and is_object_type(new_type)
+            or is_interface_type(old_type)
+            and is_interface_type(new_type)
+        ):
             schema_changes.extend(find_field_changes(old_type, new_type))
             schema_changes.extend(
                 find_implemented_interfaces_changes(old_type, new_type)
             )
         elif old_type.__class__ is not new_type.__class__:
             schema_changes.append(
                 BreakingChange(
@@ -486,24 +495,24 @@
         ) and is_change_safe_for_object_or_interface_field(
             old_type.of_type, new_type.of_type
         )
 
     if is_named_type(old_type):
         return (
             # if they're both named types, see if their names are equivalent
-            is_named_type(new_type)
-            and old_type.name == new_type.name
+            is_named_type(new_type) and old_type.name == new_type.name
         ) or (
             # moving from nullable to non-null of same underlying type is safe
             is_non_null_type(new_type)
             and is_change_safe_for_object_or_interface_field(old_type, new_type.of_type)
         )
 
     # Not reachable. All possible output types have been considered.
-    raise TypeError(f"Unexpected type {inspect(old_type)}")
+    msg = f"Unexpected type {inspect(old_type)}"  # pragma: no cover
+    raise TypeError(msg)  # pragma: no cover
 
 
 def is_change_safe_for_input_object_field_or_field_arg(
     old_type: GraphQLType, new_type: GraphQLType
 ) -> bool:
     if is_list_type(old_type):
         return is_list_type(
@@ -527,20 +536,20 @@
                 old_type.of_type, new_type
             )
         )
 
     if is_named_type(old_type):
         return (
             # if they're both named types, see if their names are equivalent
-            is_named_type(new_type)
-            and old_type.name == new_type.name
+            is_named_type(new_type) and old_type.name == new_type.name
         )
 
     # Not reachable. All possible output types have been considered.
-    raise TypeError(f"Unexpected type {inspect(old_type)}")
+    msg = f"Unexpected type {inspect(old_type)}"  # pragma: no cover
+    raise TypeError(msg)  # pragma: no cover
 
 
 def type_kind_name(type_: GraphQLNamedType) -> str:
     if is_scalar_type(type_):
         return "a Scalar type"
     if is_object_type(type_):
         return "an Object type"
@@ -550,21 +559,23 @@
         return "a Union type"
     if is_enum_type(type_):
         return "an Enum type"
     if is_input_object_type(type_):
         return "an Input type"
 
     # Not reachable. All possible output types have been considered.
-    raise TypeError(f"Unexpected type {inspect(type_)}")
+    msg = f"Unexpected type {inspect(type_)}"  # pragma: no cover
+    raise TypeError(msg)  # pragma: no cover
 
 
 def stringify_value(value: Any, type_: GraphQLInputType) -> str:
     ast = ast_from_value(value, type_)
     if ast is None:  # pragma: no cover
-        raise TypeError(f"Invalid value: {inspect(value)}")
+        msg = f"Invalid value: {inspect(value)}"
+        raise TypeError(msg)
     return print_ast(sort_value_node(ast))
 
 
 class ListDiff(NamedTuple):
     """Tuple with added, removed and persisted list items."""
 
     added: List
```

### Comparing `graphql_core-3.3.0a3/src/graphql/utilities/get_introspection_query.py` & `graphql_core-3.3.0a4/src/graphql/utilities/get_introspection_query.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,14 @@
+"""Get introspection query"""
+
 from textwrap import dedent
 from typing import Any, Dict, List, Optional, Union
 
 from ..language import DirectiveLocation
 
-
 try:
     from typing import Literal, TypedDict
 except ImportError:  # Python < 3.8
     from typing_extensions import Literal, TypedDict  # type: ignore
 try:
     from typing import TypeAlias
 except ImportError:  # Python < 3.10
```

### Comparing `graphql_core-3.3.0a3/src/graphql/utilities/get_operation_ast.py` & `graphql_core-3.3.0a4/src/graphql/utilities/get_operation_ast.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,12 +1,13 @@
+""""Get operation AST node"""
+
 from typing import Optional
 
 from ..language import DocumentNode, OperationDefinitionNode
 
-
 __all__ = ["get_operation_ast"]
 
 
 def get_operation_ast(
     document_ast: DocumentNode, operation_name: Optional[str] = None
 ) -> Optional[OperationDefinitionNode]:
     """Get operation AST node.
```

### Comparing `graphql_core-3.3.0a3/src/graphql/utilities/introspection_from_schema.py` & `graphql_core-3.3.0a4/src/graphql/utilities/introspection_from_schema.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,15 +1,16 @@
+"""Building introspection queries from GraphQL schemas"""
+
 from typing import cast
 
 from ..error import GraphQLError
 from ..language import parse
 from ..type import GraphQLSchema
 from .get_introspection_query import IntrospectionQuery, get_introspection_query
 
-
 __all__ = ["introspection_from_schema"]
 
 
 def introspection_from_schema(
     schema: GraphQLSchema,
     descriptions: bool = True,
     specified_by_url: bool = True,
@@ -35,13 +36,15 @@
         )
     )
 
     from ..execution.execute import ExecutionResult, execute_sync
 
     result = execute_sync(schema, document)
     if not isinstance(result, ExecutionResult):  # pragma: no cover
-        raise RuntimeError("Introspection cannot be executed")
+        msg = "Introspection cannot be executed"
+        raise RuntimeError(msg)  # noqa: TRY004
     if result.errors:  # pragma: no cover
         raise result.errors[0]
     if not result.data:  # pragma: no cover
-        raise GraphQLError("Introspection did not return a result")
+        msg = "Introspection did not return a result"
+        raise GraphQLError(msg)
     return cast(IntrospectionQuery, result.data)
```

### Comparing `graphql_core-3.3.0a3/src/graphql/utilities/lexicographic_sort_schema.py` & `graphql_core-3.3.0a4/src/graphql/utilities/lexicographic_sort_schema.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,7 +1,9 @@
+"""Sorting GraphQL schemas"""
+
 from typing import Collection, Dict, Optional, Tuple, Union, cast
 
 from ..language import DirectiveLocation
 from ..pyutils import inspect, merge_kwargs, natural_comparison_key
 from ..type import (
     GraphQLArgument,
     GraphQLDirective,
@@ -25,26 +27,25 @@
     is_list_type,
     is_non_null_type,
     is_object_type,
     is_scalar_type,
     is_union_type,
 )
 
-
 __all__ = ["lexicographic_sort_schema"]
 
 
 def lexicographic_sort_schema(schema: GraphQLSchema) -> GraphQLSchema:
     """Sort GraphQLSchema.
 
     This function returns a sorted copy of the given GraphQLSchema.
     """
 
     def replace_type(
-        type_: Union[GraphQLList, GraphQLNonNull, GraphQLNamedType]
+        type_: Union[GraphQLList, GraphQLNonNull, GraphQLNamedType],
     ) -> Union[GraphQLList, GraphQLNonNull, GraphQLNamedType]:
         if is_list_type(type_):
             return GraphQLList(replace_type(type_.of_type))
         if is_non_null_type(type_):
             return GraphQLNonNull(replace_type(type_.of_type))
         return replace_named_type(cast(GraphQLNamedType, type_))
 
@@ -85,15 +86,15 @@
                     type_=replace_type(cast(GraphQLNamedType, field.type)),
                     args=sort_args(field.args),
                 )
             )
         return fields
 
     def sort_input_fields(
-        fields_map: Dict[str, GraphQLInputField]
+        fields_map: Dict[str, GraphQLInputField],
     ) -> Dict[str, GraphQLInputField]:
         return {
             name: GraphQLInputField(
                 cast(
                     GraphQLInputType, replace_type(cast(GraphQLNamedType, field.type))
                 ),
                 description=field.description,
@@ -151,15 +152,16 @@
                 **merge_kwargs(
                     type_.to_kwargs(),
                     fields=lambda: sort_input_fields(type_.fields),
                 )
             )
 
         # Not reachable. All possible types have been considered.
-        raise TypeError(f"Unexpected type: {inspect(type_)}.")
+        msg = f"Unexpected type: {inspect(type_)}."  # pragma: no cover
+        raise TypeError(msg)  # pragma: no cover
 
     type_map: Dict[str, GraphQLNamedType] = {
         type_.name: sort_named_type(type_)
         for type_ in sorted(schema.type_map.values(), key=sort_by_name_key)
     }
 
     return GraphQLSchema(
@@ -176,10 +178,10 @@
             Optional[GraphQLObjectType], replace_maybe_type(schema.subscription_type)
         ),
         ast_node=schema.ast_node,
     )
 
 
 def sort_by_name_key(
-    type_: Union[GraphQLNamedType, GraphQLDirective, DirectiveLocation]
+    type_: Union[GraphQLNamedType, GraphQLDirective, DirectiveLocation],
 ) -> Tuple:
     return natural_comparison_key(type_.name)
```

### Comparing `graphql_core-3.3.0a3/src/graphql/utilities/print_schema.py` & `graphql_core-3.3.0a4/src/graphql/utilities/print_schema.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,7 +1,9 @@
+"""Printing GraphQL Schemas in SDL format"""
+
 from typing import Any, Callable, Dict, List, Optional, Union
 
 from ..language import StringValueNode, print_ast
 from ..language.block_string import is_printable_as_block_string
 from ..pyutils import inspect
 from ..type import (
     DEFAULT_DEPRECATION_REASON,
@@ -24,50 +26,54 @@
     is_object_type,
     is_scalar_type,
     is_specified_directive,
     is_union_type,
 )
 from .ast_from_value import ast_from_value
 
-
 __all__ = ["print_schema", "print_introspection_schema", "print_type", "print_value"]
 
 
 def print_schema(schema: GraphQLSchema) -> str:
+    """Print the given GraphQL schema in SDL format."""
     return print_filtered_schema(
         schema, lambda n: not is_specified_directive(n), is_defined_type
     )
 
 
 def print_introspection_schema(schema: GraphQLSchema) -> str:
+    """Print the built-in introspection schema in SDL format."""
     return print_filtered_schema(schema, is_specified_directive, is_introspection_type)
 
 
 def is_defined_type(type_: GraphQLNamedType) -> bool:
+    """Check if the given named GraphQL type is a defined type."""
     return type_.name not in GraphQLNamedType.reserved_types
 
 
 def print_filtered_schema(
     schema: GraphQLSchema,
     directive_filter: Callable[[GraphQLDirective], bool],
     type_filter: Callable[[GraphQLNamedType], bool],
 ) -> str:
+    """Print a GraphQL schema filtered by the specified directives and types."""
     directives = filter(directive_filter, schema.directives)
     types = filter(type_filter, schema.type_map.values())
 
     return "\n\n".join(
         (
             *filter(None, (print_schema_definition(schema),)),
             *map(print_directive, directives),
             *map(print_type, types),
         )
     )
 
 
 def print_schema_definition(schema: GraphQLSchema) -> Optional[str]:
+    """Print GraphQL schema definitions."""
     if schema.description is None and is_schema_of_common_names(schema):
         return None
 
     operation_types = []
 
     query_type = schema.query_type
     if query_type:
@@ -108,105 +114,117 @@
         return False
 
     subscription_type = schema.subscription_type
     return not subscription_type or subscription_type.name == "Subscription"
 
 
 def print_type(type_: GraphQLNamedType) -> str:
+    """Print a named GraphQL type."""
     if is_scalar_type(type_):
         return print_scalar(type_)
     if is_object_type(type_):
         return print_object(type_)
     if is_interface_type(type_):
         return print_interface(type_)
     if is_union_type(type_):
         return print_union(type_)
     if is_enum_type(type_):
         return print_enum(type_)
     if is_input_object_type(type_):
         return print_input_object(type_)
 
     # Not reachable. All possible types have been considered.
-    raise TypeError(f"Unexpected type: {inspect(type_)}.")
+    msg = f"Unexpected type: {inspect(type_)}."  # pragma: no cover
+    raise TypeError(msg)  # pragma: no cover
 
 
 def print_scalar(type_: GraphQLScalarType) -> str:
+    """Print a GraphQL scalar type."""
     return (
         print_description(type_)
         + f"scalar {type_.name}"
         + print_specified_by_url(type_)
     )
 
 
 def print_implemented_interfaces(
-    type_: Union[GraphQLObjectType, GraphQLInterfaceType]
+    type_: Union[GraphQLObjectType, GraphQLInterfaceType],
 ) -> str:
+    """Print the interfaces implemented by a GraphQL object or interface type."""
     interfaces = type_.interfaces
     return " implements " + " & ".join(i.name for i in interfaces) if interfaces else ""
 
 
 def print_object(type_: GraphQLObjectType) -> str:
+    """Print a GraphQL object type."""
     return (
         print_description(type_)
         + f"type {type_.name}"
         + print_implemented_interfaces(type_)
         + print_fields(type_)
     )
 
 
 def print_interface(type_: GraphQLInterfaceType) -> str:
+    """Print a GraphQL interface type."""
     return (
         print_description(type_)
         + f"interface {type_.name}"
         + print_implemented_interfaces(type_)
         + print_fields(type_)
     )
 
 
 def print_union(type_: GraphQLUnionType) -> str:
+    """Print a GraphQL union type."""
     types = type_.types
     possible_types = " = " + " | ".join(t.name for t in types) if types else ""
     return print_description(type_) + f"union {type_.name}" + possible_types
 
 
 def print_enum(type_: GraphQLEnumType) -> str:
+    """Print a GraphQL enum type."""
     values = [
         print_description(value, "  ", not i)
         + f"  {name}"
         + print_deprecated(value.deprecation_reason)
         for i, (name, value) in enumerate(type_.values.items())
     ]
     return print_description(type_) + f"enum {type_.name}" + print_block(values)
 
 
 def print_input_object(type_: GraphQLInputObjectType) -> str:
+    """Print a GraphQL input object type."""
     fields = [
         print_description(field, "  ", not i) + "  " + print_input_value(name, field)
         for i, (name, field) in enumerate(type_.fields.items())
     ]
     return print_description(type_) + f"input {type_.name}" + print_block(fields)
 
 
 def print_fields(type_: Union[GraphQLObjectType, GraphQLInterfaceType]) -> str:
+    """Print the fields of a GraphQL object or interface type."""
     fields = [
         print_description(field, "  ", not i)
         + f"  {name}"
         + print_args(field.args, "  ")
         + f": {field.type}"
         + print_deprecated(field.deprecation_reason)
         for i, (name, field) in enumerate(type_.fields.items())
     ]
     return print_block(fields)
 
 
 def print_block(items: List[str]) -> str:
+    """Print a block with the given items."""
     return " {\n" + "\n".join(items) + "\n}" if items else ""
 
 
 def print_args(args: Dict[str, GraphQLArgument], indentation: str = "") -> str:
+    """Print the given GraphQL arguments."""
     if not args:
         return ""
 
     # If every arg does not have a description, print them on one line.
     if not any(arg.description for arg in args.values()):
         return (
             "("
@@ -223,42 +241,46 @@
             for i, (name, arg) in enumerate(args.items())
         )
         + f"\n{indentation})"
     )
 
 
 def print_input_value(name: str, arg: GraphQLArgument) -> str:
+    """Print an input value."""
     default_ast = ast_from_value(arg.default_value, arg.type)
     arg_decl = f"{name}: {arg.type}"
     if default_ast:
         arg_decl += f" = {print_ast(default_ast)}"
     return arg_decl + print_deprecated(arg.deprecation_reason)
 
 
 def print_directive(directive: GraphQLDirective) -> str:
+    """Print a GraphQL directive."""
     return (
         print_description(directive)
         + f"directive @{directive.name}"
         + print_args(directive.args)
         + (" repeatable" if directive.is_repeatable else "")
         + " on "
         + " | ".join(location.name for location in directive.locations)
     )
 
 
 def print_deprecated(reason: Optional[str]) -> str:
+    """Print a deprecation reason."""
     if reason is None:
         return ""
     if reason != DEFAULT_DEPRECATION_REASON:
         ast_value = print_ast(StringValueNode(value=reason))
         return f" @deprecated(reason: {ast_value})"
     return " @deprecated"
 
 
 def print_specified_by_url(scalar: GraphQLScalarType) -> str:
+    """Print a specification URL."""
     if scalar.specified_by_url is None:
         return ""
     ast_value = print_ast(StringValueNode(value=scalar.specified_by_url))
     return f" @specifiedBy(url: {ast_value})"
 
 
 def print_description(
@@ -268,14 +290,15 @@
         GraphQLEnumValue,
         GraphQLNamedType,
         GraphQLSchema,
     ],
     indentation: str = "",
     first_in_block: bool = True,
 ) -> str:
+    """Print a description."""
     description = def_.description
     if description is None:
         return ""
 
     block_string = print_ast(
         StringValueNode(
             value=description, block=is_printable_as_block_string(description)
```

### Comparing `graphql_core-3.3.0a3/src/graphql/utilities/separate_operations.py` & `graphql_core-3.3.0a4/src/graphql/utilities/separate_operations.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,20 +1,21 @@
+"""Separation of GraphQL operations"""
+
 from typing import Any, Dict, List, Set
 
 from ..language import (
     DocumentNode,
     FragmentDefinitionNode,
     FragmentSpreadNode,
     OperationDefinitionNode,
     SelectionSetNode,
     Visitor,
     visit,
 )
 
-
 try:
     from typing import TypeAlias
 except ImportError:  # Python < 3.10
     from typing_extensions import TypeAlias
 
 
 __all__ = ["separate_operations"]
```

### Comparing `graphql_core-3.3.0a3/src/graphql/utilities/sort_value_node.py` & `graphql_core-3.3.0a4/src/graphql/utilities/sort_value_node.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,14 +1,15 @@
+"""Sorting value nodes"""
+
 from copy import copy
 from typing import Tuple
 
 from ..language import ListValueNode, ObjectFieldNode, ObjectValueNode, ValueNode
 from ..pyutils import natural_comparison_key
 
-
 __all__ = ["sort_value_node"]
 
 
 def sort_value_node(value_node: ValueNode) -> ValueNode:
     """Sort ValueNode.
 
     This function returns a sorted copy of the given ValueNode
```

### Comparing `graphql_core-3.3.0a3/src/graphql/utilities/strip_ignored_characters.py` & `graphql_core-3.3.0a4/src/graphql/utilities/strip_ignored_characters.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,20 +1,21 @@
+"""Removal of insignificant characters"""
+
 from typing import Union, cast
 
 from ..language import Lexer, TokenKind
 from ..language.block_string import print_block_string
 from ..language.lexer import is_punctuator_token_kind
 from ..language.source import Source, is_source
 
-
 __all__ = ["strip_ignored_characters"]
 
 
 def strip_ignored_characters(source: Union[str, Source]) -> str:
-    """Strip characters that are ignored anyway.
+    '''Strip characters that are ignored anyway.
 
     Strips characters that are not significant to the validity or execution
     of a GraphQL document:
 
         - UnicodeBOM
         - WhiteSpace
         - LineTerminator
@@ -27,15 +28,14 @@
 
     It is guaranteed that both input and output documents if parsed would result
     in the exact same AST except for nodes location.
 
     Warning: It is guaranteed that this function will always produce stable results.
     However, it's not guaranteed that it will stay the same between different
     releases due to bugfixes or changes in the GraphQL specification.
-    """ '''
 
     Query example::
 
         query SomeQuery($foo: String!, $bar: String) {
           someField(foo: $foo, bar: $bar) {
             a
             b {
```

### Comparing `graphql_core-3.3.0a3/src/graphql/utilities/type_comparators.py` & `graphql_core-3.3.0a4/src/graphql/utilities/type_comparators.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,26 +1,28 @@
+"""GraphQL type comparators"""
+
 from ..type import (
     GraphQLCompositeType,
     GraphQLSchema,
     GraphQLType,
     is_abstract_type,
     is_interface_type,
     is_list_type,
     is_non_null_type,
     is_object_type,
 )
 
-
 __all__ = ["is_equal_type", "is_type_sub_type_of", "do_types_overlap"]
 
 
 def is_equal_type(type_a: GraphQLType, type_b: GraphQLType) -> bool:
     """Check whether two types are equal.
 
-    Provided two types, return true if the types are equal (invariant)."""
+    Provided two types, return true if the types are equal (invariant).
+    """
     # Equivalent types are equal.
     if type_a is type_b:
         return True
 
     # If either type is non-null, the other must also be non-null.
     if is_non_null_type(type_a) and is_non_null_type(type_b):
         # noinspection PyUnresolvedReferences
@@ -50,26 +52,26 @@
     # If super_type is non-null, maybe_subtype must also be non-null.
     if is_non_null_type(super_type):
         if is_non_null_type(maybe_subtype):
             return is_type_sub_type_of(
                 schema, maybe_subtype.of_type, super_type.of_type
             )
         return False
-    elif is_non_null_type(maybe_subtype):
+    if is_non_null_type(maybe_subtype):
         # If super_type is nullable, maybe_subtype may be non-null or nullable.
         return is_type_sub_type_of(schema, maybe_subtype.of_type, super_type)
 
     # If super_type type is a list, maybeSubType type must also be a list.
     if is_list_type(super_type):
         if is_list_type(maybe_subtype):
             return is_type_sub_type_of(
                 schema, maybe_subtype.of_type, super_type.of_type
             )
         return False
-    elif is_list_type(maybe_subtype):
+    if is_list_type(maybe_subtype):
         # If super_type is not a list, maybe_subtype must also be not a list.
         return False
 
     # If super_type type is abstract, check if it is super type of maybe_subtype.
     # Otherwise, the child type is not a valid subtype of the parent type.
     return (
         is_abstract_type(super_type)
```

### Comparing `graphql_core-3.3.0a3/src/graphql/utilities/type_from_ast.py` & `graphql_core-3.3.0a4/src/graphql/utilities/type_from_ast.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,21 +1,22 @@
+"""Generating GraphQL types from AST nodes"""
+
 from typing import Optional, cast, overload
 
 from ..language import ListTypeNode, NamedTypeNode, NonNullTypeNode, TypeNode
 from ..pyutils import inspect
 from ..type import (
     GraphQLList,
     GraphQLNamedType,
     GraphQLNonNull,
     GraphQLNullableType,
     GraphQLSchema,
     GraphQLType,
 )
 
-
 __all__ = ["type_from_ast"]
 
 
 @overload
 def type_from_ast(
     schema: GraphQLSchema, type_node: NamedTypeNode
 ) -> Optional[GraphQLNamedType]:
@@ -61,8 +62,9 @@
         inner_type = type_from_ast(schema, type_node.type)
         inner_type = cast(GraphQLNullableType, inner_type)
         return GraphQLNonNull(inner_type) if inner_type else None
     if isinstance(type_node, NamedTypeNode):
         return schema.get_type(type_node.name.value)
 
     # Not reachable. All possible type nodes have been considered.
-    raise TypeError(f"Unexpected type node: {inspect(type_node)}.")
+    msg = f"Unexpected type node: {inspect(type_node)}."  # pragma: no cover
+    raise TypeError(msg)  # pragma: no cover
```

### Comparing `graphql_core-3.3.0a3/src/graphql/utilities/type_info.py` & `graphql_core-3.3.0a4/src/graphql/utilities/type_info.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,7 +1,9 @@
+"""Managing type information"""
+
 from __future__ import annotations  # Python < 3.10
 
 from typing import Any, Callable, List, Optional
 
 from ..language import (
     ArgumentNode,
     DirectiveNode,
@@ -35,15 +37,14 @@
     is_input_type,
     is_list_type,
     is_object_type,
     is_output_type,
 )
 from .type_from_ast import type_from_ast
 
-
 try:
     from typing import TypeAlias
 except ImportError:  # Python < 3.10
     from typing_extensions import TypeAlias
 
 
 __all__ = ["TypeInfo", "TypeInfoVisitor"]
@@ -140,15 +141,15 @@
 
     def leave(self, node: Node) -> None:
         method = getattr(self, "leave_" + node.kind, None)
         if method:
             method()
 
     # noinspection PyUnusedLocal
-    def enter_selection_set(self, node: SelectionSetNode) -> None:
+    def enter_selection_set(self, _node: SelectionSetNode) -> None:
         named_type = get_named_type(self.get_type())
         self._parent_type_stack.append(
             named_type if is_composite_type(named_type) else None
         )
 
     def enter_field(self, node: FieldNode) -> None:
         parent_type = self.get_parent_type()
@@ -192,15 +193,15 @@
         self._argument = arg_def
         self._default_value_stack.append(
             arg_def.default_value if arg_def else Undefined
         )
         self._input_type_stack.append(arg_type if is_input_type(arg_type) else None)
 
     # noinspection PyUnusedLocal
-    def enter_list_value(self, node: ListValueNode) -> None:
+    def enter_list_value(self, _node: ListValueNode) -> None:
         list_type = get_nullable_type(self.get_input_type())
         item_type = list_type.of_type if is_list_type(list_type) else list_type
         # List positions never have a default value.
         self._default_value_stack.append(Undefined)
         self._input_type_stack.append(item_type if is_input_type(item_type) else None)
 
     def enter_object_field(self, node: ObjectFieldNode) -> None:
@@ -264,28 +265,29 @@
 ) -> Optional[GraphQLField]:
     return schema.get_field(parent_type, field_node.name.value)
 
 
 class TypeInfoVisitor(Visitor):
     """A visitor which maintains a provided TypeInfo."""
 
-    def __init__(self, type_info: TypeInfo, visitor: Visitor):
+    def __init__(self, type_info: TypeInfo, visitor: Visitor) -> None:
         super().__init__()
         self.type_info = type_info
         self.visitor = visitor
 
     def enter(self, node: Node, *args: Any) -> Any:
         self.type_info.enter(node)
         fn = self.visitor.get_enter_leave_for_kind(node.kind).enter
-        if fn:
-            result = fn(node, *args)
-            if result is not None:
-                self.type_info.leave(node)
-                if isinstance(result, Node):
-                    self.type_info.enter(result)
-            return result
+        if not fn:
+            return None
+        result = fn(node, *args)
+        if result is not None:
+            self.type_info.leave(node)
+            if isinstance(result, Node):
+                self.type_info.enter(result)
+        return result
 
     def leave(self, node: Node, *args: Any) -> Any:
         fn = self.visitor.get_enter_leave_for_kind(node.kind).leave
         result = fn(node, *args) if fn else None
         self.type_info.leave(node)
         return result
```

### Comparing `graphql_core-3.3.0a3/src/graphql/utilities/value_from_ast.py` & `graphql_core-3.3.0a4/src/graphql/utilities/value_from_ast.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,7 +1,9 @@
+"""Conversion from GraphQL value AST to Python values."""
+
 from typing import Any, Dict, List, Optional, cast
 
 from ..language import (
     ListValueNode,
     NullValueNode,
     ObjectValueNode,
     ValueNode,
@@ -13,15 +15,14 @@
     GraphQLScalarType,
     is_input_object_type,
     is_leaf_type,
     is_list_type,
     is_non_null_type,
 )
 
-
 __all__ = ["value_from_ast"]
 
 
 def value_from_ast(
     value_node: Optional[ValueNode],
     type_: GraphQLInputType,
     variables: Optional[Dict[str, Any]] = None,
@@ -123,20 +124,21 @@
         type_ = cast(GraphQLScalarType, type_)
         # noinspection PyBroadException
         try:
             if variables:
                 result = type_.parse_literal(value_node, variables)
             else:
                 result = type_.parse_literal(value_node)
-        except Exception:
+        except Exception:  # noqa: BLE001
             return Undefined
         return result
 
     # Not reachable. All possible input types have been considered.
-    raise TypeError(f"Unexpected input type: {inspect(type_)}.")
+    msg = f"Unexpected input type: {inspect(type_)}."  # pragma: no cover
+    raise TypeError(msg)  # pragma: no cover
 
 
 def is_missing_variable(
     value_node: ValueNode, variables: Optional[Dict[str, Any]] = None
 ) -> bool:
     """Check if ``value_node`` is a variable not defined in the ``variables`` dict."""
     return isinstance(value_node, VariableNode) and (
```

### Comparing `graphql_core-3.3.0a3/src/graphql/utilities/value_from_ast_untyped.py` & `graphql_core-3.3.0a4/src/graphql/utilities/value_from_ast_untyped.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,7 +1,9 @@
+"""Conversion from GraphQL value AST to Python values without type."""
+
 from math import nan
 from typing import Any, Callable, Dict, Optional, Union
 
 from ..language import (
     BooleanValueNode,
     EnumValueNode,
     FloatValueNode,
@@ -11,15 +13,14 @@
     ObjectValueNode,
     StringValueNode,
     ValueNode,
     VariableNode,
 )
 from ..pyutils import Undefined, inspect
 
-
 __all__ = ["value_from_ast_untyped"]
 
 
 def value_from_ast_untyped(
     value_node: ValueNode, variables: Optional[Dict[str, Any]] = None
 ) -> Any:
     """Produce a Python value given a GraphQL Value AST.
@@ -40,17 +41,16 @@
 
     """
     func = _value_from_kind_functions.get(value_node.kind)
     if func:
         return func(value_node, variables)
 
     # Not reachable. All possible value nodes have been considered.
-    raise TypeError(  # pragma: no cover
-        f"Unexpected value node: {inspect(value_node)}."
-    )
+    msg = f"Unexpected value node: {inspect(value_node)}."  # pragma: no cover
+    raise TypeError(msg)  # pragma: no cover
 
 
 def value_from_null(_value_node: NullValueNode, _variables: Any) -> Any:
     return None
 
 
 def value_from_int(value_node: IntValueNode, _variables: Any) -> Any:
```

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/__init__.py` & `graphql_core-3.3.0a4/src/graphql/validation/__init__.py`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/rules/__init__.py` & `graphql_core-3.3.0a4/src/graphql/validation/rules/__init__.py`

 * *Files 5% similar despite different names*

```diff
@@ -12,19 +12,20 @@
 
 
 class ASTValidationRule(Visitor):
     """Visitor for validation of an AST."""
 
     context: ASTValidationContext
 
-    def __init__(self, context: ASTValidationContext):
+    def __init__(self, context: ASTValidationContext) -> None:
         super().__init__()
         self.context = context
 
     def report_error(self, error: GraphQLError) -> None:
+        """Report a GraphQL error."""
         self.context.report_error(error)
 
 
 class SDLValidationRule(ASTValidationRule):
     """Visitor for validation of an SDL AST."""
 
     context: SDLValidationContext
```

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/rules/custom/no_deprecated.py` & `graphql_core-3.3.0a4/src/graphql/validation/rules/custom/no_deprecated.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,16 @@
+"""No deprecated rule"""
+
 from typing import Any
 
 from ....error import GraphQLError
 from ....language import ArgumentNode, EnumValueNode, FieldNode, ObjectFieldNode
 from ....type import get_named_type, is_input_object_type
 from .. import ValidationRule
 
-
 __all__ = ["NoDeprecatedCustomRule"]
 
 
 class NoDeprecatedCustomRule(ValidationRule):
     """No deprecated
 
     A GraphQL document is only valid if all selected fields and all used enum values
```

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/rules/custom/no_schema_introspection.py` & `graphql_core-3.3.0a4/src/graphql/validation/rules/custom/no_schema_introspection.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,15 +1,16 @@
+"""No schema introspection rule"""
+
 from typing import Any
 
 from ....error import GraphQLError
 from ....language import FieldNode
 from ....type import get_named_type, is_introspection_type
 from .. import ValidationRule
 
-
 __all__ = ["NoSchemaIntrospectionCustomRule"]
 
 
 class NoSchemaIntrospectionCustomRule(ValidationRule):
     """Prohibit introspection queries
 
     A GraphQL document is only valid if all fields selected are not fields that
```

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/rules/defer_stream_directive_label.py` & `graphql_core-3.3.0a4/src/graphql/validation/rules/defer_stream_directive_label.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,26 +1,27 @@
+"""Defer stream directive label rule"""
+
 from typing import Any, Dict, List
 
 from ...error import GraphQLError
 from ...language import DirectiveNode, Node, StringValueNode
 from ...type import GraphQLDeferDirective, GraphQLStreamDirective
 from . import ASTValidationRule, ValidationContext
 
-
 __all__ = ["DeferStreamDirectiveLabel"]
 
 
 class DeferStreamDirectiveLabel(ASTValidationRule):
     """Defer and stream directive labels are unique
 
     A GraphQL document is only valid if defer and stream directives' label argument
     is static and unique.
     """
 
-    def __init__(self, context: ValidationContext):
+    def __init__(self, context: ValidationContext) -> None:
         super().__init__(context)
         self.known_labels: Dict[str, Node] = {}
 
     def enter_directive(
         self,
         node: DirectiveNode,
         _key: Any,
```

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/rules/defer_stream_directive_on_root_field.py` & `graphql_core-3.3.0a4/src/graphql/validation/rules/defer_stream_directive_on_root_field.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,15 +1,16 @@
+"""Defer stream directive on root field rule"""
+
 from typing import Any, List, cast
 
 from ...error import GraphQLError
 from ...language import DirectiveNode, Node
 from ...type import GraphQLDeferDirective, GraphQLStreamDirective
 from . import ASTValidationRule, ValidationContext
 
-
 __all__ = ["DeferStreamDirectiveOnRootField"]
 
 
 class DeferStreamDirectiveOnRootField(ASTValidationRule):
     """Defer and stream directives are used on valid root field
 
     A GraphQL document is only valid if defer directives are not used on root
```

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/rules/executable_definitions.py` & `graphql_core-3.3.0a4/src/graphql/validation/rules/executable_definitions.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,7 +1,9 @@
+"""Executable definitions rule"""
+
 from typing import Any, Union, cast
 
 from ...error import GraphQLError
 from ...language import (
     SKIP,
     DirectiveDefinitionNode,
     DocumentNode,
@@ -9,15 +11,14 @@
     SchemaDefinitionNode,
     SchemaExtensionNode,
     TypeDefinitionNode,
     VisitorAction,
 )
 from . import ASTValidationRule
 
-
 __all__ = ["ExecutableDefinitionsRule"]
 
 
 class ExecutableDefinitionsRule(ASTValidationRule):
     """Executable definitions
 
     A GraphQL document is only valid for execution if all definitions are either
```

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/rules/fields_on_correct_type.py` & `graphql_core-3.3.0a4/src/graphql/validation/rules/fields_on_correct_type.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,7 +1,9 @@
+"""Fields on correct type rule"""
+
 from collections import defaultdict
 from functools import cmp_to_key
 from typing import Any, Dict, List, Union
 
 from ...error import GraphQLError
 from ...language import FieldNode
 from ...pyutils import did_you_mean, natural_comparison_key, suggestion_list
@@ -12,15 +14,14 @@
     GraphQLSchema,
     is_abstract_type,
     is_interface_type,
     is_object_type,
 )
 from . import ValidationRule
 
-
 __all__ = ["FieldsOnCorrectTypeRule"]
 
 
 class FieldsOnCorrectTypeRule(ValidationRule):
     """Fields on correct type
 
     A GraphQL document is only valid if all fields selected are defined by the parent
@@ -58,16 +59,15 @@
             )
         )
 
 
 def get_suggested_type_names(
     schema: GraphQLSchema, type_: GraphQLOutputType, field_name: str
 ) -> List[str]:
-    """
-    Get a list of suggested type names.
+    """Get a list of suggested type names.
 
     Go through all of the implementations of type, as well as the interfaces
     that they implement. If any of those types include the provided field,
     suggest them, sorted by how often the type is referenced.
     """
     if not is_abstract_type(type_):
         # Must be an Object type, which does not have possible fields.
```

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/rules/fragments_on_composite_types.py` & `graphql_core-3.3.0a4/src/graphql/validation/rules/fragments_on_composite_types.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,16 +1,17 @@
+"""Fragments on composite type rule"""
+
 from typing import Any
 
 from ...error import GraphQLError
 from ...language import FragmentDefinitionNode, InlineFragmentNode, print_ast
 from ...type import is_composite_type
 from ...utilities import type_from_ast
 from . import ValidationRule
 
-
 __all__ = ["FragmentsOnCompositeTypesRule"]
 
 
 class FragmentsOnCompositeTypesRule(ValidationRule):
     """Fragments on composite type
 
     Fragments use a type condition to determine if they apply, since fragments can only
```

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/rules/known_argument_names.py` & `graphql_core-3.3.0a4/src/graphql/validation/rules/known_argument_names.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,36 +1,37 @@
+"""Known argument names on directives rule"""
+
 from typing import Any, Dict, List, Union, cast
 
 from ...error import GraphQLError
 from ...language import (
     SKIP,
     ArgumentNode,
     DirectiveDefinitionNode,
     DirectiveNode,
     VisitorAction,
 )
 from ...pyutils import did_you_mean, suggestion_list
 from ...type import specified_directives
 from . import ASTValidationRule, SDLValidationContext, ValidationContext
 
-
 __all__ = ["KnownArgumentNamesRule", "KnownArgumentNamesOnDirectivesRule"]
 
 
 class KnownArgumentNamesOnDirectivesRule(ASTValidationRule):
     """Known argument names on directives
 
     A GraphQL directive is only valid if all supplied arguments are defined.
 
     For internal use only.
     """
 
     context: Union[ValidationContext, SDLValidationContext]
 
-    def __init__(self, context: Union[ValidationContext, SDLValidationContext]):
+    def __init__(self, context: Union[ValidationContext, SDLValidationContext]) -> None:
         super().__init__(context)
         directive_args: Dict[str, List[str]] = {}
 
         schema = context.schema
         defined_directives = schema.directives if schema else specified_directives
         for directive in cast(List, defined_directives):
             directive_args[directive.name] = list(directive.args)
@@ -72,15 +73,15 @@
 
     See https://spec.graphql.org/draft/#sec-Argument-Names
     See https://spec.graphql.org/draft/#sec-Directives-Are-In-Valid-Locations
     """
 
     context: ValidationContext
 
-    def __init__(self, context: ValidationContext):
+    def __init__(self, context: ValidationContext) -> None:
         super().__init__(context)
 
     def enter_argument(self, arg_node: ArgumentNode, *args: Any) -> None:
         context = self.context
         arg_def = context.get_argument()
         field_def = context.get_field_def()
         parent_type = context.get_parent_type()
```

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/rules/known_directives.py` & `graphql_core-3.3.0a4/src/graphql/validation/rules/known_directives.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,36 +1,37 @@
+"""Known directives rule"""
+
 from typing import Any, Dict, List, Optional, Tuple, Union, cast
 
 from ...error import GraphQLError
 from ...language import (
     DirectiveDefinitionNode,
     DirectiveLocation,
     DirectiveNode,
     Node,
     OperationDefinitionNode,
 )
 from ...type import specified_directives
 from . import ASTValidationRule, SDLValidationContext, ValidationContext
 
-
 __all__ = ["KnownDirectivesRule"]
 
 
 class KnownDirectivesRule(ASTValidationRule):
     """Known directives
 
     A GraphQL document is only valid if all ``@directives`` are known by the schema and
     legally positioned.
 
     See https://spec.graphql.org/draft/#sec-Directives-Are-Defined
     """
 
     context: Union[ValidationContext, SDLValidationContext]
 
-    def __init__(self, context: Union[ValidationContext, SDLValidationContext]):
+    def __init__(self, context: Union[ValidationContext, SDLValidationContext]) -> None:
         super().__init__(context)
         locations_map: Dict[str, Tuple[DirectiveLocation, ...]] = {}
 
         schema = context.schema
         defined_directives = (
             schema.directives if schema else cast(List, specified_directives)
         )
@@ -100,21 +101,21 @@
 
 
 def get_directive_location_for_ast_path(
     ancestors: List[Node],
 ) -> Optional[DirectiveLocation]:
     applied_to = ancestors[-1]
     if not isinstance(applied_to, Node):  # pragma: no cover
-        raise TypeError("Unexpected error in directive.")
+        msg = "Unexpected error in directive."
+        raise TypeError(msg)
     kind = applied_to.kind
     if kind == "operation_definition":
         applied_to = cast(OperationDefinitionNode, applied_to)
         return _operation_location[applied_to.operation.value]
-    elif kind == "input_value_definition":
+    if kind == "input_value_definition":
         parent_node = ancestors[-3]
         return (
             DirectiveLocation.INPUT_FIELD_DEFINITION
             if parent_node.kind == "input_object_type_definition"
             else DirectiveLocation.ARGUMENT_DEFINITION
         )
-    else:
-        return _directive_location.get(kind)
+    return _directive_location.get(kind)
```

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/rules/known_type_names.py` & `graphql_core-3.3.0a4/src/graphql/validation/rules/known_type_names.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,7 +1,9 @@
+"""Known type names rule"""
+
 from typing import Any, Collection, List, Union, cast
 
 from ...error import GraphQLError
 from ...language import (
     NamedTypeNode,
     Node,
     TypeSystemDefinitionNode,
@@ -10,15 +12,14 @@
     is_type_system_definition_node,
     is_type_system_extension_node,
 )
 from ...pyutils import did_you_mean, suggestion_list
 from ...type import introspection_types, specified_scalar_types
 from . import ASTValidationRule, SDLValidationContext, ValidationContext
 
-
 try:
     from typing import TypeGuard
 except ImportError:  # Python < 3.10
     from typing_extensions import TypeGuard
 
 
 __all__ = ["KnownTypeNamesRule"]
@@ -29,15 +30,15 @@
 
     A GraphQL document is only valid if referenced types (specifically variable
     definitions and fragment conditions) are defined by the type schema.
 
     See https://spec.graphql.org/draft/#sec-Fragment-Spread-Type-Existence
     """
 
-    def __init__(self, context: Union[ValidationContext, SDLValidationContext]):
+    def __init__(self, context: Union[ValidationContext, SDLValidationContext]) -> None:
         super().__init__(context)
         schema = context.schema
         self.existing_types_map = schema.type_map if schema else {}
 
         defined_types = []
         for def_ in context.document.definitions:
             if is_type_definition_node(def_):
@@ -81,15 +82,15 @@
             )
 
 
 standard_type_names = set(specified_scalar_types).union(introspection_types)
 
 
 def is_sdl_node(
-    value: Union[Node, Collection[Node], None]
+    value: Union[Node, Collection[Node], None],
 ) -> TypeGuard[Union[TypeSystemDefinitionNode, TypeSystemExtensionNode]]:
     return (
         value is not None
         and not isinstance(value, list)
         and (
             is_type_system_definition_node(cast(Node, value))
             or is_type_system_extension_node(cast(Node, value))
```

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/rules/lone_anonymous_operation.py` & `graphql_core-3.3.0a4/src/graphql/validation/rules/lone_anonymous_operation.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,27 +1,28 @@
+"""Lone anonymous operation rule"""
+
 from typing import Any
 
 from ...error import GraphQLError
 from ...language import DocumentNode, OperationDefinitionNode
 from . import ASTValidationContext, ASTValidationRule
 
-
 __all__ = ["LoneAnonymousOperationRule"]
 
 
 class LoneAnonymousOperationRule(ASTValidationRule):
     """Lone anonymous operation
 
     A GraphQL document is only valid if when it contains an anonymous operation
     (the query short-hand) that it contains only that one operation definition.
 
     See https://spec.graphql.org/draft/#sec-Lone-Anonymous-Operation
     """
 
-    def __init__(self, context: ASTValidationContext):
+    def __init__(self, context: ASTValidationContext) -> None:
         super().__init__(context)
         self.operation_count = 0
 
     def enter_document(self, node: DocumentNode, *_args: Any) -> None:
         self.operation_count = sum(
             isinstance(definition, OperationDefinitionNode)
             for definition in node.definitions
```

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/rules/lone_schema_definition.py` & `graphql_core-3.3.0a4/src/graphql/validation/rules/lone_schema_definition.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,24 +1,25 @@
+"""Lone Schema definition rule"""
+
 from typing import Any
 
 from ...error import GraphQLError
 from ...language import SchemaDefinitionNode
 from . import SDLValidationContext, SDLValidationRule
 
-
 __all__ = ["LoneSchemaDefinitionRule"]
 
 
 class LoneSchemaDefinitionRule(SDLValidationRule):
     """Lone Schema definition
 
     A GraphQL document is only valid if it contains only one schema definition.
     """
 
-    def __init__(self, context: SDLValidationContext):
+    def __init__(self, context: SDLValidationContext) -> None:
         super().__init__(context)
         old_schema = context.schema
         self.already_defined = old_schema and (
             old_schema.ast_node
             or old_schema.query_type
             or old_schema.mutation_type
             or old_schema.subscription_type
```

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/rules/no_fragment_cycles.py` & `graphql_core-3.3.0a4/src/graphql/validation/rules/no_fragment_cycles.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,28 +1,29 @@
+"""No fragment cycles rule"""
+
 from typing import Any, Dict, List, Set
 
 from ...error import GraphQLError
 from ...language import SKIP, FragmentDefinitionNode, FragmentSpreadNode, VisitorAction
 from . import ASTValidationContext, ASTValidationRule
 
-
 __all__ = ["NoFragmentCyclesRule"]
 
 
 class NoFragmentCyclesRule(ASTValidationRule):
     """No fragment cycles
 
     The graph of fragment spreads must not form any cycles including spreading itself.
     Otherwise an operation could infinitely spread or infinitely execute on cycles in
     the underlying data.
 
     See https://spec.graphql.org/draft/#sec-Fragment-spreads-must-not-form-cycles
     """
 
-    def __init__(self, context: ASTValidationContext):
+    def __init__(self, context: ASTValidationContext) -> None:
         super().__init__(context)
         # Tracks already visited fragments to maintain O(N) and to ensure that
         # cycles are not redundantly reported.
         self.visited_frags: Set[str] = set()
         # List of AST nodes used to produce meaningful errors
         self.spread_path: List[FragmentSpreadNode] = []
         # Position in the spread path
```

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/rules/no_undefined_variables.py` & `graphql_core-3.3.0a4/src/graphql/validation/rules/no_undefined_variables.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,27 +1,28 @@
+"""No undefined variables rule"""
+
 from typing import Any, Set
 
 from ...error import GraphQLError
 from ...language import OperationDefinitionNode, VariableDefinitionNode
 from . import ValidationContext, ValidationRule
 
-
 __all__ = ["NoUndefinedVariablesRule"]
 
 
 class NoUndefinedVariablesRule(ValidationRule):
     """No undefined variables
 
     A GraphQL operation is only valid if all variables encountered, both directly and
     via fragment spreads, are defined by that operation.
 
     See https://spec.graphql.org/draft/#sec-All-Variable-Uses-Defined
     """
 
-    def __init__(self, context: ValidationContext):
+    def __init__(self, context: ValidationContext) -> None:
         super().__init__(context)
         self.defined_variable_names: Set[str] = set()
 
     def enter_operation_definition(self, *_args: Any) -> None:
         self.defined_variable_names.clear()
 
     def leave_operation_definition(
```

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/rules/no_unused_fragments.py` & `graphql_core-3.3.0a4/src/graphql/validation/rules/no_unused_fragments.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,32 +1,33 @@
+"""No unused fragments rule"""
+
 from typing import Any, List
 
 from ...error import GraphQLError
 from ...language import (
     SKIP,
     FragmentDefinitionNode,
     OperationDefinitionNode,
     VisitorAction,
 )
 from . import ASTValidationContext, ASTValidationRule
 
-
 __all__ = ["NoUnusedFragmentsRule"]
 
 
 class NoUnusedFragmentsRule(ASTValidationRule):
     """No unused fragments
 
     A GraphQL document is only valid if all fragment definitions are spread within
     operations, or spread within other fragments spread within operations.
 
     See https://spec.graphql.org/draft/#sec-Fragments-Must-Be-Used
     """
 
-    def __init__(self, context: ASTValidationContext):
+    def __init__(self, context: ASTValidationContext) -> None:
         super().__init__(context)
         self.operation_defs: List[OperationDefinitionNode] = []
         self.fragment_defs: List[FragmentDefinitionNode] = []
 
     def enter_operation_definition(
         self, node: OperationDefinitionNode, *_args: Any
     ) -> VisitorAction:
```

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/rules/no_unused_variables.py` & `graphql_core-3.3.0a4/src/graphql/validation/rules/no_unused_variables.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,27 +1,28 @@
+"""No unused variables rule"""
+
 from typing import Any, List, Set
 
 from ...error import GraphQLError
 from ...language import OperationDefinitionNode, VariableDefinitionNode
 from . import ValidationContext, ValidationRule
 
-
 __all__ = ["NoUnusedVariablesRule"]
 
 
 class NoUnusedVariablesRule(ValidationRule):
     """No unused variables
 
     A GraphQL operation is only valid if all variables defined by an operation are used,
     either directly or within a spread fragment.
 
     See https://spec.graphql.org/draft/#sec-All-Variables-Used
     """
 
-    def __init__(self, context: ValidationContext):
+    def __init__(self, context: ValidationContext) -> None:
         super().__init__(context)
         self.variable_defs: List[VariableDefinitionNode] = []
 
     def enter_operation_definition(self, *_args: Any) -> None:
         self.variable_defs.clear()
 
     def leave_operation_definition(
```

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/rules/overlapping_fields_can_be_merged.py` & `graphql_core-3.3.0a4/src/graphql/validation/rules/overlapping_fields_can_be_merged.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,20 +1,21 @@
+"""Overlapping fields can be merged rule"""
+
 from itertools import chain
 from typing import Any, Dict, List, Optional, Sequence, Tuple, Union, cast
 
 from ...error import GraphQLError
 from ...language import (
     DirectiveNode,
     FieldNode,
     FragmentDefinitionNode,
     FragmentSpreadNode,
     InlineFragmentNode,
-    ObjectFieldNode,
-    ObjectValueNode,
     SelectionSetNode,
+    ValueNode,
     print_ast,
 )
 from ...type import (
     GraphQLCompositeType,
     GraphQLField,
     GraphQLNamedType,
     GraphQLOutputType,
@@ -25,15 +26,14 @@
     is_non_null_type,
     is_object_type,
 )
 from ...utilities import type_from_ast
 from ...utilities.sort_value_node import sort_value_node
 from . import ValidationContext, ValidationRule
 
-
 try:
     from typing import TypeAlias
 except ImportError:  # Python < 3.10
     from typing_extensions import TypeAlias
 
 
 MYPY = False
@@ -56,15 +56,15 @@
 
     A selection set is only valid if all fields (including spreading any fragments)
     either correspond to distinct response names or can be merged without ambiguity.
 
     See https://spec.graphql.org/draft/#sec-Field-Selection-Merging
     """
 
-    def __init__(self, context: ValidationContext):
+    def __init__(self, context: ValidationContext) -> None:
         super().__init__(context)
         # A memoization for when two fragments are compared "between" each other for
         # conflicts. Two fragments may be compared many times, so memoizing this can
         # dramatically improve the performance of this validator.
         self.compared_fragment_pairs = PairSet()
 
         # A cache for the "field map" and list of fragment names found in any given
@@ -232,15 +232,15 @@
     """Collect conflicts between fields and fragment.
 
     Collect all conflicts found between a set of fields and a fragment reference
     including via spreading in any nested fragments.
     """
     fragment = context.get_fragment(fragment_name)
     if not fragment:
-        return None
+        return
 
     field_map2, referenced_fragment_names = get_referenced_fields_and_fragment_names(
         context, cached_fields_and_fragment_names, fragment
     )
 
     # Do not compare a fragment's fieldMap to itself.
     if field_map is field_map2:
@@ -305,15 +305,15 @@
     ):
         return
     compared_fragment_pairs.add(fragment_name1, fragment_name2, are_mutually_exclusive)
 
     fragment1 = context.get_fragment(fragment_name1)
     fragment2 = context.get_fragment(fragment_name2)
     if not fragment1 or not fragment2:
-        return None
+        return
 
     field_map1, referenced_fragment_names1 = get_referenced_fields_and_fragment_names(
         context, cached_fields_and_fragment_names, fragment1
     )
 
     field_map2, referenced_fragment_names2 = get_referenced_fields_and_fragment_names(
         context, cached_fields_and_fragment_names, fragment2
@@ -553,15 +553,15 @@
             return (
                 (response_name, f"'{name1}' and '{name2}' are different fields"),
                 [node1],
                 [node2],
             )
 
         # Two field calls must have the same arguments.
-        if stringify_arguments(node1) != stringify_arguments(node2):
+        if not same_arguments(node1, node2):
             return (response_name, "they have differing arguments"), [node1], [node2]
 
     directives1 = node1.directives
     directives2 = node2.directives
     if not same_streams(directives1, directives2):
         return (
             (response_name, "they have differing stream directives"),
@@ -593,22 +593,42 @@
             selection_set2,
         )
         return subfield_conflicts(conflicts, response_name, node1, node2)
 
     return None  # no conflict
 
 
-def stringify_arguments(field_node: Union[FieldNode, DirectiveNode]) -> str:
-    input_object_with_args = ObjectValueNode(
-        fields=tuple(
-            ObjectFieldNode(name=arg_node.name, value=arg_node.value)
-            for arg_node in field_node.arguments
-        )
-    )
-    return print_ast(sort_value_node(input_object_with_args))
+def same_arguments(
+    node1: Union[FieldNode, DirectiveNode], node2: Union[FieldNode, DirectiveNode]
+) -> bool:
+    args1 = node1.arguments
+    args2 = node2.arguments
+
+    if not args1:
+        return not args2
+
+    if not args2:
+        return False
+
+    if len(args1) != len(args2):
+        return False
+
+    values2 = {arg.name.value: arg.value for arg in args2}
+
+    for arg1 in args1:
+        value1 = arg1.value
+        value2 = values2.get(arg1.name.value)
+        if value2 is None or stringify_value(value1) != stringify_value(value2):
+            return False
+
+    return True
+
+
+def stringify_value(value: ValueNode) -> str:
+    return print_ast(sort_value_node(value))
 
 
 def get_stream_directive(
     directives: Sequence[DirectiveNode],
 ) -> Optional[DirectiveNode]:
     for directive in directives:
         if directive.name.value == "stream":
@@ -622,15 +642,15 @@
     stream1 = get_stream_directive(directives1)
     stream2 = get_stream_directive(directives2)
     if not stream1 and not stream2:
         # both fields do not have streams
         return True
     if stream1 and stream2:
         # check if both fields have equivalent streams
-        return stringify_arguments(stream1) == stringify_arguments(stream2)
+        return same_arguments(stream1, stream2)
     # fields have a mix of stream and no stream
     return False
 
 
 def do_types_conflict(type1: GraphQLOutputType, type2: GraphQLOutputType) -> bool:
     """Check whether two types conflict
```

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/rules/possible_fragment_spreads.py` & `graphql_core-3.3.0a4/src/graphql/validation/rules/possible_fragment_spreads.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,17 @@
+"""Possible fragment spread rule"""
+
 from typing import Any, Optional
 
 from ...error import GraphQLError
 from ...language import FragmentSpreadNode, InlineFragmentNode
 from ...type import GraphQLCompositeType, is_composite_type
 from ...utilities import do_types_overlap, type_from_ast
 from . import ValidationRule
 
-
 __all__ = ["PossibleFragmentSpreadsRule"]
 
 
 class PossibleFragmentSpreadsRule(ValidationRule):
     """Possible fragment spread
 
     A fragment spread is only valid if the type condition could ever possibly be true:
```

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/rules/possible_type_extensions.py` & `graphql_core-3.3.0a4/src/graphql/validation/rules/possible_type_extensions.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,7 +1,9 @@
+"""Possible type extension rule"""
+
 import re
 from functools import partial
 from typing import Any, Optional
 
 from ...error import GraphQLError
 from ...language import TypeDefinitionNode, TypeExtensionNode
 from ...pyutils import did_you_mean, inspect, suggestion_list
@@ -11,25 +13,24 @@
     is_interface_type,
     is_object_type,
     is_scalar_type,
     is_union_type,
 )
 from . import SDLValidationContext, SDLValidationRule
 
-
 __all__ = ["PossibleTypeExtensionsRule"]
 
 
 class PossibleTypeExtensionsRule(SDLValidationRule):
     """Possible type extension
 
     A type extension is only valid if the type is defined and has the same kind.
     """
 
-    def __init__(self, context: SDLValidationContext):
+    def __init__(self, context: SDLValidationContext) -> None:
         super().__init__(context)
         self.schema = context.schema
         self.defined_types = {
             def_.name.value: def_
             for def_ in context.document.definitions
             if isinstance(def_, TypeDefinitionNode)
         }
@@ -89,15 +90,16 @@
         return "union_type_extension"
     if is_enum_type(type_):
         return "enum_type_extension"
     if is_input_object_type(type_):
         return "input_object_type_extension"
 
     # Not reachable. All possible types have been considered.
-    raise TypeError(f"Unexpected type: {inspect(type_)}.")
+    msg = f"Unexpected type: {inspect(type_)}."  # pragma: no cover
+    raise TypeError(msg)  # pragma: no cover
 
 
 _type_names_for_extension_kinds = {
     "scalar_type_extension": "scalar",
     "object_type_extension": "object",
     "interface_type_extension": "interface",
     "union_type_extension": "union",
```

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/rules/provided_required_arguments.py` & `graphql_core-3.3.0a4/src/graphql/validation/rules/provided_required_arguments.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,7 +1,9 @@
+"""Provided required arguments on directives rule"""
+
 from typing import Any, Dict, List, Union, cast
 
 from ...error import GraphQLError
 from ...language import (
     SKIP,
     DirectiveDefinitionNode,
     DirectiveNode,
@@ -11,30 +13,29 @@
     TypeNode,
     VisitorAction,
     print_ast,
 )
 from ...type import GraphQLArgument, is_required_argument, is_type, specified_directives
 from . import ASTValidationRule, SDLValidationContext, ValidationContext
 
-
 __all__ = ["ProvidedRequiredArgumentsRule", "ProvidedRequiredArgumentsOnDirectivesRule"]
 
 
 class ProvidedRequiredArgumentsOnDirectivesRule(ASTValidationRule):
     """Provided required arguments on directives
 
     A directive is only valid if all required (non-null without a default value)
     arguments have been provided.
 
     For internal use only.
     """
 
     context: Union[ValidationContext, SDLValidationContext]
 
-    def __init__(self, context: Union[ValidationContext, SDLValidationContext]):
+    def __init__(self, context: Union[ValidationContext, SDLValidationContext]) -> None:
         super().__init__(context)
         required_args_map: Dict[
             str, Dict[str, Union[GraphQLArgument, InputValueDefinitionNode]]
         ] = {}
 
         schema = context.schema
         defined_directives = schema.directives if schema else specified_directives
@@ -85,15 +86,15 @@
 
     A field or directive is only valid if all required (non-null without a default
     value) field arguments have been provided.
     """
 
     context: ValidationContext
 
-    def __init__(self, context: ValidationContext):
+    def __init__(self, context: ValidationContext) -> None:
         super().__init__(context)
 
     def leave_field(self, field_node: FieldNode, *_args: Any) -> VisitorAction:
         # Validate on leave to allow for deeper errors to appear first.
         field_def = self.context.get_field_def()
         if not field_def:
             return SKIP
```

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/rules/scalar_leafs.py` & `graphql_core-3.3.0a4/src/graphql/validation/rules/scalar_leafs.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,15 +1,16 @@
+"""Scalar leafs rule"""
+
 from typing import Any
 
 from ...error import GraphQLError
 from ...language import FieldNode
 from ...type import get_named_type, is_leaf_type
 from . import ValidationRule
 
-
 __all__ = ["ScalarLeafsRule"]
 
 
 class ScalarLeafsRule(ValidationRule):
     """Scalar leafs
 
     A GraphQL document is valid only if all leaf fields (fields without sub selections)
```

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/rules/single_field_subscriptions.py` & `graphql_core-3.3.0a4/src/graphql/validation/rules/single_field_subscriptions.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,20 +1,21 @@
+"""Single field subscriptions rule"""
+
 from typing import Any, Dict, cast
 
 from ...error import GraphQLError
 from ...execution.collect_fields import collect_fields
 from ...language import (
     FieldNode,
     FragmentDefinitionNode,
     OperationDefinitionNode,
     OperationType,
 )
 from . import ValidationRule
 
-
 __all__ = ["SingleFieldSubscriptionsRule"]
 
 
 class SingleFieldSubscriptionsRule(ValidationRule):
     """Subscriptions must only include a single non-introspection field.
 
     A GraphQL subscription is valid only if it contains a single root field and
```

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/rules/stream_directive_on_list_field.py` & `graphql_core-3.3.0a4/src/graphql/validation/rules/stream_directive_on_list_field.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,20 +1,21 @@
+"""Stream directive on list field rule"""
+
 from typing import Any, List, cast
 
 from ...error import GraphQLError
 from ...language import DirectiveNode, Node
 from ...type import GraphQLStreamDirective, is_list_type, is_wrapping_type
 from . import ASTValidationRule, ValidationContext
 
-
 __all__ = ["StreamDirectiveOnListField"]
 
 
 class StreamDirectiveOnListField(ASTValidationRule):
-    """Stream directive on list field
+    """Stream directives are used on list fields
 
     A GraphQL document is only valid if stream directives are used on list fields.
     """
 
     def enter_directive(
         self,
         node: DirectiveNode,
```

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/rules/unique_argument_definition_names.py` & `graphql_core-3.3.0a4/src/graphql/validation/rules/unique_argument_definition_names.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,7 +1,9 @@
+"""Unique argument definition names rule"""
+
 from operator import attrgetter
 from typing import Any, Collection
 
 from ...error import GraphQLError
 from ...language import (
     SKIP,
     DirectiveDefinitionNode,
@@ -13,15 +15,14 @@
     ObjectTypeDefinitionNode,
     ObjectTypeExtensionNode,
     VisitorAction,
 )
 from ...pyutils import group_by
 from . import SDLValidationRule
 
-
 __all__ = ["UniqueArgumentDefinitionNamesRule"]
 
 
 class UniqueArgumentDefinitionNamesRule(SDLValidationRule):
     """Unique argument definition names
 
     A GraphQL Object or Interface type is only valid if all its fields have uniquely
```

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/rules/unique_argument_names.py` & `graphql_core-3.3.0a4/src/graphql/validation/rules/unique_argument_names.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,16 +1,17 @@
+"""Unique argument names rule"""
+
 from operator import attrgetter
 from typing import Any, Collection
 
 from ...error import GraphQLError
 from ...language import ArgumentNode, DirectiveNode, FieldNode
 from ...pyutils import group_by
 from . import ASTValidationRule
 
-
 __all__ = ["UniqueArgumentNamesRule"]
 
 
 class UniqueArgumentNamesRule(ASTValidationRule):
     """Unique argument names
 
     A GraphQL field or directive is only valid if all supplied arguments are uniquely
@@ -18,15 +19,15 @@
 
     See https://spec.graphql.org/draft/#sec-Argument-Names
     """
 
     def enter_field(self, node: FieldNode, *_args: Any) -> None:
         self.check_arg_uniqueness(node.arguments)
 
-    def enter_directive(self, node: DirectiveNode, *args: Any) -> None:
+    def enter_directive(self, node: DirectiveNode, *_args: Any) -> None:
         self.check_arg_uniqueness(node.arguments)
 
     def check_arg_uniqueness(self, argument_nodes: Collection[ArgumentNode]) -> None:
         seen_args = group_by(argument_nodes, attrgetter("name.value"))
 
         for arg_name, arg_nodes in seen_args.items():
             if len(arg_nodes) > 1:
```

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/rules/unique_directive_names.py` & `graphql_core-3.3.0a4/src/graphql/validation/rules/unique_directive_names.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,24 +1,25 @@
+"""Unique directive names rule"""
+
 from typing import Any, Dict
 
 from ...error import GraphQLError
 from ...language import SKIP, DirectiveDefinitionNode, NameNode, VisitorAction
 from . import SDLValidationContext, SDLValidationRule
 
-
 __all__ = ["UniqueDirectiveNamesRule"]
 
 
 class UniqueDirectiveNamesRule(SDLValidationRule):
     """Unique directive names
 
     A GraphQL document is only valid if all defined directives have unique names.
     """
 
-    def __init__(self, context: SDLValidationContext):
+    def __init__(self, context: SDLValidationContext) -> None:
         super().__init__(context)
         self.known_directive_names: Dict[str, NameNode] = {}
         self.schema = context.schema
 
     def enter_directive_definition(
         self, node: DirectiveDefinitionNode, *_args: Any
     ) -> VisitorAction:
```

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/rules/unique_directives_per_location.py` & `graphql_core-3.3.0a4/src/graphql/validation/rules/unique_directives_per_location.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,7 +1,9 @@
+"""Unique directive names per location rule"""
+
 from collections import defaultdict
 from typing import Any, Dict, List, Union, cast
 
 from ...error import GraphQLError
 from ...language import (
     DirectiveDefinitionNode,
     DirectiveNode,
@@ -10,30 +12,29 @@
     SchemaExtensionNode,
     is_type_definition_node,
     is_type_extension_node,
 )
 from ...type import specified_directives
 from . import ASTValidationRule, SDLValidationContext, ValidationContext
 
-
 __all__ = ["UniqueDirectivesPerLocationRule"]
 
 
 class UniqueDirectivesPerLocationRule(ASTValidationRule):
     """Unique directive names per location
 
     A GraphQL document is only valid if all non-repeatable directives at a given
     location are uniquely named.
 
     See https://spec.graphql.org/draft/#sec-Directives-Are-Unique-Per-Location
     """
 
     context: Union[ValidationContext, SDLValidationContext]
 
-    def __init__(self, context: Union[ValidationContext, SDLValidationContext]):
+    def __init__(self, context: Union[ValidationContext, SDLValidationContext]) -> None:
         super().__init__(context)
         unique_directive_map: Dict[str, bool] = {}
 
         schema = context.schema
         defined_directives = (
             schema.directives if schema else cast(List, specified_directives)
         )
```

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/rules/unique_enum_value_names.py` & `graphql_core-3.3.0a4/src/graphql/validation/rules/unique_enum_value_names.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,26 +1,27 @@
+"""Unique enum value names rule"""
+
 from collections import defaultdict
 from typing import Any, Dict
 
 from ...error import GraphQLError
 from ...language import SKIP, EnumTypeDefinitionNode, NameNode, VisitorAction
 from ...type import is_enum_type
 from . import SDLValidationContext, SDLValidationRule
 
-
 __all__ = ["UniqueEnumValueNamesRule"]
 
 
 class UniqueEnumValueNamesRule(SDLValidationRule):
     """Unique enum value names
 
     A GraphQL enum type is only valid if all its values are uniquely named.
     """
 
-    def __init__(self, context: SDLValidationContext):
+    def __init__(self, context: SDLValidationContext) -> None:
         super().__init__(context)
         schema = context.schema
         self.existing_type_map = schema.type_map if schema else {}
         self.known_value_names: Dict[str, Dict[str, NameNode]] = defaultdict(dict)
 
     def check_value_uniqueness(
         self, node: EnumTypeDefinitionNode, *_args: Any
```

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/rules/unique_field_definition_names.py` & `graphql_core-3.3.0a4/src/graphql/validation/rules/unique_field_definition_names.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,26 +1,27 @@
+"""Unique field definition names rule"""
+
 from collections import defaultdict
 from typing import Any, Dict
 
 from ...error import GraphQLError
 from ...language import SKIP, NameNode, ObjectTypeDefinitionNode, VisitorAction
 from ...type import is_input_object_type, is_interface_type, is_object_type
 from . import SDLValidationContext, SDLValidationRule
 
-
 __all__ = ["UniqueFieldDefinitionNamesRule"]
 
 
 class UniqueFieldDefinitionNamesRule(SDLValidationRule):
     """Unique field definition names
 
     A GraphQL complex type is only valid if all its fields are uniquely named.
     """
 
-    def __init__(self, context: SDLValidationContext):
+    def __init__(self, context: SDLValidationContext) -> None:
         super().__init__(context)
         schema = context.schema
         self.existing_type_map = schema.type_map if schema else {}
         self.known_field_names: Dict[str, Dict[str, NameNode]] = defaultdict(dict)
 
     def check_field_uniqueness(
         self, node: ObjectTypeDefinitionNode, *_args: Any
```

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/rules/unique_fragment_names.py` & `graphql_core-3.3.0a4/src/graphql/validation/rules/unique_fragment_names.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,26 +1,27 @@
+"""Unique fragment names rule"""
+
 from typing import Any, Dict
 
 from ...error import GraphQLError
 from ...language import SKIP, FragmentDefinitionNode, NameNode, VisitorAction
 from . import ASTValidationContext, ASTValidationRule
 
-
 __all__ = ["UniqueFragmentNamesRule"]
 
 
 class UniqueFragmentNamesRule(ASTValidationRule):
     """Unique fragment names
 
     A GraphQL document is only valid if all defined fragments have unique names.
 
     See https://spec.graphql.org/draft/#sec-Fragment-Name-Uniqueness
     """
 
-    def __init__(self, context: ASTValidationContext):
+    def __init__(self, context: ASTValidationContext) -> None:
         super().__init__(context)
         self.known_fragment_names: Dict[str, NameNode] = {}
 
     @staticmethod
     def enter_operation_definition(*_args: Any) -> VisitorAction:
         return SKIP
```

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/rules/unique_input_field_names.py` & `graphql_core-3.3.0a4/src/graphql/validation/rules/unique_input_field_names.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,27 +1,28 @@
+"""Unique input field names rule"""
+
 from typing import Any, Dict, List
 
 from ...error import GraphQLError
 from ...language import NameNode, ObjectFieldNode
 from . import ASTValidationContext, ASTValidationRule
 
-
 __all__ = ["UniqueInputFieldNamesRule"]
 
 
 class UniqueInputFieldNamesRule(ASTValidationRule):
     """Unique input field names
 
     A GraphQL input object value is only valid if all supplied fields are uniquely
     named.
 
     See https://spec.graphql.org/draft/#sec-Input-Object-Field-Uniqueness
     """
 
-    def __init__(self, context: ASTValidationContext):
+    def __init__(self, context: ASTValidationContext) -> None:
         super().__init__(context)
         self.known_names_stack: List[Dict[str, NameNode]] = []
         self.known_names: Dict[str, NameNode] = {}
 
     def enter_object_value(self, *_args: Any) -> None:
         self.known_names_stack.append(self.known_names)
         self.known_names = {}
```

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/rules/unique_operation_names.py` & `graphql_core-3.3.0a4/src/graphql/validation/rules/unique_operation_names.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,26 +1,27 @@
+"""Unique operation names rule"""
+
 from typing import Any, Dict
 
 from ...error import GraphQLError
 from ...language import SKIP, NameNode, OperationDefinitionNode, VisitorAction
 from . import ASTValidationContext, ASTValidationRule
 
-
 __all__ = ["UniqueOperationNamesRule"]
 
 
 class UniqueOperationNamesRule(ASTValidationRule):
     """Unique operation names
 
     A GraphQL document is only valid if all defined operations have unique names.
 
     See https://spec.graphql.org/draft/#sec-Operation-Name-Uniqueness
     """
 
-    def __init__(self, context: ASTValidationContext):
+    def __init__(self, context: ASTValidationContext) -> None:
         super().__init__(context)
         self.known_operation_names: Dict[str, NameNode] = {}
 
     def enter_operation_definition(
         self, node: OperationDefinitionNode, *_args: Any
     ) -> VisitorAction:
         operation_name = node.name
```

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/rules/unique_operation_types.py` & `graphql_core-3.3.0a4/src/graphql/validation/rules/unique_operation_types.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,32 +1,35 @@
-from typing import Any, Dict, Optional, Union
+"""Unique operation types rule"""
+
+from typing import TYPE_CHECKING, Any, Dict, Optional, Union
 
 from ...error import GraphQLError
 from ...language import (
     SKIP,
     OperationType,
     OperationTypeDefinitionNode,
     SchemaDefinitionNode,
     SchemaExtensionNode,
     VisitorAction,
 )
-from ...type import GraphQLObjectType
-from . import SDLValidationContext, SDLValidationRule
 
+if TYPE_CHECKING:
+    from ...type import GraphQLObjectType
+from . import SDLValidationContext, SDLValidationRule
 
 __all__ = ["UniqueOperationTypesRule"]
 
 
 class UniqueOperationTypesRule(SDLValidationRule):
     """Unique operation types
 
     A GraphQL document is only valid if it has only one type per operation.
     """
 
-    def __init__(self, context: SDLValidationContext):
+    def __init__(self, context: SDLValidationContext) -> None:
         super().__init__(context)
         schema = context.schema
         self.defined_operation_types: Dict[
             OperationType, OperationTypeDefinitionNode
         ] = {}
         self.existing_operation_types: Dict[
             OperationType, Optional[GraphQLObjectType]
```

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/rules/unique_type_names.py` & `graphql_core-3.3.0a4/src/graphql/validation/rules/unique_type_names.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,24 +1,25 @@
+"""Unique type names rule"""
+
 from typing import Any, Dict
 
 from ...error import GraphQLError
 from ...language import SKIP, NameNode, TypeDefinitionNode, VisitorAction
 from . import SDLValidationContext, SDLValidationRule
 
-
 __all__ = ["UniqueTypeNamesRule"]
 
 
 class UniqueTypeNamesRule(SDLValidationRule):
     """Unique type names
 
     A GraphQL document is only valid if all defined types have unique names.
     """
 
-    def __init__(self, context: SDLValidationContext):
+    def __init__(self, context: SDLValidationContext) -> None:
         super().__init__(context)
         self.known_type_names: Dict[str, NameNode] = {}
         self.schema = context.schema
 
     def check_type_name(self, node: TypeDefinitionNode, *_args: Any) -> VisitorAction:
         type_name = node.name.value
```

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/rules/unique_variable_names.py` & `graphql_core-3.3.0a4/src/graphql/validation/rules/unique_variable_names.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,16 +1,17 @@
+"""Unique variable names rule"""
+
 from operator import attrgetter
 from typing import Any
 
 from ...error import GraphQLError
 from ...language import OperationDefinitionNode
 from ...pyutils import group_by
 from . import ASTValidationRule
 
-
 __all__ = ["UniqueVariableNamesRule"]
 
 
 class UniqueVariableNamesRule(ASTValidationRule):
     """Unique variable names
 
     A GraphQL operation is only valid if all its variables are uniquely named.
```

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/rules/values_of_correct_type.py` & `graphql_core-3.3.0a4/src/graphql/validation/rules/values_of_correct_type.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,7 +1,9 @@
+"""Value literals of correct type rule"""
+
 from typing import Any, cast
 
 from ...error import GraphQLError
 from ...language import (
     SKIP,
     BooleanValueNode,
     EnumValueNode,
@@ -25,15 +27,14 @@
     is_leaf_type,
     is_list_type,
     is_non_null_type,
     is_required_input_field,
 )
 from . import ValidationRule
 
-
 __all__ = ["ValuesOfCorrectTypeRule"]
 
 
 class ValuesOfCorrectTypeRule(ValidationRule):
     """Value literals of correct type
 
     A GraphQL document is only valid if all value literals are of the type expected at
@@ -143,15 +144,15 @@
                         f"Expected value of type '{location_type}',"
                         f" found {print_ast(node)}.",
                         node,
                     )
                 )
         except GraphQLError as error:
             self.report_error(error)
-        except Exception as error:
+        except Exception as error:  # noqa: BLE001
             self.report_error(
                 GraphQLError(
                     f"Expected value of type '{location_type}',"
                     f" found {print_ast(node)}; {error}",
                     node,
                     # Ensure a reference to the original error is maintained.
                     original_error=error,
```

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/rules/variables_are_input_types.py` & `graphql_core-3.3.0a4/src/graphql/validation/rules/variables_are_input_types.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,16 +1,17 @@
+"""Variables are input types rule"""
+
 from typing import Any
 
 from ...error import GraphQLError
 from ...language import VariableDefinitionNode, print_ast
 from ...type import is_input_type
 from ...utilities import type_from_ast
 from . import ValidationRule
 
-
 __all__ = ["VariablesAreInputTypesRule"]
 
 
 class VariablesAreInputTypesRule(ValidationRule):
     """Variables are input types
 
     A GraphQL operation is only valid if all the variables it defines are of input types
```

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/rules/variables_in_allowed_position.py` & `graphql_core-3.3.0a4/src/graphql/validation/rules/variables_in_allowed_position.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,34 +1,35 @@
+"""Variables in allowed position rule"""
+
 from typing import Any, Dict, Optional
 
 from ...error import GraphQLError
 from ...language import (
     NullValueNode,
     OperationDefinitionNode,
     ValueNode,
     VariableDefinitionNode,
 )
 from ...pyutils import Undefined
 from ...type import GraphQLSchema, GraphQLType, is_non_null_type
 from ...utilities import is_type_sub_type_of, type_from_ast
 from . import ValidationContext, ValidationRule
 
-
 __all__ = ["VariablesInAllowedPositionRule"]
 
 
 class VariablesInAllowedPositionRule(ValidationRule):
     """Variables in allowed position
 
     Variable usages must be compatible with the arguments they are passed to.
 
     See https://spec.graphql.org/draft/#sec-All-Variable-Usages-are-Allowed
     """
 
-    def __init__(self, context: ValidationContext):
+    def __init__(self, context: ValidationContext) -> None:
         super().__init__(context)
         self.var_def_map: Dict[str, Any] = {}
 
     def enter_operation_definition(self, *_args: Any) -> None:
         self.var_def_map.clear()
 
     def leave_operation_definition(
```

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/specified_rules.py` & `graphql_core-3.3.0a4/src/graphql/validation/specified_rules.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,7 +1,9 @@
+"""Specified rules"""
+
 from typing import Tuple, Type
 
 from .rules import ASTValidationRule
 
 # Spec Section: "Defer And Stream Directive Labels Are Unique"
 from .rules.defer_stream_directive_label import DeferStreamDirectiveLabel
 
@@ -101,15 +103,14 @@
 
 # Spec Section: "Variables are Input Types"
 from .rules.variables_are_input_types import VariablesAreInputTypesRule
 
 # Spec Section: "All Variable Usages Are Allowed"
 from .rules.variables_in_allowed_position import VariablesInAllowedPositionRule
 
-
 __all__ = ["specified_rules", "specified_sdl_rules"]
 
 
 # This list includes all validation rules defined by the GraphQL spec.
 #
 # The order of the rules in this list has been adjusted to lead to the
 # most clear output when encountering multiple validation errors.
```

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/validate.py` & `graphql_core-3.3.0a4/src/graphql/validation/validate.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,18 +1,19 @@
+"""Validation"""
+
 from typing import Collection, List, Optional, Type
 
 from ..error import GraphQLError
 from ..language import DocumentNode, ParallelVisitor, visit
 from ..type import GraphQLSchema, assert_valid_schema
 from ..utilities import TypeInfo, TypeInfoVisitor
 from .rules import ASTValidationRule
 from .specified_rules import specified_rules, specified_sdl_rules
 from .validation_context import SDLValidationContext, ValidationContext
 
-
 __all__ = ["assert_valid_sdl", "assert_valid_sdl_extension", "validate", "validate_sdl"]
 
 
 class ValidationAbortedError(GraphQLError):
     """Error when a validation has been aborted (error limit reached)."""
 
 
@@ -54,15 +55,15 @@
         type_info = TypeInfo(schema)
     if rules is None:
         rules = specified_rules
 
     errors: List[GraphQLError] = []
 
     def on_error(error: GraphQLError) -> None:
-        if len(errors) >= max_errors:  # type: ignore
+        if len(errors) >= max_errors:
             raise validation_aborted_error
         errors.append(error)
 
     context = ValidationContext(schema, document_ast, type_info, on_error)
 
     # This uses a specialized visitor which runs multiple visitors in parallel,
     # while maintaining the visitor skip and break API.
@@ -96,25 +97,23 @@
 
 def assert_valid_sdl(document_ast: DocumentNode) -> None:
     """Assert document is valid SDL.
 
     Utility function which asserts a SDL document is valid by throwing an error if it
     is invalid.
     """
-
     errors = validate_sdl(document_ast)
     if errors:
         raise TypeError("\n\n".join(error.message for error in errors))
 
 
 def assert_valid_sdl_extension(
     document_ast: DocumentNode, schema: GraphQLSchema
 ) -> None:
     """Assert document is a valid SDL extension.
 
     Utility function which asserts a SDL document is valid by throwing an error if it
     is invalid.
     """
-
     errors = validate_sdl(document_ast, schema)
     if errors:
         raise TypeError("\n\n".join(error.message for error in errors))
```

### Comparing `graphql_core-3.3.0a3/src/graphql/validation/validation_context.py` & `graphql_core-3.3.0a4/src/graphql/validation/validation_context.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,7 +1,9 @@
+"""Validation context"""
+
 from typing import Any, Callable, Dict, List, NamedTuple, Optional, Set, Union, cast
 
 from ..error import GraphQLError
 from ..language import (
     DocumentNode,
     FragmentDefinitionNode,
     FragmentSpreadNode,
@@ -20,15 +22,14 @@
     GraphQLField,
     GraphQLInputType,
     GraphQLOutputType,
     GraphQLSchema,
 )
 from ..utilities import TypeInfo, TypeInfoVisitor
 
-
 try:
     from typing import TypeAlias
 except ImportError:  # Python < 3.10
     from typing_extensions import TypeAlias
 
 
 __all__ = [
@@ -39,25 +40,27 @@
     "VariableUsageVisitor",
 ]
 
 NodeWithSelectionSet: TypeAlias = Union[OperationDefinitionNode, FragmentDefinitionNode]
 
 
 class VariableUsage(NamedTuple):
+    """Variable usage"""
+
     node: VariableNode
     type: Optional[GraphQLInputType]
     default_value: Any
 
 
 class VariableUsageVisitor(Visitor):
     """Visitor adding all variable usages to a given list."""
 
     usages: List[VariableUsage]
 
-    def __init__(self, type_info: TypeInfo):
+    def __init__(self, type_info: TypeInfo) -> None:
         super().__init__()
         self.usages = []
         self._append_usage = self.usages.append
         self._type_info = type_info
 
     def enter_variable_definition(self, *_args: Any) -> VisitorAction:
         return self.SKIP
```

### Comparing `graphql_core-3.3.0a3/src/graphql/version.py` & `graphql_core-3.3.0a4/src/graphql/version.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,13 +1,14 @@
+"""GraphQL-core version number"""
+
 from __future__ import annotations  # Python < 3.10
 
 import re
 from typing import NamedTuple
 
-
 __all__ = ["version", "version_info", "version_js", "version_info_js"]
 
 
 version = "3.3.0a3"
 
 version_js = "17.0.0a2"
```

### Comparing `graphql_core-3.3.0a3/tests/benchmarks/test_async_iterable.py` & `graphql_core-3.3.0a4/tests/benchmarks/test_async_iterable.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,21 +1,20 @@
 import asyncio
 
 from graphql import ExecutionResult, build_schema, execute, parse
 from graphql.pyutils import is_awaitable
 
-
 schema = build_schema("type Query { listField: [String] }")
 document = parse("{ listField }")
 
 
 class Data:
     # noinspection PyPep8Naming
     @staticmethod
-    async def listField(info_):
+    async def listField(_info):
         for index in range(1000):
             yield index
 
 
 async def execute_async() -> ExecutionResult:
     result = execute(schema, document, Data())
     assert is_awaitable(result)
```

### Comparing `graphql_core-3.3.0a3/tests/benchmarks/test_execution_async.py` & `graphql_core-3.3.0a4/tests/benchmarks/test_execution_async.py`

 * *Files 3% similar despite different names*

```diff
@@ -4,25 +4,24 @@
     GraphQLField,
     GraphQLObjectType,
     GraphQLSchema,
     GraphQLString,
     graphql,
 )
 
-
 user = GraphQLObjectType(
     name="User",
     fields={
         "id": GraphQLField(GraphQLString),
         "name": GraphQLField(GraphQLString),
     },
 )
 
 
-async def resolve_user(obj, info):
+async def resolve_user(_obj, _info):
     return {
         "id": "1",
         "name": "Sarah",
     }
 
 
 schema = GraphQLSchema(
```

### Comparing `graphql_core-3.3.0a3/tests/benchmarks/test_execution_sync.py` & `graphql_core-3.3.0a4/tests/benchmarks/test_execution_sync.py`

 * *Files 1% similar despite different names*

```diff
@@ -2,25 +2,24 @@
     GraphQLField,
     GraphQLObjectType,
     GraphQLSchema,
     GraphQLString,
     graphql_sync,
 )
 
-
 user = GraphQLObjectType(
     name="User",
     fields={
         "id": GraphQLField(GraphQLString),
         "name": GraphQLField(GraphQLString),
     },
 )
 
 
-def resolve_user(obj, info):
+def resolve_user(_obj, _info):
     return {
         "id": "1",
         "name": "Sarah",
     }
 
 
 schema = GraphQLSchema(
```

### Comparing `graphql_core-3.3.0a3/tests/benchmarks/test_validate_invalid_gql.py` & `graphql_core-3.3.0a4/tests/benchmarks/test_validate_invalid_gql.py`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/tests/benchmarks/test_visit.py` & `graphql_core-3.3.0a4/tests/benchmarks/test_visit.py`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/tests/conftest.py` & `graphql_core-3.3.0a4/tests/conftest.py`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/tests/error/test_graphql_error.py` & `graphql_core-3.3.0a4/tests/error/test_graphql_error.py`

 * *Files 1% similar despite different names*

```diff
@@ -7,29 +7,29 @@
     OperationDefinitionNode,
     Source,
     parse,
 )
 
 from ..utils import dedent
 
-
 source = Source(
     dedent(
         """
         {
           field
         }
         """
     )
 )
 
 ast = parse(source)
 operation_node = ast.definitions[0]
 operation_node = cast(OperationDefinitionNode, operation_node)
-assert operation_node and operation_node.kind == "operation_definition"
+assert operation_node
+assert operation_node.kind == "operation_definition"
 field_node = operation_node.selection_set.selections[0]
 assert field_node
 
 
 def describe_graphql_error():
     def is_a_class_and_is_a_subclass_of_exception():
         assert type(GraphQLError) is type
@@ -243,26 +243,27 @@
         path: List[Union[int, str]] = ["path", 3, "to", "field"]
         e = GraphQLError("msg,", path=tuple(path))
         assert isinstance(e.path, list)
         assert e.path == path
 
     def is_comparable():
         e1 = GraphQLError("msg,", path=["field", 1])
-        assert e1 == e1
+        assert e1 == e1  # noqa: PLR0124
+        assert e1 == e1.formatted
+        assert e1 == e1  # noqa: PLR0124
         assert e1 == e1.formatted
-        assert not e1 != e1
-        assert not e1 != e1.formatted
         e2 = GraphQLError("msg,", path=["field", 1])
         assert e1 == e2
-        assert not e1 != e2
-        assert e2.path and e2.path[1] == 1
+        assert e1 == e2
+        assert e2.path
+        assert e2.path[1] == 1
         e2.path[1] = 2
-        assert not e1 == e2
         assert e1 != e2
-        assert not e1 == e2.formatted
+        assert e1 != e2
+        assert e1 != e2.formatted
         assert e1 != e2.formatted
 
     def is_hashable():
         hash(GraphQLError("msg"))
 
     def hashes_are_unique_per_instance():
         e1 = GraphQLError("msg")
@@ -293,15 +294,17 @@
                     """
                 ),
                 "SourceA",
             )
         )
         op_a = doc_a.definitions[0]
         op_a = cast(ObjectTypeDefinitionNode, op_a)
-        assert op_a and op_a.kind == "object_type_definition" and op_a.fields
+        assert op_a
+        assert op_a.kind == "object_type_definition"
+        assert op_a.fields
         field_a = op_a.fields[0]
         doc_b = parse(
             Source(
                 dedent(
                     """
                     type Foo {
                       field: Int
@@ -309,15 +312,17 @@
                     """
                 ),
                 "SourceB",
             )
         )
         op_b = doc_b.definitions[0]
         op_b = cast(ObjectTypeDefinitionNode, op_b)
-        assert op_b and op_b.kind == "object_type_definition" and op_b.fields
+        assert op_b
+        assert op_b.kind == "object_type_definition"
+        assert op_b.fields
         field_b = op_b.fields[0]
 
         error = GraphQLError(
             "Example error with two nodes", [field_a.type, field_b.type]
         )
 
         assert str(error) == dedent(
@@ -382,22 +387,22 @@
         error = GraphQLError("msg", extensions={"foo": "bar"})
         assert error.formatted == {
             "message": "msg",
             "extensions": {"foo": "bar"},
         }
 
     def can_be_created_from_dict():
-        args = dict(
-            nodes=[operation_node],
-            source=source,
-            positions=[6],
-            path=["path", 2, "a"],
-            original_error=Exception("I like turtles"),
-            extensions=dict(hee="I like turtles"),
-        )
+        args = {
+            "nodes": [operation_node],
+            "source": source,
+            "positions": [6],
+            "path": ["path", 2, "a"],
+            "original_error": Exception("I like turtles"),
+            "extensions": {"hee": "I like turtles"},
+        }
         error = GraphQLError("msg", **args)  # type: ignore
         assert error.formatted == {
             "message": "msg",
             "locations": [{"column": 5, "line": 2}],
             "path": ["path", 2, "a"],
             "extensions": {"hee": "I like turtles"},
         }
```

### Comparing `graphql_core-3.3.0a3/tests/error/test_located_error.py` & `graphql_core-3.3.0a4/tests/error/test_located_error.py`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/tests/error/test_print_location.py` & `graphql_core-3.3.0a4/tests/error/test_print_location.py`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/tests/execution/test_abstract.py` & `graphql_core-3.3.0a4/tests/execution/test_abstract.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,11 +1,10 @@
 from typing import Any, NamedTuple, Optional
 
-from pytest import mark
-
+import pytest
 from graphql.execution import ExecutionResult, execute, execute_sync
 from graphql.language import parse
 from graphql.pyutils import is_awaitable
 from graphql.type import (
     GraphQLBoolean,
     GraphQLField,
     GraphQLInterfaceType,
@@ -16,37 +15,35 @@
     GraphQLUnionType,
 )
 from graphql.utilities import build_schema
 
 
 def sync_and_async(spec):
     """Decorator for running a test synchronously and asynchronously."""
-    return mark.asyncio(
-        mark.parametrize("sync", (True, False), ids=("sync", "async"))(spec)
+    return pytest.mark.asyncio(
+        pytest.mark.parametrize("sync", (True, False), ids=("sync", "async"))(spec)
     )
 
 
 def access_variants(spec):
     """Decorator for tests with dict and object access, including inheritance."""
-    return mark.asyncio(
-        mark.parametrize("access", ("dict", "object", "inheritance"))(spec)
+    return pytest.mark.asyncio(
+        pytest.mark.parametrize("access", ("dict", "object", "inheritance"))(spec)
     )
 
 
 async def execute_query(
     sync: bool, schema: GraphQLSchema, query: str, root_value: Any = None
 ) -> ExecutionResult:
     """Execute the query against the given schema synchronously or asynchronously."""
     assert isinstance(sync, bool)
     assert isinstance(schema, GraphQLSchema)
     assert isinstance(query, str)
     document = parse(query)
-    result = (execute_sync if sync else execute)(
-        schema, document, root_value
-    )  # type: ignore
+    result = (execute_sync if sync else execute)(schema, document, root_value)  # type: ignore
     if not sync and is_awaitable(result):
         result = await result
     assert isinstance(result, ExecutionResult)
     return result
 
 
 def get_is_type_of(type_, sync=True):
@@ -525,15 +522,15 @@
                 """
                 type Query {
                   pets: [Pet]
                 }
 
                 interface Pet {
                   name: String
-                  }
+                }
 
                 type Cat implements Pet {
                   name: String
                   meows: Boolean
                 }
 
                 type Dog implements Pet {
```

### Comparing `graphql_core-3.3.0a3/tests/execution/test_customize.py` & `graphql_core-3.3.0a4/tests/execution/test_customize.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,21 +1,19 @@
 from inspect import isasyncgen
 
-from pytest import mark
-
+import pytest
 from graphql.execution import ExecutionContext, execute, subscribe
 from graphql.language import parse
 from graphql.type import GraphQLField, GraphQLObjectType, GraphQLSchema, GraphQLString
 
-
 try:
-    anext
+    anext  # noqa: B018
 except NameError:  # pragma: no cover (Python < 3.10)
     # noinspection PyShadowingBuiltins
-    async def anext(iterator):
+    async def anext(iterator):  # noqa: A001
         """Return the next item from an async iterator."""
         return await iterator.__anext__()
 
 
 def describe_customize_execution():
     def uses_a_custom_field_resolver():
         query = parse("{ foo }")
@@ -55,15 +53,15 @@
         assert execute(schema, query, execution_context_class=TestExecutionContext) == (
             {"foo": "barbar"},
             None,
         )
 
 
 def describe_customize_subscription():
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def uses_a_custom_subscribe_field_resolver():
         schema = GraphQLSchema(
             query=GraphQLObjectType("Query", {"foo": GraphQLField(GraphQLString)}),
             subscription=GraphQLObjectType(
                 "Subscription", {"foo": GraphQLField(GraphQLString)}
             ),
         )
@@ -84,15 +82,15 @@
         assert await anext(subscription) == (
             {"foo": "FooValue"},
             None,
         )
 
         await subscription.aclose()
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def uses_a_custom_execution_context_class():
         class TestExecutionContext(ExecutionContext):
             def build_resolve_info(self, *args, **kwargs):
                 resolve_info = super().build_resolve_info(*args, **kwargs)
                 resolve_info.context["foo"] = "bar"
                 return resolve_info
```

### Comparing `graphql_core-3.3.0a3/tests/execution/test_defer.py` & `graphql_core-3.3.0a4/tests/execution/test_defer.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,69 +1,81 @@
 from asyncio import sleep
-from typing import Any, Dict, List, NamedTuple
-
-from pytest import mark, raises
+from typing import Any, AsyncGenerator, Dict, List, NamedTuple
 
+import pytest
 from graphql.error import GraphQLError
 from graphql.execution import (
     ExecutionContext,
     ExecutionResult,
     ExperimentalIncrementalExecutionResults,
     IncrementalDeferResult,
     InitialIncrementalExecutionResult,
     SubsequentIncrementalExecutionResult,
     execute,
     experimental_execute_incrementally,
 )
 from graphql.execution.execute import DeferredFragmentRecord
 from graphql.language import DocumentNode, parse
-from graphql.pyutils import Path
+from graphql.pyutils import Path, is_awaitable
 from graphql.type import (
     GraphQLField,
     GraphQLID,
     GraphQLList,
     GraphQLNonNull,
     GraphQLObjectType,
     GraphQLSchema,
     GraphQLString,
 )
 
 
+def resolve_null_sync(_obj, _info) -> None:
+    """A resolver returning a null value synchronously."""
+    return
+
+
+async def resolve_null_async(_obj, _info) -> None:
+    """A resolver returning a null value asynchronously."""
+    return
+
+
 friend_type = GraphQLObjectType(
-    "Friend", {"id": GraphQLField(GraphQLID), "name": GraphQLField(GraphQLString)}
+    "Friend",
+    {
+        "id": GraphQLField(GraphQLID),
+        "name": GraphQLField(GraphQLString),
+        "asyncNonNullErrorField": GraphQLField(
+            GraphQLNonNull(GraphQLString), resolve=resolve_null_async
+        ),
+    },
 )
 
 
 class Friend(NamedTuple):
-    name: str
     id: int
+    name: str
 
 
-friends = [Friend("Han", 2), Friend("Leia", 3), Friend("C-3PO", 4)]
+friends = [Friend(2, "Han"), Friend(3, "Leia"), Friend(4, "C-3PO")]
 
 
 async def resolve_slow(_obj, _info) -> str:
     """Simulate a slow async resolver returning a value."""
     await sleep(0)
     return "slow"
 
 
 async def resolve_bad(_obj, _info) -> str:
     """Simulate a bad async resolver raising an error."""
     raise RuntimeError("bad")
 
 
-def resolve_null_sync(_obj, _info) -> None:
-    """Simulate a resolver returning a null value synchronously."""
-    return None
-
-
-async def resolve_null_async(_obj, _info) -> None:
-    """Simulate a resolver returning a null value asynchronously."""
-    return None
+async def resolve_friends_async(_obj, _info) -> AsyncGenerator[Friend, None]:
+    """A slow async generator yielding the first friend."""
+    await sleep(0)
+    yield friends[0]
 
 
 hero_type = GraphQLObjectType(
     "Hero",
     {
         "id": GraphQLField(GraphQLID),
         "name": GraphQLField(GraphQLString),
@@ -74,28 +86,33 @@
         ),
         "asyncNonNullErrorField": GraphQLField(
             GraphQLNonNull(GraphQLString), resolve=resolve_null_async
         ),
         "friends": GraphQLField(
             GraphQLList(friend_type), resolve=lambda _obj, _info: friends
         ),
+        "asyncFriends": GraphQLField(
+            GraphQLList(friend_type), resolve=resolve_friends_async
+        ),
     },
 )
 
-hero = Friend("Luke", 1)
+hero = Friend(1, "Luke")
 
 query = GraphQLObjectType(
     "Query", {"hero": GraphQLField(hero_type, resolve=lambda _obj, _info: hero)}
 )
 
 schema = GraphQLSchema(query)
 
 
 async def complete(document: DocumentNode, root_value: Any = None) -> Any:
     result = experimental_execute_incrementally(schema, document, root_value)
+    if is_awaitable(result):
+        result = await result
 
     if isinstance(result, ExperimentalIncrementalExecutionResults):
         results: List[Any] = [result.initial_result.formatted]
         async for patch in result.subsequent_results:
             results.append(patch.formatted)
         return results
 
@@ -327,15 +344,15 @@
         )
         record.data = {"hello": "world"}
         assert (
             str(record) == "DeferredFragmentRecord("
             "path=['bar'], label='foo', parent_context, data)"
         )
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def can_defer_fragments_containing_scalar_types():
         document = parse(
             """
             query HeroNameQuery {
               hero {
                 id
                 ...NameFragment @defer
@@ -355,15 +372,15 @@
                 "incremental": [
                     {"data": {"id": "1", "name": "Luke"}, "path": ["hero"]}
                 ],
                 "hasNext": False,
             },
         ]
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def can_disable_defer_using_if_argument():
         document = parse(
             """
             query HeroNameQuery {
               hero {
                 id
                 ...NameFragment @defer(if: false)
@@ -381,15 +398,15 @@
                 "hero": {
                     "id": "1",
                     "name": "Luke",
                 },
             },
         }
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def does_not_disable_defer_with_null_if_argument():
         document = parse(
             """
             query HeroNameQuery($shouldDefer: Boolean) {
               hero {
                 id
                 ...NameFragment @defer(if: $shouldDefer)
@@ -406,15 +423,15 @@
             {"data": {"hero": {"id": "1"}}, "hasNext": True},
             {
                 "incremental": [{"data": {"name": "Luke"}, "path": ["hero"]}],
                 "hasNext": False,
             },
         ]
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def throws_an_error_for_defer_directive_with_non_string_label():
         document = parse(
             """
             query Deferred {
               ... @defer(label: 42) { hero { id } }
             }
             """
@@ -427,15 +444,15 @@
                 {
                     "locations": [{"column": 33, "line": 3}],
                     "message": "Argument 'label' has invalid value 42.",
                 }
             ],
         }
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def can_defer_fragments_on_the_top_level_query_field():
         document = parse(
             """
             query HeroNameQuery {
               ...QueryFragment @defer(label: "DeferQuery")
             }
             fragment QueryFragment on Query {
@@ -453,15 +470,15 @@
                 "incremental": [
                     {"data": {"hero": {"id": "1"}}, "path": [], "label": "DeferQuery"}
                 ],
                 "hasNext": False,
             },
         ]
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def can_defer_fragments_with_errors_on_the_top_level_query_field():
         document = parse(
             """
             query HeroNameQuery {
               ...QueryFragment @defer(label: "DeferQuery")
             }
             fragment QueryFragment on Query {
@@ -490,15 +507,15 @@
                         "label": "DeferQuery",
                     }
                 ],
                 "hasNext": False,
             },
         ]
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def can_defer_a_fragment_within_an_already_deferred_fragment():
         document = parse(
             """
             query HeroNameQuery {
               hero {
                 id
                 ...TopFragment @defer(label: "DeferTop")
@@ -538,15 +555,15 @@
                         "label": "DeferTop",
                     },
                 ],
                 "hasNext": False,
             },
         ]
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def can_defer_a_fragment_that_is_also_not_deferred_with_deferred_first():
         document = parse(
             """
             query HeroNameQuery {
               hero {
                 id
                 ...TopFragment @defer(label: "DeferTop")
@@ -570,15 +587,15 @@
                         "label": "DeferTop",
                     },
                 ],
                 "hasNext": False,
             },
         ]
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def can_defer_a_fragment_that_is_also_not_deferred_with_non_deferred_first():
         document = parse(
             """
             query HeroNameQuery {
               hero {
                 id
                 ...TopFragment
@@ -602,15 +619,15 @@
                         "label": "DeferTop",
                     },
                 ],
                 "hasNext": False,
             },
         ]
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def can_defer_an_inline_fragment():
         document = parse(
             """
             query HeroNameQuery {
               hero {
                 id
                 ... on Hero @defer(label: "InlineDeferred") {
@@ -632,15 +649,15 @@
                         "label": "InlineDeferred",
                     },
                 ],
                 "hasNext": False,
             },
         ]
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def handles_errors_thrown_in_deferred_fragments():
         document = parse(
             """
             query HeroNameQuery {
               hero {
                 id
                 ...NameFragment @defer
@@ -669,15 +686,15 @@
                         ],
                     },
                 ],
                 "hasNext": False,
             },
         ]
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def handles_non_nullable_errors_thrown_in_deferred_fragments():
         document = parse(
             """
             query HeroNameQuery {
               hero {
                 id
                 ...NameFragment @defer
@@ -707,15 +724,15 @@
                         ],
                     },
                 ],
                 "hasNext": False,
             },
         ]
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def handles_non_nullable_errors_thrown_outside_deferred_fragments():
         document = parse(
             """
             query HeroNameQuery {
               hero {
                 nonNullErrorField
                 ...NameFragment @defer
@@ -736,15 +753,15 @@
                     " Hero.nonNullErrorField.",
                     "locations": [{"line": 4, "column": 17}],
                     "path": ["hero", "nonNullErrorField"],
                 }
             ],
         }
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def handles_async_non_nullable_errors_thrown_in_deferred_fragments():
         document = parse(
             """
             query HeroNameQuery {
               hero {
                 id
                 ...NameFragment @defer
@@ -774,15 +791,15 @@
                         ],
                     },
                 ],
                 "hasNext": False,
             },
         ]
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def returns_payloads_in_correct_order():
         document = parse(
             """
             query HeroNameQuery {
               hero {
                 id
                 ...NameFragment @defer
@@ -827,15 +844,15 @@
                         "path": ["hero", "friends", 2],
                     },
                 ],
                 "hasNext": False,
             },
         ]
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def returns_payloads_from_synchronous_data_in_correct_order():
         document = parse(
             """
             query HeroNameQuery {
               hero {
                 id
                 ...NameFragment @defer
@@ -880,33 +897,65 @@
                         "path": ["hero", "friends", 2],
                     },
                 ],
                 "hasNext": False,
             },
         ]
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
+    async def filters_deferred_payloads_when_list_item_from_async_iterable_nulled():
+        document = parse(
+            """
+            query {
+              hero {
+                asyncFriends {
+                  asyncNonNullErrorField
+                  ...NameFragment @defer
+                }
+              }
+            }
+            fragment NameFragment on Friend {
+              name
+            }
+            """
+        )
+
+        result = await complete(document)
+
+        assert result == {
+            "data": {"hero": {"asyncFriends": [None]}},
+            "errors": [
+                {
+                    "message": "Cannot return null for non-nullable field"
+                    " Friend.asyncNonNullErrorField.",
+                    "locations": [{"line": 5, "column": 19}],
+                    "path": ["hero", "asyncFriends", 0, "asyncNonNullErrorField"],
+                }
+            ],
+        }
+
+    @pytest.mark.asyncio()
     async def original_execute_function_throws_error_if_deferred_and_all_is_sync():
         document = parse(
             """
             query Deferred {
               ... @defer { hero { id } }
             }
             """
         )
 
-        with raises(GraphQLError) as exc_info:
+        with pytest.raises(GraphQLError) as exc_info:
             await execute(schema, document, {})  # type: ignore
 
         assert str(exc_info.value) == (
             "Executing this GraphQL operation would unexpectedly produce"
             " multiple payloads (due to @defer or @stream directive)"
         )
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def original_execute_function_throws_error_if_deferred_and_not_all_is_sync():
         document = parse(
             """
             query Deferred {
               hero { slowField }
               ... @defer { hero { id } }
             }
@@ -916,11 +965,12 @@
         result = await execute(schema, document, {})  # type: ignore
 
         assert result == (
             None,
             [
                 {
                     "message": "Executing this GraphQL operation would unexpectedly"
-                    " produce multiple payloads (due to @defer or @stream directive)"
+                    " produce multiple payloads"
+                    " (due to @defer or @stream directive)"
                 }
             ],
         )
```

### Comparing `graphql_core-3.3.0a3/tests/execution/test_directives.py` & `graphql_core-3.3.0a4/tests/execution/test_directives.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,12 +1,11 @@
 from graphql.execution import ExecutionResult, execute_sync
 from graphql.language import parse
 from graphql.type import GraphQLField, GraphQLObjectType, GraphQLSchema, GraphQLString
 
-
 schema = GraphQLSchema(
     GraphQLObjectType(
         "TestType", {"a": GraphQLField(GraphQLString), "b": GraphQLField(GraphQLString)}
     )
 )
```

### Comparing `graphql_core-3.3.0a3/tests/execution/test_execution_result.py` & `graphql_core-3.3.0a4/tests/execution/test_execution_result.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,8 @@
-from pytest import raises
-
+import pytest
 from graphql.error import GraphQLError
 from graphql.execution import ExecutionResult
 
 
 def describe_execution_result():
     data = {"foo": "Some data"}
     error = GraphQLError("Some error")
@@ -103,13 +102,13 @@
         res2 = ExecutionResult(data, [GraphQLError("Another error")], extensions)
         assert res1 != res2
         res2 = ExecutionResult(data, errors, {"bar": "Another extension"})
         assert res1 != res2
 
     def unpacks_as_two_tuple():
         res = ExecutionResult(data, errors)
-        res_data, res_errors = res  # type: ignore
-        assert res_data == data  # type: ignore
-        assert res_errors == errors  # type: ignore
-        with raises(ValueError):
-            res = ExecutionResult(data, errors, extensions)
-            _res_data, _res_errors, _res_extensions = res  # type: ignore
+        res_data, res_errors = res
+        assert res_data == data
+        assert res_errors == errors
+        res = ExecutionResult(data, errors, extensions)
+        with pytest.raises(ValueError, match="not enough values to unpack"):
+            _res_data, _res_errors, _res_extensions = res
```

### Comparing `graphql_core-3.3.0a3/tests/execution/test_executor.py` & `graphql_core-3.3.0a4/tests/execution/test_executor.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,12 +1,11 @@
 import asyncio
 from typing import Any, Awaitable, Optional, cast
 
-from pytest import mark
-
+import pytest
 from graphql.error import GraphQLError
 from graphql.execution import execute, execute_sync
 from graphql.language import FieldNode, OperationDefinitionNode, parse
 from graphql.pyutils import Undefined, inspect
 from graphql.type import (
     GraphQLArgument,
     GraphQLBoolean,
@@ -26,23 +25,23 @@
 
 
 def describe_execute_handles_basic_execution_tasks():
     def accepts_positional_arguments():
         schema = GraphQLSchema(
             GraphQLObjectType(
                 "Type",
-                {"a": GraphQLField(GraphQLString, resolve=lambda obj, *args: obj)},
+                {"a": GraphQLField(GraphQLString, resolve=lambda obj, *_args: obj)},
             )
         )
 
         result = execute_sync(schema, parse("{ a }"), "rootValue")
 
         assert result == ({"a": "rootValue"}, None)
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def executes_arbitrary_code():
         # noinspection PyMethodMayBeStatic,PyMethodMayBeStatic
         class Data:
             def a(self, _info):
                 return "Apple"
 
             def b(self, _info):
@@ -238,15 +237,16 @@
         document = parse("query ($var: String) { result: test }")
         root_value = {"root": "val"}
         variable_values = {"var": "abc"}
         execute_sync(schema, document, root_value, variable_values=variable_values)
 
         assert len(resolved_infos) == 1
         operation = cast(OperationDefinitionNode, document.definitions[0])
-        assert operation and operation.kind == "operation_definition"
+        assert operation
+        assert operation.kind == "operation_definition"
         field = cast(FieldNode, operation.selection_set.selections[0])
 
         assert resolved_infos[0] == GraphQLResolveInfo(
             field_name="test",
             field_nodes=[field],
             return_type=GraphQLString,
             parent_type=cast(GraphQLObjectType, schema.query_type),
@@ -365,15 +365,15 @@
         )
 
         execute_sync(schema, document)
 
         assert len(resolved_args) == 1
         assert resolved_args[0] == {"numArg": 123, "stringArg": "foo"}
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def nulls_out_error_subtrees():
         document = parse(
             """
             {
               syncOk
               syncError
               syncRawError
@@ -510,14 +510,62 @@
                     "locations": [(12, 15)],
                     "path": ["asyncReturnErrorWithExtensions"],
                     "extensions": {"foo": "bar"},
                 },
             ],
         )
 
+    @pytest.mark.filterwarnings("ignore:.* was never awaited:RuntimeWarning")
+    def handles_sync_errors_combined_with_async_ones():
+        is_async_resolver_finished = False
+
+        async def async_resolver(_obj, _info):
+            nonlocal is_async_resolver_finished
+            is_async_resolver_finished = True  # pragma: no cover
+
+        schema = GraphQLSchema(
+            GraphQLObjectType(
+                "Query",
+                {
+                    "syncNullError": GraphQLField(
+                        GraphQLNonNull(GraphQLString), resolve=lambda _obj, _info: None
+                    ),
+                    "asyncNullError": GraphQLField(
+                        GraphQLNonNull(GraphQLString), resolve=async_resolver
+                    ),
+                },
+            )
+        )
+
+        document = parse(
+            """
+            {
+              asyncNullError
+              syncNullError
+            }
+            """
+        )
+
+        result = execute(schema, document)
+
+        assert is_async_resolver_finished is False
+
+        assert result == (
+            None,
+            [
+                {
+                    "message": "Cannot return null"
+                    " for non-nullable field Query.syncNullError.",
+                    "locations": [(4, 15)],
+                    "path": ["syncNullError"],
+                }
+            ],
+        )
+
+    @pytest.mark.filterwarnings("ignore:.* was never awaited:RuntimeWarning")
     def full_response_path_is_included_for_non_nullable_fields():
         def resolve_ok(*_args):
             return {}
 
         def resolve_error(*_args):
             raise Exception("Catch me if you can")
 
@@ -572,14 +620,15 @@
 
         class Data:
             a = "b"
 
         result = execute_sync(schema, document, Data())
         assert result == ({"a": "b"}, None)
 
+    @pytest.mark.filterwarnings("ignore:.* was never awaited:RuntimeWarning")
     def uses_the_only_operation_if_no_operation_name_is_provided():
         schema = GraphQLSchema(
             GraphQLObjectType("Type", {"a": GraphQLField(GraphQLString)})
         )
 
         document = parse("query Example { a }")
 
@@ -775,15 +824,15 @@
                     "message": "Schema is not configured to execute"
                     " subscription operation.",
                     "locations": [(4, 13)],
                 }
             ],
         )
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def correct_field_ordering_despite_execution_order():
         schema = GraphQLSchema(
             GraphQLObjectType(
                 "Type",
                 {
                     "a": GraphQLField(GraphQLString),
                     "b": GraphQLField(GraphQLString),
@@ -891,15 +940,15 @@
         document = parse("{ field(a: true, c: false, e: 0) }")
 
         assert execute_sync(schema, document) == (
             {"field": "{'a': True, 'c': False, 'e': 0}"},
             None,
         )
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def fails_when_is_type_of_check_is_not_met():
         class Special:
             value: str
 
             def __init__(self, value):
                 self.value = value
 
@@ -951,15 +1000,16 @@
         async_result = execute(schema, document, root_value, {"async": True})
         assert isinstance(async_result, Awaitable)
         awaited_result = await async_result
         assert awaited_result == result
 
     def fails_when_serialize_of_custom_scalar_does_not_return_a_value():
         custom_scalar = GraphQLScalarType(
-            "CustomScalar", serialize=lambda _value: Undefined  # returns nothing
+            "CustomScalar",
+            serialize=lambda _value: Undefined,  # returns nothing
         )
         schema = GraphQLSchema(
             GraphQLObjectType(
                 "Query",
                 {
                     "customScalar": GraphQLField(
                         custom_scalar, resolve=lambda *_args: "CUSTOM_VALUE"
```

### Comparing `graphql_core-3.3.0a3/tests/execution/test_flatten_async_iterable.py` & `graphql_core-3.3.0a4/tests/execution/test_flatten_async_iterable.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,25 +1,24 @@
+from contextlib import suppress
 from typing import AsyncGenerator
 
-from pytest import mark, raises
-
+import pytest
 from graphql.execution import flatten_async_iterable
 
-
 try:  # pragma: no cover
-    anext
+    anext  # noqa: B018
 except NameError:  # pragma: no cover (Python < 3.10)
     # noinspection PyShadowingBuiltins
-    async def anext(iterator):
+    async def anext(iterator):  # noqa: A001
         """Return the next item from an async iterator."""
         return await iterator.__anext__()
 
 
 def describe_flatten_async_iterable():
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def flattens_nested_async_generators():
         async def source():
             async def nested1() -> AsyncGenerator[float, None]:
                 yield 1.1
                 yield 1.2
 
             async def nested2() -> AsyncGenerator[float, None]:
@@ -31,15 +30,15 @@
 
         doubles = flatten_async_iterable(source())
 
         result = [x async for x in doubles]
 
         assert result == [1.1, 1.2, 2.1, 2.2]
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def allows_returning_early_from_a_nested_async_generator():
         async def source():
             async def nested1() -> AsyncGenerator[float, None]:
                 yield 1.1
                 yield 1.2
 
             async def nested2() -> AsyncGenerator[float, None]:
@@ -59,26 +58,24 @@
         doubles = flatten_async_iterable(source())
 
         assert await anext(doubles) == 1.1
         assert await anext(doubles) == 1.2
         assert await anext(doubles) == 2.1
 
         # early return
-        try:
+        with suppress(RuntimeError):  # suppress error for Python < 3.8
             await doubles.aclose()
-        except RuntimeError:  # Python < 3.8
-            pass
 
         # subsequent anext calls
-        with raises(StopAsyncIteration):
+        with pytest.raises(StopAsyncIteration):
             assert await anext(doubles)
-        with raises(StopAsyncIteration):
+        with pytest.raises(StopAsyncIteration):
             assert await anext(doubles)
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def allows_throwing_errors_from_a_nested_async_generator():
         async def source():
             async def nested1() -> AsyncGenerator[float, None]:
                 yield 1.1
                 yield 1.2
 
             async def nested2() -> AsyncGenerator[float, None]:
@@ -98,18 +95,18 @@
         doubles = flatten_async_iterable(source())
 
         assert await anext(doubles) == 1.1
         assert await anext(doubles) == 1.2
         assert await anext(doubles) == 2.1
 
         # throw error
-        with raises(RuntimeError, match="ouch"):
-            await doubles.athrow(RuntimeError, "ouch")
+        with pytest.raises(RuntimeError, match="ouch"):
+            await doubles.athrow(RuntimeError("ouch"))
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def completely_yields_sub_iterables_even_when_anext_called_in_parallel():
         async def source():
             async def nested1() -> AsyncGenerator[float, None]:
                 yield 1.1
                 yield 1.2
 
             async def nested2() -> AsyncGenerator[float, None]:
@@ -123,18 +120,18 @@
 
         anext1 = anext(doubles)
         anext2 = anext(doubles)
         assert await anext1 == 1.1
         assert await anext2 == 1.2
         assert await anext(doubles) == 2.1
         assert await anext(doubles) == 2.2
-        with raises(StopAsyncIteration):
+        with pytest.raises(StopAsyncIteration):
             assert await anext(doubles)
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def closes_nested_async_iterators():
         closed = []
 
         class Source:
             def __init__(self):
                 self.counter = 0
 
@@ -173,15 +170,15 @@
 
         result = [x async for x in doubles]
 
         assert result == [1.1, 1.2, 2.1, 2.2]
 
         assert closed == [1.2, 2.2, 2]
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def works_with_nested_async_iterators_that_have_no_close_method():
         class Source:
             def __init__(self):
                 self.counter = 0
 
             def __aiter__(self):
                 return self
```

### Comparing `graphql_core-3.3.0a3/tests/execution/test_lists.py` & `graphql_core-3.3.0a4/tests/execution/test_lists.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 from typing import Any, AsyncGenerator
 
-from pytest import mark
-
+import pytest
 from graphql.execution import ExecutionResult, execute, execute_sync
 from graphql.language import parse
 from graphql.pyutils import is_awaitable
 from graphql.type import (
     GraphQLField,
     GraphQLFieldResolver,
     GraphQLList,
+    GraphQLNonNull,
     GraphQLObjectType,
     GraphQLResolveInfo,
     GraphQLSchema,
     GraphQLString,
 )
 from graphql.utilities import build_schema
 
@@ -138,52 +138,56 @@
         def __init__(self, index: int):
             self.index = index
 
     async def _complete_object_lists(
         resolve: GraphQLFieldResolver, count=3
     ) -> ExecutionResult:
         async def _list_field(
-            obj_: Any, info_: GraphQLResolveInfo
+            _obj: Any, _info: GraphQLResolveInfo
         ) -> AsyncGenerator[_IndexData, None]:
             for index in range(count):
                 yield _IndexData(index)
 
         schema = GraphQLSchema(
             GraphQLObjectType(
                 "Query",
                 {
                     "listField": GraphQLField(
                         GraphQLList(
                             GraphQLObjectType(
                                 "ObjectWrapper",
-                                {"index": GraphQLField(GraphQLString, resolve=resolve)},
+                                {
+                                    "index": GraphQLField(
+                                        GraphQLNonNull(GraphQLString), resolve=resolve
+                                    )
+                                },
                             )
                         ),
                         resolve=_list_field,
                     )
                 },
             )
         )
         result = execute(schema, document=parse("{ listField { index } }"))
         assert is_awaitable(result)
         return await result
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def accepts_an_async_generator_as_a_list_value():
         async def list_field():
             yield "two"
             yield 4
             yield False
 
         assert await _complete(list_field()) == (
             {"listField": ["two", "4", "false"]},
             None,
         )
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def accepts_a_custom_async_iterable_as_a_list_value():
         class ListField:
             def __aiter__(self):
                 self.last = "hello"
                 return self
 
             async def __anext__(self):
@@ -194,27 +198,27 @@
                 return last
 
         assert await _complete(ListField()) == (
             {"listField": ["hello", "world"]},
             None,
         )
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def handles_an_async_generator_that_throws():
         async def list_field():
             yield "two"
             yield 4
             raise RuntimeError("bad")
 
         assert await _complete(list_field()) == (
             {"listField": ["two", "4", None]},
             [{"message": "bad", "locations": [(1, 3)], "path": ["listField", 2]}],
         )
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def handles_an_async_generator_where_intermediate_value_triggers_an_error():
         async def list_field():
             yield "two"
             yield {}
             yield 4
 
         assert await _complete(list_field()) == (
@@ -224,15 +228,15 @@
                     "message": "String cannot represent value: {}",
                     "locations": [(1, 3)],
                     "path": ["listField", 1],
                 }
             ],
         )
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def handles_errors_from_complete_value_in_async_iterables():
         async def list_field():
             yield "two"
             yield {}
 
         assert await _complete(list_field()) == (
             {"listField": ["two", None]},
@@ -241,54 +245,54 @@
                     "message": "String cannot represent value: {}",
                     "locations": [(1, 3)],
                     "path": ["listField", 1],
                 }
             ],
         )
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def handles_async_functions_from_complete_value_in_async_iterables():
-        async def resolve(data: _IndexData, info_: GraphQLResolveInfo) -> int:
+        async def resolve(data: _IndexData, _info: GraphQLResolveInfo) -> int:
             return data.index
 
         assert await _complete_object_lists(resolve) == (
             {"listField": [{"index": "0"}, {"index": "1"}, {"index": "2"}]},
             None,
         )
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def handles_single_async_functions_from_complete_value_in_async_iterables():
-        async def resolve(data: _IndexData, info_: GraphQLResolveInfo) -> int:
+        async def resolve(data: _IndexData, _info: GraphQLResolveInfo) -> int:
             return data.index
 
         assert await _complete_object_lists(resolve, 1) == (
             {"listField": [{"index": "0"}]},
             None,
         )
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def handles_async_errors_from_complete_value_in_async_iterables():
-        async def resolve(data: _IndexData, info_: GraphQLResolveInfo) -> int:
+        async def resolve(data: _IndexData, _info: GraphQLResolveInfo) -> int:
             index = data.index
             if index == 2:
                 raise RuntimeError("bad")
             return index
 
         assert await _complete_object_lists(resolve) == (
-            {"listField": [{"index": "0"}, {"index": "1"}, {"index": None}]},
+            {"listField": [{"index": "0"}, {"index": "1"}, None]},
             [
                 {
                     "message": "bad",
                     "locations": [(1, 15)],
                     "path": ["listField", 2, "index"],
                 }
             ],
         )
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def handles_nulls_yielded_by_async_generator():
         async def list_field():
             yield 1
             yield None
             yield 2
 
         data = {"listField": [1, None, 2]}
@@ -314,23 +318,23 @@
         assert await execute_query(get_async(list_field)) == result
         if isinstance(list_field, list):
             assert await execute_query(list(map(get_async, list_field))) == result
             assert await execute_query(get_async(list_field)) == result
 
         return result
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def contains_values():
         list_field = [1, 2]
         assert await _complete(list_field, "[Int]") == ({"listField": [1, 2]}, None)
         assert await _complete(list_field, "[Int]!") == ({"listField": [1, 2]}, None)
         assert await _complete(list_field, "[Int!]") == ({"listField": [1, 2]}, None)
         assert await _complete(list_field, "[Int!]!") == ({"listField": [1, 2]}, None)
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def contains_null():
         list_field = [1, None, 2]
         errors = [
             {
                 "message": "Cannot return null for non-nullable field Query.listField.",
                 "locations": [(1, 3)],
                 "path": ["listField", 1],
@@ -343,30 +347,30 @@
         assert await _complete(list_field, "[Int]!") == (
             {"listField": [1, None, 2]},
             None,
         )
         assert await _complete(list_field, "[Int!]") == ({"listField": None}, errors)
         assert await _complete(list_field, "[Int!]!") == (None, errors)
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def returns_null():
         list_field = None
         errors = [
             {
                 "message": "Cannot return null for non-nullable field Query.listField.",
                 "locations": [(1, 3)],
                 "path": ["listField"],
             }
         ]
         assert await _complete(list_field, "[Int]") == ({"listField": None}, None)
         assert await _complete(list_field, "[Int]!") == (None, errors)
         assert await _complete(list_field, "[Int!]") == ({"listField": None}, None)
         assert await _complete(list_field, "[Int!]!") == (None, errors)
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def contains_error():
         list_field = [1, RuntimeError("bad"), 2]
         errors = [
             {
                 "message": "bad",
                 "locations": [(1, 3)],
                 "path": ["listField", 1],
@@ -385,15 +389,15 @@
             errors,
         )
         assert await _complete(list_field, "[Int!]!") == (
             None,
             errors,
         )
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def results_in_errors():
         list_field = RuntimeError("bad")
         errors = [
             {
                 "message": "bad",
                 "locations": [(1, 3)],
                 "path": ["listField"],
```

### Comparing `graphql_core-3.3.0a3/tests/execution/test_map_async_iterable.py` & `graphql_core-3.3.0a4/tests/execution/test_map_async_iterable.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,17 +1,15 @@
-from pytest import mark, raises
-
+import pytest
 from graphql.execution import map_async_iterable
 
-
 try:  # pragma: no cover
-    anext
+    anext  # noqa: B018
 except NameError:  # pragma: no cover (Python < 3.10)
     # noinspection PyShadowingBuiltins
-    async def anext(iterator):
+    async def anext(iterator):  # noqa: A001
         """Return the next item from an async iterator."""
         return await iterator.__anext__()
 
 
 async def double(x: int) -> int:
     """Test callback that doubles the input value."""
     return x + x
@@ -19,30 +17,30 @@
 
 async def throw(_x: int) -> int:
     """Test callback that raises a RuntimeError."""
     raise RuntimeError("Ouch")
 
 
 def describe_map_async_iterable():
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def maps_over_async_generator():
         async def source():
             yield 1
             yield 2
             yield 3
 
         doubles = map_async_iterable(source(), double)
 
         assert await anext(doubles) == 2
         assert await anext(doubles) == 4
         assert await anext(doubles) == 6
-        with raises(StopAsyncIteration):
+        with pytest.raises(StopAsyncIteration):
             assert await anext(doubles)
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def maps_over_async_iterable():
         items = [1, 2, 3]
 
         class Iterable:
             def __aiter__(self):
                 return self
 
@@ -55,28 +53,28 @@
         doubles = map_async_iterable(Iterable(), double)
 
         values = [value async for value in doubles]
 
         assert not items
         assert values == [2, 4, 6]
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def compatible_with_async_for():
         async def source():
             yield 1
             yield 2
             yield 3
 
         doubles = map_async_iterable(source(), double)
 
         values = [value async for value in doubles]
 
         assert values == [2, 4, 6]
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def allows_returning_early_from_mapped_async_generator():
         async def source():
             yield 1
             yield 2
             yield 3  # pragma: no cover
 
         doubles = map_async_iterable(source(), double)
@@ -84,20 +82,20 @@
         assert await anext(doubles) == 2
         assert await anext(doubles) == 4
 
         # Early return
         await doubles.aclose()
 
         # Subsequent next calls
-        with raises(StopAsyncIteration):
+        with pytest.raises(StopAsyncIteration):
             await anext(doubles)
-        with raises(StopAsyncIteration):
+        with pytest.raises(StopAsyncIteration):
             await anext(doubles)
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def allows_returning_early_from_mapped_async_iterable():
         items = [1, 2, 3]
 
         class Iterable:
             def __aiter__(self):
                 return self
 
@@ -112,20 +110,20 @@
         assert await anext(doubles) == 2
         assert await anext(doubles) == 4
 
         # Early return
         await doubles.aclose()
 
         # Subsequent next calls
-        with raises(StopAsyncIteration):
+        with pytest.raises(StopAsyncIteration):
             await anext(doubles)
-        with raises(StopAsyncIteration):
+        with pytest.raises(StopAsyncIteration):
             await anext(doubles)
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def allows_throwing_errors_through_async_iterable():
         items = [1, 2, 3]
 
         class Iterable:
             def __aiter__(self):
                 return self
 
@@ -138,106 +136,81 @@
         doubles = map_async_iterable(Iterable(), double)
 
         assert await anext(doubles) == 2
         assert await anext(doubles) == 4
 
         # Throw error
         message = "allows throwing errors when mapping async iterable"
-        with raises(RuntimeError) as exc_info:
+        with pytest.raises(RuntimeError) as exc_info:
             await doubles.athrow(RuntimeError(message))
 
         assert str(exc_info.value) == message
 
-        with raises(StopAsyncIteration):
+        with pytest.raises(StopAsyncIteration):
             await anext(doubles)
-        with raises(StopAsyncIteration):
+        with pytest.raises(StopAsyncIteration):
             await anext(doubles)
 
-    @mark.asyncio
-    async def allows_throwing_errors_with_values_through_async_iterables():
-        class Iterable:
-            def __aiter__(self):
-                return self
-
-            async def __anext__(self):
-                return 1
-
-        one = map_async_iterable(Iterable(), double)
-
-        assert await anext(one) == 2
-
-        # Throw error with value passed separately
-        try:
-            raise RuntimeError("Ouch")
-        except RuntimeError as error:
-            with raises(RuntimeError, match="Ouch") as exc_info:
-                await one.athrow(error.__class__, error)
-
-            assert exc_info.value is error
-            assert exc_info.tb is error.__traceback__
-
-        with raises(StopAsyncIteration):
-            await anext(one)
-
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def allows_throwing_errors_with_traceback_through_async_iterables():
         class Iterable:
             def __aiter__(self):
                 return self
 
             async def __anext__(self):
                 return 1
 
         one = map_async_iterable(Iterable(), double)
 
         assert await anext(one) == 2
 
-        # Throw error with traceback passed separately
         try:
             raise RuntimeError("Ouch")
         except RuntimeError as error:
-            with raises(RuntimeError) as exc_info:
-                await one.athrow(error.__class__, None, error.__traceback__)
+            with pytest.raises(RuntimeError, match="Ouch") as exc_info:
+                await one.athrow(error)
 
-            assert exc_info.tb and error.__traceback__
-            assert exc_info.tb.tb_frame is error.__traceback__.tb_frame
+            assert exc_info.value is error  # noqa: PT017
+            assert exc_info.tb
+            assert error.__traceback__  # noqa: PT017
+            assert exc_info.tb is error.__traceback__  # noqa: PT017
 
-        with raises(StopAsyncIteration):
+        with pytest.raises(StopAsyncIteration):
             await anext(one)
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def does_not_map_over_thrown_errors():
         async def source():
             yield 1
             raise RuntimeError("Goodbye")
 
         doubles = map_async_iterable(source(), double)
 
         assert await anext(doubles) == 2
 
-        with raises(RuntimeError) as exc_info:
+        with pytest.raises(RuntimeError) as exc_info:
             await anext(doubles)
 
         assert str(exc_info.value) == "Goodbye"
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def does_not_map_over_externally_thrown_errors():
         async def source():
             yield 1
 
         doubles = map_async_iterable(source(), double)
 
         assert await anext(doubles) == 2
 
-        with raises(RuntimeError) as exc_info:
+        with pytest.raises(RuntimeError) as exc_info:
             await doubles.athrow(RuntimeError("Goodbye"))
 
         assert str(exc_info.value) == "Goodbye"
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def iterable_is_closed_when_mapped_iterable_is_closed():
         class Iterable:
             def __init__(self):
                 self.closed = False
 
             def __aiter__(self):
                 return self
@@ -250,18 +223,18 @@
 
         iterable = Iterable()
         doubles = map_async_iterable(iterable, double)
         assert await anext(doubles) == 2
         assert not iterable.closed
         await doubles.aclose()
         assert iterable.closed
-        with raises(StopAsyncIteration):
+        with pytest.raises(StopAsyncIteration):
             await anext(doubles)
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def iterable_is_closed_on_callback_error():
         class Iterable:
             def __init__(self):
                 self.closed = False
 
             def __aiter__(self):
                 return self
@@ -270,61 +243,61 @@
                 return 1
 
             async def aclose(self):
                 self.closed = True
 
         iterable = Iterable()
         doubles = map_async_iterable(iterable, throw)
-        with raises(RuntimeError, match="Ouch"):
+        with pytest.raises(RuntimeError, match="Ouch"):
             await anext(doubles)
         assert iterable.closed
-        with raises(StopAsyncIteration):
+        with pytest.raises(StopAsyncIteration):
             await anext(doubles)
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def iterable_exits_on_callback_error():
         exited = False
 
         async def iterable():
             nonlocal exited
             try:
                 while True:
                     yield 1
             except GeneratorExit:
                 exited = True
 
         doubles = map_async_iterable(iterable(), throw)
-        with raises(RuntimeError, match="Ouch"):
+        with pytest.raises(RuntimeError, match="Ouch"):
             await anext(doubles)
         assert exited
-        with raises(StopAsyncIteration):
+        with pytest.raises(StopAsyncIteration):
             await anext(doubles)
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def mapped_iterable_is_closed_when_iterable_cannot_be_closed():
         class Iterable:
             def __aiter__(self):
                 return self
 
             async def __anext__(self):
                 return 1
 
         doubles = map_async_iterable(Iterable(), double)
         assert await anext(doubles) == 2
         await doubles.aclose()
-        with raises(StopAsyncIteration):
+        with pytest.raises(StopAsyncIteration):
             await anext(doubles)
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def ignores_that_iterable_cannot_be_closed_on_callback_error():
         class Iterable:
             def __aiter__(self):
                 return self
 
             async def __anext__(self):
                 return 1
 
         doubles = map_async_iterable(Iterable(), throw)
-        with raises(RuntimeError, match="Ouch"):
+        with pytest.raises(RuntimeError, match="Ouch"):
             await anext(doubles)
-        with raises(StopAsyncIteration):
+        with pytest.raises(StopAsyncIteration):
             await anext(doubles)
```

### Comparing `graphql_core-3.3.0a3/tests/execution/test_middleware.py` & `graphql_core-3.3.0a4/tests/execution/test_middleware.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,11 +1,10 @@
 from typing import Awaitable, cast
 
-from pytest import mark, raises
-
+import pytest
 from graphql.execution import Middleware, MiddlewareManager, execute
 from graphql.language.parser import parse
 from graphql.type import GraphQLField, GraphQLObjectType, GraphQLSchema, GraphQLString
 
 
 def describe_middleware():
     def describe_with_manager():
@@ -86,15 +85,15 @@
             middlewares = MiddlewareManager(reverse_middleware, capitalize_middleware)
             result = execute(
                 GraphQLSchema(test_type), doc, Data(), middleware=middlewares
             )
 
             assert result.data == {"first": "Eno", "second": "Owt"}  # type: ignore
 
-        @mark.asyncio
+        @pytest.mark.asyncio()
         async def single_async_function():
             doc = parse("{ first second }")
 
             # noinspection PyMethodMayBeStatic
             class Data:
                 async def first(self, _info):
                     return "one"
@@ -196,15 +195,15 @@
 
             middlewares = MiddlewareManager(CaptitalizeMiddleware(), reverse_middleware)
             result = execute(
                 GraphQLSchema(test_type), doc, Data(), middleware=middlewares
             )
             assert result.data == {"field": "devloseR"}  # type: ignore
 
-        @mark.asyncio
+        @pytest.mark.asyncio()
         async def with_async_function_and_object():
             doc = parse("{ field }")
 
             # noinspection PyMethodMayBeStatic
             class Data:
                 async def field(self, _info):
                     return "resolved"
@@ -273,15 +272,15 @@
         def bad_middleware_object():
             doc = parse("{ field }")
 
             test_type = GraphQLObjectType(
                 "TestType", {"field": GraphQLField(GraphQLString)}
             )
 
-            with raises(TypeError) as exc_info:
+            with pytest.raises(TypeError) as exc_info:
                 # noinspection PyTypeChecker
                 execute(
                     GraphQLSchema(test_type),
                     doc,
                     None,
                     middleware=cast(Middleware, {"bad": "value"}),
                 )
```

### Comparing `graphql_core-3.3.0a3/tests/execution/test_mutations.py` & `graphql_core-3.3.0a4/tests/execution/test_mutations.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,12 +1,11 @@
 from asyncio import sleep
 from typing import Any, Awaitable, List
 
-from pytest import mark
-
+import pytest
 from graphql.execution import (
     ExperimentalIncrementalExecutionResults,
     execute,
     execute_sync,
     experimental_execute_incrementally,
 )
 from graphql.language import parse
@@ -101,15 +100,15 @@
             ),
         },
     ),
 )
 
 
 def describe_execute_handles_mutation_execution_ordering():
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def evaluates_mutations_serially():
         document = parse(
             """
             mutation M {
               first: immediatelyChangeTheNumber(newNumber: 1) {
                 theNumber
               },
@@ -149,15 +148,15 @@
 
     def does_not_include_illegal_mutation_fields_in_output():
         document = parse("mutation { thisIsIllegalDoNotIncludeMe }")
 
         result = execute_sync(schema=schema, document=document)
         assert result == ({}, None)
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def evaluates_mutations_correctly_in_presence_of_a_failed_mutation():
         document = parse(
             """
             mutation M {
               first: immediatelyChangeTheNumber(newNumber: 1) {
                 theNumber
               },
@@ -206,15 +205,15 @@
                     "message": "Cannot change the number to 6",
                     "locations": [(18, 15)],
                     "path": ["sixth"],
                 },
             ],
         )
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def mutation_fields_with_defer_do_not_block_next_mutation():
         document = parse(
             """
             mutation M {
               first: promiseToChangeTheNumber(newNumber: 1) {
                 ...DeferFragment @defer(label: "defer-label")
               },
@@ -251,15 +250,15 @@
                         },
                     },
                 ],
                 "hasNext": False,
             },
         ]
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def mutation_inside_of_a_fragment():
         document = parse(
             """
             mutation M {
               ...MutationFragment
               second: immediatelyChangeTheNumber(newNumber: 2) {
                 theNumber
@@ -277,15 +276,15 @@
         mutation_result = await execute(schema, document, root_value)  # type: ignore
 
         assert mutation_result == (
             {"first": {"theNumber": 1}, "second": {"theNumber": 2}},
             None,
         )
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def mutation_with_defer_is_not_executed_serially():
         document = parse(
             """
             mutation M {
               ...MutationFragment @defer(label: "defer-label")
               second: immediatelyChangeTheNumber(newNumber: 2) {
                 theNumber
```

### Comparing `graphql_core-3.3.0a3/tests/execution/test_nonnull.py` & `graphql_core-3.3.0a4/tests/execution/test_nonnull.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,27 +1,25 @@
 import asyncio
 import re
 from typing import Any, Awaitable, cast
 
-from pytest import mark
-
+import pytest
 from graphql.execution import ExecutionResult, execute, execute_sync
 from graphql.language import parse
 from graphql.pyutils import AwaitableOrValue
 from graphql.type import (
     GraphQLArgument,
     GraphQLField,
     GraphQLNonNull,
     GraphQLObjectType,
     GraphQLSchema,
     GraphQLString,
 )
 from graphql.utilities import build_schema
 
-
 sync_error = RuntimeError("sync")
 sync_non_null_error = RuntimeError("syncNonNull")
 promise_error = RuntimeError("promise")
 promise_non_null_error = RuntimeError("promiseNonNull")
 
 
 # noinspection PyPep8Naming,PyMethodMayBeStatic
@@ -123,20 +121,20 @@
     def describe_nulls_a_nullable_field():
         query = """
             {
               sync
             }
             """
 
-        @mark.asyncio
+        @pytest.mark.asyncio()
         async def returns_null():
             result = await execute_sync_and_async(query, NullingData())
             assert result == ({"sync": None}, None)
 
-        @mark.asyncio
+        @pytest.mark.asyncio()
         async def throws():
             result = await execute_sync_and_async(query, ThrowingData())
             assert result == (
                 {"sync": None},
                 [
                     {
                         "message": str(sync_error),
@@ -151,30 +149,30 @@
             {
               syncNest {
                 syncNonNull,
               }
             }
             """
 
-        @mark.asyncio
+        @pytest.mark.asyncio()
         async def that_returns_null():
             result = await execute_sync_and_async(query, NullingData())
             assert result == (
                 {"syncNest": None},
                 [
                     {
                         "message": "Cannot return null for non-nullable field"
                         " DataType.syncNonNull.",
                         "path": ["syncNest", "syncNonNull"],
                         "locations": [(4, 17)],
                     }
                 ],
             )
 
-        @mark.asyncio
+        @pytest.mark.asyncio()
         async def that_throws():
             result = await execute_sync_and_async(query, ThrowingData())
             assert result == (
                 {"syncNest": None},
                 [
                     {
                         "message": str(sync_non_null_error),
@@ -212,22 +210,22 @@
                 "sync": None,
                 "promise": None,
                 "syncNest": {"sync": None, "promise": None},
                 "promiseNest": {"sync": None, "promise": None},
             },
         }
 
-        @mark.asyncio
+        @pytest.mark.asyncio()
         async def returns_null():
             result = await cast(
                 Awaitable[ExecutionResult], execute_query(query, NullingData())
             )
             assert result == (data, None)
 
-        @mark.asyncio
+        @pytest.mark.asyncio()
         async def throws():
             result = await cast(
                 Awaitable[ExecutionResult], execute_query(query, ThrowingData())
             )
             assert result == (
                 data,
                 [
@@ -346,15 +344,15 @@
         data = {
             "syncNest": None,
             "promiseNest": None,
             "anotherNest": None,
             "anotherPromiseNest": None,
         }
 
-        @mark.asyncio
+        @pytest.mark.asyncio()
         async def returns_null():
             result = await cast(
                 Awaitable[ExecutionResult], execute_query(query, NullingData())
             )
             assert result == (
                 data,
                 [
@@ -409,15 +407,15 @@
                             "promiseNonNull",
                         ],
                         "locations": [(41, 25)],
                     },
                 ],
             )
 
-        @mark.asyncio
+        @pytest.mark.asyncio()
         async def throws():
             result = await cast(
                 Awaitable[ExecutionResult], execute_query(query, ThrowingData())
             )
             assert result == (
                 data,
                 [
@@ -475,15 +473,15 @@
     def describe_nulls_the_top_level_if_non_nullable_field():
         query = """
             {
                 syncNonNull
             }
             """
 
-        @mark.asyncio
+        @pytest.mark.asyncio()
         async def returns_null():
             result = await execute_sync_and_async(query, NullingData())
             await asyncio.sleep(0)  # strangely needed to get coverage on Python 3.11
             assert result == (
                 None,
                 [
                     {
@@ -491,15 +489,15 @@
                         " DataType.syncNonNull.",
                         "path": ["syncNonNull"],
                         "locations": [(3, 17)],
                     }
                 ],
             )
 
-        @mark.asyncio
+        @pytest.mark.asyncio()
         async def throws():
             result = await execute_sync_and_async(query, ThrowingData())
             await asyncio.sleep(0)  # strangely needed to get coverage on Python 3.11
             assert result == (
                 None,
                 [
                     {
```

### Comparing `graphql_core-3.3.0a3/tests/execution/test_parallel.py` & `graphql_core-3.3.0a4/tests/execution/test_parallel.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,12 +1,11 @@
 import asyncio
 from typing import Awaitable
 
-from pytest import mark
-
+import pytest
 from graphql.execution import execute
 from graphql.language import parse
 from graphql.type import (
     GraphQLBoolean,
     GraphQLField,
     GraphQLInt,
     GraphQLInterfaceType,
@@ -28,15 +27,15 @@
         self.number -= 1
         if not self.number:
             self.event.set()
         return await self.event.wait()
 
 
 def describe_parallel_execution():
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def resolve_single_field():
         # make sure that the special case of resolving a single field works
         async def resolve(*_args):
             return True
 
         schema = GraphQLSchema(
             GraphQLObjectType(
@@ -49,15 +48,15 @@
 
         awaitable_result = execute(schema, parse("{foo}"))
         assert isinstance(awaitable_result, Awaitable)
         result = await awaitable_result
 
         assert result == ({"foo": True}, None)
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def resolve_fields_in_parallel():
         barrier = Barrier(2)
 
         async def resolve(*_args):
             return await barrier.wait()
 
         schema = GraphQLSchema(
@@ -75,15 +74,15 @@
         # raises TimeoutError if not parallel
         awaitable_result = execute(schema, ast)
         assert isinstance(awaitable_result, Awaitable)
         result = await asyncio.wait_for(awaitable_result, 1.0)
 
         assert result == ({"foo": True, "bar": True}, None)
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def resolve_single_element_list():
         # make sure that the special case of resolving a single element list works
         async def resolve(*_args):
             return [True]
 
         schema = GraphQLSchema(
             GraphQLObjectType(
@@ -94,15 +93,15 @@
 
         awaitable_result = execute(schema, parse("{foo}"))
         assert isinstance(awaitable_result, Awaitable)
         result = await awaitable_result
 
         assert result == ({"foo": [True]}, None)
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def resolve_list_in_parallel():
         barrier = Barrier(2)
 
         async def resolve(*_args):
             return await barrier.wait()
 
         async def resolve_list(*args):
@@ -124,15 +123,15 @@
         # raises TimeoutError if not parallel
         awaitable_result = execute(schema, ast)
         assert isinstance(awaitable_result, Awaitable)
         result = await asyncio.wait_for(awaitable_result, 1.0)
 
         assert result == ({"foo": [True, True]}, None)
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def resolve_is_type_of_in_parallel():
         FooType = GraphQLInterfaceType("Foo", {"foo": GraphQLField(GraphQLString)})
 
         barrier = Barrier(4)
 
         async def is_type_of_bar(obj, *_args):
             await barrier.wait()
```

### Comparing `graphql_core-3.3.0a3/tests/execution/test_resolve.py` & `graphql_core-3.3.0a4/tests/execution/test_resolve.py`

 * *Files 1% similar despite different names*

```diff
@@ -50,15 +50,15 @@
             schema=_test_schema(GraphQLField(GraphQLString)),
             document=parse("{ test }"),
             root_value=root_value,
         ) == ({"test": "testValue"}, None)
 
     def default_function_calls_methods():
         class RootValue:
-            _secret = "secretValue"
+            _secret = "secretValue"  # noqa: S105
 
             def test(self, _info):
                 return self._secret
 
         assert execute_sync(
             schema=_test_schema(GraphQLField(GraphQLString)),
             document=parse("{ test }"),
@@ -104,15 +104,15 @@
         schema = _test_schema(
             GraphQLField(
                 GraphQLString,
                 args={
                     "aStr": GraphQLArgument(GraphQLString),
                     "aInt": GraphQLArgument(GraphQLInt),
                 },
-                resolve=lambda source, info, **args: repr([source, args]),
+                resolve=lambda source, _info, **args: repr([source, args]),
             )
         )
 
         def execute_query(query: str, root_value: Any = None) -> ExecutionResult:
             document = parse(query)
             return execute_sync(
                 schema=schema,
@@ -142,15 +142,15 @@
         schema = _test_schema(
             GraphQLField(
                 GraphQLString,
                 args={
                     "aStr": GraphQLArgument(GraphQLString, out_name="a_str"),
                     "aInt": GraphQLArgument(GraphQLInt, out_name="a_int"),
                 },
-                resolve=lambda source, info, **args: repr([source, args]),
+                resolve=lambda source, _info, **args: repr([source, args]),
             )
         )
 
         def execute_query(query: str, root_value: Any = None) -> ExecutionResult:
             document = parse(query)
             return execute_sync(schema=schema, document=document, root_value=root_value)
 
@@ -183,15 +183,15 @@
             },
         )
 
         schema = _test_schema(
             GraphQLField(
                 GraphQLString,
                 args={"aInput": GraphQLArgument(TestInputObject, out_name="a_input")},
-                resolve=lambda source, info, **args: repr([source, args]),
+                resolve=lambda source, _info, **args: repr([source, args]),
             )
         )
 
         def execute_query(query: str, root_value: Any = None) -> ExecutionResult:
             document = parse(query)
             return execute_sync(schema=schema, document=document, root_value=root_value)
```

### Comparing `graphql_core-3.3.0a3/tests/execution/test_schema.py` & `graphql_core-3.3.0a4/tests/execution/test_schema.py`

 * *Files 3% similar despite different names*

```diff
@@ -16,15 +16,15 @@
 )
 
 
 def describe_execute_handles_execution_with_a_complex_schema():
     def executes_using_a_schema():
         class Article:
             # noinspection PyShadowingBuiltins
-            def __init__(self, id: int):
+            def __init__(self, id: int):  # noqa: A002
                 self.id = id
                 self.isPublished = True
                 self.author = JohnSmith()
                 self.title = f"My Article {id}"
                 self.body = "This is a post"
                 self.hidden = "This data is not exposed in the schema"
                 self.keywords = ["foo", "bar", 1, True, None]
@@ -74,28 +74,28 @@
         # noinspection PyShadowingBuiltins
         BlogQuery = GraphQLObjectType(
             "Query",
             {
                 "article": GraphQLField(
                     BlogArticle,
                     args={"id": GraphQLArgument(GraphQLID)},
-                    resolve=lambda _obj, _info, id: Article(id),
+                    resolve=lambda _obj, _info, id: Article(id),  # noqa: A002
                 ),
                 "feed": GraphQLField(
                     GraphQLList(BlogArticle),
                     resolve=lambda *_args: [Article(n + 1) for n in range(10)],
                 ),
             },
         )
 
         BlogSchema = GraphQLSchema(BlogQuery)
 
         # noinspection PyPep8Naming,PyMethodMayBeStatic
         class Author:
-            def pic(self, info_, width: int, height: int) -> Pic:
+            def pic(self, _info, width: int, height: int) -> Pic:
                 return Pic(123, width, height)
 
             @property
             def recentArticle(self) -> Article:
                 return Article(1)
 
         class JohnSmith(Author):
```

### Comparing `graphql_core-3.3.0a3/tests/execution/test_stream.py` & `graphql_core-3.3.0a4/tests/execution/test_stream.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,12 +1,11 @@
 from asyncio import Event, Lock, gather, sleep
 from typing import Any, Awaitable, Dict, List, NamedTuple
 
-from pytest import mark, raises
-
+import pytest
 from graphql.error import GraphQLError
 from graphql.execution import (
     ExecutionContext,
     ExecutionResult,
     ExperimentalIncrementalExecutionResults,
     IncrementalStreamResult,
     experimental_execute_incrementally,
@@ -20,20 +19,19 @@
     GraphQLList,
     GraphQLNonNull,
     GraphQLObjectType,
     GraphQLSchema,
     GraphQLString,
 )
 
-
 try:  # pragma: no cover
-    anext
+    anext  # noqa: B018
 except NameError:  # pragma: no cover (Python < 3.10)
     # noinspection PyShadowingBuiltins
-    async def anext(iterator):
+    async def anext(iterator):  # noqa: A001
         """Return the next item from an async iterator."""
         return await iterator.__anext__()
 
 
 friend_type = GraphQLObjectType(
     "Friend",
     {
@@ -41,19 +39,19 @@
         "name": GraphQLField(GraphQLString),
         "nonNullName": GraphQLField(GraphQLNonNull(GraphQLString)),
     },
 )
 
 
 class Friend(NamedTuple):
-    name: str
     id: int
+    name: str
 
 
-friends = [Friend("Luke", 1), Friend("Han", 2), Friend("Leia", 3)]
+friends = [Friend(1, "Luke"), Friend(2, "Han"), Friend(3, "Leia")]
 
 query = GraphQLObjectType(
     "Query",
     {
         "scalarList": GraphQLField(GraphQLList(GraphQLString)),
         "scalarListList": GraphQLField(GraphQLList(GraphQLList(GraphQLString))),
         "friendList": GraphQLField(GraphQLList(friend_type)),
@@ -215,15 +213,15 @@
         assert result != (["hello", "world"], [])
         assert result == args
         assert result == dict(list(args.items())[:2])
         assert result == dict(list(args.items())[:3])
         assert result != dict(list(args.items())[:2] + [("path", ["foo", 2])])
         assert result != {**args, "label": "baz"}
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def can_stream_a_list_field():
         document = parse("{ scalarList @stream(initialCount: 1) }")
         result = await complete(
             document, {"scalarList": ["apple", "banana", "coconut"]}
         )
         assert result == [
             {
@@ -238,15 +236,15 @@
             },
             {
                 "incremental": [{"items": ["coconut"], "path": ["scalarList", 2]}],
                 "hasNext": False,
             },
         ]
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def can_use_default_value_of_initial_count():
         document = parse("{ scalarList @stream }")
         result = await complete(
             document, {"scalarList": ["apple", "banana", "coconut"]}
         )
         assert result == [
             {
@@ -265,15 +263,15 @@
             },
             {
                 "incremental": [{"items": ["coconut"], "path": ["scalarList", 2]}],
                 "hasNext": False,
             },
         ]
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def negative_values_of_initial_count_throw_field_errors():
         document = parse("{ scalarList @stream(initialCount: -2) }")
         result = await complete(
             document, {"scalarList": ["apple", "banana", "coconut"]}
         )
         assert result == {
             "data": {
@@ -284,15 +282,15 @@
                     "message": "initialCount must be a positive integer",
                     "locations": [{"line": 1, "column": 3}],
                     "path": ["scalarList"],
                 }
             ],
         }
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def non_integer_values_of_initial_count_throw_field_errors():
         document = parse("{ scalarList @stream(initialCount: 1.5) }")
         result = await complete(document, {"scalarList": ["apple", "half of a banana"]})
         assert result == {
             "data": {
                 "scalarList": None,
             },
@@ -301,15 +299,15 @@
                     "message": "Argument 'initialCount' has invalid value 1.5.",
                     "locations": [{"line": 1, "column": 36}],
                     "path": ["scalarList"],
                 }
             ],
         }
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def returns_label_from_stream_directive():
         document = parse(
             '{ scalarList @stream(initialCount: 1, label: "scalar-stream") }'
         )
         result = await complete(
             document, {"scalarList": ["apple", "banana", "coconut"]}
         )
@@ -338,15 +336,15 @@
                         "label": "scalar-stream",
                     }
                 ],
                 "hasNext": False,
             },
         ]
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def throws_an_error_for_stream_directive_with_non_string_label():
         document = parse("{ scalarList @stream(initialCount: 1, label: 42) }")
         result = await complete(document, {"scalarList": ["some apples"]})
         assert result == {
             "data": {"scalarList": None},
             "errors": [
                 {
@@ -358,27 +356,27 @@
                     ],
                     "message": "Argument 'label' has invalid value 42.",
                     "path": ["scalarList"],
                 }
             ],
         }
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def can_disable_stream_using_if_argument():
         document = parse("{ scalarList @stream(initialCount: 0, if: false) }")
         result = await complete(
             document, {"scalarList": ["apple", "banana", "coconut"]}
         )
         assert result == {
             "data": {
                 "scalarList": ["apple", "banana", "coconut"],
             },
         }
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def does_not_disable_stream_with_null_if_argument():
         document = parse(
             "query ($shouldStream: Boolean)"
             " { scalarList @stream(initialCount: 2, if: $shouldStream) }"
         )
         result = await complete(
             document, {"scalarList": ["apple", "banana", "coconut"]}
@@ -397,15 +395,15 @@
                         "path": ["scalarList", 2],
                     }
                 ],
                 "hasNext": False,
             },
         ]
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def can_stream_multi_dimensional_lists():
         document = parse("{ scalarListList @stream(initialCount: 1) }")
         result = await complete(
             document,
             {
                 "scalarListList": lambda _info: [
                     ["apple", "apple", "apple"],
@@ -437,15 +435,15 @@
                         "path": ["scalarListList", 2],
                     }
                 ],
                 "hasNext": False,
             },
         ]
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def can_stream_a_field_that_returns_a_list_of_awaitables():
         document = parse(
             """
             query {
               friendList @stream(initialCount: 2) {
                 name
                 id
@@ -479,15 +477,15 @@
                         "path": ["friendList", 2],
                     }
                 ],
                 "hasNext": False,
             },
         ]
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def can_stream_in_correct_order_with_list_of_awaitables():
         document = parse(
             """
             query {
               friendList @stream(initialCount: 0) {
                 name
                 id
@@ -534,15 +532,63 @@
                         "path": ["friendList", 2],
                     }
                 ],
                 "hasNext": False,
             },
         ]
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
+    async def can_stream_a_field_that_returns_a_list_with_nested_async_fields():
+        document = parse(
+            """
+            query {
+              friendList @stream(initialCount: 2) {
+                name
+                id
+              }
+            }
+            """
+        )
+
+        async def get_name(f):
+            return f.name
+
+        async def get_id(f):
+            return f.id
+
+        result = await complete(
+            document,
+            {
+                "friendList": lambda _info: [
+                    {"name": get_name(f), "id": get_id(f)} for f in friends
+                ]
+            },
+        )
+        assert result == [
+            {
+                "data": {
+                    "friendList": [
+                        {"name": "Luke", "id": "1"},
+                        {"name": "Han", "id": "2"},
+                    ]
+                },
+                "hasNext": True,
+            },
+            {
+                "incremental": [
+                    {
+                        "items": [{"name": "Leia", "id": "3"}],
+                        "path": ["friendList", 2],
+                    }
+                ],
+                "hasNext": False,
+            },
+        ]
+
+    @pytest.mark.asyncio()
     async def handles_error_in_list_of_awaitables_before_initial_count_reached():
         document = parse(
             """
             query {
               friendList @stream(initialCount: 2) {
                 name
                 id
@@ -584,15 +630,15 @@
                         "path": ["friendList", 2],
                     }
                 ],
                 "hasNext": False,
             },
         ]
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def handles_error_in_list_of_awaitables_after_initial_count_reached():
         document = parse(
             """
             query {
               friendList @stream(initialCount: 1) {
                 name
                 id
@@ -643,15 +689,15 @@
                         "path": ["friendList", 2],
                     }
                 ],
                 "hasNext": False,
             },
         ]
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def can_stream_a_field_that_returns_an_async_iterable():
         document = parse(
             """
             query {
               friendList @stream {
                 name
                 id
@@ -696,15 +742,15 @@
                         "path": ["friendList", 2],
                     }
                 ],
                 "hasNext": False,
             },
         ]
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def can_stream_a_field_that_returns_an_async_iterable_with_initial_count():
         document = parse(
             """
             query {
               friendList @stream(initialCount: 2) {
                 name
                 id
@@ -736,15 +782,15 @@
                         "path": ["friendList", 2],
                     }
                 ],
                 "hasNext": False,
             },
         ]
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def negative_initial_count_throw_error_on_field_returning_async_iterable():
         document = parse(
             """
             query {
               friendList @stream(initialCount: -2) {
                 name
                 id
@@ -764,15 +810,15 @@
                     "locations": [{"line": 3, "column": 15}],
                     "path": ["friendList"],
                 }
             ],
             "data": {"friendList": None},
         }
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def can_handle_concurrent_calls_to_next_without_waiting():
         document = parse(
             """
             query {
               friendList @stream(initialCount: 2) {
                 name
                 id
@@ -812,15 +858,15 @@
                     "hasNext": False,
                 },
             },
             {"done": True, "value": None},
             {"done": True, "value": None},
         ]
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def handles_error_in_async_iterable_before_initial_count_is_reached():
         document = parse(
             """
             query {
               friendList @stream(initialCount: 2) {
                 name
                 id
@@ -843,15 +889,15 @@
                     "locations": [{"line": 3, "column": 15}],
                     "path": ["friendList", 1],
                 }
             ],
             "data": {"friendList": [{"name": "Luke", "id": "1"}, None]},
         }
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def handles_error_in_async_iterable_after_initial_count_is_reached():
         document = parse(
             """
             query {
               friendList @stream(initialCount: 1) {
                 name
                 id
@@ -888,15 +934,15 @@
                         ],
                     },
                 ],
                 "hasNext": False,
             },
         ]
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def handles_null_for_non_null_list_items_after_initial_count_is_reached():
         document = parse(
             """
             query {
               nonNullFriendList @stream(initialCount: 1) {
                 name
               }
@@ -929,15 +975,15 @@
                         ],
                     },
                 ],
                 "hasNext": False,
             },
         ]
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def handles_null_for_non_null_async_items_after_initial_count_is_reached():
         document = parse(
             """
             query {
               nonNullFriendList @stream(initialCount: 1) {
                 name
               }
@@ -977,15 +1023,15 @@
                         ],
                     },
                 ],
                 "hasNext": False,
             },
         ]
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def handles_error_thrown_in_complete_value_after_initial_count_is_reached():
         document = parse(
             """
             query {
               scalarList @stream(initialCount: 1)
             }
             """
@@ -1016,19 +1062,81 @@
                         ],
                     },
                 ],
                 "hasNext": False,
             },
         ]
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def handles_async_error_in_complete_value_after_initial_count_is_reached():
         document = parse(
             """
             query {
+              friendList @stream(initialCount: 1) {
+                nonNullName
+              }
+            }
+            """
+        )
+
+        async def throw():
+            raise RuntimeError("Oops")
+
+        async def get_friend(i):
+            await sleep(0)
+            return {"nonNullName": throw() if i < 0 else friends[i].name}
+
+        def get_friends(_info):
+            return [get_friend(0), get_friend(-1), get_friend(1)]
+
+        result = await complete(
+            document,
+            {
+                "friendList": get_friends,
+            },
+        )
+        assert result == [
+            {
+                "data": {
+                    "friendList": [{"nonNullName": "Luke"}],
+                },
+                "hasNext": True,
+            },
+            {
+                "incremental": [
+                    {
+                        "items": [None],
+                        "path": ["friendList", 1],
+                        "errors": [
+                            {
+                                "message": "Oops",
+                                "locations": [{"line": 4, "column": 17}],
+                                "path": ["friendList", 1, "nonNullName"],
+                            },
+                        ],
+                    },
+                ],
+                "hasNext": True,
+            },
+            {
+                "incremental": [
+                    {
+                        "items": [{"nonNullName": "Han"}],
+                        "path": ["friendList", 2],
+                    },
+                ],
+                "hasNext": False,
+            },
+        ]
+
+    @pytest.mark.asyncio()
+    async def handles_async_error_in_complete_value_for_non_nullable_list():
+        document = parse(
+            """
+            query {
               nonNullFriendList @stream(initialCount: 1) {
                 nonNullName
               }
             }
             """
         )
 
@@ -1069,15 +1177,15 @@
                         ],
                     },
                 ],
                 "hasNext": False,
             },
         ]
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def handles_async_error_after_initial_count_reached_from_async_iterable():
         document = parse(
             """
             query {
               friendList @stream(initialCount: 1) {
                 nonNullName
               }
@@ -1133,15 +1241,15 @@
                         "path": ["friendList", 2],
                     },
                 ],
                 "hasNext": False,
             },
         ]
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def filters_payloads_that_are_nulled():
         document = parse(
             """
             query {
               nestedObject {
                 nonNullScalarField
                 nestedFriendList @stream(initialCount: 0) {
@@ -1150,15 +1258,14 @@
               }
             }
             """
         )
 
         async def resolve_null(_info):
             await sleep(0)
-            return None
 
         async def friend_list(_info):
             await sleep(0)
             yield friends[0]
 
         result = await complete(
             document,
@@ -1185,15 +1292,59 @@
                 },
             ],
             "data": {
                 "nestedObject": None,
             },
         }
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
+    async def filters_payloads_that_are_nulled_by_a_later_synchronous_error():
+        document = parse(
+            """
+            query {
+              nestedObject {
+                nestedFriendList @stream(initialCount: 0) {
+                  name
+                }
+                nonNullScalarField
+              }
+            }
+            """
+        )
+
+        async def friend_list(_info):
+            await sleep(0)  # pragma: no cover
+            yield friends[0]  # pragma: no cover
+
+        result = await complete(
+            document,
+            {
+                "nestedObject": {
+                    "nestedFriendList": friend_list,
+                    "nonNullScalarField": lambda _info: None,
+                }
+            },
+        )
+
+        assert result == {
+            "errors": [
+                {
+                    "message": "Cannot return null for non-nullable field"
+                    " NestedObject.nonNullScalarField.",
+                    "locations": [{"line": 7, "column": 17}],
+                    "path": ["nestedObject", "nonNullScalarField"],
+                },
+            ],
+            "data": {
+                "nestedObject": None,
+            },
+        }
+
+    @pytest.mark.asyncio()
+    @pytest.mark.filterwarnings("ignore:.* was never awaited:RuntimeWarning")
     async def does_not_filter_payloads_when_null_error_is_in_a_different_path():
         document = parse(
             """
             query {
               otherNestedObject: nestedObject {
                 ... @defer {
                   scalarField
@@ -1252,15 +1403,16 @@
                         "path": ["nestedObject", "nestedFriendList", 0],
                     },
                 ],
                 "hasNext": False,
             },
         ]
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
+    @pytest.mark.filterwarnings("ignore:.* was never awaited:RuntimeWarning")
     async def filters_stream_payloads_that_are_nulled_in_a_deferred_payload():
         document = parse(
             """
             query {
               nestedObject {
                 ... @defer {
                   deeperNestedObject {
@@ -1273,15 +1425,14 @@
               }
             }
             """
         )
 
         async def resolve_null(_info):
             await sleep(0)
-            return None
 
         async def friend_list(_info):
             await sleep(0)
             yield friends[0]
 
         result = await complete(
             document,
@@ -1323,15 +1474,15 @@
                         ],
                     },
                 ],
                 "hasNext": False,
             },
         ]
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def filters_defer_payloads_that_are_nulled_in_a_stream_response():
         document = parse(
             """
             query {
               friendList @stream(initialCount: 0) {
                 nonNullName
                 ... @defer {
@@ -1340,15 +1491,14 @@
               }
             }
             """
         )
 
         async def resolve_null(_info):
             await sleep(0)
-            return None
 
         async def friend():
             await sleep(0)
             return {
                 "name": friends[0].name,
                 "nonNullName": resolve_null,
             }
@@ -1381,22 +1531,21 @@
                         ],
                     },
                 ],
                 "hasNext": False,
             },
         ]
 
-    @mark.timeout(1)
-    @mark.asyncio
+    @pytest.mark.timeout(1)
+    @pytest.mark.asyncio()
     async def returns_iterator_and_ignores_error_when_stream_payloads_are_filtered():
         finished = False
 
         async def resolve_null(_info):
             await sleep(0)
-            return None
 
         async def iterable(_info):
             nonlocal finished
             for i in range(3):
                 await sleep(0)
                 friend = friends[i]
                 yield {"name": friend.name, "nonNullName": None}
@@ -1457,20 +1606,20 @@
                         },
                     ],
                 },
             ],
             "hasNext": False,
         }
 
-        with raises(StopAsyncIteration):
+        with pytest.raises(StopAsyncIteration):
             await anext(iterator)
 
         assert not finished  # running iterator cannot be canceled
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def handles_awaitables_from_complete_value_after_initial_count_is_reached():
         document = parse(
             """
             query {
               friendList @stream(initialCount: 1) {
                 id
                 name
@@ -1522,15 +1671,15 @@
                         "path": ["friendList", 2],
                     }
                 ],
                 "hasNext": False,
             },
         ]
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def returns_payloads_properly_when_parent_deferred_slower_than_stream():
         resolve_slow_field = Event()
 
         async def slow_field(_info):
             await resolve_slow_field.wait()
             return "slow"
 
@@ -1600,19 +1749,19 @@
                     "items": [{"name": "Han"}],
                     "path": ["nestedObject", "nestedFriendList", 1],
                 },
             ],
             "hasNext": False,
         }
 
-        with raises(StopAsyncIteration):
+        with pytest.raises(StopAsyncIteration):
             await anext(iterator)
 
-    @mark.timeout(1)
-    @mark.asyncio
+    @pytest.mark.timeout(1)
+    @pytest.mark.asyncio()
     async def can_defer_fields_that_are_resolved_after_async_iterable_is_complete():
         resolve_slow_field = Event()
         resolve_iterable = Event()
 
         async def slow_field(_info):
             await resolve_slow_field.wait()
             return "Han"
@@ -1679,18 +1828,18 @@
                     "path": ["friendList", 1],
                     "label": "DeferName",
                 },
             ],
             "hasNext": False,
         }
 
-        with raises(StopAsyncIteration):
+        with pytest.raises(StopAsyncIteration):
             await anext(iterator)
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def can_defer_fields_that_are_resolved_before_async_iterable_is_complete():
         resolve_slow_field = Event()
         resolve_iterable = Event()
 
         async def slow_field(_info):
             await resolve_slow_field.wait()
             return "Han"
@@ -1763,18 +1912,18 @@
 
         resolve_iterable.set()
         result4 = await anext(iterator)
         assert result4.formatted == {
             "hasNext": False,
         }
 
-        with raises(StopAsyncIteration):
+        with pytest.raises(StopAsyncIteration):
             await anext(iterator)
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def finishes_async_iterable_when_returned_generator_is_closed():
         finished = False
 
         async def iterable(_info):
             nonlocal finished
             for i in range(3):
                 await sleep(0)
@@ -1800,20 +1949,21 @@
         assert isinstance(execute_result, ExperimentalIncrementalExecutionResults)
         iterator = execute_result.subsequent_results
 
         result1 = execute_result.initial_result
         assert result1 == {"data": {"friendList": [{"id": "1"}]}, "hasNext": True}
 
         await iterator.aclose()
-        with raises(StopAsyncIteration):
+        with pytest.raises(StopAsyncIteration):
             await anext(iterator)
 
+        await sleep(0)
         assert finished
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def finishes_async_iterable_when_underlying_iterator_has_no_close_method():
         class Iterable:
             def __init__(self):
                 self.index = 0
 
             def __aiter__(self):
                 return self
@@ -1849,20 +1999,22 @@
         result1 = execute_result.initial_result
         assert result1 == {
             "data": {"friendList": [{"id": "1", "name": "Luke"}]},
             "hasNext": True,
         }
 
         await iterator.aclose()
-        with raises(StopAsyncIteration):
+        with pytest.raises(StopAsyncIteration):
             await anext(iterator)
 
+        await sleep(0)
+        await sleep(0)
         assert iterable.index == 4
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def finishes_async_iterable_when_error_is_raised_in_returned_generator():
         finished = False
 
         async def iterable(_info):
             nonlocal finished
             for i in range(3):
                 await sleep(0)
@@ -1887,14 +2039,15 @@
         )
         assert isinstance(execute_result, ExperimentalIncrementalExecutionResults)
         iterator = execute_result.subsequent_results
 
         result1 = execute_result.initial_result
         assert result1 == {"data": {"friendList": [{"id": "1"}]}, "hasNext": True}
 
-        with raises(RuntimeError, match="bad"):
+        with pytest.raises(RuntimeError, match="bad"):
             await iterator.athrow(RuntimeError("bad"))
 
-        with raises(StopAsyncIteration):
+        with pytest.raises(StopAsyncIteration):
             await anext(iterator)
 
+        await sleep(0)
         assert finished
```

### Comparing `graphql_core-3.3.0a3/tests/execution/test_subscribe.py` & `graphql_core-3.3.0a4/tests/execution/test_subscribe.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,22 +1,22 @@
 import asyncio
+from contextlib import suppress
 from typing import (
     Any,
     AsyncIterable,
     AsyncIterator,
     Callable,
     Dict,
     List,
     Optional,
     TypeVar,
     Union,
 )
 
-from pytest import mark, raises
-
+import pytest
 from graphql.execution import (
     ExecutionResult,
     create_source_event_stream,
     experimental_subscribe_incrementally,
     subscribe,
 )
 from graphql.language import DocumentNode, parse
@@ -32,25 +32,24 @@
     GraphQLSchema,
     GraphQLString,
 )
 
 from ..fixtures import cleanup
 from ..utils.assert_equal_awaitables_or_values import assert_equal_awaitables_or_values
 
-
 try:
     from typing import TypedDict
 except ImportError:  # Python < 3.8
     from typing_extensions import TypedDict
 
 try:
-    anext
+    anext  # noqa: B018
 except NameError:  # pragma: no cover (Python < 3.10)
     # noinspection PyShadowingBuiltins
-    async def anext(iterator):
+    async def anext(iterator):  # noqa: A001
         """Return the next item from an async iterator."""
         return await iterator.__anext__()
 
 
 T = TypeVar("T")
 
 Email = TypedDict(
@@ -160,17 +159,15 @@
         return {"importantEmail": {"email": new_email, "inbox": data["inbox"]}}
 
     data: Dict[str, Any] = {
         "inbox": {"emails": emails},
         "importantEmail": pubsub.get_subscriber(transform),
     }
 
-    return (
-        subscribe if original_subscribe else experimental_subscribe_incrementally
-    )(  # type: ignore
+    return (subscribe if original_subscribe else experimental_subscribe_incrementally)(  # type: ignore
         email_schema, document, data, variable_values=variable_values
     )
 
 
 DummyQueryType = GraphQLObjectType("Query", {"dummy": GraphQLField(GraphQLString)})
 
 
@@ -197,15 +194,15 @@
         subscribe(schema, document, variable_values=variable_values),
         create_source_event_stream(schema, document, variable_values=variable_values),
     )
 
 
 # Check all error cases when initializing the subscription.
 def describe_subscription_initialization_phase():
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def accepts_positional_arguments():
         document = parse(
             """
             subscription {
               importantEmail
             }
             """
@@ -213,19 +210,19 @@
 
         async def empty_async_iterable(_info):
             for value in ():  # type: ignore
                 yield value  # pragma: no cover
 
         ai = subscribe(email_schema, document, {"importantEmail": empty_async_iterable})
 
-        with raises(StopAsyncIteration):
+        with pytest.raises(StopAsyncIteration):
             await anext(ai)
         await ai.aclose()  # type: ignore
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def accepts_multiple_subscription_fields_defined_in_schema():
         schema = GraphQLSchema(
             query=DummyQueryType,
             subscription=GraphQLObjectType(
                 "Subscription",
                 {
                     "foo": GraphQLField(GraphQLString),
@@ -242,15 +239,15 @@
         )
         assert isinstance(subscription, AsyncIterator)
 
         assert await anext(subscription) == ({"foo": "FooValue"}, None)
 
         await subscription.aclose()  # type: ignore
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def accepts_type_definition_with_sync_subscribe_function():
         async def foo_generator(_obj, _info):
             yield {"foo": "FooValue"}
 
         schema = GraphQLSchema(
             query=DummyQueryType,
             subscription=GraphQLObjectType(
@@ -262,15 +259,15 @@
         subscription = subscribe(schema, parse("subscription { foo }"))
         assert isinstance(subscription, AsyncIterator)
 
         assert await anext(subscription) == ({"foo": "FooValue"}, None)
 
         await subscription.aclose()  # type: ignore
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def accepts_type_definition_with_async_subscribe_function():
         async def foo_generator(_obj, _info):
             await asyncio.sleep(0)
             yield {"foo": "FooValue"}
 
         async def subscribe_fn(obj, info):
             await asyncio.sleep(0)
@@ -290,15 +287,15 @@
         subscription = await awaitable
         assert isinstance(subscription, AsyncIterator)
 
         assert await anext(subscription) == ({"foo": "FooValue"}, None)
 
         await subscription.aclose()  # type: ignore
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def should_only_resolve_the_first_field_of_invalid_multi_field():
         did_resolve = {"foo": False, "bar": False}
 
         async def subscribe_foo(_obj, _info):
             did_resolve["foo"] = True
             yield {"foo": "FooValue"}
 
@@ -325,15 +322,15 @@
             None,
         )
 
         assert did_resolve == {"foo": True, "bar": False}
 
         await subscription.aclose()  # type: ignore
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def resolves_to_an_error_if_schema_does_not_support_subscriptions():
         schema = GraphQLSchema(query=DummyQueryType)
         document = parse("subscription { unknownField }")
 
         result = subscribe_with_bad_args(schema, document)
 
         assert result == (
@@ -343,15 +340,15 @@
                     "message": "Schema is not configured to execute"
                     " subscription operation.",
                     "locations": [(1, 1)],
                 }
             ],
         )
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def resolves_to_an_error_for_unknown_subscription_field():
         schema = GraphQLSchema(
             query=DummyQueryType,
             subscription=GraphQLObjectType(
                 "Subscription", {"foo": GraphQLField(GraphQLString)}
             ),
         )
@@ -364,27 +361,27 @@
                 {
                     "message": "The subscription field 'unknownField' is not defined.",
                     "locations": [(1, 16)],
                 }
             ],
         )
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def should_pass_through_unexpected_errors_thrown_in_subscribe():
         schema = GraphQLSchema(
             query=DummyQueryType,
             subscription=GraphQLObjectType(
                 "Subscription", {"foo": GraphQLField(GraphQLString)}
             ),
         )
-        with raises(AttributeError):
+        with pytest.raises(AttributeError):
             subscribe_with_bad_args(schema=schema, document={})  # type: ignore
 
-    @mark.asyncio
-    @mark.filterwarnings("ignore:.* was never awaited:RuntimeWarning")
+    @pytest.mark.asyncio()
+    @pytest.mark.filterwarnings("ignore:.* was never awaited:RuntimeWarning")
     async def throws_an_error_if_subscribe_does_not_return_an_iterator():
         expected_result = (
             None,
             [
                 {
                     "message": "Subscription field must return AsyncIterable."
                     " Received: 'test'.",
@@ -405,15 +402,15 @@
         result = subscribe_with_bad_fn(async_fn)
         assert is_awaitable(result)
         assert await result == expected_result
 
         del result
         cleanup()
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def resolves_to_an_error_for_subscription_resolver_errors():
         expected_result = (
             None,
             [
                 {
                     "message": "test error",
                     "locations": [(1, 16)],
@@ -447,15 +444,15 @@
         async def reject_with_error(*args):
             return throw_error(*args)
 
         result = subscribe_with_bad_fn(reject_with_error)
         assert is_awaitable(result)
         assert await result == expected_result
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def resolves_to_an_error_if_variables_were_wrong_type():
         schema = GraphQLSchema(
             query=DummyQueryType,
             subscription=GraphQLObjectType(
                 "Subscription",
                 {
                     "foo": GraphQLField(
@@ -487,20 +484,20 @@
                     "message": "Variable '$arg' got invalid value 'meow';"
                     " Int cannot represent non-integer value: 'meow'",
                     "locations": [(2, 27)],
                 }
             ],
         )
 
-        assert result.errors[0].original_error is None
+        assert result.errors[0].original_error
 
 
 # Once a subscription returns a valid AsyncIterator, it can still yield errors.
 def describe_subscription_publish_phase():
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def produces_a_payload_for_multiple_subscribe_in_same_subscription():
         pubsub = SimplePubSub()
 
         subscription = create_subscription(pubsub)
         assert isinstance(subscription, AsyncIterator)
 
         second_subscription = create_subscription(pubsub)
@@ -527,15 +524,15 @@
                 "inbox": {"unread": 1, "total": 2},
             }
         }
 
         assert await payload1 == (expected_payload, None)
         assert await payload2 == (expected_payload, None)
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def produces_a_payload_when_queried_fields_are_async():
         pubsub = SimplePubSub()
         subscription = create_subscription(pubsub, {"asyncResolver": True})
         assert isinstance(subscription, AsyncIterator)
 
         assert (
             pubsub.emit(
@@ -559,22 +556,20 @@
                     },
                     "inbox": {"unread": 1, "total": 2},
                 }
             },
             None,
         )
 
-        try:
+        with suppress(RuntimeError):  # suppress error for Python < 3.8
             await subscription.aclose()  # type: ignore
-        except RuntimeError:  # Python < 3.8
-            pass
-        with raises(StopAsyncIteration):
+        with pytest.raises(StopAsyncIteration):
             await anext(subscription)
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def produces_a_payload_per_subscription_event():
         pubsub = SimplePubSub()
         subscription = create_subscription(pubsub)
         assert isinstance(subscription, AsyncIterator)
 
         # Wait for the next subscription payload.
         payload = anext(subscription)
@@ -625,18 +620,16 @@
                 }
             },
             None,
         )
 
         # The client decides to disconnect.
         # noinspection PyUnresolvedReferences
-        try:
+        with suppress(RuntimeError):  # suppress error for Python < 3.8
             await subscription.aclose()  # type: ignore
-        except RuntimeError:  # Python < 3.8
-            pass
 
         # Which may result in disconnecting upstream services as well.
         assert (
             pubsub.emit(
                 {
                     "from": "adam@graphql.org",
                     "subject": "Important",
@@ -644,18 +637,18 @@
                     "unread": True,
                 }
             )
             is False
         )  # No more listeners.
 
         # Awaiting subscription after closing it results in completed results.
-        with raises(StopAsyncIteration):
+        with pytest.raises(StopAsyncIteration):
             assert await anext(subscription)
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def produces_additional_payloads_for_subscriptions_with_defer():
         pubsub = SimplePubSub()
         subscription = create_subscription(pubsub, {"shouldDefer": True})
         assert isinstance(subscription, AsyncIterator)
 
         # Wait for the next subscription payload.
         payload = anext(subscription)
@@ -764,24 +757,22 @@
                     },
                 },
             },
             "hasNext": True,
         }
 
         # The client disconnects before the deferred payload is consumed.
-        try:
+        with suppress(RuntimeError):  # suppress error for Python < 3.8
             await subscription.aclose()  # type: ignore
-        except RuntimeError:  # Python < 3.8
-            pass
 
         # Awaiting a subscription after closing it results in completed results.
-        with raises(StopAsyncIteration):
+        with pytest.raises(StopAsyncIteration):
             assert await anext(subscription)
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def original_subscribe_function_returns_errors_with_defer():
         pubsub = SimplePubSub()
         subscription = create_subscription(pubsub, {"shouldDefer": True}, True)
         assert isinstance(subscription, AsyncIterator)
 
         # Wait for the next subscription payload.
         payload = anext(subscription)
@@ -836,18 +827,18 @@
         # The next waited on payload will have a value.
         assert await anext(subscription) == error_payload
 
         # The client disconnects before the deferred payload is consumed.
         await subscription.aclose()  # type: ignore
 
         # Awaiting a subscription after closing it results in completed results.
-        with raises(StopAsyncIteration):
+        with pytest.raises(StopAsyncIteration):
             assert await anext(subscription)
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def produces_a_payload_when_there_are_multiple_events():
         pubsub = SimplePubSub()
         subscription = create_subscription(pubsub)
         assert isinstance(subscription, AsyncIterator)
 
         payload = anext(subscription)
 
@@ -895,15 +886,15 @@
                     "email": {"from": "yuzhi@graphql.org", "subject": "Alright 2"},
                     "inbox": {"unread": 2, "total": 3},
                 }
             },
             None,
         )
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def should_not_trigger_when_subscription_is_already_done():
         pubsub = SimplePubSub()
         subscription = create_subscription(pubsub)
         assert isinstance(subscription, AsyncIterator)
 
         payload = anext(subscription)
 
@@ -927,36 +918,34 @@
                     "inbox": {"unread": 1, "total": 2},
                 }
             },
             None,
         )
 
         payload = anext(subscription)
-        try:
+        with suppress(RuntimeError):  # suppress error for Python < 3.8
             await subscription.aclose()  # type: ignore
-        except RuntimeError:  # Python < 3.8
-            pass
 
         # A new email arrives!
         assert (
             pubsub.emit(
                 {
                     "from": "yuzhi@graphql.org",
                     "subject": "Alright 2",
                     "message": "Tests are good 2",
                     "unread": True,
                 }
             )
             is False
         )
 
-        with raises(StopAsyncIteration):
+        with pytest.raises(StopAsyncIteration):
             await payload
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def should_not_trigger_when_subscription_is_thrown():
         pubsub = SimplePubSub()
         subscription = create_subscription(pubsub)
         assert isinstance(subscription, AsyncIterator)
 
         payload = anext(subscription)
 
@@ -982,22 +971,22 @@
             },
             None,
         )
 
         payload = anext(subscription)
 
         # Throw error
-        with raises(RuntimeError) as exc_info:
+        with pytest.raises(RuntimeError) as exc_info:
             await subscription.athrow(RuntimeError("ouch"))  # type: ignore
         assert str(exc_info.value) == "ouch"
 
-        with raises(StopAsyncIteration):
+        with pytest.raises(StopAsyncIteration):
             await payload
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def event_order_is_correct_for_multiple_publishes():
         pubsub = SimplePubSub()
         subscription = create_subscription(pubsub)
         assert isinstance(subscription, AsyncIterator)
 
         payload = anext(subscription)
 
@@ -1045,15 +1034,15 @@
                     "email": {"from": "yuzhi@graphql.org", "subject": "Message 2"},
                     "inbox": {"unread": 2, "total": 3},
                 }
             },
             None,
         )
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def should_handle_error_during_execution_of_source_event():
         async def generate_messages(_obj, _info):
             yield "Hello"
             yield "Goodbye"
             yield "Bonjour"
 
         def resolve_message(message, _info):
@@ -1093,15 +1082,15 @@
             ],
         )
 
         # However that does not close the response event stream.
         # Subsequent events are still executed.
         assert await anext(subscription) == ({"newMessage": "Bonjour"}, None)
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def should_pass_through_error_thrown_in_source_event_stream():
         async def generate_messages(_obj, _info):
             yield "Hello"
             raise RuntimeError("test error")
 
         def resolve_message(message, _info):
             return message
@@ -1122,23 +1111,23 @@
 
         document = parse("subscription { newMessage }")
         subscription = subscribe(schema, document)
         assert isinstance(subscription, AsyncIterator)
 
         assert await anext(subscription) == ({"newMessage": "Hello"}, None)
 
-        with raises(RuntimeError) as exc_info:
+        with pytest.raises(RuntimeError) as exc_info:
             await anext(subscription)
 
         assert str(exc_info.value) == "test error"
 
-        with raises(StopAsyncIteration):
+        with pytest.raises(StopAsyncIteration):
             await anext(subscription)
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def should_work_with_sync_resolve_function():
         async def generate_messages(_obj, _info):
             yield "Hello"
 
         def resolve_message(message, _info):
             return message
 
@@ -1158,15 +1147,15 @@
 
         document = parse("subscription { newMessage }")
         subscription = subscribe(schema, document)
         assert isinstance(subscription, AsyncIterator)
 
         assert await anext(subscription) == ({"newMessage": "Hello"}, None)
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def should_work_with_async_resolve_function():
         async def generate_messages(_obj, _info):
             await asyncio.sleep(0)
             yield "Hello"
 
         async def resolve_message(message, _info):
             await asyncio.sleep(0)
@@ -1188,15 +1177,15 @@
 
         document = parse("subscription { newMessage }")
         subscription = subscribe(schema, document)
         assert isinstance(subscription, AsyncIterator)
 
         assert await anext(subscription) == ({"newMessage": "Hello"}, None)
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def should_work_with_custom_async_iterator():
         class MessageGenerator:
             resolved: List[str] = []
 
             def __init__(self, values, _info):
                 self.values = values
 
@@ -1206,15 +1195,15 @@
             async def __anext__(self):
                 if not self.values:
                     raise StopAsyncIteration
                 await asyncio.sleep(0)
                 return self.values.pop(0)
 
             @classmethod
-            async def resolve(cls, message, _info):
+            async def resolve(cls, message, _info) -> str:
                 await asyncio.sleep(0)
                 cls.resolved.append(message)
                 return message + "!"
 
         schema = GraphQLSchema(
             query=QueryType,
             subscription=GraphQLObjectType(
@@ -1238,15 +1227,15 @@
             ({"newMessage": "Dolly!"}, None),
         ]
 
         assert MessageGenerator.resolved == ["Hello", "Dolly"]
 
         await subscription.aclose()  # type: ignore
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def should_close_custom_async_iterator():
         class MessageGenerator:
             closed: bool = False
             resolved: List[str] = []
 
             def __init__(self, values, _info):
                 self.values = values
@@ -1257,21 +1246,21 @@
             async def __anext__(self):
                 if not self.values:
                     raise StopAsyncIteration
                 await asyncio.sleep(0)
                 return self.values.pop(0)
 
             @classmethod
-            async def resolve(cls, message, _info):
+            async def resolve(cls, message, _info) -> str:
                 await asyncio.sleep(0)
                 cls.resolved.append(message)
                 return message + "!"
 
             @classmethod
-            async def aclose(cls):
+            async def aclose(cls) -> None:
                 cls.closed = True
 
         schema = GraphQLSchema(
             query=QueryType,
             subscription=GraphQLObjectType(
                 "Subscription",
                 {
```

### Comparing `graphql_core-3.3.0a3/tests/execution/test_sync.py` & `graphql_core-3.3.0a4/tests/execution/test_sync.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,9 +1,8 @@
-from pytest import mark, raises
-
+import pytest
 from graphql import graphql_sync
 from graphql.execution import execute, execute_sync
 from graphql.language import parse
 from graphql.pyutils import is_awaitable
 from graphql.type import GraphQLField, GraphQLObjectType, GraphQLSchema, GraphQLString
 from graphql.validation import validate
 
@@ -48,15 +47,15 @@
     def does_not_return_an_awaitable_if_mutation_fields_are_all_synchronous():
         doc = "mutation Example { syncMutationField }"
         assert execute(schema, parse(doc), "rootValue") == (
             {"syncMutationField": "rootValue"},
             None,
         )
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def returns_an_awaitable_if_any_field_is_asynchronous():
         doc = "query Example { syncField, asyncField }"
         result = execute(schema, parse(doc), "rootValue")
         assert is_awaitable(result)
         assert await result == (
             {"syncField": "rootValue", "asyncField": "rootValue"},
             None,
@@ -77,29 +76,29 @@
                 schema, document=parse(doc), root_value="rootValue", check_sync=True
             )
             assert result == (
                 {"syncField": "rootValue"},
                 None,
             )
 
-        @mark.asyncio
-        @mark.filterwarnings("ignore:.* was never awaited:RuntimeWarning")
+        @pytest.mark.asyncio()
+        @pytest.mark.filterwarnings("ignore:.* was never awaited:RuntimeWarning")
         async def throws_if_encountering_async_execution_with_check_sync():
             doc = "query Example { syncField, asyncField }"
-            with raises(RuntimeError) as exc_info:
+            with pytest.raises(RuntimeError) as exc_info:
                 execute_sync(
                     schema, document=parse(doc), root_value="rootValue", check_sync=True
                 )
             msg = str(exc_info.value)
             assert msg == "GraphQL execution failed to complete synchronously."
             del exc_info
             cleanup()
 
-        @mark.asyncio
-        @mark.filterwarnings("ignore:.* was never awaited:RuntimeWarning")
+        @pytest.mark.asyncio()
+        @pytest.mark.filterwarnings("ignore:.* was never awaited:RuntimeWarning")
         async def throws_if_encountering_async_operation_without_check_sync():
             doc = "query Example { syncField, asyncField }"
             result = execute_sync(schema, document=parse(doc), root_value="rootValue")
             assert result == (
                 {"syncField": "rootValue", "asyncField": None},
                 [
                     {
@@ -109,46 +108,46 @@
                         "path": ["asyncField"],
                     }
                 ],
             )
             del result
             cleanup()
 
-        @mark.asyncio
-        @mark.filterwarnings("ignore:.* was never awaited:RuntimeWarning")
+        @pytest.mark.asyncio()
+        @pytest.mark.filterwarnings("ignore:.* was never awaited:RuntimeWarning")
         async def throws_if_encountering_async_iterable_execution_with_check_sync():
             doc = """
                 query Example {
                   ...deferFrag @defer(label: "deferLabel")
                 }
                 fragment deferFrag on Query {
                   syncField
                 }
             """
-            with raises(RuntimeError) as exc_info:
+            with pytest.raises(RuntimeError) as exc_info:
                 execute_sync(
                     schema, document=parse(doc), root_value="rootValue", check_sync=True
                 )
             msg = str(exc_info.value)
             assert msg == "GraphQL execution failed to complete synchronously."
             del exc_info
             cleanup()
 
-        @mark.asyncio
-        @mark.filterwarnings("ignore:.* was never awaited:RuntimeWarning")
+        @pytest.mark.asyncio()
+        @pytest.mark.filterwarnings("ignore:.* was never awaited:RuntimeWarning")
         async def throws_if_encountering_async_iterable_execution_without_check_sync():
             doc = """
                 query Example {
                   ...deferFrag @defer(label: "deferLabel")
                 }
                 fragment deferFrag on Query {
                   syncField
                 }
             """
-            with raises(RuntimeError) as exc_info:
+            with pytest.raises(RuntimeError) as exc_info:
                 execute_sync(schema, document=parse(doc), root_value="rootValue")
             msg = str(exc_info.value)
             assert msg == "GraphQL execution failed to complete synchronously."
             del exc_info
             cleanup()
 
     def describe_graphql_sync():
@@ -185,27 +184,27 @@
         def does_not_throw_if_not_encountering_async_operation_with_check_sync():
             doc = "query Example { syncField }"
             assert graphql_sync(schema, doc, "rootValue") == (
                 {"syncField": "rootValue"},
                 None,
             )
 
-        @mark.asyncio
-        @mark.filterwarnings("ignore:.* was never awaited:RuntimeWarning")
+        @pytest.mark.asyncio()
+        @pytest.mark.filterwarnings("ignore:.* was never awaited:RuntimeWarning")
         async def throws_if_encountering_async_operation_with_check_sync():
             doc = "query Example { syncField, asyncField }"
-            with raises(RuntimeError) as exc_info:
+            with pytest.raises(RuntimeError) as exc_info:
                 graphql_sync(schema, doc, "rootValue", check_sync=True)
             msg = str(exc_info.value)
             assert msg == "GraphQL execution failed to complete synchronously."
             del exc_info
             cleanup()
 
-        @mark.asyncio
-        @mark.filterwarnings("ignore:.* was never awaited:RuntimeWarning")
+        @pytest.mark.asyncio()
+        @pytest.mark.filterwarnings("ignore:.* was never awaited:RuntimeWarning")
         async def throws_if_encountering_async_operation_without_check_sync():
             doc = "query Example { syncField, asyncField }"
             result = graphql_sync(schema, doc, "rootValue")
             assert result == (
                 {"syncField": "rootValue", "asyncField": None},
                 [
                     {
```

### Comparing `graphql_core-3.3.0a3/tests/execution/test_union_interface.py` & `graphql_core-3.3.0a4/tests/execution/test_union_interface.py`

 * *Files 0% similar despite different names*

```diff
@@ -61,15 +61,16 @@
         self.pets = pets
         self.friends = friends
 
 
 NamedType = GraphQLInterfaceType("Named", {"name": GraphQLField(GraphQLString)})
 
 LifeType = GraphQLInterfaceType(
-    "Life", lambda: {"progeny": GraphQLField(GraphQLList(LifeType))}  # type: ignore
+    "Life",
+    lambda: {"progeny": GraphQLField(GraphQLList(LifeType))},  # type: ignore
 )
 
 MammalType = GraphQLInterfaceType(
     "Mammal",
     lambda: {
         "progeny": GraphQLField(GraphQLList(MammalType)),  # type: ignore
         "mother": GraphQLField(MammalType),  # type: ignore
@@ -84,39 +85,39 @@
         "name": GraphQLField(GraphQLString),
         "barks": GraphQLField(GraphQLBoolean),
         "progeny": GraphQLField(GraphQLList(DogType)),  # type: ignore
         "mother": GraphQLField(DogType),  # type: ignore
         "father": GraphQLField(DogType),  # type: ignore
     },
     interfaces=[MammalType, LifeType, NamedType],
-    is_type_of=lambda value, info: isinstance(value, Dog),
+    is_type_of=lambda value, _info: isinstance(value, Dog),
 )
 
 CatType = GraphQLObjectType(
     "Cat",
     lambda: {
         "name": GraphQLField(GraphQLString),
         "meows": GraphQLField(GraphQLBoolean),
         "progeny": GraphQLField(GraphQLList(CatType)),  # type: ignore
         "mother": GraphQLField(CatType),  # type: ignore
         "father": GraphQLField(CatType),  # type: ignore
     },
     interfaces=[MammalType, LifeType, NamedType],
-    is_type_of=lambda value, info: isinstance(value, Cat),
+    is_type_of=lambda value, _info: isinstance(value, Cat),
 )
 
 
 def resolve_pet_type(value, _info, _type):
     if isinstance(value, Dog):
         return DogType.name
     if isinstance(value, Cat):
         return CatType.name
 
     # Not reachable. All possible types have been considered.
-    assert False, "Unexpected pet type"
+    assert False, "Unexpected pet type"  # pragma: no cover
 
 
 PetType = GraphQLUnionType("Pet", [DogType, CatType], resolve_type=resolve_pet_type)
 
 PersonType = GraphQLObjectType(
     "Person",
     lambda: {
```

### Comparing `graphql_core-3.3.0a3/tests/execution/test_variables.py` & `graphql_core-3.3.0a4/tests/execution/test_variables.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,10 +1,11 @@
 from math import nan
 from typing import Any, Dict, Optional
 
+from graphql.error import GraphQLError
 from graphql.execution import ExecutionResult, execute_sync
 from graphql.execution.values import get_variable_values
 from graphql.language import OperationDefinitionNode, StringValueNode, ValueNode, parse
 from graphql.pyutils import Undefined
 from graphql.type import (
     GraphQLArgument,
     GraphQLEnumType,
@@ -17,14 +18,33 @@
     GraphQLNonNull,
     GraphQLObjectType,
     GraphQLScalarType,
     GraphQLSchema,
     GraphQLString,
 )
 
+TestFaultyScalarGraphQLError = GraphQLError(
+    "FaultyScalarErrorMessage", extensions={"code": "FaultyScalarExtensionCode"}
+)
+
+
+def faulty_parse_value(_value: str) -> str:
+    raise TestFaultyScalarGraphQLError
+
+
+def faulty_parse_literal(_ast: ValueNode, _variables=None) -> str:
+    raise TestFaultyScalarGraphQLError
+
+
+TestFaultyScalar = GraphQLScalarType(
+    name="FaultyScalar",
+    parse_value=faulty_parse_value,
+    parse_literal=faulty_parse_literal,
+)
+
 
 def parse_serialized_value(value: str) -> str:
     assert value == "SerializedValue"
     return "DeserializedValue"
 
 
 def parse_literal_value(ast: ValueNode, _variables=None) -> str:
@@ -43,14 +63,15 @@
 TestInputObject = GraphQLInputObjectType(
     "TestInputObject",
     {
         "a": GraphQLInputField(GraphQLString),
         "b": GraphQLInputField(GraphQLList(GraphQLString)),
         "c": GraphQLInputField(GraphQLNonNull(GraphQLString)),
         "d": GraphQLInputField(TestComplexScalar),
+        "e": GraphQLInputField(TestFaultyScalar),
     },
 )
 
 TestCustomInputObject = GraphQLInputObjectType(
     "TestCustomInputObject",
     {"x": GraphQLInputField(GraphQLFloat), "y": GraphQLInputField(GraphQLFloat)},
     out_type=lambda value: f"(x|y) = ({value['x']}|{value['y']})",
@@ -249,14 +270,35 @@
                 )
 
                 assert result == (
                     {"fieldWithObjectInput": "{'c': 'foo', 'd': 'DeserializedValue'}"},
                     None,
                 )
 
+            def errors_on_faulty_scalar_type_input():
+                result = execute_query(
+                    """
+                    {
+                      fieldWithObjectInput(input: {c: "foo", e: "bar"})
+                    }
+                    """
+                )
+
+                assert result == (
+                    {"fieldWithObjectInput": None},
+                    [
+                        {
+                            "message": "Argument 'input' has invalid value"
+                            ' { c: "foo", e: "bar" }.',
+                            "path": ["fieldWithObjectInput"],
+                            "locations": [(3, 51)],
+                        }
+                    ],
+                )
+
         def describe_using_variables():
             doc = """
                 query ($input: TestInputObject) {
                   fieldWithObjectInput(input: $input)
                 }
                 """
 
@@ -361,14 +403,30 @@
                 result = execute_query(doc, params)
 
                 assert result == (
                     {"fieldWithObjectInput": "{'c': 'foo', 'd': 'DeserializedValue'}"},
                     None,
                 )
 
+            def errors_on_faulty_scalar_type_input():
+                params = {"input": {"c": "foo", "e": "SerializedValue"}}
+                result = execute_query(doc, params)
+
+                assert result == (
+                    None,
+                    [
+                        {
+                            "message": "Variable '$input' got invalid value"
+                            " 'SerializedValue' at 'input.e'; FaultyScalarErrorMessage",
+                            "locations": [(2, 24)],
+                            "extensions": {"code": "FaultyScalarExtensionCode"},
+                        }
+                    ],
+                )
+
             def errors_on_null_for_nested_non_null():
                 params = {"input": {"a": "foo", "b": "bar", "c": None}}
                 result = execute_query(doc, params)
 
                 assert result == (
                     None,
                     [
@@ -672,16 +730,16 @@
                         "locations": [(2, 24)],
                         "path": None,
                     }
                 ],
             )
 
             errors = result.errors
-            assert errors is not None
-            assert errors[0].original_error is None
+            assert errors
+            assert errors[0].original_error
 
         def reports_error_for_non_provided_variables_for_non_nullable_inputs():
             # Note: this test would typically fail validation before
             # encountering this execution error, however for queries which
             # previously validated and are being run against a new schema which
             # have introduced a breaking change to make a formerly non-required
             # argument required, this asserts failure before allowing the
```

### Comparing `graphql_core-3.3.0a3/tests/fixtures/__init__.py` & `graphql_core-3.3.0a4/tests/fixtures/__init__.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 """Fixtures for graphql tests"""
+
 import json
 from gc import collect
-from os.path import dirname, join
-
-from pytest import fixture
+from pathlib import Path
 
+import pytest
 
 __all__ = [
     "cleanup",
     "kitchen_sink_query",
     "kitchen_sink_sdl",
     "big_schema_sdl",
     "big_schema_introspection_result",
@@ -21,34 +21,36 @@
     This can be used to remove coroutines that were not awaited after running tests.
     """
     for _generation in range(rounds):
         collect()
 
 
 def read_graphql(name):
-    path = join(dirname(__file__), name + ".graphql")
-    return open(path, encoding="utf-8").read()
+    path = (Path(__file__).parent / name).with_suffix(".graphql")
+    with path.open(encoding="utf-8") as file:
+        return file.read()
 
 
 def read_json(name):
-    path = join(dirname(__file__), name + ".json")
-    return json.load(open(path, encoding="utf-8"))
+    path = (Path(__file__).parent / name).with_suffix(".json")
+    with path.open(encoding="utf-8") as file:
+        return json.load(file)
 
 
-@fixture(scope="module")
+@pytest.fixture(scope="module")
 def kitchen_sink_query():
     return read_graphql("kitchen_sink")
 
 
-@fixture(scope="module")
+@pytest.fixture(scope="module")
 def kitchen_sink_sdl():
     return read_graphql("schema_kitchen_sink")
 
 
-@fixture(scope="module")
+@pytest.fixture(scope="module")
 def big_schema_sdl():
     return read_graphql("github_schema")
 
 
-@fixture(scope="module")
+@pytest.fixture(scope="module")
 def big_schema_introspection_result():
     return read_json("github_schema")
```

### Comparing `graphql_core-3.3.0a3/tests/fixtures/github_schema.graphql` & `graphql_core-3.3.0a4/tests/fixtures/github_schema.graphql`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/tests/fixtures/github_schema.json` & `graphql_core-3.3.0a4/tests/fixtures/github_schema.json`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/tests/fixtures/kitchen_sink.graphql` & `graphql_core-3.3.0a4/tests/fixtures/kitchen_sink.graphql`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/tests/fixtures/schema_kitchen_sink.graphql` & `graphql_core-3.3.0a4/tests/fixtures/schema_kitchen_sink.graphql`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/tests/language/test_ast.py` & `graphql_core-3.3.0a4/tests/language/test_ast.py`

 * *Files 2% similar despite different names*

```diff
@@ -48,26 +48,26 @@
         assert repr(token) == "<Token Name 'test' 1:2>"
         assert inspect(token) == repr(token)
 
     def can_check_equality():
         token1 = Token(TokenKind.NAME, 1, 2, 1, 2, value="test")
         token2 = Token(TokenKind.NAME, 1, 2, 1, 2, value="test")
         assert token2 == token1
-        assert not token2 != token1
+        assert token2 == token1
         token3 = Token(TokenKind.NAME, 1, 2, 1, 2, value="text")
         assert token3 != token1
         token4 = Token(TokenKind.NAME, 1, 4, 1, 2, value="test")
         assert token4 != token1
         token5 = Token(TokenKind.NAME, 1, 2, 1, 4, value="test")
         assert token5 != token1
 
     def can_compare_with_string():
         token = Token(TokenKind.NAME, 1, 2, 1, 2, value="test")
-        assert token == "Name 'test'"
-        assert token != "Name 'foo'"
+        assert token == "Name 'test'"  # noqa: S105
+        assert token != "Name 'foo'"  # noqa: S105
 
     def does_not_equal_incompatible_object():
         token = Token(TokenKind.NAME, 1, 2, 1, 2, value="test")
         assert token != {"Name": "test"}
 
     def can_hash():
         token1 = Token(TokenKind.NAME, 1, 2, 1, 2, value="hash")
@@ -117,24 +117,24 @@
         assert loc4 != loc1
         assert loc4 != loc3
 
     def can_check_equality_with_tuple_or_list():
         loc = Location(token1, token2, source)
         assert loc == (1, 3)
         assert loc == [1, 3]
-        assert not loc != (1, 3)
-        assert not loc != [1, 3]
+        assert loc == (1, 3)
+        assert loc == [1, 3]
         assert loc != (1, 2)
         assert loc != [2, 3]
 
     def does_not_equal_incompatible_object():
         loc = Location(token1, token2, source)
-        assert not loc == (1, 2, 3)
         assert loc != (1, 2, 3)
-        assert not loc == {1: 2}
+        assert loc != (1, 2, 3)
+        assert loc != {1: 2}
         assert loc != {1: 2}
 
     def can_hash():
         loc1 = Location(token1, token2, source)
         loc2 = Location(token1, token2, source)
         assert loc2 == loc1
         assert hash(loc2) == hash(loc1)
@@ -187,15 +187,15 @@
         node = NameNode(value="foo", loc=3)
         assert repr(node) == "NameNode('foo') at 3"
 
     def can_check_equality():
         node = SampleTestNode(alpha=1, beta=2)
         node2 = SampleTestNode(alpha=1, beta=2)
         assert node2 == node
-        assert not node2 != node
+        assert node2 == node
         node2 = SampleTestNode(alpha=1, beta=1)
         assert node2 != node
         node3 = Node(alpha=1, beta=2)
         assert node3 != node
 
     def can_hash():
         node = SampleTestNode(alpha=1, beta=2)
@@ -209,21 +209,21 @@
 
     # noinspection PyProtectedMember
     def caches_are_hashed():
         node = SampleTestNode(alpha=1)
         assert not hasattr(node, "_hash")
         hash1 = hash(node)
         assert hasattr(node, "_hash")
-        assert hash1 == node._hash
+        assert hash1 == node._hash  # noqa: SLF001
         node.alpha = 2
         assert not hasattr(node, "_hash")
         hash2 = hash(node)
         assert hash2 != hash1
         assert hasattr(node, "_hash")
-        assert hash2 == node._hash
+        assert hash2 == node._hash  # noqa: SLF001
 
     def can_create_weak_reference():
         node = SampleTestNode(alpha=1, beta=2)
         ref = weakref.ref(node)
         assert ref() is node
 
     def can_create_custom_attribute():
```

### Comparing `graphql_core-3.3.0a3/tests/language/test_block_string.py` & `graphql_core-3.3.0a4/tests/language/test_block_string.py`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/tests/language/test_block_string_fuzz.py` & `graphql_core-3.3.0a4/tests/language/test_block_string_fuzz.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,9 +1,8 @@
-from pytest import mark
-
+import pytest
 from graphql.language import Lexer, Source, TokenKind
 from graphql.language.block_string import (
     is_printable_as_block_string,
     print_block_string,
 )
 
 from ..utils import dedent, gen_fuzz_strings
@@ -37,16 +36,16 @@
         Expected lexValue({block_string!r})
           to not equal {test_value!r}
         """
     )
 
 
 def describe_print_block_string():
-    @mark.slow
-    @mark.timeout(80)
+    @pytest.mark.slow()
+    @pytest.mark.timeout(80)
     def correctly_print_random_strings():
         # Testing with length >7 is taking exponentially more time. However, it is
         # highly recommended testing with increased limit if you make any change.
         for fuzz_str in gen_fuzz_strings(allowed_chars='\n\t "a\\', max_length=7):
             if not is_printable_as_block_string(fuzz_str):
                 assert_non_printable_block_string(fuzz_str)
                 continue
```

### Comparing `graphql_core-3.3.0a3/tests/language/test_character_classes.py` & `graphql_core-3.3.0a4/tests/language/test_character_classes.py`

 * *Files 1% similar despite different names*

```diff
@@ -4,16 +4,15 @@
 from graphql.language.character_classes import (
     is_digit,
     is_letter,
     is_name_continue,
     is_name_start,
 )
 
-
-non_ascii = "¯＿±¹²³½£ºµÄäÖöØø×〇᧐〸αΑωΩ"
+non_ascii = "¯＿±¹²³½£ºµÄäÖöØø×〇᧐〸αΑωΩ"  #  noqa: RUF001
 
 
 def describe_digit():
     def accepts_digits():
         assert all(is_digit(char) for char in digits)
 
     def rejects_letters():
```

### Comparing `graphql_core-3.3.0a3/tests/language/test_lexer.py` & `graphql_core-3.3.0a4/tests/language/test_lexer.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,19 +1,17 @@
 from typing import List, Optional, Tuple
 
-from pytest import raises
-
+import pytest
 from graphql.error import GraphQLSyntaxError
 from graphql.language import Lexer, Source, SourceLocation, Token, TokenKind
 from graphql.language.lexer import is_punctuator_token_kind
 from graphql.pyutils import inspect
 
 from ..utils import dedent
 
-
 try:
     from typing import TypeAlias
 except ImportError:  # Python < 3.10
     from typing_extensions import TypeAlias
 
 
 Location: TypeAlias = Optional[Tuple[int, int]]
@@ -27,15 +25,15 @@
 def lex_second(s: str) -> Token:
     lexer = Lexer(Source(s))
     lexer.advance()
     return lexer.advance()
 
 
 def assert_syntax_error(text: str, message: str, location: Location) -> None:
-    with raises(GraphQLSyntaxError) as exc_info:
+    with pytest.raises(GraphQLSyntaxError) as exc_info:
         lex_second(text)
     error = exc_info.value
     assert error.message == f"Syntax Error: {message}"
     assert error.description == message
     assert error.locations == [location]
 
 
@@ -75,15 +73,15 @@
         assert token == Token(TokenKind.NAME, 2, 5, 1, 3, "foo")
         token = lex_one("\n    #comment\n    foo#comment\n")
         assert token == Token(TokenKind.NAME, 18, 21, 3, 5, "foo")
         token = lex_one(",,,foo,,,")
         assert token == Token(TokenKind.NAME, 3, 6, 1, 4, "foo")
 
     def errors_respect_whitespace():
-        with raises(GraphQLSyntaxError) as exc_info:
+        with pytest.raises(GraphQLSyntaxError) as exc_info:
             lex_one("\n\n ~\n")
 
         assert str(exc_info.value) == dedent(
             """
             Syntax Error: Unexpected character: '~'.
 
             GraphQL request:3:2
@@ -93,15 +91,15 @@
             4 |
             """
         )
 
     def updates_line_numbers_in_error_for_file_context():
         s = "\n\n     ~\n\n"
         source = Source(s, "foo.js", SourceLocation(11, 12))
-        with raises(GraphQLSyntaxError) as exc_info:
+        with pytest.raises(GraphQLSyntaxError) as exc_info:
             Lexer(source).advance()
         assert str(exc_info.value) == dedent(
             """
             Syntax Error: Unexpected character: '~'.
 
             foo.js:13:6
             12 |
@@ -109,15 +107,15 @@
                |      ^
             14 |
             """
         )
 
     def updates_column_numbers_in_error_for_file_context():
         source = Source("~", "foo.js", SourceLocation(1, 5))
-        with raises(GraphQLSyntaxError) as exc_info:
+        with pytest.raises(GraphQLSyntaxError) as exc_info:
             Lexer(source).advance()
         assert str(exc_info.value) == dedent(
             """
             Syntax Error: Unexpected character: '~'.
 
             foo.js:1:5
             1 |     ~
@@ -394,26 +392,23 @@
         )
         assert lex_one(
             '"""\n\n        spans\n          multiple\n'
             '            lines\n\n        """'
         ) == Token(TokenKind.BLOCK_STRING, 0, 68, 1, 1, "spans\n  multiple\n    lines")
 
     def advance_line_after_lexing_multiline_block_string():
-        assert (
-            lex_second(
-                '''"""
+        assert lex_second(
+            '''"""
 
         spans
           multiple
             lines
 
         \n """ second_token'''
-            )
-            == Token(TokenKind.NAME, 71, 83, 8, 6, "second_token")
-        )
+        ) == Token(TokenKind.NAME, 71, 83, 8, 6, "second_token")
 
     def lex_reports_useful_block_string_errors():
         assert_syntax_error('"""', "Unterminated string.", (1, 4))
         assert_syntax_error('"""no end quote', "Unterminated string.", (1, 16))
         assert_syntax_error(
             '"""contains invalid surrogate \uDEAD"""',
             "Invalid character within String: U+DEAD.",
@@ -551,15 +546,15 @@
 
     # noinspection PyArgumentEqualDefault
     def lex_reports_useful_information_for_dashes_in_names():
         source = Source("a-b")
         lexer = Lexer(source)
         first_token = lexer.advance()
         assert first_token == Token(TokenKind.NAME, 0, 1, 1, 1, "a")
-        with raises(GraphQLSyntaxError) as exc_info:
+        with pytest.raises(GraphQLSyntaxError) as exc_info:
             lexer.advance()
         error = exc_info.value
         assert error.message == (
             "Syntax Error: Invalid number, expected digit but got: 'b'."
         )
         assert error.locations == [(1, 3)]
```

### Comparing `graphql_core-3.3.0a3/tests/language/test_parser.py` & `graphql_core-3.3.0a4/tests/language/test_parser.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,11 +1,10 @@
 from typing import Optional, Tuple, cast
 
-from pytest import raises
-
+import pytest
 from graphql.error import GraphQLSyntaxError
 from graphql.language import (
     ArgumentNode,
     DefinitionNode,
     DocumentNode,
     ErrorBoundaryNode,
     FieldNode,
@@ -36,49 +35,48 @@
     parse_value,
 )
 from graphql.pyutils import inspect
 
 from ..fixtures import kitchen_sink_query  # noqa: F401
 from ..utils import dedent
 
-
 try:
     from typing import TypeAlias
 except ImportError:  # Python < 3.10
     from typing_extensions import TypeAlias
 
 
 Location: TypeAlias = Optional[Tuple[int, int]]
 
 
 def parse_ccn(source: str) -> DocumentNode:
     return parse(source, experimental_client_controlled_nullability=True)
 
 
 def assert_syntax_error(text: str, message: str, location: Location) -> None:
-    with raises(GraphQLSyntaxError) as exc_info:
+    with pytest.raises(GraphQLSyntaxError) as exc_info:
         parse(text)
     error = exc_info.value
     assert error.message == f"Syntax Error: {message}"
     assert error.description == message
     assert error.locations == [location]
 
 
 def assert_syntax_error_ccn(text: str, message: str, location: Location) -> None:
-    with raises(GraphQLSyntaxError) as exc_info:
+    with pytest.raises(GraphQLSyntaxError) as exc_info:
         parse_ccn(text)
     error = exc_info.value
     assert error.message == f"Syntax Error: {message}"
     assert error.description == message
     assert error.locations == [location]
 
 
 def describe_parser():
     def parse_provides_useful_errors():
-        with raises(GraphQLSyntaxError) as exc_info:
+        with pytest.raises(GraphQLSyntaxError) as exc_info:
             parse("{")
         error = exc_info.value
         assert error.message == "Syntax Error: Expected Name, found <EOF>."
         assert error.positions == [1]
         assert error.locations == [(1, 2)]
         assert str(error) == dedent(
             """
@@ -98,40 +96,40 @@
         assert_syntax_error(
             "notAnOperation Foo { field }", "Unexpected Name 'notAnOperation'.", (1, 1)
         )
         assert_syntax_error("...", "Unexpected '...'.", (1, 1))
         assert_syntax_error('{ ""', "Expected Name, found String ''.", (1, 3))
 
     def parse_provides_useful_error_when_using_source():
-        with raises(GraphQLSyntaxError) as exc_info:
+        with pytest.raises(GraphQLSyntaxError) as exc_info:
             parse(Source("query", "MyQuery.graphql"))
         error = exc_info.value
         assert str(error) == dedent(
             """
             Syntax Error: Expected '{', found <EOF>.
 
             MyQuery.graphql:1:6
             1 | query
               |      ^
             """
         )
 
-    def limits_maximum_number_of_tokens():
+    def limits_by_a_maximum_number_of_tokens():
         parse("{ foo }", max_tokens=3)
-        with raises(
+        with pytest.raises(
             GraphQLSyntaxError,
             match="Syntax Error:"
-            r" Document contains more that 2 tokens\. Parsing aborted\.",
+            r" Document contains more than 2 tokens\. Parsing aborted\.",
         ):
             parse("{ foo }", max_tokens=2)
         parse('{ foo(bar: "baz") }', max_tokens=8)
-        with raises(
+        with pytest.raises(
             GraphQLSyntaxError,
             match="Syntax Error:"
-            r" Document contains more that 7 tokens\. Parsing aborted\.",
+            r" Document contains more than 7 tokens\. Parsing aborted\.",
         ):
             parse('{ foo(bar: "baz") }', max_tokens=7)
 
     def parses_variable_inline_values():
         parse("{ field(complex: { a: { b: [ $var ] } }) }")
 
     def parses_constant_default_values():
@@ -613,27 +611,28 @@
     def allows_parsing_without_source_location_information():
         result = parse("{ id }", no_location=True)
         assert result.loc is None
 
     def legacy_allows_parsing_fragment_defined_variables():
         document = "fragment a($v: Boolean = false) on t { f(v: $v) }"
         parse(document, allow_legacy_fragment_variables=True)
-        with raises(GraphQLSyntaxError):
+        with pytest.raises(GraphQLSyntaxError):
             parse(document)
 
     def contains_location_information_that_only_stringifies_start_end():
         result = parse("{ id }")
         assert str(result.loc) == "0:6"
         assert repr(result.loc) == "<Location 0:6>"
         assert inspect(result.loc) == repr(result.loc)
 
     def contains_references_to_source():
         source = Source("{ id }")
         result = parse(source)
-        assert result.loc and result.loc.source is source
+        assert result.loc
+        assert result.loc.source is source
 
     def contains_references_to_start_and_end_tokens():
         result = parse("{ id }")
         start_token = result.loc and result.loc.start_token
         assert isinstance(start_token, Token)
         assert start_token.kind == TokenKind.SOF
         end_token = result.loc and result.loc.end_token
@@ -646,21 +645,24 @@
             """# top comment
             {
               field # field comment
             }
             # bottom comment"""
         )
         top_comment = result.loc and result.loc.start_token.next
-        assert top_comment and top_comment.kind is TokenKind.COMMENT
+        assert top_comment
+        assert top_comment.kind is TokenKind.COMMENT
         assert top_comment.value == " top comment"
         field_comment = top_comment.next.next.next  # type: ignore
-        assert field_comment and field_comment.kind is TokenKind.COMMENT
+        assert field_comment
+        assert field_comment.kind is TokenKind.COMMENT
         assert field_comment.value == " field comment"
         bottom_comment = field_comment.next.next  # type: ignore
-        assert bottom_comment and bottom_comment.kind is TokenKind.COMMENT
+        assert bottom_comment
+        assert bottom_comment.kind is TokenKind.COMMENT
         assert bottom_comment.value == " bottom comment"
 
 
 def describe_parse_value():
     def parses_null_value():
         result = parse_value("null")
         assert isinstance(result, NullValueNode)
@@ -724,23 +726,23 @@
         assert value.loc == (9, 13)
         name = value.name
         assert isinstance(name, NameNode)
         assert name.loc == (10, 13)
         assert name.value == "var"
 
     def correct_message_for_incomplete_variable():
-        with raises(GraphQLSyntaxError) as exc_info:
+        with pytest.raises(GraphQLSyntaxError) as exc_info:
             parse_value("$")
         assert exc_info.value == {
             "message": "Syntax Error: Expected Name, found <EOF>.",
             "locations": [(1, 2)],
         }
 
     def correct_message_for_unexpected_token():
-        with raises(GraphQLSyntaxError) as exc_info:
+        with pytest.raises(GraphQLSyntaxError) as exc_info:
             parse_value(":")
         assert exc_info.value == {
             "message": "Syntax Error: Unexpected ':'.",
             "locations": [(1, 1)],
         }
 
 
@@ -758,23 +760,23 @@
         value = values[1]
         assert isinstance(value, StringValueNode)
         assert value.loc == (5, 10)
         assert value.value == "abc"
         assert value.block is False
 
     def does_not_allow_variables():
-        with raises(GraphQLSyntaxError) as exc_info:
+        with pytest.raises(GraphQLSyntaxError) as exc_info:
             parse_const_value("{ field: $var }")
         assert exc_info.value == {
             "message": "Syntax Error: Unexpected variable '$var' in constant value.",
             "locations": [(1, 10)],
         }
 
     def correct_message_for_unexpected_token():
-        with raises(GraphQLSyntaxError) as exc_info:
+        with pytest.raises(GraphQLSyntaxError) as exc_info:
             parse_const_value("$$")
         assert exc_info.value == {
             "message": "Syntax Error: Unexpected '$'.",
             "locations": [(1, 1)],
         }
```

### Comparing `graphql_core-3.3.0a3/tests/language/test_predicates.py` & `graphql_core-3.3.0a4/tests/language/test_predicates.py`

 * *Files 0% similar despite different names*

```diff
@@ -14,15 +14,14 @@
     is_type_node,
     is_type_system_definition_node,
     is_type_system_extension_node,
     is_value_node,
     parse_value,
 )
 
-
 all_ast_nodes = sorted(
     [
         node_type()
         for node_type in vars(ast).values()
         if type(node_type) is type
         and issubclass(node_type, Node)
         and not node_type.__name__.startswith("Const")
```

### Comparing `graphql_core-3.3.0a3/tests/language/test_print_string.py` & `graphql_core-3.3.0a4/tests/language/test_print_string.py`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/tests/language/test_printer.py` & `graphql_core-3.3.0a4/tests/language/test_printer.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,30 +1,29 @@
 from copy import deepcopy
 
-from pytest import raises
-
+import pytest
 from graphql.language import FieldNode, NameNode, parse, print_ast
 
 from ..fixtures import kitchen_sink_query  # noqa: F401
 from ..utils import dedent
 
 
 def describe_printer_query_document():
     def prints_minimal_ast():
         ast = FieldNode(name=NameNode(value="foo"))
         assert print_ast(ast) == "foo"
 
     def produces_helpful_error_messages():
         bad_ast = {"random": "Data"}
-        with raises(TypeError) as exc_info:
+        with pytest.raises(TypeError) as exc_info:
             # noinspection PyTypeChecker
             print_ast(bad_ast)  # type: ignore
         assert str(exc_info.value) == "Not an AST Node: {'random': 'Data'}."
         corrupt_ast = FieldNode(name="random data")
-        with raises(TypeError) as exc_info:
+        with pytest.raises(TypeError) as exc_info:
             print_ast(corrupt_ast)
         assert str(exc_info.value) == "Invalid AST Node: 'random data'."
 
     def correctly_prints_query_operation_without_name():
         query_ast_shorthanded = parse("query { id, name }")
         assert print_ast(query_ast_shorthanded) == "{\n  id\n  name\n}"
```

### Comparing `graphql_core-3.3.0a3/tests/language/test_schema_parser.py` & `graphql_core-3.3.0a4/tests/language/test_schema_parser.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,14 +1,13 @@
 import pickle
 from copy import deepcopy
 from textwrap import dedent
 from typing import List, Optional, Tuple
 
-from pytest import raises
-
+import pytest
 from graphql.error import GraphQLSyntaxError
 from graphql.language import (
     ArgumentNode,
     BooleanValueNode,
     DirectiveDefinitionNode,
     DirectiveNode,
     DocumentNode,
@@ -35,26 +34,25 @@
     UnionTypeDefinitionNode,
     ValueNode,
     parse,
 )
 
 from ..fixtures import kitchen_sink_sdl  # noqa: F401
 
-
 try:
     from typing import TypeAlias
 except ImportError:  # Python < 3.10
     from typing_extensions import TypeAlias
 
 
 Location: TypeAlias = Optional[Tuple[int, int]]
 
 
 def assert_syntax_error(text: str, message: str, location: Location) -> None:
-    with raises(GraphQLSyntaxError) as exc_info:
+    with pytest.raises(GraphQLSyntaxError) as exc_info:
         parse(text)
     error = exc_info.value
     assert error.message == f"Syntax Error: {message}"
     assert error.description == message
     assert error.locations == [location]
```

### Comparing `graphql_core-3.3.0a3/tests/language/test_schema_printer.py` & `graphql_core-3.3.0a4/tests/language/test_schema_printer.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,25 +1,24 @@
 from copy import deepcopy
 
-from pytest import raises
-
+import pytest
 from graphql.language import NameNode, ScalarTypeDefinitionNode, parse, print_ast
 
 from ..fixtures import kitchen_sink_sdl  # noqa: F401
 from ..utils import dedent
 
 
 def describe_printer_sdl_document():
     def prints_minimal_ast():
         node = ScalarTypeDefinitionNode(name=NameNode(value="foo"))
         assert print_ast(node) == "scalar foo"
 
     def produces_helpful_error_messages():
         bad_ast = {"random": "Data"}
-        with raises(TypeError) as exc_info:
+        with pytest.raises(TypeError) as exc_info:
             # noinspection PyTypeChecker
             print_ast(bad_ast)  # type: ignore
         msg = str(exc_info.value)
         assert msg == "Not an AST Node: {'random': 'Data'}."
 
     # noinspection PyShadowingNames
     def prints_kitchen_sink_without_altering_ast(kitchen_sink_sdl):  # noqa: F811
```

### Comparing `graphql_core-3.3.0a3/tests/language/test_visitor.py` & `graphql_core-3.3.0a4/tests/language/test_visitor.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,12 @@
 from copy import copy
 from functools import partial
 from typing import Any, List, Optional, cast
 
-from pytest import mark, raises
-
+import pytest
 from graphql.language import (
     BREAK,
     REMOVE,
     SKIP,
     FieldNode,
     NameNode,
     Node,
@@ -79,122 +78,110 @@
 
 def get_value(node):
     return getattr(node, "value", None)
 
 
 def describe_visitor():
     def visit_with_invalid_node():
-        with raises(TypeError) as exc_info:
+        with pytest.raises(TypeError) as exc_info:
             # noinspection PyTypeChecker
             visit("invalid", Visitor())  # type: ignore
         assert str(exc_info.value) == "Not an AST Node: 'invalid'."
 
     def visit_with_invalid_visitor():
         ast = parse("{ a }", no_location=True)
 
         class TestVisitor:
             def enter(self, *_args):
                 pass
 
-        with raises(TypeError) as exc_info:
+        with pytest.raises(TypeError) as exc_info:
             # noinspection PyTypeChecker
             visit(ast, TestVisitor())  # type: ignore
         assert str(exc_info.value) == "Not an AST Visitor: <TestVisitor instance>."
 
     def visitors_support_all_method_variants():
         class TestVisitorWithInstanceMethods(Visitor):
             def enter(self, node, *args):
                 assert isinstance(self, TestVisitorWithInstanceMethods)
                 assert isinstance(node, Node)
                 assert len(args) == 4
                 visited.append(f"enter:{node.kind}")
-                pass
 
             def leave(self, node, *args):
                 assert isinstance(self, TestVisitorWithInstanceMethods)
                 assert isinstance(node, Node)
                 assert len(args) == 4
                 visited.append(f"leave:{node.kind}")
-                pass
 
             def enter_field(self, node, *args):
                 assert isinstance(self, TestVisitorWithInstanceMethods)
                 assert isinstance(node, Node)
                 assert len(args) == 4
                 visited.append(f"enter_field:{node.kind}")
-                pass
 
             def leave_field(self, node, *args):
                 assert isinstance(self, TestVisitorWithInstanceMethods)
                 assert isinstance(node, Node)
                 assert len(args) == 4
                 visited.append(f"leave_field:{node.kind}")
-                pass
 
         class TestVisitorWithClassMethods(Visitor):
             @classmethod
-            def enter(cls, node, *args):
+            def enter(cls, node, *args) -> None:
                 assert cls is TestVisitorWithClassMethods
                 assert isinstance(node, Node)
                 assert len(args) == 4
                 visited.append(f"enter:{node.kind}")
-                pass
 
             @classmethod
-            def leave(cls, node, *args):
+            def leave(cls, node, *args) -> None:
                 assert cls is TestVisitorWithClassMethods
                 assert isinstance(node, Node)
                 assert len(args) == 4
                 visited.append(f"leave:{node.kind}")
-                pass
 
             @classmethod
-            def enter_field(cls, node, *args):
+            def enter_field(cls, node, *args) -> None:
                 assert cls is TestVisitorWithClassMethods
                 assert isinstance(node, Node)
                 assert len(args) == 4
                 visited.append(f"enter_field:{node.kind}")
-                pass
 
             @classmethod
-            def leave_field(cls, node, *args):
+            def leave_field(cls, node, *args) -> None:
                 assert cls is TestVisitorWithClassMethods
                 assert isinstance(node, Node)
                 assert len(args) == 4
                 visited.append(f"leave_field:{node.kind}")
-                pass
 
         class TestVisitorWithStaticMethods(Visitor):
             @staticmethod
             def enter(node, *args):
                 assert isinstance(node, Node)
                 assert len(args) == 4
                 visited.append(f"enter:{node.kind}")
-                pass
 
             @staticmethod
             def leave(node, *args):
                 assert isinstance(node, Node)
                 assert len(args) == 4
                 visited.append(f"leave:{node.kind}")
-                pass
 
             @staticmethod
             def enter_field(node, *args):
                 assert isinstance(node, Node)
                 assert len(args) == 4
                 visited.append(f"enter_field:{node.kind}")
-                pass
 
             @staticmethod
             def leave_field(node, *args):
                 assert isinstance(node, Node)
                 assert len(args) == 4
                 visited.append(f"leave_field:{node.kind}")
-                pass
 
         for visitor_class in (
             TestVisitorWithInstanceMethods,
             TestVisitorWithClassMethods,
             TestVisitorWithStaticMethods,
         ):
             ast = parse("{ a }")
@@ -338,53 +325,59 @@
                 visited.append("leave")
                 return node
 
         edited_ast = visit(ast, TestVisitor())
         assert edited_ast == ast
         assert visited == ["enter", "leave"]
 
-    @mark.parametrize("remove_action", (REMOVE, Ellipsis), ids=("REMOVE", "Ellipsis"))
+    @pytest.mark.parametrize(
+        "remove_action", [REMOVE, Ellipsis], ids=["REMOVE", "Ellipsis"]
+    )
     def allows_for_editing_on_enter(remove_action):
         ast = parse("{ a, b, c { a, b, c } }", no_location=True)
 
         class TestVisitor(Visitor):
             @staticmethod
             def enter(*args):
                 check_visitor_fn_args(ast, *args)
                 node = args[0]
                 if isinstance(node, FieldNode) and node.name.value == "b":
                     return remove_action
+                return None
 
         edited_ast = visit(ast, TestVisitor())
         assert ast == parse("{ a, b, c { a, b, c } }", no_location=True)
         assert edited_ast == parse("{ a,    c { a,    c } }", no_location=True)
 
-    @mark.parametrize("remove_action", (REMOVE, Ellipsis), ids=("REMOVE", "Ellipsis"))
+    @pytest.mark.parametrize(
+        "remove_action", [REMOVE, Ellipsis], ids=["REMOVE", "Ellipsis"]
+    )
     def allows_for_editing_on_leave(remove_action):
         ast = parse("{ a, b, c { a, b, c } }", no_location=True)
 
         class TestVisitor(Visitor):
             @staticmethod
             def leave(*args):
                 check_visitor_fn_args_edited(ast, *args)
                 node = args[0]
                 if isinstance(node, FieldNode) and node.name.value == "b":
                     return remove_action
+                return None
 
         edited_ast = visit(ast, TestVisitor())
         assert ast == parse("{ a, b, c { a, b, c } }", no_location=True)
         assert edited_ast == parse("{ a,    c { a,    c } }", no_location=True)
 
-    @mark.parametrize("skip_action", (SKIP, False), ids=("SKIP", "False"))
+    @pytest.mark.parametrize("skip_action", [SKIP, False], ids=["SKIP", "False"])
     def ignores_false_returned_on_leave(skip_action):
         ast = parse("{ a, b, c { a, b, c } }", no_location=True)
 
         class TestVisitor(Visitor):
             @staticmethod
-            def leave(*args):
+            def leave(*_args):
                 return skip_action
 
         returned_ast = visit(ast, TestVisitor())
         assert returned_ast == parse("{ a, b, c { a, b, c } }", no_location=True)
 
     def visits_edited_node():
         ast = parse("{ a { x } }", no_location=True)
@@ -397,37 +390,40 @@
                 check_visitor_fn_args_edited(ast, *args)
                 node = args[0]
                 if isinstance(node, FieldNode) and node.name.value == "a":
                     node = copy(node)
                     assert node.selection_set
                     node.selection_set.selections = (
                         added_field,
-                    ) + node.selection_set.selections
+                        *node.selection_set.selections,
+                    )
                     return node
                 if node == added_field:
                     self.did_visit_added_field = True
+                return None
 
         visitor = TestVisitor()
         visit(ast, visitor)
         assert visitor.did_visit_added_field
 
-    @mark.parametrize("skip_action", (SKIP, False), ids=("SKIP", "False"))
+    @pytest.mark.parametrize("skip_action", [SKIP, False], ids=["SKIP", "False"])
     def allows_skipping_a_sub_tree(skip_action):
         ast = parse("{ a, b { x }, c }", no_location=True)
         visited = []
 
         class TestVisitor(Visitor):
             @staticmethod
             def enter(*args):
                 check_visitor_fn_args(ast, *args)
                 node = args[0]
                 kind, value = node.kind, get_value(node)
                 visited.append(["enter", kind, value])
                 if kind == "field" and node.name.value == "b":
                     return skip_action
+                return None
 
             @staticmethod
             def leave(*args):
                 check_visitor_fn_args(ast, *args)
                 node = args[0]
                 kind, value = node.kind, get_value(node)
                 visited.append(["leave", kind, value])
@@ -447,28 +443,29 @@
             ["leave", "name", "c"],
             ["leave", "field", None],
             ["leave", "selection_set", None],
             ["leave", "operation_definition", None],
             ["leave", "document", None],
         ]
 
-    @mark.parametrize("break_action", (BREAK, True), ids=("BREAK", "True"))
+    @pytest.mark.parametrize("break_action", [BREAK, True], ids=["BREAK", "True"])
     def allows_early_exit_while_visiting(break_action):
         ast = parse("{ a, b { x }, c }", no_location=True)
         visited = []
 
         class TestVisitor(Visitor):
             @staticmethod
             def enter(*args):
                 check_visitor_fn_args(ast, *args)
                 node = args[0]
                 kind, value = node.kind, get_value(node)
                 visited.append(["enter", kind, value])
                 if kind == "name" and node.value == "x":
                     return break_action
+                return None
 
             @staticmethod
             def leave(*args):
                 check_visitor_fn_args(ast, *args)
                 node = args[0]
                 kind, value = node.kind, get_value(node)
                 visited.append(["leave", kind, value])
@@ -486,15 +483,15 @@
             ["enter", "name", "b"],
             ["leave", "name", "b"],
             ["enter", "selection_set", None],
             ["enter", "field", None],
             ["enter", "name", "x"],
         ]
 
-    @mark.parametrize("break_action", (BREAK, True), ids=("BREAK", "True"))
+    @pytest.mark.parametrize("break_action", [BREAK, True], ids=["BREAK", "True"])
     def allows_early_exit_while_leaving(break_action):
         ast = parse("{ a, b { x }, c }", no_location=True)
         visited = []
 
         class TestVisitor(Visitor):
             @staticmethod
             def enter(*args):
@@ -507,14 +504,15 @@
             def leave(*args):
                 check_visitor_fn_args(ast, *args)
                 node = args[0]
                 kind, value = node.kind, get_value(node)
                 visited.append(["leave", kind, value])
                 if kind == "name" and node.value == "x":
                     return break_action
+                return None
 
         visit(ast, TestVisitor())
         assert visited == [
             ["enter", "document", None],
             ["enter", "operation_definition", None],
             ["enter", "selection_set", None],
             ["enter", "field", None],
@@ -578,15 +576,16 @@
             __slots__ = "name", "selection_set"
 
             name: NameNode
             selection_set: Optional[SelectionSetNode]
 
         custom_selection_set = cast(FieldNode, custom_ast.definitions[0]).selection_set
         assert custom_selection_set is not None
-        custom_selection_set.selections = custom_selection_set.selections + (
+        custom_selection_set.selections = (
+            *custom_selection_set.selections,
             CustomFieldNode(
                 name=NameNode(value="NameNodeToBeSkipped"),
                 selection_set=SelectionSetNode(
                     selections=CustomFieldNode(
                         name=NameNode(value="NameNodeToBeSkipped")
                     )
                 ),
@@ -652,26 +651,26 @@
             ["enter", "name", "ExampleOperation"],
             ["leave", "name", "ExampleOperation"],
             ["leave", "operation_definition", None],
             ["leave", "document", None],
         ]
 
     def cannot_define_visitor_with_unknown_ast_nodes():
-        with raises(TypeError) as exc_info:
+        with pytest.raises(TypeError) as exc_info:
 
             class VisitorWithNonExistingNode(Visitor):
                 def enter_field(self, *_args):
                     pass
 
                 def leave_garfield(self, *_args):
                     pass
 
         assert str(exc_info.value) == "Invalid AST node kind: garfield."
 
-        with raises(TypeError) as exc_info:
+        with pytest.raises(TypeError) as exc_info:
 
             class VisitorWithUnspecificNode(Visitor):
                 def enter_type_system_extension(self, *_args):
                     pass
 
         assert str(exc_info.value) == "Invalid AST node kind: type_system_extension."
 
@@ -1373,29 +1372,30 @@
             ["leave", "selection_set", "selection_set", "operation_definition"],
             ["leave", "operation_definition", 5, None],
             ["leave", "document", None, None],
         ]
 
 
 def describe_visit_in_parallel():
-    @mark.parametrize("skip_action", (SKIP, False), ids=("SKIP", "False"))
+    @pytest.mark.parametrize("skip_action", [SKIP, False], ids=["SKIP", "False"])
     def allows_skipping_a_sub_tree(skip_action):
         # Note: nearly identical to the above test but using ParallelVisitor
         ast = parse("{ a, b { x }, c }")
         visited = []
 
         class TestVisitor(Visitor):
             @staticmethod
             def enter(*args):
                 check_visitor_fn_args(ast, *args)
                 node = args[0]
                 kind, value = node.kind, get_value(node)
                 visited.append(["enter", kind, value])
                 if kind == "field" and node.name.value == "b":
                     return skip_action
+                return None
 
             @staticmethod
             def leave(*args):
                 check_visitor_fn_args(ast, *args)
                 node = args[0]
                 kind, value = node.kind, get_value(node)
                 visited.append(["leave", kind, value])
@@ -1415,15 +1415,15 @@
             ["leave", "name", "c"],
             ["leave", "field", None],
             ["leave", "selection_set", None],
             ["leave", "operation_definition", None],
             ["leave", "document", None],
         ]
 
-    @mark.parametrize("skip_action", (SKIP, False), ids=("SKIP", "False"))
+    @pytest.mark.parametrize("skip_action", [SKIP, False], ids=["SKIP", "False"])
     def allows_skipping_different_sub_trees(skip_action):
         ast = parse("{ a { x }, b { y} }")
         visited = []
 
         class TestVisitor(Visitor):
             def __init__(self, name):
                 super().__init__()
@@ -1433,14 +1433,15 @@
                 check_visitor_fn_args(ast, *args)
                 node = args[0]
                 kind, value = node.kind, get_value(node)
                 name = self.name
                 visited.append([f"no-{name}", "enter", kind, value])
                 if kind == "field" and node.name.value == name:
                     return skip_action
+                return None
 
             def leave(self, *args):
                 check_visitor_fn_args(ast, *args)
                 node = args[0]
                 kind, value = node.kind, get_value(node)
                 name = self.name
                 visited.append([f"no-{name}", "leave", kind, value])
@@ -1479,29 +1480,30 @@
             ["no-b", "leave", "selection_set", None],
             ["no-a", "leave", "operation_definition", None],
             ["no-b", "leave", "operation_definition", None],
             ["no-a", "leave", "document", None],
             ["no-b", "leave", "document", None],
         ]
 
-    @mark.parametrize("break_action", (BREAK, True), ids=("BREAK", "True"))
+    @pytest.mark.parametrize("break_action", [BREAK, True], ids=["BREAK", "True"])
     def allows_early_exit_while_visiting(break_action):
         # Note: nearly identical to the above test but using ParallelVisitor.
         ast = parse("{ a, b { x }, c }")
         visited = []
 
         class TestVisitor(Visitor):
             @staticmethod
             def enter(*args):
                 check_visitor_fn_args(ast, *args)
                 node = args[0]
                 kind, value = node.kind, get_value(node)
                 visited.append(["enter", kind, value])
                 if kind == "name" and node.value == "x":
                     return break_action
+                return None
 
             @staticmethod
             def leave(*args):
                 check_visitor_fn_args(ast, *args)
                 node = args[0]
                 kind, value = node.kind, get_value(node)
                 visited.append(["leave", kind, value])
@@ -1519,15 +1521,15 @@
             ["enter", "name", "b"],
             ["leave", "name", "b"],
             ["enter", "selection_set", None],
             ["enter", "field", None],
             ["enter", "name", "x"],
         ]
 
-    @mark.parametrize("break_action", (BREAK, True), ids=("BREAK", "True"))
+    @pytest.mark.parametrize("break_action", [BREAK, True], ids=["BREAK", "True"])
     def allows_early_exit_from_different_points(break_action):
         ast = parse("{ a { y }, b { x } }")
         visited = []
 
         class TestVisitor(Visitor):
             def __init__(self, name):
                 super().__init__()
@@ -1537,14 +1539,15 @@
                 check_visitor_fn_args(ast, *args)
                 node = args[0]
                 kind, value = node.kind, get_value(node)
                 name = self.name
                 visited.append([f"break-{name}", "enter", kind, value])
                 if kind == "name" and node.value == name:
                     return break_action
+                return None
 
             def leave(self, *args):
                 assert self.name == "b"
                 check_visitor_fn_args(ast, *args)
                 node = args[0]
                 kind, value = node.kind, get_value(node)
                 name = self.name
@@ -1570,15 +1573,15 @@
             ["break-b", "leave", "field", None],
             ["break-b", "leave", "selection_set", None],
             ["break-b", "leave", "field", None],
             ["break-b", "enter", "field", None],
             ["break-b", "enter", "name", "b"],
         ]
 
-    @mark.parametrize("break_action", (BREAK, True), ids=("BREAK", "True"))
+    @pytest.mark.parametrize("break_action", [BREAK, True], ids=["BREAK", "True"])
     def allows_early_exit_while_leaving(break_action):
         # Note: nearly identical to the above test but using ParallelVisitor.
         ast = parse("{ a, b { x }, c }")
         visited = []
 
         class TestVisitor(Visitor):
             @staticmethod
@@ -1592,14 +1595,15 @@
             def leave(*args):
                 check_visitor_fn_args(ast, *args)
                 node = args[0]
                 kind, value = node.kind, get_value(node)
                 visited.append(["leave", kind, value])
                 if kind == "name" and node.value == "x":
                     return break_action
+                return None
 
         visit(ast, ParallelVisitor([TestVisitor()]))
         assert visited == [
             ["enter", "document", None],
             ["enter", "operation_definition", None],
             ["enter", "selection_set", None],
             ["enter", "field", None],
@@ -1611,15 +1615,15 @@
             ["leave", "name", "b"],
             ["enter", "selection_set", None],
             ["enter", "field", None],
             ["enter", "name", "x"],
             ["leave", "name", "x"],
         ]
 
-    @mark.parametrize("break_action", (BREAK, True), ids=("BREAK", "True"))
+    @pytest.mark.parametrize("break_action", [BREAK, True], ids=["BREAK", "True"])
     def allows_early_exit_from_leaving_different_points(break_action):
         ast = parse("{ a { y }, b { x } }")
         visited = []
 
         class TestVisitor(Visitor):
             def __init__(self, name):
                 super().__init__()
@@ -1636,14 +1640,15 @@
                 check_visitor_fn_args(ast, *args)
                 node = args[0]
                 kind, value = node.kind, get_value(node)
                 name = self.name
                 visited.append([f"break-{name}", "leave", kind, value])
                 if kind == "field" and node.name.value == name:
                     return break_action
+                return None
 
         visit(ast, ParallelVisitor([TestVisitor("a"), TestVisitor("b")]))
         assert visited == [
             ["break-a", "enter", "document", None],
             ["break-b", "enter", "document", None],
             ["break-a", "enter", "operation_definition", None],
             ["break-b", "enter", "operation_definition", None],
@@ -1677,26 +1682,29 @@
             ["break-b", "enter", "name", "x"],
             ["break-b", "leave", "name", "x"],
             ["break-b", "leave", "field", None],
             ["break-b", "leave", "selection_set", None],
             ["break-b", "leave", "field", None],
         ]
 
-    @mark.parametrize("remove_action", (REMOVE, Ellipsis), ids=("REMOVE", "Ellipsis"))
+    @pytest.mark.parametrize(
+        "remove_action", [REMOVE, Ellipsis], ids=["REMOVE", "Ellipsis"]
+    )
     def allows_for_editing_on_enter(remove_action):
         ast = parse("{ a, b, c { a, b, c } }", no_location=True)
         visited = []
 
         class TestVisitor1(Visitor):
             @staticmethod
             def enter(*args):
                 check_visitor_fn_args(ast, *args)
                 node = args[0]
                 if node.kind == "field" and node.name.value == "b":
                     return remove_action
+                return None
 
         class TestVisitor2(Visitor):
             @staticmethod
             def enter(*args):
                 check_visitor_fn_args(ast, *args)
                 node = args[0]
                 kind, value = node.kind, get_value(node)
@@ -1735,26 +1743,29 @@
             ["leave", "selection_set", None],
             ["leave", "field", None],
             ["leave", "selection_set", None],
             ["leave", "operation_definition", None],
             ["leave", "document", None],
         ]
 
-    @mark.parametrize("remove_action", (REMOVE, Ellipsis), ids=("REMOVE", "Ellipsis"))
+    @pytest.mark.parametrize(
+        "remove_action", [REMOVE, Ellipsis], ids=["REMOVE", "Ellipsis"]
+    )
     def allows_for_editing_on_leave(remove_action):
         ast = parse("{ a, b, c { a, b, c } }", no_location=True)
         visited = []
 
         class TestVisitor1(Visitor):
             @staticmethod
             def leave(*args):
                 check_visitor_fn_args_edited(ast, *args)
                 node = args[0]
                 if node.kind == "field" and node.name.value == "b":
                     return remove_action
+                return None
 
         class TestVisitor2(Visitor):
             @staticmethod
             def enter(*args):
                 check_visitor_fn_args(ast, *args)
                 node = args[0]
                 kind, value = node.kind, get_value(node)
```

### Comparing `graphql_core-3.3.0a3/tests/pyutils/test_async_reduce.py` & `graphql_core-3.3.0a4/tests/pyutils/test_async_reduce.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,11 +1,10 @@
 from functools import reduce
 
-from pytest import mark
-
+import pytest
 from graphql.pyutils import async_reduce, is_awaitable
 
 
 def describe_async_reduce():
     def works_like_reduce_for_lists_of_ints():
         initial_value = -15
 
@@ -13,48 +12,48 @@
             return accumulator + current_value
 
         values = range(7, 13)
         result = async_reduce(callback, values, initial_value)
         assert result == 42
         assert result == reduce(callback, values, initial_value)
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def works_with_sync_values_and_sync_initial_value():
         def callback(accumulator, current_value):
             return accumulator + "-" + current_value
 
         values = ["bar", "baz"]
         result = async_reduce(callback, values, "foo")
         assert not is_awaitable(result)
         assert result == "foo-bar-baz"
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def works_with_async_initial_value():
         async def async_initial_value():
             return "foo"
 
         def callback(accumulator, current_value):
             return accumulator + "-" + current_value
 
         values = ["bar", "baz"]
         result = async_reduce(callback, values, async_initial_value())
         assert is_awaitable(result)
         assert await result == "foo-bar-baz"
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def works_with_async_callback():
         async def async_callback(accumulator, current_value):
             return accumulator + "-" + current_value
 
         values = ["bar", "baz"]
         result = async_reduce(async_callback, values, "foo")
         assert is_awaitable(result)
         assert await result == "foo-bar-baz"
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def works_with_async_callback_and_async_initial_value():
         async def async_initial_value():
             return 1 / 8
 
         async def async_callback(accumulator, current_value):
             return accumulator * current_value
```

### Comparing `graphql_core-3.3.0a3/tests/pyutils/test_cached_property.py` & `graphql_core-3.3.0a4/tests/pyutils/test_cached_property.py`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/tests/pyutils/test_convert_case.py` & `graphql_core-3.3.0a4/tests/pyutils/test_convert_case.py`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/tests/pyutils/test_description.py` & `graphql_core-3.3.0a4/tests/pyutils/test_description.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,12 +1,11 @@
 from contextlib import contextmanager
 from typing import cast
 
-from pytest import raises
-
+import pytest
 from graphql import graphql_sync
 from graphql.pyutils import (
     Description,
     is_description,
     register_description,
     unregister_description,
 )
@@ -91,20 +90,20 @@
             assert Description.bases is object
             unregister_description(str)
             assert Description.bases is object
         finally:
             Description.bases = str
 
     def can_only_register_types():
-        with raises(TypeError, match="Only types can be registered\\."):
+        with pytest.raises(TypeError, match="Only types can be registered\\."):
             # noinspection PyTypeChecker
             register_description("foo")  # type: ignore
 
     def can_only_unregister_types():
-        with raises(TypeError, match="Only types can be unregistered\\."):
+        with pytest.raises(TypeError, match="Only types can be unregistered\\."):
             # noinspection PyTypeChecker
             unregister_description("foo")  # type: ignore
 
     def describe_graphql_types():
         def graphql_named_type():
             named_type = GraphQLNamedType(name="Foo", description="not lazy")
             assert named_type.name == "Foo"
```

### Comparing `graphql_core-3.3.0a3/tests/pyutils/test_did_you_mean.py` & `graphql_core-3.3.0a4/tests/pyutils/test_did_you_mean.py`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/tests/pyutils/test_group_by.py` & `graphql_core-3.3.0a4/tests/pyutils/test_group_by.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 from graphql.pyutils import group_by
 
 
 def describe_group_by():
     def does_accept_an_empty_list():
         def key_fn(_x: str) -> str:
-            raise TypeError("Unexpected call of key function.")
+            raise TypeError("Unexpected call of key function.")  # pragma: no cover
 
         assert group_by([], key_fn) == {}
 
     def does_not_change_order():
         def key_fn(_x: int) -> str:
             return "all"
```

### Comparing `graphql_core-3.3.0a3/tests/pyutils/test_identity_func.py` & `graphql_core-3.3.0a4/tests/pyutils/test_identity_func.py`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/tests/pyutils/test_inspect.py` & `graphql_core-3.3.0a4/tests/pyutils/test_inspect.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,26 +1,24 @@
 from contextlib import contextmanager
 from importlib import import_module
 from math import inf, nan
 from typing import Any, Dict, FrozenSet, List, Set, Tuple
 
-from pytest import mark
-
+import pytest
 from graphql.pyutils import Undefined, inspect
 from graphql.type import (
     GraphQLDirective,
     GraphQLField,
     GraphQLInt,
     GraphQLList,
     GraphQLNonNull,
     GraphQLObjectType,
     GraphQLString,
 )
 
-
 inspect_module = import_module(inspect.__module__)
 
 
 @contextmanager
 def increased_recursive_depth():
     inspect_module.max_recursive_depth += 1  # type: ignore
     try:
@@ -134,15 +132,15 @@
     def inspect_generator():
         def test_generator():
             yield None  # pragma: no cover
 
         assert inspect(test_generator) == "<generator function test_generator>"
         assert inspect(test_generator()) == "<generator test_generator>"
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def inspect_coroutine():
         async def test_coroutine():
             pass
 
         assert inspect(test_coroutine) == "<coroutine function test_coroutine>"
         coroutine_object = test_coroutine()
         assert inspect(coroutine_object) == "<coroutine test_coroutine>"
@@ -256,16 +254,18 @@
         assert inspect(set()) == "set()"
         assert inspect({"a"}) == "{'a'}"
         assert inspect({"a", 1}) in ("{'a', 1}", "{1, 'a'}")  # sets are unordered
 
     def inspect_overly_large_set():
         s = set(range(20))
         r = inspect(s)
-        assert r.startswith("{") and r.endswith("}")
-        assert "..., " in r and "5" not in s  # sets are unordered
+        assert r.startswith("{")
+        assert r.endswith("}")
+        assert "..., " in r
+        assert "5" not in s  # sets are unordered
         assert len(r) == 36
         with increased_list_size():
             assert inspect(s) == repr(s)
 
     def inspect_overly_nested_set():
         s: List[List[Set]] = [[set()]]
         assert inspect(s) == "[[set()]]"
@@ -281,16 +281,18 @@
             "frozenset({'a', 1})",
             "frozenset({1, 'a'})",
         )  # frozensets are unordered
 
     def inspect_overly_large_frozenset():
         s = frozenset(range(20))
         r = inspect(s)
-        assert r.startswith("frozenset({") and r.endswith("})")
-        assert "..., " in r and "5" not in s  # frozensets are unordered
+        assert r.startswith("frozenset({")
+        assert r.endswith("})")
+        assert "..., " in r
+        assert "5" not in s  # frozensets are unordered
         assert len(r) == 47
         with increased_list_size():
             assert inspect(s) == repr(s)
 
     def inspect_overly_nested_frozenset():
         s: FrozenSet[FrozenSet[FrozenSet]] = frozenset([frozenset([frozenset()])])
         assert inspect(s) == "frozenset({frozenset({frozenset()})})"
```

### Comparing `graphql_core-3.3.0a3/tests/pyutils/test_is_awaitable.py` & `graphql_core-3.3.0a4/tests/pyutils/test_is_awaitable.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,13 +1,12 @@
 import asyncio
 from inspect import isawaitable
 from sys import version_info as python_version
 
-from pytest import mark
-
+import pytest
 from graphql.pyutils import is_awaitable
 
 
 def describe_is_awaitable():
     def declines_the_none_value():
         assert not isawaitable(None)
         assert not is_awaitable(None)
@@ -63,54 +62,54 @@
     def declines_a_coroutine_function():
         async def some_async_function():
             return True  # pragma: no cover
 
         assert not isawaitable(some_async_function)
         assert not is_awaitable(some_async_function)
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def recognizes_a_coroutine_object():
         async def some_async_function():
             return True
 
         some_coroutine = some_async_function()
 
         assert isawaitable(some_coroutine)
         assert is_awaitable(some_coroutine)
 
         assert await some_coroutine is True
 
-    @mark.filterwarnings("ignore::Warning")  # Deprecation and Runtime warnings
-    @mark.skipif(
+    @pytest.mark.filterwarnings("ignore::Warning")  # Deprecation and Runtime warnings
+    @pytest.mark.skipif(
         python_version >= (3, 11),
         reason="Generator-based coroutines not supported any more since Python 3.11",
     )
     async def recognizes_an_old_style_coroutine():  # pragma: no cover
         @asyncio.coroutine  # type: ignore
         def some_function():
             yield True
 
         some_old_style_coroutine = some_function()
         assert is_awaitable(some_old_style_coroutine)
         assert is_awaitable(some_old_style_coroutine)
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def recognizes_a_future_object():
         async def some_async_function():
             return True
 
         some_coroutine = some_async_function()
         some_future = asyncio.ensure_future(some_coroutine)
 
         assert is_awaitable(some_future)
         assert is_awaitable(some_future)
 
         assert await some_future is True
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def declines_an_async_generator():
         async def some_async_generator_function():
             yield True
 
         some_async_generator = some_async_generator_function()
 
         assert not isawaitable(some_async_generator)
```

### Comparing `graphql_core-3.3.0a3/tests/pyutils/test_is_iterable.py` & `graphql_core-3.3.0a4/tests/pyutils/test_is_iterable.py`

 * *Files 1% similar despite different names*

```diff
@@ -14,15 +14,15 @@
 
     def should_return_true_for_tuples():
         assert is_collection(()) is True
         assert is_collection((0, 1, 1)) is True
         assert is_collection(("A", "B", "C")) is True
 
     def should_return_true_for_named_tuples():
-        named = namedtuple("named", "A B C")
+        named = namedtuple("named", "A B C")  # noqa: PYI024
         assert is_collection(named(0, 1, 2)) is True
 
     def should_return_true_for_arrays():
         assert is_collection(array("b")) is True
         assert is_collection(array("b", [0, 1, 2])) is True
         assert is_collection(array("i")) is True
         assert is_collection(array("i", [0, 1, 2])) is True
@@ -118,15 +118,15 @@
 
     def should_return_true_for_tuples():
         assert is_iterable(()) is True
         assert is_iterable((0, 1, 1)) is True
         assert is_iterable(("A", "B", "C")) is True
 
     def should_return_true_for_named_tuples():
-        named = namedtuple("named", "a b c")
+        named = namedtuple("named", "a b c")  # noqa: PYI024
         assert is_iterable(named(0, 1, 2)) is True
 
     def should_return_true_for_arrays():
         assert is_iterable(array("b")) is True
         assert is_iterable(array("b", [0, 1, 2])) is True
         assert is_iterable(array("i")) is True
         assert is_iterable(array("i", [0, 1, 2])) is True
```

### Comparing `graphql_core-3.3.0a3/tests/pyutils/test_merge_kwargs.py` & `graphql_core-3.3.0a4/tests/pyutils/test_merge_kwargs.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,9 @@
 from graphql.pyutils import merge_kwargs
 
-
 try:
     from typing import TypedDict
 except ImportError:  # Python < 3.8
     from typing_extensions import TypedDict
 
 
 class FooDict(TypedDict):
```

### Comparing `graphql_core-3.3.0a3/tests/pyutils/test_natural_compare.py` & `graphql_core-3.3.0a4/tests/pyutils/test_natural_compare.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,10 +1,9 @@
 from graphql.pyutils import natural_comparison_key
 
-
 key = natural_comparison_key
 
 
 def describe_natural_compare():
     def handles_empty_strings():
         assert key("") < key("a")
         assert key("") < key("1")
```

### Comparing `graphql_core-3.3.0a3/tests/pyutils/test_path.py` & `graphql_core-3.3.0a4/tests/pyutils/test_path.py`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/tests/pyutils/test_simple_pub_sub.py` & `graphql_core-3.3.0a4/tests/pyutils/test_simple_pub_sub.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,16 +1,15 @@
 from asyncio import sleep
 
-from pytest import mark, raises
-
+import pytest
 from graphql.pyutils import SimplePubSub, is_awaitable
 
 
 def describe_simple_pub_sub():
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def subscribe_async_iterator_mock():
         pubsub = SimplePubSub()
         iterator = pubsub.get_subscriber()
 
         # Queue up publishes
         assert pubsub.emit("Apple") is True
         assert pubsub.emit("Banana") is True
@@ -39,22 +38,22 @@
         # Terminate queue
         await iterator.aclose()
 
         # Publish is not caught after terminate
         assert pubsub.emit("Fig") is False
 
         # Find that cancelled read-ahead got a "done" result
-        with raises(StopAsyncIteration):
+        with pytest.raises(StopAsyncIteration):
             await i5
 
         # And next returns empty completion value
-        with raises(StopAsyncIteration):
+        with pytest.raises(StopAsyncIteration):
             await iterator.__anext__()
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def iterator_aclose_empties_push_queue():
         pubsub = SimplePubSub()
         assert not pubsub.subscribers
         iterator = pubsub.get_subscriber()
         assert len(pubsub.subscribers) == 1
         assert iterator.listening
         for value in range(3):
@@ -64,15 +63,15 @@
         assert iterator.pull_queue.qsize() == 0
         await iterator.aclose()
         assert not pubsub.subscribers
         assert iterator.push_queue.qsize() == 0
         assert iterator.pull_queue.qsize() == 0
         assert not iterator.listening
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def iterator_aclose_empties_pull_queue():
         pubsub = SimplePubSub()
         assert not pubsub.subscribers
         iterator = pubsub.get_subscriber()
         assert len(pubsub.subscribers) == 1
         assert iterator.listening
         for _n in range(3):
@@ -81,15 +80,15 @@
         assert iterator.pull_queue.qsize() == 3
         await iterator.aclose()
         assert not pubsub.subscribers
         assert iterator.push_queue.qsize() == 0
         assert iterator.pull_queue.qsize() == 0
         assert not iterator.listening
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def iterator_aclose_is_idempotent():
         pubsub = SimplePubSub()
         iterator = pubsub.get_subscriber()
         assert iterator.listening
         for _n in range(3):
             await iterator.aclose()
             assert not iterator.listening
```

### Comparing `graphql_core-3.3.0a3/tests/pyutils/test_suggestion_list.py` & `graphql_core-3.3.0a4/tests/pyutils/test_suggestion_list.py`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/tests/pyutils/test_undefined.py` & `graphql_core-3.3.0a4/tests/pyutils/test_undefined.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,11 +1,10 @@
 import pickle
 
-from pytest import warns
-
+import pytest
 from graphql.pyutils import Undefined, UndefinedType
 
 
 def describe_Undefined():
     def has_repr():
         assert repr(Undefined) == "Undefined"
 
@@ -19,31 +18,30 @@
         assert hash(Undefined) != hash(True)
 
     def as_bool_is_false():
         assert bool(Undefined) is False
 
     def only_equal_to_itself_and_none():
         # because we want it to behave similarly to JavaScript
-        assert Undefined == Undefined
-        assert not Undefined != Undefined
+        assert Undefined == Undefined  # noqa: PLR0124
         none_object = None
         assert Undefined == none_object
-        assert not Undefined != none_object
+        assert none_object == Undefined
         false_object = False
         assert Undefined != false_object
-        assert not Undefined == false_object
+        assert false_object != Undefined
 
     def should_not_be_an_exception():
         # because we want to create similar code to JavaScript where
         # undefined return values are different from exceptions
         # (for instance, this is used in the completeValue function)
         assert not isinstance(Undefined, Exception)
 
     def cannot_be_redefined():
-        with warns(RuntimeWarning, match="Redefinition of 'Undefined'"):
+        with pytest.warns(RuntimeWarning, match="Redefinition of 'Undefined'"):
             redefined_undefined = UndefinedType()
         assert redefined_undefined is Undefined
 
     def can_be_pickled():
         pickled_undefined = pickle.dumps(Undefined)
         unpickled_undefined = pickle.loads(pickled_undefined)
         assert unpickled_undefined is Undefined
```

### Comparing `graphql_core-3.3.0a3/tests/star_wars_data.py` & `graphql_core-3.3.0a4/tests/star_wars_data.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,17 +1,16 @@
-"""This defines a basic set of data for our Star Wars Schema.
+"""Define a basic set of data for our Star Wars Schema.
 
-This data is hard coded for the sake of the demo, but you could imagine fetching this
+The data is hard coded for the sake of the demo, but you could imagine fetching this
 data from a backend service rather than from hardcoded JSON objects in a more complex
 demo.
 """
 
 from typing import Awaitable, Collection, Dict, Iterator, Optional
 
-
 __all__ = ["get_droid", "get_friends", "get_hero", "get_human", "get_secret_backstory"]
 
 # These are classes which correspond to the schema.
 # They represent the shape of the data visited during field resolution.
 
 
 class Character:
@@ -23,27 +22,27 @@
 
 # noinspection PyPep8Naming
 class Human(Character):
     type = "Human"
     homePlanet: str
 
     # noinspection PyShadowingBuiltins
-    def __init__(self, id, name, friends, appearsIn, homePlanet):
+    def __init__(self, id, name, friends, appearsIn, homePlanet):  # noqa: A002
         self.id, self.name = id, name
         self.friends, self.appearsIn = friends, appearsIn
         self.homePlanet = homePlanet
 
 
 # noinspection PyPep8Naming
 class Droid(Character):
     type = "Droid"
     primaryFunction: str
 
     # noinspection PyShadowingBuiltins
-    def __init__(self, id, name, friends, appearsIn, primaryFunction):
+    def __init__(self, id, name, friends, appearsIn, primaryFunction):  # noqa: A002
         self.id, self.name = id, name
         self.friends, self.appearsIn = friends, appearsIn
         self.primaryFunction = primaryFunction
 
 
 luke = Human(
     id="1000",
@@ -105,15 +104,15 @@
     primaryFunction="Astromech",
 )
 
 droid_data: Dict[str, Droid] = {"2000": threepio, "2001": artoo}
 
 
 # noinspection PyShadowingBuiltins
-async def get_character(id: str) -> Optional[Character]:
+async def get_character(id: str) -> Optional[Character]:  # noqa: A002
     """Helper function to get a character by ID."""
     # We use an async function just to illustrate that GraphQL-core supports it.
     return human_data.get(id) or droid_data.get(id)
 
 
 def get_friends(character: Character) -> Iterator[Awaitable[Optional[Character]]]:
     """Allows us to query for a character's friends."""
@@ -127,22 +126,22 @@
         # Luke is the hero of Episode V.
         return luke
     # Artoo is the hero otherwise.
     return artoo
 
 
 # noinspection PyShadowingBuiltins
-def get_human(id: str) -> Optional[Human]:
+def get_human(id: str) -> Optional[Human]:  # noqa: A002
     """Allows us to query for the human with the given id."""
     return human_data.get(id)
 
 
 # noinspection PyShadowingBuiltins
-def get_droid(id: str) -> Optional[Droid]:
+def get_droid(id: str) -> Optional[Droid]:  # noqa: A002
     """Allows us to query for the droid with the given id."""
     return droid_data.get(id)
 
 
 # noinspection PyUnusedLocal
-def get_secret_backstory(character: Character) -> str:
+def get_secret_backstory(character: Character) -> str:  # noqa: ARG001
     """Raise an error when attempting to get the secret backstory."""
     raise RuntimeError("secretBackstory is secret.")
```

### Comparing `graphql_core-3.3.0a3/tests/star_wars_schema.py` & `graphql_core-3.3.0a4/tests/star_wars_schema.py`

 * *Ordering differences only*

 * *Files 0% similar despite different names*

```diff
@@ -50,23 +50,23 @@
     GraphQLInterfaceType,
     GraphQLList,
     GraphQLNonNull,
     GraphQLObjectType,
     GraphQLSchema,
     GraphQLString,
 )
+
 from tests.star_wars_data import (
     get_droid,
     get_friends,
     get_hero,
     get_human,
     get_secret_backstory,
 )
 
-
 __all__ = ["star_wars_schema"]
 
 # We begin by setting up our schema.
 
 # The original trilogy consists of three movies.
 #
 # This implements the following type system shorthand:
```

### Comparing `graphql_core-3.3.0a3/tests/test_docs.py` & `graphql_core-3.3.0a4/tests/test_docs.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,42 +1,41 @@
 """Test all code snippets in the documentation"""
 
 from pathlib import Path
 from typing import Any, Dict, List
 
 from .utils import dedent
 
-
 try:
     from typing import TypeAlias
 except ImportError:  # Python < 3.10
     from typing_extensions import TypeAlias
 
 
 Scope: TypeAlias = Dict[str, Any]
 
 
 def get_snippets(source, indent=4):
     """Get all code snippets from a given documentation source file."""
     if not source.endswith(".rst"):  # pragma: no cover
         source += ".rst"
     source_path = Path(__file__).parents[1] / "docs" / source
-    lines = open(source_path).readlines()
+    with source_path.open() as source_file:
+        lines = source_file.readlines()
     snippets: List[str] = []
     snippet: List[str] = []
     snippet_start = " " * indent
     for line in lines:
         if not line.rstrip() and snippet:
             snippet.append(line)
         elif line.startswith(snippet_start):
             snippet.append(line[indent:])
-        else:
-            if snippet:
-                snippets.append("".join(snippet).rstrip() + "\n")
-                snippet = []
+        elif snippet:
+            snippets.append("".join(snippet).rstrip() + "\n")
+            snippet = []
     if snippet:
         snippets.append("".join(snippet).rstrip() + "\n")
     return snippets
 
 
 def expected_result(snippets):
     """Get and normalize expected result from snippet."""
@@ -52,24 +51,27 @@
     return " ".join(out.split()).replace("( ", "(").replace('" "', "")
 
 
 def describe_introduction():
     def getting_started(capsys):
         intro = get_snippets("intro")
         pip_install = intro.pop(0)
-        assert "pip install" in pip_install and "graphql-core" in pip_install
+        assert "pip install" in pip_install
+        assert "graphql-core" in pip_install
         poetry_install = intro.pop(0)
         assert "poetry install" in poetry_install
         create_schema = intro.pop(0)
         assert "schema = GraphQLSchema(" in create_schema
         scope: Scope = {}
         exec(create_schema, scope)
         schema = scope.get("schema")
         schema_class = scope.get("GraphQLSchema")
-        assert schema and schema_class and isinstance(schema, schema_class)
+        assert schema
+        assert schema_class
+        assert isinstance(schema, schema_class)
         query = intro.pop(0)
         assert "graphql_sync" in query
         exec(query, scope)
         out, err = capsys.readouterr()
         assert out.startswith("ExecutionResult")
         assert not err
         expected_out = intro.pop(0)
@@ -136,26 +138,28 @@
         scope: Scope = {}
         exec(resolvers, scope)
         schema = "\n".join(get_snippets("usage/schema")[1:])
         exec(schema, scope)
         queries = get_snippets("usage/queries")
 
         async_query = queries.pop(0)
-        assert "asyncio" in async_query and "graphql_sync" not in async_query
+        assert "asyncio" in async_query
+        assert "graphql_sync" not in async_query
         assert "asyncio.run" in async_query
         from asyncio import run  # noqa: F401
 
         exec(async_query, scope)
         out, err = capsys.readouterr()
         assert not err
         assert "R2-D2" in out
         assert out == expected_result(queries)
 
         sync_query = queries.pop(0)
-        assert "graphql_sync" in sync_query and "asyncio" not in sync_query
+        assert "graphql_sync" in sync_query
+        assert "asyncio" not in sync_query
         exec(sync_query, scope)
         out, err = capsys.readouterr()
         assert not err
         assert "Luke" in out
         assert out == expected_result(queries)
 
         bad_query = queries.pop(0)
@@ -167,23 +171,25 @@
         assert out == expected_result(queries)
 
         typename_query = queries.pop(0)
         assert "__typename" in typename_query
         exec(typename_query, scope)
         out, err = capsys.readouterr()
         assert not err
-        assert "__typename" in out and "Human" in out
+        assert "__typename" in out
+        assert "Human" in out
         assert out == expected_result(queries)
 
         backstory_query = queries.pop(0)
         assert "secretBackstory" in backstory_query
         exec(backstory_query, scope)
         out, err = capsys.readouterr()
         assert not err
-        assert "errors" in out and "secretBackstory" in out
+        assert "errors" in out
+        assert "secretBackstory" in out
         assert out == expected_result(queries)
 
     def using_the_sdl(capsys):
         use_sdl = get_snippets("usage/sdl")
         build_schema = use_sdl.pop(0)
         build_schema_sdl = dedent(
             build_schema.partition('build_schema("""\n')[2].partition('""")')[0]
@@ -204,19 +210,22 @@
         define_episode_enum = define_episode_enum.partition("episode_enum =")[0]
         assert "class EpisodeEnum" in define_episode_enum
         exec(define_episode_enum, scope)
         exec(define_enum_values, scope)
         assert schema.get_type("Episode").values["EMPIRE"].value == 5
 
         query = use_sdl.pop(0)
-        assert "graphql_sync" in query and "print(result)" in query
+        assert "graphql_sync" in query
+        assert "print(result)" in query
         exec(query, scope)
         out, err = capsys.readouterr()
         assert not err
-        assert "Luke" in out and "appearsIn" in out and "EMPIRE" in out
+        assert "Luke" in out
+        assert "appearsIn" in out
+        assert "EMPIRE" in out
         assert out == expected_result(use_sdl)
 
     def using_resolver_methods(capsys):
         scope: Scope = {}
         exec(resolvers, scope)
         build_schema = get_snippets("usage/sdl")[0]
         exec(build_schema, scope)
@@ -225,19 +234,22 @@
         root_class = methods.pop(0)
         assert root_class.startswith("class Root:")
         assert "def human(self, info, id):" in root_class
         exec(root_class, scope)
         assert "Root" in scope
 
         query = methods.pop(0)
-        assert "graphql_sync" in query and "Root()" in query
+        assert "graphql_sync" in query
+        assert "Root()" in query
         exec(query, scope)
         out, err = capsys.readouterr()
         assert not err
-        assert "R2-D2" in out and "primaryFunction" in out and "Astromech" in out
+        assert "R2-D2" in out
+        assert "primaryFunction" in out
+        assert "Astromech" in out
         assert out == expected_result(methods)
 
     def using_introspection(capsys):
         introspect = get_snippets("usage/introspection")
         get_query = introspect.pop(0)
         assert "import get_introspection_query" in get_query
         assert "descriptions=True" in get_query
@@ -339,15 +351,16 @@
         assert human_type.fields["lastName"].resolve is scope["get_last_name"]
 
         query = extension.pop(0)
         assert "graphql_sync(" in query
         exec(query, scope)
         out, err = capsys.readouterr()
         assert not err
-        assert "lastName" in out and "Skywalker" in out
+        assert "lastName" in out
+        assert "Skywalker" in out
         assert out == expected_result(extension)
 
     def validating_queries():
         scope: Scope = {}
         exec(resolvers, scope)
         create_schema = "\n".join(get_snippets("usage/schema")[1:])
         exec(create_schema, scope)
```

### Comparing `graphql_core-3.3.0a3/tests/test_star_wars_introspection.py` & `graphql_core-3.3.0a4/tests/test_star_wars_introspection.py`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/tests/test_star_wars_query.py` & `graphql_core-3.3.0a4/tests/test_star_wars_query.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,44 +1,43 @@
-from pytest import mark
-
+import pytest
 from graphql import graphql, graphql_sync
 
 from .star_wars_schema import star_wars_schema as schema
 
 
 def describe_star_wars_query_tests():
     def describe_basic_queries():
-        @mark.asyncio
+        @pytest.mark.asyncio()
         async def correctly_identifies_r2_d2_as_hero_of_the_star_wars_saga():
             source = """
                 query HeroNameQuery {
                   hero {
                     name
                   }
                 }
                 """
             result = await graphql(schema=schema, source=source)
             assert result == ({"hero": {"name": "R2-D2"}}, None)
 
-        @mark.asyncio
+        @pytest.mark.asyncio()
         async def accepts_positional_arguments_to_graphql():
             source = """
                 query HeroNameQuery {
                   hero {
                     name
                   }
                 }
                 """
             result = await graphql(schema, source)
             assert result == ({"hero": {"name": "R2-D2"}}, None)
 
             sync_result = graphql_sync(schema, source)
             assert sync_result == result
 
-        @mark.asyncio
+        @pytest.mark.asyncio()
         async def allows_us_to_query_for_the_id_and_friends_of_r2_d2():
             source = """
                 query HeroNameAndFriendsQuery {
                   hero {
                     id
                     name
                     friends {
@@ -60,15 +59,15 @@
                         ],
                     }
                 },
                 None,
             )
 
     def describe_nested_queries():
-        @mark.asyncio
+        @pytest.mark.asyncio()
         async def allows_us_to_query_for_the_friends_of_friends_of_r2_d2():
             source = """
                 query NestedQuery {
                   hero {
                     name
                     friends {
                       name
@@ -118,27 +117,27 @@
                         ],
                     }
                 },
                 None,
             )
 
     def describe_using_ids_and_query_parameters_to_refetch_objects():
-        @mark.asyncio
+        @pytest.mark.asyncio()
         async def allows_us_to_query_for_r2_d2_directly_using_his_id():
             source = """
                 query {
                   droid(id: "2001") {
                     name
                   }
                 }
                 """
             result = await graphql(schema=schema, source=source)
             assert result == ({"droid": {"name": "R2-D2"}}, None)
 
-        @mark.asyncio
+        @pytest.mark.asyncio()
         async def allows_us_to_query_characters_directly_using_their_id():
             source = """
                 query FetchLukeAndC3POQuery {
                   human(id: "1000") {
                     name
                   }
                   droid(id: "2000") {
@@ -148,45 +147,45 @@
                 """
             result = await graphql(schema=schema, source=source)
             assert result == (
                 {"human": {"name": "Luke Skywalker"}, "droid": {"name": "C-3PO"}},
                 None,
             )
 
-        @mark.asyncio
+        @pytest.mark.asyncio()
         async def allows_creating_a_generic_query_to_fetch_luke_using_his_id():
             source = """
                 query FetchSomeIDQuery($someId: String!) {
                   human(id: $someId) {
                     name
                   }
                 }
                 """
             variable_values = {"someId": "1000"}
             result = await graphql(
                 schema=schema, source=source, variable_values=variable_values
             )
             assert result == ({"human": {"name": "Luke Skywalker"}}, None)
 
-        @mark.asyncio
+        @pytest.mark.asyncio()
         async def allows_creating_a_generic_query_to_fetch_han_using_his_id():
             source = """
                 query FetchSomeIDQuery($someId: String!) {
                   human(id: $someId) {
                     name
                   }
                 }
                 """
             variable_values = {"someId": "1002"}
             result = await graphql(
                 schema=schema, source=source, variable_values=variable_values
             )
             assert result == ({"human": {"name": "Han Solo"}}, None)
 
-        @mark.asyncio
+        @pytest.mark.asyncio()
         async def generic_query_that_gets_null_back_when_passed_invalid_id():
             source = """
                 query humanQuery($id: String!) {
                   human(id: $id) {
                     name
                   }
                 }
@@ -194,27 +193,27 @@
             variable_values = {"id": "not a valid id"}
             result = await graphql(
                 schema=schema, source=source, variable_values=variable_values
             )
             assert result == ({"human": None}, None)
 
     def describe_using_aliases_to_change_the_key_in_the_response():
-        @mark.asyncio
+        @pytest.mark.asyncio()
         async def allows_us_to_query_for_luke_changing_his_key_with_an_alias():
             source = """
                 query FetchLukeAliased {
                   luke: human(id: "1000") {
                     name
                   }
                 }
                 """
             result = await graphql(schema=schema, source=source)
             assert result == ({"luke": {"name": "Luke Skywalker"}}, None)
 
-        @mark.asyncio
+        @pytest.mark.asyncio()
         async def query_for_luke_and_leia_using_two_root_fields_and_an_alias():
             source = """
                 query FetchLukeAndLeiaAliased {
                   luke: human(id: "1000") {
                     name
                   }
                   leia: human(id: "1003") {
@@ -225,15 +224,15 @@
             result = await graphql(schema=schema, source=source)
             assert result == (
                 {"luke": {"name": "Luke Skywalker"}, "leia": {"name": "Leia Organa"}},
                 None,
             )
 
     def describe_uses_fragments_to_express_more_complex_queries():
-        @mark.asyncio
+        @pytest.mark.asyncio()
         async def allows_us_to_query_using_duplicated_content():
             source = """
                 query DuplicateFields {
                   luke: human(id: "1000") {
                     name
                     homePlanet
                   }
@@ -248,15 +247,15 @@
                 {
                     "luke": {"name": "Luke Skywalker", "homePlanet": "Tatooine"},
                     "leia": {"name": "Leia Organa", "homePlanet": "Alderaan"},
                 },
                 None,
             )
 
-        @mark.asyncio
+        @pytest.mark.asyncio()
         async def allows_us_to_use_a_fragment_to_avoid_duplicating_content():
             source = """
                 query UseFragment {
                   luke: human(id: "1000") {
                     ...HumanFragment
                   }
                   leia: human(id: "1003") {
@@ -274,28 +273,28 @@
                     "luke": {"name": "Luke Skywalker", "homePlanet": "Tatooine"},
                     "leia": {"name": "Leia Organa", "homePlanet": "Alderaan"},
                 },
                 None,
             )
 
     def describe_using_typename_to_find_the_type_of_an_object():
-        @mark.asyncio
+        @pytest.mark.asyncio()
         async def allows_us_to_verify_that_r2_d2_is_a_droid():
             source = """
                 query CheckTypeOfR2 {
                   hero {
                     __typename
                     name
                   }
                 }
                 """
             result = await graphql(schema=schema, source=source)
             assert result == ({"hero": {"__typename": "Droid", "name": "R2-D2"}}, None)
 
-        @mark.asyncio
+        @pytest.mark.asyncio()
         async def allows_us_to_verify_that_luke_is_a_human():
             source = """
                 query CheckTypeOfLuke {
                   hero(episode: EMPIRE) {
                     __typename
                     name
                   }
@@ -304,15 +303,15 @@
             result = await graphql(schema=schema, source=source)
             assert result == (
                 {"hero": {"__typename": "Human", "name": "Luke Skywalker"}},
                 None,
             )
 
     def describe_reporting_errors_raised_in_resolvers():
-        @mark.asyncio
+        @pytest.mark.asyncio()
         async def correctly_reports_error_on_accessing_secret_backstory():
             source = """
                 query HeroNameQuery {
                   hero {
                     name
                     secretBackstory
                   }
@@ -326,15 +325,15 @@
                         "message": "secretBackstory is secret.",
                         "locations": [(5, 21)],
                         "path": ["hero", "secretBackstory"],
                     }
                 ],
             )
 
-        @mark.asyncio
+        @pytest.mark.asyncio()
         async def correctly_reports_error_on_accessing_backstory_in_a_list():
             source = """
                 query HeroNameQuery {
                   hero {
                     name
                     friends {
                       name
@@ -370,15 +369,15 @@
                         "message": "secretBackstory is secret.",
                         "locations": [(7, 23)],
                         "path": ["hero", "friends", 2, "secretBackstory"],
                     },
                 ],
             )
 
-        @mark.asyncio
+        @pytest.mark.asyncio()
         async def correctly_reports_error_on_accessing_through_an_alias():
             source = """
                 query HeroNameQuery {
                   mainHero: hero {
                     name
                     story: secretBackstory
                   }
```

### Comparing `graphql_core-3.3.0a3/tests/test_star_wars_validation.py` & `graphql_core-3.3.0a4/tests/test_star_wars_validation.py`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/tests/test_user_registry.py` & `graphql_core-3.3.0a4/tests/test_user_registry.py`

 * *Files 3% similar despite different names*

```diff
@@ -5,16 +5,15 @@
 """
 
 from asyncio import create_task, sleep, wait
 from collections import defaultdict
 from enum import Enum
 from typing import Any, AsyncIterable, Dict, List, NamedTuple, Optional
 
-from pytest import fixture, mark
-
+import pytest
 from graphql import (
     GraphQLArgument,
     GraphQLBoolean,
     GraphQLEnumType,
     GraphQLField,
     GraphQLID,
     GraphQLInputField,
@@ -128,43 +127,41 @@
 async def resolve_user(_root, info, **args):
     """Resolver function for fetching a user object"""
     return await info.context["registry"].get(args["id"])
 
 
 async def resolve_create_user(_root, info, data):
     """Resolver function for creating a user object"""
-    user = await info.context["registry"].create(**data)
-    return user
+    return await info.context["registry"].create(**data)
 
 
 # noinspection PyShadowingBuiltins
-async def resolve_update_user(_root, info, id, data):
+async def resolve_update_user(_root, info, id, data):  # noqa: A002
     """Resolver function for updating a user object"""
-    user = await info.context["registry"].update(id, **data)
-    return user
+    return await info.context["registry"].update(id, **data)
 
 
 # noinspection PyShadowingBuiltins
-async def resolve_delete_user(_root, info, id):
+async def resolve_delete_user(_root, info, id):  # noqa: A002
     """Resolver function for deleting a user object"""
     user = await info.context["registry"].get(id)
     await info.context["registry"].delete(user.id)
     return True
 
 
 # noinspection PyShadowingBuiltins
-async def subscribe_user(_root, info, id=None):
+async def subscribe_user(_root, info, id=None):  # noqa: A002
     """Subscribe to mutations of a specific user object or all user objects"""
     async_iterator = info.context["registry"].event_iterator(id)
     async for event in async_iterator:
         yield await event if is_awaitable(event) else event  # pragma: no cover exit
 
 
 # noinspection PyShadowingBuiltins,PyUnusedLocal
-async def resolve_subscription_user(event, info, id):
+async def resolve_subscription_user(event, info, id):  # noqa: ARG001, A002
     """Resolver function for user subscriptions"""
     user = event["user"]
     mutation = MutationEnum(event["mutation"]).value
     return {"user": user, "mutation": mutation}
 
 
 schema = GraphQLSchema(
@@ -209,21 +206,21 @@
                 resolve=resolve_subscription_user,
             )
         },
     ),
 )
 
 
-@fixture
+@pytest.fixture()
 def context():
     return {"registry": UserRegistry()}
 
 
 def describe_query():
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def query_user(context):
         user = await context["registry"].create(
             firstName="John", lastName="Doe", tweets=42, verified=True
         )
 
         query = """
             query ($userId: ID!) {
@@ -247,37 +244,42 @@
                 "tweets": user.tweets,
                 "verified": user.verified,
             }
         }
 
 
 def describe_mutation():
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def create_user(context):
         received = {}
 
         def subscriber(event_name):
             def receive(msg):
                 received[event_name] = msg
 
             return receive
 
         # noinspection PyProtectedMember
-        pubsub = context["registry"]._pubsub
+        pubsub = context["registry"]._pubsub  # noqa: SLF001s
         pubsub[None].subscribers.add(subscriber("User"))
         pubsub["0"].subscribers.add(subscriber("User 0"))
 
         query = """
             mutation ($userData: UserInputType!) {
                 createUser(data: $userData) {
                     id, firstName, lastName, tweets, verified
                 }
             }
             """
-        user_data = dict(firstName="John", lastName="Doe", tweets=42, verified=True)
+        user_data = {
+            "firstName": "John",
+            "lastName": "Doe",
+            "tweets": 42,
+            "verified": True,
+        }
         variables = {"userData": user_data}
         result = await graphql(
             schema, query, context_value=context, variable_values=variables
         )
 
         user = await context["registry"].get("0")
         assert user == User(id="0", **user_data)  # type: ignore
@@ -294,26 +296,26 @@
         }
 
         assert received == {
             "User": {"user": user, "mutation": MutationEnum.CREATED.value},
             "User 0": {"user": user, "mutation": MutationEnum.CREATED.value},
         }
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def update_user(context):
         received = {}
 
         def subscriber(event_name):
             def receive(msg):
                 received[event_name] = msg
 
             return receive
 
         # noinspection PyProtectedMember
-        pubsub = context["registry"]._pubsub
+        pubsub = context["registry"]._pubsub  # noqa: SLF001
         pubsub[None].subscribers.add(subscriber("User"))
         pubsub["0"].subscribers.add(subscriber("User 0"))
 
         user = await context["registry"].create(
             firstName="John", lastName="Doe", tweets=42, verified=True
         )
         user_data = {
@@ -350,26 +352,26 @@
         }
 
         assert received == {
             "User": {"user": user, "mutation": MutationEnum.UPDATED.value},
             "User 0": {"user": user, "mutation": MutationEnum.UPDATED.value},
         }
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def delete_user(context):
         received = {}
 
         def subscriber(name):
             def receive(msg):
                 received[name] = msg
 
             return receive
 
         # noinspection PyProtectedMember
-        pubsub = context["registry"]._pubsub
+        pubsub = context["registry"]._pubsub  # noqa: SLF001
         pubsub[None].subscribers.add(subscriber("User"))
         pubsub["0"].subscribers.add(subscriber("User 0"))
 
         user = await context["registry"].create(
             firstName="John", lastName="Doe", tweets=42, verified=True
         )
 
@@ -392,15 +394,15 @@
         assert received == {
             "User": {"user": user, "mutation": MutationEnum.DELETED.value},
             "User 0": {"user": user, "mutation": MutationEnum.DELETED.value},
         }
 
 
 def describe_subscription():
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def subscribe_to_user_mutations(context):
         query = """
             subscription ($userId: ID!) {
                 subscribeUser(id: $userId) {
                     mutation
                     user { id, firstName, lastName, tweets, verified }
                 }
@@ -486,21 +488,21 @@
                 """
                 mutation {deleteUser(id: "1")}
                 """,
                 context_value=context,
             )
 
         async def receive_one():
-            async for result in subscription_one:  # type: ignore # pragma: no cover
+            async for result in subscription_one:  # pragma: no cover
                 received_one.append(result)
                 if len(received_one) == 3:  # pragma: no cover else
                     break
 
         async def receive_all():
-            async for result in subscription_all:  # type: ignore # pragma: no cover
+            async for result in subscription_all:  # pragma: no cover
                 received_all.append(result)
                 if len(received_all) == 6:  # pragma: no cover else
                     break
 
         tasks = [
             create_task(task()) for task in (mutate_users, receive_one, receive_all)
         ]
```

### Comparing `graphql_core-3.3.0a3/tests/test_version.py` & `graphql_core-3.3.0a4/tests/test_version.py`

 * *Files 0% similar despite different names*

```diff
@@ -5,15 +5,14 @@
     VersionInfo,
     version,
     version_info,
     version_info_js,
     version_js,
 )
 
-
 _re_version = re.compile(r"(\d+)\.(\d+)\.(\d+)(?:(a|b|r?c)(\d+))?$")
 
 
 def describe_version():
     def describe_version_info_class():
         def create_version_info_from_fields():
             v = VersionInfo(1, 2, 3, "alpha", 4)
```

### Comparing `graphql_core-3.3.0a3/tests/type/test_assert_name.py` & `graphql_core-3.3.0a4/tests/type/test_assert_name.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,68 +1,67 @@
-from pytest import mark, raises
-
+import pytest
 from graphql.error import GraphQLError
 from graphql.type import assert_enum_value_name, assert_name
 
 
 def describe_assert_name():
     def pass_through_valid_name():
         assert assert_name("_ValidName123") == "_ValidName123"
 
     def throws_on_empty_strings():
-        with raises(GraphQLError) as exc_info:
+        with pytest.raises(GraphQLError) as exc_info:
             assert_name("")
         msg = str(exc_info.value)
         assert msg == "Expected name to be a non-empty string."
 
     def throws_for_names_with_invalid_characters():
-        with raises(GraphQLError) as exc_info:
+        with pytest.raises(GraphQLError) as exc_info:
             assert_name(">--()-->")
         msg = str(exc_info.value)
         assert msg == "Names must only contain [_a-zA-Z0-9] but '>--()-->' does not."
 
     def throws_for_names_starting_with_invalid_characters():
-        with raises(GraphQLError) as exc_info:
+        with pytest.raises(GraphQLError) as exc_info:
             assert_name("42MeaningsOfLife")
         msg = str(exc_info.value)
         assert msg == (
             "Names must start with [_a-zA-Z] but '42MeaningsOfLife' does not."
         )
 
 
 def describe_assert_enum_value_name():
     def pass_through_valid_name():
         assert assert_enum_value_name("_ValidName123") == "_ValidName123"
 
     def throws_for_non_strings():
-        with raises(TypeError) as exc_info:
+        with pytest.raises(TypeError) as exc_info:
             # noinspection PyTypeChecker
             assert_enum_value_name({})  # type: ignore
         msg = str(exc_info.value)
         assert msg == "Expected name to be a string."
 
     def throws_on_empty_strings():
-        with raises(GraphQLError) as exc_info:
+        with pytest.raises(GraphQLError) as exc_info:
             assert_enum_value_name("")
         msg = str(exc_info.value)
         assert msg == "Expected name to be a non-empty string."
 
     def throws_for_names_with_invalid_characters():
-        with raises(GraphQLError) as exc_info:
+        with pytest.raises(GraphQLError) as exc_info:
             assert_enum_value_name(">--()-->")
         msg = str(exc_info.value)
         assert msg == "Names must only contain [_a-zA-Z0-9] but '>--()-->' does not."
 
     def throws_for_names_starting_with_invalid_characters():
-        with raises(GraphQLError) as exc_info:
+        with pytest.raises(GraphQLError) as exc_info:
             assert_enum_value_name("42MeaningsOfLife")
         msg = str(exc_info.value)
         assert msg == (
             "Names must start with [_a-zA-Z] but '42MeaningsOfLife' does not."
         )
 
-    @mark.parametrize("name", ("true", "false", "null"))
+    @pytest.mark.parametrize("name", ["true", "false", "null"])
     def throws_for_restricted_names(name):
-        with raises(GraphQLError) as exc_info:
+        with pytest.raises(GraphQLError) as exc_info:
             assert_enum_value_name(name)
         msg = str(exc_info.value)
         assert msg == (f"Enum values cannot be named: {name}.")
```

### Comparing `graphql_core-3.3.0a3/tests/type/test_custom_scalars.py` & `graphql_core-3.3.0a4/tests/type/test_custom_scalars.py`

 * *Files 0% similar despite different names*

```diff
@@ -11,15 +11,14 @@
     GraphQLFloat,
     GraphQLObjectType,
     GraphQLScalarType,
     GraphQLSchema,
 )
 from graphql.utilities import value_from_ast_untyped
 
-
 # this test is not (yet) part of GraphQL.js, see
 # https://github.com/graphql/graphql-js/issues/2657
 
 
 class Money(NamedTuple):
     amount: float
     currency: str
```

### Comparing `graphql_core-3.3.0a3/tests/type/test_definition.py` & `graphql_core-3.3.0a4/tests/type/test_definition.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,14 +1,13 @@
 import pickle
 from enum import Enum
 from math import isnan, nan
 from typing import Dict
 
-from pytest import mark, raises
-
+import pytest
 from graphql.error import GraphQLError
 from graphql.language import (
     EnumTypeDefinitionNode,
     EnumTypeExtensionNode,
     EnumValueNode,
     InputObjectTypeDefinitionNode,
     InputObjectTypeExtensionNode,
@@ -40,15 +39,14 @@
     GraphQLObjectType,
     GraphQLScalarType,
     GraphQLString,
     GraphQLUnionType,
     introspection_types,
 )
 
-
 ScalarType = GraphQLScalarType("Scalar")
 ObjectType = GraphQLObjectType("Object", {})
 InterfaceType = GraphQLInterfaceType("Interface", {})
 UnionType = GraphQLUnionType(
     "Union",
     [ObjectType],
     resolve_type=lambda _obj, _info, _type: None,  # pragma: no cover
@@ -76,15 +74,15 @@
             "parse_literal": None,
             "extensions": {},
             "ast_node": None,
             "extension_ast_nodes": (),
         }
 
     def accepts_a_scalar_type_defining_serialize():
-        def serialize(value):
+        def serialize(_value):
             pass
 
         scalar = GraphQLScalarType("SomeScalar", serialize)
         assert scalar.serialize is serialize
         assert scalar.to_kwargs()["serialize"] is serialize
 
     def defines_a_scalar_type_with_a_description():
@@ -152,41 +150,41 @@
         scalar = GraphQLScalarType(
             "SomeScalar", ast_node=ast_node, extension_ast_nodes=extension_ast_nodes
         )
         assert scalar.ast_node is ast_node
         assert scalar.extension_ast_nodes == tuple(extension_ast_nodes)
 
     def rejects_a_scalar_type_with_incorrectly_typed_name():
-        with raises(TypeError, match="missing .* required .* 'name'"):
+        with pytest.raises(TypeError, match="missing .* required .* 'name'"):
             # noinspection PyArgumentList
             GraphQLScalarType()  # type: ignore
-        with raises(TypeError) as exc_info:
+        with pytest.raises(TypeError) as exc_info:
             # noinspection PyTypeChecker
             GraphQLScalarType(None)  # type: ignore
         assert str(exc_info.value) == "Must provide name."
-        with raises(TypeError) as exc_info:
+        with pytest.raises(TypeError) as exc_info:
             # noinspection PyTypeChecker
             GraphQLScalarType(42, {})  # type: ignore
         assert str(exc_info.value) == "Expected name to be a string."
 
     def rejects_a_scalar_type_with_invalid_name():
-        with raises(GraphQLError) as exc_info:
+        with pytest.raises(GraphQLError) as exc_info:
             GraphQLScalarType("")
         assert str(exc_info.value) == "Expected name to be a non-empty string."
-        with raises(GraphQLError) as exc_info:
+        with pytest.raises(GraphQLError) as exc_info:
             GraphQLScalarType("bad-name")
         assert str(exc_info.value) == (
             "Names must only contain [_a-zA-Z0-9] but 'bad-name' does not."
         )
 
     def rejects_a_scalar_type_defining_parse_literal_but_not_parse_value():
         def parse_literal(_node: ValueNode, _vars=None):
             return Undefined  # pragma: no cover
 
-        with raises(TypeError) as exc_info:
+        with pytest.raises(TypeError) as exc_info:
             GraphQLScalarType("SomeScalar", parse_literal=parse_literal)
         assert str(exc_info.value) == (
             "SomeScalar must provide both"
             " 'parse_value' and 'parse_literal' functions."
         )
 
     def pickles_a_custom_scalar_type():
@@ -409,15 +407,16 @@
         assert calls == 1
 
     def accepts_a_lambda_as_an_object_field_resolver():
         obj_type = GraphQLObjectType(
             "SomeObject",
             {
                 "f": GraphQLField(
-                    ScalarType, resolve=lambda _obj, _info: {}  # pragma: no cover
+                    ScalarType,
+                    resolve=lambda _obj, _info: {},  # pragma: no cover
                 )
             },
         )
         assert obj_type.fields
 
     def accepts_an_object_type_with_ast_node_and_extension_ast_nodes():
         ast_node = ObjectTypeDefinitionNode()
@@ -428,77 +427,77 @@
             ast_node=ast_node,
             extension_ast_nodes=extension_ast_nodes,
         )
         assert object_type.ast_node is ast_node
         assert object_type.extension_ast_nodes == tuple(extension_ast_nodes)
 
     def rejects_an_object_type_with_incorrectly_typed_name():
-        with raises(TypeError, match="missing .* required .* 'name'"):
+        with pytest.raises(TypeError, match="missing .* required .* 'name'"):
             # noinspection PyArgumentList
             GraphQLObjectType()  # type: ignore
-        with raises(TypeError) as exc_info:
+        with pytest.raises(TypeError) as exc_info:
             # noinspection PyTypeChecker
             GraphQLObjectType(None, {})  # type: ignore
         assert str(exc_info.value) == "Must provide name."
-        with raises(TypeError) as exc_info:
+        with pytest.raises(TypeError) as exc_info:
             # noinspection PyTypeChecker
             GraphQLObjectType(42, {})  # type: ignore
         assert str(exc_info.value) == "Expected name to be a string."
 
     def rejects_an_object_type_with_invalid_name():
-        with raises(GraphQLError) as exc_info:
+        with pytest.raises(GraphQLError) as exc_info:
             GraphQLObjectType("", {})
         assert str(exc_info.value) == "Expected name to be a non-empty string."
-        with raises(GraphQLError) as exc_info:
+        with pytest.raises(GraphQLError) as exc_info:
             GraphQLObjectType("bad-name", {})
         assert str(exc_info.value) == (
             "Names must only contain [_a-zA-Z0-9] but 'bad-name' does not."
         )
 
     def rejects_an_object_type_with_incorrectly_named_fields():
         obj_type = GraphQLObjectType(
             "SomeObject", {"bad-name": GraphQLField(ScalarType)}
         )
-        with raises(GraphQLError) as exc_info:
+        with pytest.raises(GraphQLError) as exc_info:
             assert not obj_type.fields
         msg = str(exc_info.value)
         assert msg == "Names must only contain [_a-zA-Z0-9] but 'bad-name' does not."
 
     def rejects_an_object_type_field_function_that_raises_an_error():
         def fields():
             raise RuntimeError("Oops!")
 
         obj_type = GraphQLObjectType("SomeObject", fields)
-        with raises(TypeError) as exc_info:
+        with pytest.raises(TypeError) as exc_info:
             assert not obj_type.fields
         assert str(exc_info.value) == "SomeObject fields cannot be resolved. Oops!"
 
     def rejects_an_object_type_with_incorrectly_named_field_args():
         obj_type = GraphQLObjectType(
             "SomeObject",
             lambda: {
                 "badField": GraphQLField(
                     ScalarType, args={"bad-name": GraphQLArgument(ScalarType)}
                 )
             },
         )
-        with raises(GraphQLError) as exc_info:
+        with pytest.raises(GraphQLError) as exc_info:
             assert not obj_type.fields
         msg = str(exc_info.value)
         assert msg == (
             "SomeObject fields cannot be resolved."
             " Names must only contain [_a-zA-Z0-9] but 'bad-name' does not."
         )
 
     def rejects_object_type_with_interfaces_as_function_that_raises_an_error():
         def interfaces():
             raise RuntimeError("Oops!")
 
         obj_type = GraphQLObjectType("SomeObject", {}, interfaces=interfaces)
-        with raises(TypeError) as exc_info:
+        with pytest.raises(TypeError) as exc_info:
             assert not obj_type.interfaces
         assert str(exc_info.value) == "SomeObject interfaces cannot be resolved. Oops!"
 
 
 def describe_type_system_interfaces():
     def defines_an_interface_type():
         fields = {"f": GraphQLField(ScalarType)}
@@ -527,15 +526,16 @@
         interface = GraphQLInterfaceType(
             "AnotherInterface", {}, resolve_type=resolve_type
         )
         assert interface.resolve_type is resolve_type
 
     def accepts_an_interface_type_with_output_types_as_fields():
         interface = GraphQLInterfaceType(
-            "AnotherInterface", {"someField": ScalarType}  # type: ignore
+            "AnotherInterface",
+            {"someField": ScalarType},  # type: ignore
         )
         fields = interface.fields
         assert isinstance(fields, dict)
         assert list(fields) == ["someField"]
         field = fields["someField"]
         assert isinstance(field, GraphQLField)
         assert field.type is ScalarType
@@ -600,34 +600,34 @@
         assert interface_type.extension_ast_nodes == tuple(extension_ast_nodes)
 
     def rejects_an_interface_type_with_unresolvable_fields():
         def fields():
             raise RuntimeError("Oops!")
 
         interface = GraphQLInterfaceType("SomeInterface", fields)
-        with raises(TypeError) as exc_info:
+        with pytest.raises(TypeError) as exc_info:
             assert not interface.fields
         assert str(exc_info.value) == "SomeInterface fields cannot be resolved. Oops!"
 
     def rejects_an_interface_type_with_invalid_name():
-        with raises(GraphQLError) as exc_info:
+        with pytest.raises(GraphQLError) as exc_info:
             GraphQLInterfaceType("", {})
         assert str(exc_info.value) == "Expected name to be a non-empty string."
-        with raises(GraphQLError) as exc_info:
+        with pytest.raises(GraphQLError) as exc_info:
             GraphQLInterfaceType("bad-name", {})
         assert str(exc_info.value) == (
             "Names must only contain [_a-zA-Z0-9] but 'bad-name' does not."
         )
 
     def rejects_an_interface_type_with_unresolvable_interfaces():
         def interfaces():
             raise RuntimeError("Oops!")
 
         interface = GraphQLInterfaceType("AnotherInterface", {}, interfaces)
-        with raises(TypeError) as exc_info:
+        with pytest.raises(TypeError) as exc_info:
             assert not interface.interfaces
         assert (
             str(exc_info.value)
             == "AnotherInterface interfaces cannot be resolved. Oops!"
         )
 
 
@@ -640,15 +640,17 @@
         assert union_type.types == (ObjectType,)
 
     def accepts_a_union_type_with_function_returning_a_list_of_types():
         union_type = GraphQLUnionType("SomeUnion", lambda: [ObjectType])
         assert union_type.types == (ObjectType,)
 
     def accepts_a_union_type_without_types():
-        with raises(TypeError, match="missing 1 required positional argument: 'types'"):
+        with pytest.raises(
+            TypeError, match="missing 1 required positional argument: 'types'"
+        ):
             # noinspection PyArgumentList
             GraphQLUnionType("SomeUnion")  # type: ignore
         union_type = GraphQLUnionType("SomeUnion", None)  # type: ignore
         assert union_type.types == ()
         union_type = GraphQLUnionType("SomeUnion", [])
         assert union_type.types == ()
 
@@ -661,29 +663,29 @@
             ast_node=ast_node,
             extension_ast_nodes=extension_ast_nodes,
         )
         assert union_type.ast_node is ast_node
         assert union_type.extension_ast_nodes == tuple(extension_ast_nodes)
 
     def rejects_a_union_type_with_invalid_name():
-        with raises(GraphQLError) as exc_info:
+        with pytest.raises(GraphQLError) as exc_info:
             GraphQLUnionType("", [])
         assert str(exc_info.value) == "Expected name to be a non-empty string."
-        with raises(GraphQLError) as exc_info:
+        with pytest.raises(GraphQLError) as exc_info:
             GraphQLUnionType("bad-name", [])
         assert str(exc_info.value) == (
             "Names must only contain [_a-zA-Z0-9] but 'bad-name' does not."
         )
 
     def rejects_a_union_type_with_unresolvable_types():
         def types():
             raise RuntimeError("Oops!")
 
         union_type = GraphQLUnionType("SomeUnion", types)
-        with raises(TypeError) as exc_info:
+        with pytest.raises(TypeError) as exc_info:
             assert not union_type.types
         assert str(exc_info.value) == "SomeUnion types cannot be resolved. Oops!"
 
 
 def describe_type_system_enums():
     def defines_an_enum_using_a_dict():
         enum_type = GraphQLEnumType("SomeEnum", {"RED": 1, "BLUE": 2})
@@ -728,15 +730,17 @@
             "RED": GraphQLEnumValue(colors.RED),
             "BLUE": GraphQLEnumValue(colors.BLUE),
         }
 
     def defines_an_enum_type_with_a_description():
         description = "nice enum"
         enum_type = GraphQLEnumType(
-            "SomeEnum", {}, description=description  # type: ignore
+            "SomeEnum",
+            {},
+            description=description,
         )
         assert enum_type.description is description
         assert enum_type.to_kwargs()["description"] is description
 
     def defines_an_enum_type_with_deprecated_value():
         EnumTypeWithDeprecatedValue = GraphQLEnumType(
             name="EnumWithDeprecatedValue",
@@ -798,38 +802,38 @@
     def serializes_an_enum():
         enum_type = GraphQLEnumType(
             "SomeEnum", {"FOO": "fooValue", "BAR": ["barValue"], "BAZ": None}
         )
         assert enum_type.values["FOO"].value == "fooValue"
         assert enum_type.values["BAR"].value == ["barValue"]
         assert enum_type.values["BAZ"].value is None
-        with raises(GraphQLError) as exc_info:
+        with pytest.raises(GraphQLError) as exc_info:
             enum_type.serialize(None)
         msg = exc_info.value.message
         assert msg == "Enum 'SomeEnum' cannot represent value: None"
-        with raises(GraphQLError) as exc_info:
+        with pytest.raises(GraphQLError) as exc_info:
             enum_type.serialize(Undefined)
         msg = exc_info.value.message
         assert msg == "Enum 'SomeEnum' cannot represent value: Undefined"
         assert enum_type.serialize("fooValue") == "FOO"
-        with raises(GraphQLError) as exc_info:
+        with pytest.raises(GraphQLError) as exc_info:
             enum_type.serialize("FOO")
         msg = exc_info.value.message
         assert msg == "Enum 'SomeEnum' cannot represent value: 'FOO'"
         assert enum_type.serialize(["barValue"]) == "BAR"
-        with raises(GraphQLError) as exc_info:
+        with pytest.raises(GraphQLError) as exc_info:
             enum_type.serialize("BAR")
         msg = exc_info.value.message
         assert msg == "Enum 'SomeEnum' cannot represent value: 'BAR'"
         assert enum_type.serialize("BAZ") == "BAZ"
-        with raises(GraphQLError) as exc_info:
+        with pytest.raises(GraphQLError) as exc_info:
             enum_type.serialize("bazValue")
         msg = exc_info.value.message
         assert msg == "Enum 'SomeEnum' cannot represent value: 'bazValue'"
-        with raises(GraphQLError) as exc_info:
+        with pytest.raises(GraphQLError) as exc_info:
             enum_type.serialize(["bazValue"])
         msg = exc_info.value.message
         assert msg == "Enum 'SomeEnum' cannot represent value: ['bazValue']"
 
     def use_first_name_for_duplicate_values():
         enum_type = GraphQLEnumType("SomeEnum", {"FOO": "fooValue", "BAR": "fooValue"})
         assert enum_type.values["FOO"].value == "fooValue"
@@ -837,106 +841,106 @@
         assert enum_type.serialize("fooValue") == "FOO"
 
     def parses_an_enum():
         enum_type = GraphQLEnumType(
             "SomeEnum", {"FOO": "fooValue", "BAR": ["barValue"], "BAZ": None}
         )
         assert enum_type.parse_value("FOO") == "fooValue"
-        with raises(GraphQLError) as exc_info:
+        with pytest.raises(GraphQLError) as exc_info:
             enum_type.parse_value("fooValue")
         msg = exc_info.value.message
         assert msg == "Value 'fooValue' does not exist in 'SomeEnum' enum."
         assert enum_type.parse_value("BAR") == ["barValue"]
-        with raises(GraphQLError) as exc_info:
+        with pytest.raises(GraphQLError) as exc_info:
             # noinspection PyTypeChecker
             enum_type.parse_value(["barValue"])  # type: ignore
         msg = exc_info.value.message
         assert msg == "Enum 'SomeEnum' cannot represent non-string value: ['barValue']."
         assert enum_type.parse_value("BAZ") is None
         assert enum_type.parse_literal(EnumValueNode(value="FOO")) == "fooValue"
-        with raises(GraphQLError) as exc_info:
+        with pytest.raises(GraphQLError) as exc_info:
             enum_type.parse_literal(StringValueNode(value="FOO"))
         assert exc_info.value.message == (
             "Enum 'SomeEnum' cannot represent non-enum value: \"FOO\"."
             " Did you mean the enum value 'FOO'?"
         )
-        with raises(GraphQLError) as exc_info:
+        with pytest.raises(GraphQLError) as exc_info:
             enum_type.parse_literal(EnumValueNode(value="fooValue"))
         msg = exc_info.value.message
         assert msg == "Value 'fooValue' does not exist in 'SomeEnum' enum."
         assert enum_type.parse_literal(EnumValueNode(value="BAR")) == ["barValue"]
-        with raises(GraphQLError) as exc_info:
+        with pytest.raises(GraphQLError) as exc_info:
             enum_type.parse_literal(StringValueNode(value="BAR"))
         assert exc_info.value.message == (
             "Enum 'SomeEnum' cannot represent non-enum value: \"BAR\"."
             " Did you mean the enum value 'BAR' or 'BAZ'?"
         )
         assert enum_type.parse_literal(EnumValueNode(value="BAZ")) is None
-        with raises(GraphQLError) as exc_info:
+        with pytest.raises(GraphQLError) as exc_info:
             enum_type.parse_literal(StringValueNode(value="BAZ"))
         assert exc_info.value.message == (
             "Enum 'SomeEnum' cannot represent non-enum value: \"BAZ\"."
             " Did you mean the enum value 'BAZ' or 'BAR'?"
         )
 
     def accepts_an_enum_type_with_ast_node_and_extension_ast_nodes():
         ast_node = EnumTypeDefinitionNode()
         extension_ast_nodes = [EnumTypeExtensionNode()]
         enum_type = GraphQLEnumType(
             "SomeEnum",
-            {},  # type: ignore
+            {},
             ast_node=ast_node,
             extension_ast_nodes=extension_ast_nodes,
         )
         assert enum_type.ast_node is ast_node
         assert enum_type.extension_ast_nodes == tuple(extension_ast_nodes)
 
     def rejects_an_enum_type_with_incorrectly_typed_name():
-        with raises(TypeError, match="missing .* required .* 'name'"):
+        with pytest.raises(TypeError, match="missing .* required .* 'name'"):
             # noinspection PyArgumentList
             GraphQLEnumType()  # type: ignore
-        with raises(TypeError) as exc_info:
+        with pytest.raises(TypeError) as exc_info:
             # noinspection PyTypeChecker
             GraphQLEnumType(None, {})  # type: ignore
         assert str(exc_info.value) == "Must provide name."
-        with raises(TypeError) as exc_info:
+        with pytest.raises(TypeError) as exc_info:
             # noinspection PyTypeChecker
             GraphQLEnumType(42, {})  # type: ignore
         assert str(exc_info.value) == "Expected name to be a string."
 
     def rejects_an_enum_type_with_invalid_name():
         values: Dict[str, GraphQLEnumValue] = {}
-        with raises(GraphQLError) as exc_info:
+        with pytest.raises(GraphQLError) as exc_info:
             GraphQLEnumType("", values)
         assert str(exc_info.value) == "Expected name to be a non-empty string."
-        with raises(GraphQLError) as exc_info:
+        with pytest.raises(GraphQLError) as exc_info:
             GraphQLEnumType("bad-name", values)
         assert str(exc_info.value) == (
             "Names must only contain [_a-zA-Z0-9] but 'bad-name' does not."
         )
 
     def rejects_an_enum_type_with_incorrectly_named_values():
-        with raises(GraphQLError) as exc_info:
+        with pytest.raises(GraphQLError) as exc_info:
             GraphQLEnumType("SomeEnum", {"bad-name": GraphQLField(ScalarType)})
         msg = str(exc_info.value)
         assert msg == "Names must only contain [_a-zA-Z0-9] but 'bad-name' does not."
 
     def rejects_an_enum_type_without_values():
-        with raises(TypeError, match="missing .* required .* 'values'"):
+        with pytest.raises(TypeError, match="missing .* required .* 'values'"):
             # noinspection PyArgumentList
             GraphQLEnumType("SomeEnum")  # type: ignore
-        with raises(TypeError) as exc_info:
+        with pytest.raises(TypeError) as exc_info:
             # noinspection PyTypeChecker
             GraphQLEnumType("SomeEnum", values=None)  # type: ignore
         assert str(exc_info.value) == (
             "SomeEnum values must be an Enum or a mapping with value names as keys."
         )
 
     def rejects_an_enum_type_with_incorrectly_typed_values():
-        with raises(TypeError) as exc_info:
+        with pytest.raises(TypeError) as exc_info:
             # noinspection PyTypeChecker
             GraphQLEnumType("SomeEnum", [{"FOO": 10}])  # type: ignore
         assert str(exc_info.value) == (
             "SomeEnum values must be an Enum or a mapping with value names as keys."
         )
 
     def describe_enum_values():
@@ -1027,15 +1031,16 @@
             assert input_field.extensions == {}
             assert input_field.ast_node is None
             assert input_field.out_name is None
 
         def accepts_an_input_object_type_with_input_type_as_field():
             # this is a shortcut syntax for simple input fields
             input_obj_type = GraphQLInputObjectType(
-                "SomeInputObject", {"f": ScalarType}  # type: ignore
+                "SomeInputObject",
+                {"f": ScalarType},  # type: ignore
             )
             field = input_obj_type.fields["f"]
             assert isinstance(field, GraphQLInputField)
             assert field.type is ScalarType
 
         def accepts_an_input_object_type_with_a_field_function():
             input_obj_type = GraphQLInputObjectType(
@@ -1049,79 +1054,79 @@
             assert input_field.default_value is Undefined
             assert input_field.deprecation_reason is None
             assert input_field.extensions == {}
             assert input_field.ast_node is None
             assert input_field.out_name is None
 
         def rejects_an_input_object_type_with_incorrectly_typed_name():
-            with raises(TypeError, match="missing .* required .* 'name'"):
+            with pytest.raises(TypeError, match="missing .* required .* 'name'"):
                 # noinspection PyArgumentList
                 GraphQLInputObjectType()  # type: ignore
-            with raises(TypeError) as exc_info:
+            with pytest.raises(TypeError) as exc_info:
                 # noinspection PyTypeChecker
                 GraphQLInputObjectType(None, {})  # type: ignore
             assert str(exc_info.value) == "Must provide name."
-            with raises(TypeError) as exc_info:
+            with pytest.raises(TypeError) as exc_info:
                 # noinspection PyTypeChecker
                 GraphQLInputObjectType(42, {})  # type: ignore
             assert str(exc_info.value) == "Expected name to be a string."
 
         def rejects_an_input_object_type_with_invalid_name():
-            with raises(GraphQLError) as exc_info:
+            with pytest.raises(GraphQLError) as exc_info:
                 GraphQLInputObjectType("", {})
             assert str(exc_info.value) == "Expected name to be a non-empty string."
-            with raises(GraphQLError) as exc_info:
+            with pytest.raises(GraphQLError) as exc_info:
                 GraphQLInputObjectType("bad-name", {})
             assert str(exc_info.value) == (
                 "Names must only contain [_a-zA-Z0-9] but 'bad-name' does not."
             )
 
         def rejects_an_input_object_type_with_incorrectly_named_fields():
             input_obj_type = GraphQLInputObjectType(
                 "SomeInputObject", {"bad-name": GraphQLInputField(ScalarType)}
             )
-            with raises(GraphQLError) as exc_info:
+            with pytest.raises(GraphQLError) as exc_info:
                 assert not input_obj_type.fields
             msg = str(exc_info.value)
             assert msg == (
                 "Names must only contain [_a-zA-Z0-9] but 'bad-name' does not."
             )
 
         def rejects_an_input_object_type_with_unresolvable_fields():
             def fields():
                 raise RuntimeError("Oops!")
 
             input_obj_type = GraphQLInputObjectType("SomeInputObject", fields)
-            with raises(TypeError) as exc_info:
+            with pytest.raises(TypeError) as exc_info:
                 assert not input_obj_type.fields
             assert str(exc_info.value) == (
                 "SomeInputObject fields cannot be resolved. Oops!"
             )
 
     def describe_input_objects_fields_must_not_have_resolvers():
         def rejects_an_input_object_type_with_resolvers():
             def resolve():
                 pass
 
-            with raises(
+            with pytest.raises(
                 TypeError, match="got an unexpected keyword argument 'resolve'"
             ):
                 # noinspection PyArgumentList
                 GraphQLInputObjectType(
                     "SomeInputObject",
                     {
                         "f": GraphQLInputField(  # type: ignore
                             ScalarType,
                             resolve=resolve,
                         )
                     },
                 )
 
         def rejects_an_input_object_type_with_resolver_constant():
-            with raises(
+            with pytest.raises(
                 TypeError, match="got an unexpected keyword argument 'resolve'"
             ):
                 # noinspection PyArgumentList
                 GraphQLInputObjectType(
                     "SomeInputObject",
                     {"f": GraphQLInputField(ScalarType, resolve={})},  # type: ignore
                 )
@@ -1150,15 +1155,15 @@
     def accepts_an_argument_with_an_ast_node():
         ast_node = InputValueDefinitionNode()
         argument = GraphQLArgument(GraphQLString, ast_node=ast_node)
         assert argument.ast_node is ast_node
         assert argument.to_kwargs()["ast_node"] is ast_node
 
     def rejects_an_argument_without_type():
-        with raises(TypeError, match="missing 1 required positional argument"):
+        with pytest.raises(TypeError, match="missing 1 required positional argument"):
             # noinspection PyArgumentList
             GraphQLArgument()  # type: ignore
 
 
 def describe_type_system_input_fields():
     def accepts_an_input_field_with_a_description():
         description = "good input"
@@ -1182,15 +1187,15 @@
     def accepts_an_input_field_with_an_ast_node():
         ast_node = InputValueDefinitionNode()
         input_field = GraphQLArgument(GraphQLString, ast_node=ast_node)
         assert input_field.ast_node is ast_node
         assert input_field.to_kwargs()["ast_node"] is ast_node
 
     def rejects_an_input_field_without_type():
-        with raises(TypeError, match="missing 1 required positional argument"):
+        with pytest.raises(TypeError, match="missing 1 required positional argument"):
             # noinspection PyArgumentList
             GraphQLInputField()  # type: ignore
 
     def deprecation_reason_is_preserved_on_fields():
         input_obj_type = GraphQLInputObjectType(
             "someInputObject",
             {
@@ -1216,15 +1221,15 @@
         InterfaceType,
         EnumType,
         InputObjectType,
         ListOfScalarsType,
         NonNullScalarType,
     ]
 
-    @mark.parametrize("type_", types, ids=lambda type_: type_.__class__.__name__)
+    @pytest.mark.parametrize("type_", types, ids=lambda type_: type_.__class__.__name__)
     def accepts_a_type_as_item_type_of_list(type_):
         assert GraphQLList(type_)
 
 
 def describe_type_system_non_null():
     types = [
         ScalarType,
@@ -1233,15 +1238,15 @@
         InterfaceType,
         EnumType,
         InputObjectType,
         ListOfScalarsType,
         ListOfNonNullScalarsType,
     ]
 
-    @mark.parametrize("type_", types, ids=lambda type_: type_.__class__.__name__)
+    @pytest.mark.parametrize("type_", types, ids=lambda type_: type_.__class__.__name__)
     def accepts_a_type_as_nullable_type_of_non_null(type_):
         assert GraphQLNonNull(type_)
 
 
 def describe_type_system_test_utility_methods():
     def stringifies_simple_types():
         assert str(ScalarType) == "Scalar"
@@ -1288,9 +1293,11 @@
         )
 
 
 def describe_type_system_introspection_types():
     def cannot_redefine_introspection_types():
         for name, introspection_type in introspection_types.items():
             assert introspection_type.name == name
-            with raises(TypeError, match=f"Redefinition of reserved type '{name}'"):
+            with pytest.raises(
+                TypeError, match=f"Redefinition of reserved type '{name}'"
+            ):
                 introspection_type.__class__(**introspection_type.to_kwargs())
```

### Comparing `graphql_core-3.3.0a3/tests/type/test_directives.py` & `graphql_core-3.3.0a4/tests/type/test_directives.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,9 +1,8 @@
-from pytest import raises
-
+import pytest
 from graphql.error import GraphQLError
 from graphql.language import DirectiveDefinitionNode, DirectiveLocation
 from graphql.type import GraphQLArgument, GraphQLDirective, GraphQLInt, GraphQLString
 
 
 def describe_type_system_directive():
     def can_create_instance():
@@ -57,24 +56,27 @@
         assert directive.args == {}
         assert directive.is_repeatable is True
         assert directive.locations == tuple(locations)
 
     def directive_accepts_input_types_as_arguments():
         # noinspection PyTypeChecker
         directive = GraphQLDirective(
-            name="Foo", locations=[], args={"arg": GraphQLString}  # type: ignore
+            name="Foo",
+            locations=[],
+            args={"arg": GraphQLString},  # type: ignore
         )
         arg = directive.args["arg"]
         assert isinstance(arg, GraphQLArgument)
         assert arg.type is GraphQLString
 
     def directive_accepts_strings_as_locations():
         # noinspection PyTypeChecker
         directive = GraphQLDirective(
-            name="Foo", locations=["SCHEMA", "OBJECT"]  # type: ignore
+            name="Foo",
+            locations=["SCHEMA", "OBJECT"],  # type: ignore
         )
         assert directive.locations == (
             DirectiveLocation.SCHEMA,
             DirectiveLocation.OBJECT,
         )
 
     def directive_has_str():
@@ -84,86 +86,86 @@
     def directive_has_repr():
         directive = GraphQLDirective("foo", [])
         assert repr(directive) == "<GraphQLDirective(@foo)>"
 
     def can_compare_with_other_source_directive():
         locations = [DirectiveLocation.QUERY]
         directive = GraphQLDirective("Foo", locations)
-        assert directive == directive
-        assert not directive != directive
-        assert not directive == {}
+        assert directive == directive  # noqa: PLR0124
+        assert not directive != directive  # noqa: PLR0124, SIM202
+        assert not directive == {}  # noqa: SIM201
         assert directive != {}
         same_directive = GraphQLDirective("Foo", locations)
         assert directive == same_directive
-        assert not directive != same_directive
+        assert not directive != same_directive  # noqa: SIM202
         other_directive = GraphQLDirective("Bar", locations)
-        assert not directive == other_directive
+        assert not directive == other_directive  # noqa: SIM201
         assert directive != other_directive
         other_locations = [DirectiveLocation.MUTATION]
         other_directive = GraphQLDirective("Foo", other_locations)
-        assert not directive == other_directive
+        assert not directive == other_directive  # noqa: SIM201
         assert directive != other_directive
         other_directive = GraphQLDirective("Foo", locations, is_repeatable=True)
-        assert not directive == other_directive
+        assert not directive == other_directive  # noqa: SIM201
         assert directive != other_directive
         other_directive = GraphQLDirective("Foo", locations, description="other")
-        assert not directive == other_directive
+        assert not directive == other_directive  # noqa: SIM201
         assert directive != other_directive
 
     def rejects_a_directive_with_incorrectly_typed_name():
-        with raises(TypeError, match="missing .* required .* 'name'"):
+        with pytest.raises(TypeError, match="missing .* required .* 'name'"):
             # noinspection PyArgumentList
             GraphQLDirective()  # type: ignore
-        with raises(TypeError) as exc_info:
+        with pytest.raises(TypeError) as exc_info:
             # noinspection PyTypeChecker
             GraphQLDirective(None, [])  # type: ignore
         assert str(exc_info.value) == "Must provide name."
-        with raises(TypeError) as exc_info:
+        with pytest.raises(TypeError) as exc_info:
             # noinspection PyTypeChecker
             GraphQLDirective(42, {})  # type: ignore
         assert str(exc_info.value) == "Expected name to be a string."
 
     def rejects_a_directive_with_invalid_name():
-        with raises(GraphQLError) as exc_info:
+        with pytest.raises(GraphQLError) as exc_info:
             GraphQLDirective("", [])
         assert str(exc_info.value) == "Expected name to be a non-empty string."
-        with raises(GraphQLError) as exc_info:
+        with pytest.raises(GraphQLError) as exc_info:
             GraphQLDirective("bad-name", [])
         assert str(exc_info.value) == (
             "Names must only contain [_a-zA-Z0-9] but 'bad-name' does not."
         )
 
     def rejects_a_directive_with_incorrectly_named_args():
-        with raises(GraphQLError) as exc_info:
+        with pytest.raises(GraphQLError) as exc_info:
             GraphQLDirective(
                 "Foo",
                 locations=[DirectiveLocation.QUERY],
                 args={"bad-name": GraphQLArgument(GraphQLString)},
             )
         assert str(exc_info.value) == (
             "Names must only contain [_a-zA-Z0-9] but 'bad-name' does not."
         )
 
     def rejects_a_directive_with_undefined_locations():
-        with raises(TypeError) as exc_info:
+        with pytest.raises(TypeError) as exc_info:
             # noinspection PyTypeChecker
             GraphQLDirective("Foo", locations=None)  # type: ignore
         assert str(exc_info.value) == (
             "Foo locations must be specified"
             " as a collection of DirectiveLocation enum values."
         )
 
     def rejects_a_directive_with_incorrectly_typed_locations():
-        with raises(TypeError) as exc_info:
+        with pytest.raises(TypeError) as exc_info:
             # noinspection PyTypeChecker
             GraphQLDirective("Foo", locations="bad")  # type: ignore
         assert (
             str(exc_info.value) == "Foo locations must be specified"
             " as a collection of DirectiveLocation enum values."
         )
-        with raises(TypeError) as exc_info:
+        with pytest.raises(TypeError) as exc_info:
             # noinspection PyTypeChecker
             GraphQLDirective("Foo", locations=["bad"])  # type: ignore
         assert str(exc_info.value) == (
             "Foo locations must be specified"
             " as a collection of DirectiveLocation enum values."
         )
```

### Comparing `graphql_core-3.3.0a3/tests/type/test_enum.py` & `graphql_core-3.3.0a4/tests/type/test_enum.py`

 * *Files 2% similar despite different names*

```diff
@@ -12,27 +12,26 @@
     GraphQLInt,
     GraphQLObjectType,
     GraphQLSchema,
     GraphQLString,
 )
 from graphql.utilities import introspection_from_schema
 
-
 ColorType = GraphQLEnumType("Color", values={"RED": 0, "GREEN": 1, "BLUE": 2})
 
 
 class ColorTypeEnumValues(Enum):
     RED = 0
     GREEN = 1
     BLUE = 2
 
 
 class Complex1:
     # noinspection PyMethodMayBeStatic
-    some_random_object = datetime.now()
+    some_random_object = datetime.now()  # noqa: DTZ005
 
 
 class Complex2:
     some_random_value = 123
 
 
 complex1 = Complex1()
@@ -48,64 +47,67 @@
         "colorEnum": GraphQLField(
             ColorType,
             args={
                 "fromEnum": GraphQLArgument(ColorType),
                 "fromInt": GraphQLArgument(GraphQLInt),
                 "fromString": GraphQLArgument(GraphQLString),
             },
-            resolve=lambda _source, info, **args: args.get("fromInt")
+            resolve=lambda _source, _info, **args: args.get("fromInt")
             or args.get("fromString")
             or args.get("fromEnum"),
         ),
         "colorInt": GraphQLField(
             GraphQLInt,
             args={
                 "fromEnum": GraphQLArgument(ColorType),
                 "fromInt": GraphQLArgument(GraphQLInt),
             },
-            resolve=lambda _source, info, **args: args.get("fromEnum"),
+            resolve=lambda _source, _info, **args: args.get("fromEnum"),
         ),
         "complexEnum": GraphQLField(
             ComplexEnum,
             args={
                 # Note: default_value is provided an *internal* representation for
                 # Enums, rather than the string name.
                 "fromEnum": GraphQLArgument(ComplexEnum, default_value=complex1),
                 "provideGoodValue": GraphQLArgument(GraphQLBoolean),
                 "provideBadValue": GraphQLArgument(GraphQLBoolean),
             },
-            resolve=lambda _source, info, **args:
+            resolve=lambda _source, _info, **args:
             # Note: this is one of the references of the internal values
             # which ComplexEnum allows.
-            complex2 if args.get("provideGoodValue")
+            complex2
+            if args.get("provideGoodValue")
             # Note: similar object, but not the same *reference* as
             # complex2 above. Enum internal values require object equality.
-            else Complex2() if args.get("provideBadValue") else args.get("fromEnum"),
+            else Complex2()
+            if args.get("provideBadValue")
+            else args.get("fromEnum"),
         ),
     },
 )
 
 MutationType = GraphQLObjectType(
     "Mutation",
     {
         "favoriteEnum": GraphQLField(
             ColorType,
             args={"color": GraphQLArgument(ColorType)},
-            resolve=lambda _source, info, color=None: color,
+            resolve=lambda _source, _info, color=None: color,
         )
     },
 )
 
 SubscriptionType = GraphQLObjectType(
     "Subscription",
     {
         "subscribeToEnum": GraphQLField(
             ColorType,
             args={"color": GraphQLArgument(ColorType)},
-            resolve=lambda _source, info, color=None: color,
+            resolve=lambda _source, _info, color=None: color,
         )
     },
 )
 
 schema = GraphQLSchema(
     query=QueryType, mutation=MutationType, subscription=SubscriptionType
 )
@@ -114,16 +116,16 @@
 def execute_query(source: str, variable_values: Optional[Dict[str, Any]] = None):
     return graphql_sync(schema, source, variable_values=variable_values)
 
 
 def describe_type_system_enum_values():
     def can_use_python_enums_instead_of_dicts():
         assert ColorType2.values == ColorType.values
-        keys = [key for key in ColorType.values]
-        keys2 = [key for key in ColorType2.values]
+        keys = list(ColorType.values)
+        keys2 = list(ColorType2.values)
         assert keys2 == keys
         values = [value.value for value in ColorType.values.values()]
         values2 = [value.value for value in ColorType2.values.values()]
         assert values2 == values
 
     def accepts_enum_literals_as_input():
         result = execute_query("{ colorInt(fromEnum: GREEN) }")
```

### Comparing `graphql_core-3.3.0a3/tests/type/test_extensions.py` & `graphql_core-3.3.0a4/tests/type/test_extensions.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,8 @@
-from pytest import param
-
+import pytest
 from graphql.type import (
     GraphQLArgument,
     GraphQLDirective,
     GraphQLEnumType,
     GraphQLEnumValue,
     GraphQLField,
     GraphQLInputField,
@@ -11,18 +10,20 @@
     GraphQLInterfaceType,
     GraphQLObjectType,
     GraphQLScalarType,
     GraphQLSchema,
     GraphQLUnionType,
 )
 
-
 dummy_type = GraphQLScalarType("DummyScalar")
 
-bad_extensions = [param([], id="list"), param({1: "ext"}, id="non_string_key")]
+bad_extensions = [
+    pytest.param([], id="list"),
+    pytest.param({1: "ext"}, id="non_string_key"),
+]
 
 
 def describe_type_system_extensions():
     def describe_graphql_scalar_type():
         def without_extensions():
             some_scalar = GraphQLScalarType("SomeScalar")
             assert some_scalar.extensions == {}
```

### Comparing `graphql_core-3.3.0a3/tests/type/test_introspection.py` & `graphql_core-3.3.0a4/tests/type/test_introspection.py`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/tests/type/test_predicate.py` & `graphql_core-3.3.0a4/tests/type/test_predicate.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,11 +1,10 @@
 from typing import Any
 
-from pytest import raises
-
+import pytest
 from graphql.language import DirectiveLocation
 from graphql.type import (
     GraphQLArgument,
     GraphQLBoolean,
     GraphQLDeprecatedDirective,
     GraphQLDirective,
     GraphQLEnumType,
@@ -66,15 +65,14 @@
     is_specified_directive,
     is_specified_scalar_type,
     is_type,
     is_union_type,
     is_wrapping_type,
 )
 
-
 ObjectType = GraphQLObjectType("Object", {})
 InterfaceType = GraphQLInterfaceType("Interface", {})
 UnionType = GraphQLUnionType("Union", types=[ObjectType])
 EnumType = GraphQLEnumType("Enum", values={"foo": {}})
 InputObjectType = GraphQLInputObjectType("InputObject", {})
 ScalarType = GraphQLScalarType("Scalar")
 Directive = GraphQLDirective("Directive", [DirectiveLocation.QUERY])
@@ -90,55 +88,55 @@
 
         def returns_true_for_wrapped_types():
             assert is_type(GraphQLNonNull(GraphQLString)) is True
             assert_type(GraphQLNonNull(GraphQLString))
 
         def returns_false_for_type_classes_rather_than_instance():
             assert is_type(GraphQLObjectType) is False
-            with raises(TypeError):
+            with pytest.raises(TypeError):
                 assert_type(GraphQLObjectType)
 
         def returns_false_for_random_garbage():
             assert is_type({"what": "is this"}) is False
-            with raises(TypeError):
+            with pytest.raises(TypeError):
                 assert_type({"what": "is this"})
 
     def describe_is_scalar_type():
         def returns_true_for_spec_defined_scalar():
             assert is_scalar_type(GraphQLString) is True
             assert_scalar_type(GraphQLString)
 
         def returns_true_for_custom_scalar():
             assert is_scalar_type(ScalarType) is True
             assert_scalar_type(ScalarType)
 
         def returns_false_for_scalar_class_rather_than_instance():
             assert is_scalar_type(GraphQLScalarType) is False
-            with raises(TypeError):
+            with pytest.raises(TypeError):
                 assert_scalar_type(GraphQLScalarType)
 
         def returns_false_for_wrapped_scalar():
             assert is_scalar_type(GraphQLList(ScalarType)) is False
-            with raises(TypeError):
+            with pytest.raises(TypeError):
                 assert_scalar_type(GraphQLList(ScalarType))
 
         def returns_false_for_non_scalar():
             assert is_scalar_type(EnumType) is False
-            with raises(TypeError):
+            with pytest.raises(TypeError):
                 assert_scalar_type(EnumType)
             assert is_scalar_type(Directive) is False
-            with raises(TypeError):
+            with pytest.raises(TypeError):
                 assert_scalar_type(Directive)
 
         def returns_false_for_random_garbage():
             assert is_scalar_type(None) is False
-            with raises(TypeError):
+            with pytest.raises(TypeError):
                 assert_scalar_type(None)
             assert is_scalar_type({"what": "is this"}) is False
-            with raises(TypeError):
+            with pytest.raises(TypeError):
                 assert_scalar_type({"what": "is this"})
 
     def describe_is_specified_scalar_type():
         def returns_true_for_specified_scalars():
             assert is_specified_scalar_type(GraphQLString) is True
             assert is_specified_scalar_type(GraphQLInt) is True
             assert is_specified_scalar_type(GraphQLFloat) is True
@@ -148,110 +146,110 @@
     def describe_is_object_type():
         def returns_true_for_object_type():
             assert is_object_type(ObjectType) is True
             assert_object_type(ObjectType)
 
         def returns_false_for_wrapped_object_type():
             assert is_object_type(GraphQLList(ObjectType)) is False
-            with raises(TypeError):
+            with pytest.raises(TypeError):
                 assert_object_type(GraphQLList(ObjectType))
 
         def returns_false_for_non_object_type():
             assert is_scalar_type(InterfaceType) is False
-            with raises(TypeError):
+            with pytest.raises(TypeError):
                 assert_scalar_type(InterfaceType)
 
     def describe_is_interface_type():
         def returns_true_for_interface_type():
             assert is_interface_type(InterfaceType) is True
             assert_interface_type(InterfaceType)
 
         def returns_false_for_wrapped_interface_type():
             assert is_interface_type(GraphQLList(InterfaceType)) is False
-            with raises(TypeError):
+            with pytest.raises(TypeError):
                 assert_interface_type(GraphQLList(InterfaceType))
 
         def returns_false_for_non_interface_type():
             assert is_interface_type(ObjectType) is False
-            with raises(TypeError):
+            with pytest.raises(TypeError):
                 assert_interface_type(ObjectType)
 
     def describe_is_union_type():
         def returns_true_for_union_type():
             assert is_union_type(UnionType) is True
             assert_union_type(UnionType)
 
         def returns_false_for_wrapped_union_type():
             assert is_union_type(GraphQLList(UnionType)) is False
-            with raises(TypeError):
+            with pytest.raises(TypeError):
                 assert_union_type(GraphQLList(UnionType))
 
         def returns_false_for_non_union_type():
             assert is_union_type(ObjectType) is False
-            with raises(TypeError):
+            with pytest.raises(TypeError):
                 assert_union_type(ObjectType)
 
     def describe_is_enum_type():
         def returns_true_for_enum_type():
             assert is_enum_type(EnumType) is True
             assert_enum_type(EnumType)
 
         def returns_false_for_wrapped_enum_type():
             assert is_enum_type(GraphQLList(EnumType)) is False
-            with raises(TypeError):
+            with pytest.raises(TypeError):
                 assert_enum_type(GraphQLList(EnumType))
 
         def returns_false_for_non_enum_type():
             assert is_enum_type(ScalarType) is False
-            with raises(TypeError):
+            with pytest.raises(TypeError):
                 assert_enum_type(ScalarType)
 
     def describe_is_input_object_type():
         def returns_true_for_input_object_type():
             assert is_input_object_type(InputObjectType) is True
             assert_input_object_type(InputObjectType)
 
         def returns_false_for_wrapped_input_object_type():
             assert is_input_object_type(GraphQLList(InputObjectType)) is False
-            with raises(TypeError):
+            with pytest.raises(TypeError):
                 assert_input_object_type(GraphQLList(InputObjectType))
 
         def returns_false_for_non_input_object_type():
             assert is_input_object_type(ObjectType) is False
-            with raises(TypeError):
+            with pytest.raises(TypeError):
                 assert_input_object_type(ObjectType)
 
     def describe_is_list_type():
         def returns_true_for_a_list_wrapped_type():
             assert is_list_type(GraphQLList(ObjectType)) is True
             assert_list_type(GraphQLList(ObjectType))
 
         def returns_false_for_a_unwrapped_type():
             assert is_list_type(ObjectType) is False
-            with raises(TypeError):
+            with pytest.raises(TypeError):
                 assert_list_type(ObjectType)
 
         def returns_false_for_a_non_list_wrapped_type():
             assert is_list_type(GraphQLNonNull(GraphQLList(ObjectType))) is False
-            with raises(TypeError):
+            with pytest.raises(TypeError):
                 assert_list_type(GraphQLNonNull(GraphQLList(ObjectType)))
 
     def describe_is_non_null_type():
         def returns_true_for_a_non_null_wrapped_type():
             assert is_non_null_type(GraphQLNonNull(ObjectType)) is True
             assert_non_null_type(GraphQLNonNull(ObjectType))
 
         def returns_false_for_an_unwrapped_type():
             assert is_non_null_type(ObjectType) is False
-            with raises(TypeError):
+            with pytest.raises(TypeError):
                 assert_non_null_type(ObjectType)
 
         def returns_false_for_a_not_non_null_wrapped_type():
             assert is_non_null_type(GraphQLList(GraphQLNonNull(ObjectType))) is False
-            with raises(TypeError):
+            with pytest.raises(TypeError):
                 assert_non_null_type(GraphQLList(GraphQLNonNull(ObjectType)))
 
     def describe_is_input_type():
         def _assert_input_type(type_: Any):
             assert is_input_type(type_) is True
             assert_input_type(type_)
 
@@ -267,15 +265,15 @@
 
             _assert_input_type(GraphQLNonNull(GraphQLString))
             _assert_input_type(GraphQLNonNull(EnumType))
             _assert_input_type(GraphQLNonNull(InputObjectType))
 
         def _assert_non_input_type(type_: Any):
             assert is_input_type(type_) is False
-            with raises(TypeError):
+            with pytest.raises(TypeError):
                 assert_input_type(type_)
 
         def returns_false_for_an_output_type():
             _assert_non_input_type(ObjectType)
             _assert_non_input_type(InterfaceType)
             _assert_non_input_type(UnionType)
 
@@ -311,15 +309,15 @@
             _assert_output_type(GraphQLNonNull(ObjectType))
             _assert_output_type(GraphQLNonNull(InterfaceType))
             _assert_output_type(GraphQLNonNull(UnionType))
             _assert_output_type(GraphQLNonNull(EnumType))
 
         def _assert_non_output_type(type_: Any):
             assert is_output_type(type_) is False
-            with raises(TypeError):
+            with pytest.raises(TypeError):
                 assert_output_type(type_)
 
         def returns_false_for_an_input_type():
             _assert_non_output_type(InputObjectType)
 
         def returns_false_for_a_wrapped_input_type():
             _assert_non_output_type(GraphQLList(InputObjectType))
@@ -330,97 +328,97 @@
             assert is_leaf_type(ScalarType) is True
             assert_leaf_type(ScalarType)
             assert is_leaf_type(EnumType) is True
             assert_leaf_type(EnumType)
 
         def returns_false_for_wrapped_leaf_type():
             assert is_leaf_type(GraphQLList(ScalarType)) is False
-            with raises(TypeError):
+            with pytest.raises(TypeError):
                 assert_leaf_type(GraphQLList(ScalarType))
 
         def returns_false_for_non_leaf_type():
             assert is_leaf_type(ObjectType) is False
-            with raises(TypeError):
+            with pytest.raises(TypeError):
                 assert_leaf_type(ObjectType)
 
         def returns_false_for_wrapped_non_leaf_type():
             assert is_leaf_type(GraphQLList(ObjectType)) is False
-            with raises(TypeError):
+            with pytest.raises(TypeError):
                 assert_leaf_type(GraphQLList(ObjectType))
 
     def describe_is_composite_type():
         def returns_true_for_object_interface_and_union_types():
             assert is_composite_type(ObjectType) is True
             assert_composite_type(ObjectType)
             assert is_composite_type(InterfaceType) is True
             assert_composite_type(InterfaceType)
             assert is_composite_type(UnionType) is True
             assert_composite_type(UnionType)
 
         def returns_false_for_wrapped_composite_type():
             assert is_composite_type(GraphQLList(ObjectType)) is False
-            with raises(TypeError):
+            with pytest.raises(TypeError):
                 assert_composite_type(GraphQLList(ObjectType))
 
         def returns_false_for_non_composite_type():
             assert is_composite_type(InputObjectType) is False
-            with raises(TypeError):
+            with pytest.raises(TypeError):
                 assert_composite_type(InputObjectType)
 
         def returns_false_for_wrapped_non_composite_type():
             assert is_composite_type(GraphQLList(InputObjectType)) is False
-            with raises(TypeError):
+            with pytest.raises(TypeError):
                 assert_composite_type(GraphQLList(InputObjectType))
 
     def describe_is_abstract_type():
         def returns_true_for_interface_and_union_types():
             assert is_abstract_type(InterfaceType) is True
             assert_abstract_type(InterfaceType)
             assert is_abstract_type(UnionType) is True
             assert_abstract_type(UnionType)
 
         def returns_false_for_wrapped_abstract_type():
             assert is_abstract_type(GraphQLList(InterfaceType)) is False
-            with raises(TypeError):
+            with pytest.raises(TypeError):
                 assert_abstract_type(GraphQLList(InterfaceType))
 
         def returns_false_for_non_abstract_type():
             assert is_abstract_type(ObjectType) is False
-            with raises(TypeError):
+            with pytest.raises(TypeError):
                 assert_abstract_type(ObjectType)
 
         def returns_false_for_wrapped_non_abstract_type():
             assert is_abstract_type(GraphQLList(ObjectType)) is False
-            with raises(TypeError):
+            with pytest.raises(TypeError):
                 assert_abstract_type(GraphQLList(ObjectType))
 
     def describe_is_wrapping_type():
         def returns_true_for_list_and_non_null_types():
             assert is_wrapping_type(GraphQLList(ObjectType)) is True
             assert_wrapping_type(GraphQLList(ObjectType))
             assert is_wrapping_type(GraphQLNonNull(ObjectType)) is True
             assert_wrapping_type(GraphQLNonNull(ObjectType))
 
         def returns_false_for_unwrapped_types():
             assert is_wrapping_type(ObjectType) is False
-            with raises(TypeError):
+            with pytest.raises(TypeError):
                 assert_wrapping_type(ObjectType)
 
     def describe_is_nullable_type():
         def returns_true_for_unwrapped_types():
             assert is_nullable_type(ObjectType) is True
             assert_nullable_type(ObjectType)
 
         def returns_true_for_list_of_non_null_types():
             assert is_nullable_type(GraphQLList(GraphQLNonNull(ObjectType))) is True
             assert_nullable_type(GraphQLList(GraphQLNonNull(ObjectType)))
 
         def returns_false_for_non_null_types():
             assert is_nullable_type(GraphQLNonNull(ObjectType)) is False
-            with raises(TypeError):
+            with pytest.raises(TypeError):
                 assert_nullable_type(GraphQLNonNull(ObjectType))
 
     def describe_get_nullable_type():
         def returns_none_for_no_type():
             assert get_nullable_type(None) is None
 
         def returns_self_for_a_nullable_type():
@@ -434,18 +432,18 @@
     def describe_is_named_type():
         def returns_true_for_unwrapped_types():
             assert is_named_type(ObjectType) is True
             assert_named_type(ObjectType)
 
         def returns_false_for_list_and_non_null_types():
             assert is_named_type(GraphQLList(ObjectType)) is False
-            with raises(TypeError):
+            with pytest.raises(TypeError):
                 assert_named_type(GraphQLList(ObjectType))
             assert is_named_type(GraphQLNonNull(ObjectType)) is False
-            with raises(TypeError):
+            with pytest.raises(TypeError):
                 assert_named_type(GraphQLNonNull(ObjectType))
 
     def describe_get_named_type():
         def returns_none_for_no_type():
             assert get_named_type(None) is None
 
         def returns_self_for_an_unwrapped_type():
@@ -509,31 +507,31 @@
 
             def returns_true_for_custom_directive():
                 assert is_directive(Directive) is True
                 assert_directive(Directive)
 
             def returns_false_for_directive_class_rather_than_instance():
                 assert is_directive(GraphQLDirective) is False
-                with raises(TypeError):
+                with pytest.raises(TypeError):
                     assert_directive(GraphQLScalarType)
 
             def returns_false_for_non_directive():
                 assert is_directive(EnumType) is False
-                with raises(TypeError):
+                with pytest.raises(TypeError):
                     assert_directive(EnumType)
                 assert is_directive(ScalarType) is False
-                with raises(TypeError):
+                with pytest.raises(TypeError):
                     assert_directive(ScalarType)
 
             def returns_false_for_random_garbage():
                 assert is_directive(None) is False
-                with raises(TypeError):
+                with pytest.raises(TypeError):
                     assert_directive(None)
                 assert is_directive({"what": "is this"}) is False
-                with raises(TypeError):
+                with pytest.raises(TypeError):
                     assert_directive({"what": "is this"})
 
         def describe_is_specified_directive():
             def returns_true_for_specified_directives():
                 assert is_specified_directive(GraphQLIncludeDirective) is True
                 assert is_specified_directive(GraphQLSkipDirective) is True
                 assert is_specified_directive(GraphQLDeprecatedDirective) is True
@@ -548,22 +546,22 @@
     def describe_is_schema_and_assert_schema():
         def returns_true_for_schema():
             assert is_schema(schema) is True
             assert assert_schema(schema) is schema
 
         def returns_false_for_schema_class_rather_than_instance():
             assert is_schema(GraphQLSchema) is False
-            with raises(TypeError):
+            with pytest.raises(TypeError):
                 assert_schema(GraphQLSchema)
 
         def returns_false_for_non_schema():
             assert is_schema(EnumType) is False
-            with raises(TypeError):
+            with pytest.raises(TypeError):
                 assert_schema(EnumType)
             assert is_schema(ScalarType) is False
-            with raises(TypeError):
+            with pytest.raises(TypeError):
                 assert_schema(ScalarType)
 
         def return_false_for_random_garbage():
             assert is_schema({"what": "is this"}) is False
-            with raises(TypeError):
+            with pytest.raises(TypeError):
                 assert_schema({"what": "is this"})
```

### Comparing `graphql_core-3.3.0a3/tests/type/test_scalars.py` & `graphql_core-3.3.0a4/tests/type/test_scalars.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,13 +1,12 @@
 import pickle
 from math import inf, nan, pi
 from typing import Any
 
-from pytest import raises
-
+import pytest
 from graphql.error import GraphQLError
 from graphql.language import parse_value as parse_value_to_ast
 from graphql.pyutils import Undefined
 from graphql.type import (
     GraphQLBoolean,
     GraphQLFloat,
     GraphQLID,
@@ -19,15 +18,15 @@
 
 def describe_type_system_specified_scalar_types():
     def describe_graphql_int():
         def parse_value():
             _parse_value = GraphQLInt.parse_value
 
             def _parse_value_raises(s: Any, message: str):
-                with raises(GraphQLError) as exc_info:
+                with pytest.raises(GraphQLError) as exc_info:
                     _parse_value(s)
                 assert str(exc_info.value) == message
 
             assert _parse_value(1) == 1
             assert _parse_value(0) == 0
             assert _parse_value(-1) == -1
 
@@ -56,15 +55,15 @@
             )
 
         def parse_literal():
             def _parse_literal(s: str):
                 return GraphQLInt.parse_literal(parse_value_to_ast(s))
 
             def _parse_literal_raises(s: str, message: str):
-                with raises(GraphQLError) as exc_info:
+                with pytest.raises(GraphQLError) as exc_info:
                     _parse_literal(s)
                 assert str(exc_info.value).startswith(message + "\n")
 
             assert _parse_literal("1") == 1
             assert _parse_literal("0") == 0
             assert _parse_literal("-1") == -1
 
@@ -114,83 +113,83 @@
             assert serialize(1e5) == 100000
             assert serialize(False) == 0
             assert serialize(True) == 1
             assert serialize(type("Int", (int,), {})(5)) == 5
 
             # The GraphQL specification does not allow serializing non-integer
             # values as Int to avoid accidental data loss.
-            with raises(GraphQLError) as exc_info:
+            with pytest.raises(GraphQLError) as exc_info:
                 serialize(0.1)
             assert str(exc_info.value) == "Int cannot represent non-integer value: 0.1"
-            with raises(GraphQLError) as exc_info:
+            with pytest.raises(GraphQLError) as exc_info:
                 serialize(1.1)
             assert str(exc_info.value) == "Int cannot represent non-integer value: 1.1"
-            with raises(GraphQLError) as exc_info:
+            with pytest.raises(GraphQLError) as exc_info:
                 serialize(-1.1)
             assert str(exc_info.value) == "Int cannot represent non-integer value: -1.1"
-            with raises(GraphQLError) as exc_info:
+            with pytest.raises(GraphQLError) as exc_info:
                 serialize("-1.1")
             assert (
                 str(exc_info.value) == "Int cannot represent non-integer value: '-1.1'"
             )
             # Maybe a safe JavaScript int, but bigger than 2^32, so not
             # representable as a GraphQL Int
-            with raises(GraphQLError) as exc_info:
+            with pytest.raises(GraphQLError) as exc_info:
                 serialize(9876504321)
             assert str(exc_info.value) == (
                 "Int cannot represent non 32-bit signed integer value: 9876504321"
             )
-            with raises(GraphQLError) as exc_info:
+            with pytest.raises(GraphQLError) as exc_info:
                 serialize(-9876504321)
             assert str(exc_info.value) == (
                 "Int cannot represent non 32-bit signed integer value: -9876504321"
             )
             # Too big to represent as an Int in JavaScript or GraphQL
-            with raises(GraphQLError) as exc_info:
+            with pytest.raises(GraphQLError) as exc_info:
                 serialize(1e100)
             assert str(exc_info.value) == (
                 "Int cannot represent non 32-bit signed integer value: 1e+100"
             )
-            with raises(GraphQLError) as exc_info:
+            with pytest.raises(GraphQLError) as exc_info:
                 serialize(-1e100)
             assert str(exc_info.value) == (
                 "Int cannot represent non 32-bit signed integer value: -1e+100"
             )
-            with raises(GraphQLError) as exc_info:
+            with pytest.raises(GraphQLError) as exc_info:
                 serialize("one")
             assert (
                 str(exc_info.value) == "Int cannot represent non-integer value: 'one'"
             )
             # Doesn't represent number
-            with raises(GraphQLError) as exc_info:
+            with pytest.raises(GraphQLError) as exc_info:
                 serialize("")
             assert str(exc_info.value) == "Int cannot represent non-integer value: ''"
-            with raises(GraphQLError) as exc_info:
+            with pytest.raises(GraphQLError) as exc_info:
                 serialize(nan)
             assert str(exc_info.value) == "Int cannot represent non-integer value: nan"
-            with raises(GraphQLError) as exc_info:
+            with pytest.raises(GraphQLError) as exc_info:
                 serialize(inf)
             assert str(exc_info.value) == "Int cannot represent non-integer value: inf"
-            with raises(GraphQLError) as exc_info:
+            with pytest.raises(GraphQLError) as exc_info:
                 serialize([5])
             assert str(exc_info.value) == "Int cannot represent non-integer value: [5]"
 
         def cannot_be_redefined():
-            with raises(TypeError, match="Redefinition of reserved type 'Int'"):
+            with pytest.raises(TypeError, match="Redefinition of reserved type 'Int'"):
                 GraphQLScalarType(name="Int")
 
         def pickles():
             assert pickle.loads(pickle.dumps(GraphQLInt)) is GraphQLInt
 
     def describe_graphql_float():
         def parse_value():
             _parse_value = GraphQLFloat.parse_value
 
             def _parse_value_raises(s: Any, message: str):
-                with raises(GraphQLError) as exc_info:
+                with pytest.raises(GraphQLError) as exc_info:
                     _parse_value(s)
                 assert str(exc_info.value) == message
 
             assert _parse_value(1) == 1
             assert _parse_value(0) == 0
             assert _parse_value(-1) == -1
             assert _parse_value(0.1) == 0.1
@@ -218,15 +217,15 @@
             )
 
         def parse_literal():
             def _parse_literal(s: str):
                 return GraphQLFloat.parse_literal(parse_value_to_ast(s))
 
             def _parse_literal_raises(s: str, message: str):
-                with raises(GraphQLError) as exc_info:
+                with pytest.raises(GraphQLError) as exc_info:
                     _parse_literal(s)
                 assert str(exc_info.value).startswith(message + "\n")
 
             assert _parse_literal("1") == 1
             assert _parse_literal("0") == 0
             assert _parse_literal("-1") == -1
             assert _parse_literal("0.1") == 0.1
@@ -276,51 +275,53 @@
             assert serialize(1.1) == 1.1
             assert serialize(-1.1) == -1.1
             assert serialize("-1.1") == -1.1
             assert serialize(False) == 0
             assert serialize(True) == 1
             assert serialize(type("Float", (float,), {})(5.5)) == 5.5
 
-            with raises(GraphQLError) as exc_info:
+            with pytest.raises(GraphQLError) as exc_info:
                 serialize(nan)
             assert (
                 str(exc_info.value) == "Float cannot represent non numeric value: nan"
             )
-            with raises(GraphQLError) as exc_info:
+            with pytest.raises(GraphQLError) as exc_info:
                 serialize(inf)
             assert (
                 str(exc_info.value) == "Float cannot represent non numeric value: inf"
             )
-            with raises(GraphQLError) as exc_info:
+            with pytest.raises(GraphQLError) as exc_info:
                 serialize("one")
             assert str(exc_info.value) == (
                 "Float cannot represent non numeric value: 'one'"
             )
-            with raises(GraphQLError) as exc_info:
+            with pytest.raises(GraphQLError) as exc_info:
                 serialize("")
             assert str(exc_info.value) == "Float cannot represent non numeric value: ''"
-            with raises(GraphQLError) as exc_info:
+            with pytest.raises(GraphQLError) as exc_info:
                 serialize([5])
             assert (
                 str(exc_info.value) == "Float cannot represent non numeric value: [5]"
             )
 
         def cannot_be_redefined():
-            with raises(TypeError, match="Redefinition of reserved type 'Float'"):
+            with pytest.raises(
+                TypeError, match="Redefinition of reserved type 'Float'"
+            ):
                 GraphQLScalarType(name="Float")
 
         def pickles():
             assert pickle.loads(pickle.dumps(GraphQLFloat)) is GraphQLFloat
 
     def describe_graphql_string():
         def parse_value():
             _parse_value = GraphQLString.parse_value
 
             def _parse_value_raises(s: Any, message: str):
-                with raises(GraphQLError) as exc_info:
+                with pytest.raises(GraphQLError) as exc_info:
                     _parse_value(s)
                 assert str(exc_info.value) == message
 
             assert _parse_value("foo") == "foo"
 
             _parse_value_raises(
                 Undefined, "String cannot represent a non string value: Undefined"
@@ -342,15 +343,15 @@
             )
 
         def parse_literal():
             def _parse_literal(s: str):
                 return GraphQLString.parse_literal(parse_value_to_ast(s))
 
             def _parse_literal_raises(s: str, message: str):
-                with raises(GraphQLError) as exc_info:
+                with pytest.raises(GraphQLError) as exc_info:
                     _parse_literal(s)
                 assert str(exc_info.value).startswith(message + "\n")
 
             assert _parse_literal('"foo"') == "foo"
             assert _parse_literal('"""bar"""') == "bar"
 
             _parse_literal_raises(
@@ -394,46 +395,48 @@
 
             class StringableObjValue:
                 def __str__(self):
                     return "something useful"
 
             assert serialize(StringableObjValue()) == "something useful"
 
-            with raises(GraphQLError) as exc_info:
+            with pytest.raises(GraphQLError) as exc_info:
                 serialize(nan)
             assert str(exc_info.value) == "String cannot represent value: nan"
 
-            with raises(GraphQLError) as exc_info:
+            with pytest.raises(GraphQLError) as exc_info:
                 serialize([1])
             assert str(exc_info.value) == "String cannot represent value: [1]"
 
-            with raises(GraphQLError) as exc_info:
+            with pytest.raises(GraphQLError) as exc_info:
                 serialize({})
             assert str(exc_info.value) == "String cannot represent value: {}"
 
-            with raises(GraphQLError) as exc_info:
+            with pytest.raises(GraphQLError) as exc_info:
                 serialize({"value_of": "value_of string"})
             assert (
                 str(exc_info.value) == "String cannot represent value:"
                 " {'value_of': 'value_of string'}"
             )
 
         def cannot_be_redefined():
-            with raises(TypeError, match="Redefinition of reserved type 'String'"):
+            with pytest.raises(
+                TypeError, match="Redefinition of reserved type 'String'"
+            ):
                 GraphQLScalarType(name="String")
 
         def pickles():
             assert pickle.loads(pickle.dumps(GraphQLString)) is GraphQLString
 
     def describe_graphql_boolean():
         def parse_value():
             _parse_value = GraphQLBoolean.parse_value
 
             def _parse_value_raises(s: Any, message: str):
-                with raises(GraphQLError) as exc_info:
+                with pytest.raises(GraphQLError) as exc_info:
                     _parse_value(s)
                 assert str(exc_info.value) == message
 
             assert _parse_value(True) is True
             assert _parse_value(False) is False
 
             _parse_value_raises(
@@ -463,15 +466,15 @@
             )
 
         def parse_literal():
             def _parse_literal(s: str):
                 return GraphQLBoolean.parse_literal(parse_value_to_ast(s))
 
             def _parse_literal_raises(s: str, message: str):
-                with raises(GraphQLError) as exc_info:
+                with pytest.raises(GraphQLError) as exc_info:
                     _parse_literal(s)
                 assert str(exc_info.value).startswith(message + "\n")
 
             assert _parse_literal("true") is True
             assert _parse_literal("false") is False
 
             _parse_literal_raises(
@@ -528,61 +531,63 @@
         def serializes():
             serialize = GraphQLBoolean.serialize
 
             assert serialize(1) is True
             assert serialize(0) is False
             assert serialize(True) is True
             assert serialize(False) is False
-            with raises(TypeError, match="not an acceptable base type"):
+            with pytest.raises(TypeError, match="not an acceptable base type"):
                 # you can't subclass bool in Python
                 assert serialize(type("Boolean", (bool,), {})(True)) is True
 
-            with raises(GraphQLError) as exc_info:
+            with pytest.raises(GraphQLError) as exc_info:
                 serialize(nan)
             assert str(exc_info.value) == (
                 "Boolean cannot represent a non boolean value: nan"
             )
 
-            with raises(GraphQLError) as exc_info:
+            with pytest.raises(GraphQLError) as exc_info:
                 serialize("")
             assert str(exc_info.value) == (
                 "Boolean cannot represent a non boolean value: ''"
             )
 
-            with raises(GraphQLError) as exc_info:
+            with pytest.raises(GraphQLError) as exc_info:
                 serialize("True")
             assert str(exc_info.value) == (
                 "Boolean cannot represent a non boolean value: 'True'"
             )
 
-            with raises(GraphQLError) as exc_info:
+            with pytest.raises(GraphQLError) as exc_info:
                 serialize([False])
             assert str(exc_info.value) == (
                 "Boolean cannot represent a non boolean value: [False]"
             )
 
-            with raises(GraphQLError) as exc_info:
+            with pytest.raises(GraphQLError) as exc_info:
                 serialize({})
             assert str(exc_info.value) == (
                 "Boolean cannot represent a non boolean value: {}"
             )
 
         def cannot_be_redefined():
-            with raises(TypeError, match="Redefinition of reserved type 'Boolean'"):
+            with pytest.raises(
+                TypeError, match="Redefinition of reserved type 'Boolean'"
+            ):
                 GraphQLScalarType(name="Boolean")
 
         def pickles():
             assert pickle.loads(pickle.dumps(GraphQLBoolean)) is GraphQLBoolean
 
     def describe_graphql_id():
         def parse_value():
             _parse_value = GraphQLID.parse_value
 
             def _parse_value_raises(s: Any, message: str):
-                with raises(GraphQLError) as exc_info:
+                with pytest.raises(GraphQLError) as exc_info:
                     _parse_value(s)
                 assert str(exc_info.value) == message
 
             assert _parse_value("") == ""
             assert _parse_value("1") == "1"
             assert _parse_value("foo") == "foo"
             assert _parse_value(1) == "1"
@@ -606,15 +611,15 @@
             )
 
         def parse_literal():
             def _parse_literal(s: str):
                 return GraphQLID.parse_literal(parse_value_to_ast(s))
 
             def _parse_literal_raises(s: str, message: str):
-                with raises(GraphQLError) as exc_info:
+                with pytest.raises(GraphQLError) as exc_info:
                     _parse_literal(s)
                 assert str(exc_info.value).startswith(message + "\n")
 
             assert _parse_literal('""') == ""
             assert _parse_literal('"1"') == "1"
             assert _parse_literal('"foo"') == "foo"
             assert _parse_literal('"""foo"""') == "foo"
@@ -674,29 +679,29 @@
 
                 def __str__(self):
                     return str(self._id)
 
             obj_value = ObjValue(123)
             assert serialize(obj_value) == "123"
 
-            with raises(GraphQLError) as exc_info:
+            with pytest.raises(GraphQLError) as exc_info:
                 serialize(True)
             assert str(exc_info.value) == "ID cannot represent value: True"
 
-            with raises(GraphQLError) as exc_info:
+            with pytest.raises(GraphQLError) as exc_info:
                 serialize(3.14)
             assert str(exc_info.value) == "ID cannot represent value: 3.14"
 
-            with raises(GraphQLError) as exc_info:
+            with pytest.raises(GraphQLError) as exc_info:
                 serialize({})
             assert str(exc_info.value) == "ID cannot represent value: {}"
 
-            with raises(GraphQLError) as exc_info:
+            with pytest.raises(GraphQLError) as exc_info:
                 serialize(["abc"])
             assert str(exc_info.value) == "ID cannot represent value: ['abc']"
 
         def cannot_be_redefined():
-            with raises(TypeError, match="Redefinition of reserved type 'ID'"):
+            with pytest.raises(TypeError, match="Redefinition of reserved type 'ID'"):
                 GraphQLScalarType(name="ID")
 
         def pickles():
             assert pickle.loads(pickle.dumps(GraphQLID)) is GraphQLID
```

### Comparing `graphql_core-3.3.0a3/tests/type/test_schema.py` & `graphql_core-3.3.0a4/tests/type/test_schema.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,11 +1,10 @@
 from copy import deepcopy
 
-from pytest import raises
-
+import pytest
 from graphql.language import (
     DirectiveLocation,
     SchemaDefinitionNode,
     SchemaExtensionNode,
 )
 from graphql.type import (
     GraphQLArgument,
@@ -365,40 +364,40 @@
                 "Query",
                 {
                     "normal": GraphQLField(GraphQLString),
                     "fake": GraphQLField(FakeString),
                 },
             )
 
-            with raises(TypeError) as exc_info:
+            with pytest.raises(TypeError) as exc_info:
                 GraphQLSchema(QueryType)
             msg = str(exc_info.value)
             assert msg == (
                 "Schema must contain uniquely named types"
                 " but contains multiple types named 'String'."
             )
 
         def rejects_a_schema_when_a_provided_type_has_no_name():
             query = GraphQLObjectType("Query", {"foo": GraphQLField(GraphQLString)})
             types = [GraphQLType(), query, GraphQLType()]
 
-            with raises(TypeError) as exc_info:
+            with pytest.raises(TypeError) as exc_info:
                 GraphQLSchema(query, types=types)  # type: ignore
             msg = str(exc_info.value)
             assert msg == (
                 "One of the provided types for building the Schema is missing a name."
             )
 
         def rejects_a_schema_which_defines_an_object_twice():
             types = [
                 GraphQLObjectType("SameName", {}),
                 GraphQLObjectType("SameName", {}),
             ]
 
-            with raises(TypeError) as exc_info:
+            with pytest.raises(TypeError) as exc_info:
                 GraphQLSchema(types=types)
             msg = str(exc_info.value)
             assert msg == (
                 "Schema must contain uniquely named types"
                 " but contains multiple types named 'SameName'."
             )
 
@@ -408,15 +407,15 @@
                 "Query",
                 {
                     "a": GraphQLField(GraphQLObjectType("SameName", fields)),
                     "b": GraphQLField(GraphQLObjectType("SameName", fields)),
                 },
             )
 
-            with raises(TypeError) as exc_info:
+            with pytest.raises(TypeError) as exc_info:
                 GraphQLSchema(QueryType)
             msg = str(exc_info.value)
             assert msg == (
                 "Schema must contain uniquely named types"
                 " but contains multiple types named 'SameName'."
             )
```

### Comparing `graphql_core-3.3.0a3/tests/type/test_validation.py` & `graphql_core-3.3.0a4/tests/type/test_validation.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,12 +1,11 @@
 from operator import attrgetter
 from typing import List, Union
 
-from pytest import mark, raises
-
+import pytest
 from graphql.language import DirectiveLocation, parse
 from graphql.pyutils import inspect
 from graphql.type import (
     GraphQLArgument,
     GraphQLDirective,
     GraphQLEnumType,
     GraphQLField,
@@ -32,15 +31,14 @@
     assert_valid_schema,
     validate_schema,
 )
 from graphql.utilities import build_schema, extend_schema
 
 from ..utils import dedent
 
-
 SomeSchema = build_schema(
     """
     scalar SomeScalar
 
     interface SomeInterface { f: SomeObject }
 
     type SomeObject implements SomeInterface { f: SomeObject }
@@ -551,15 +549,15 @@
         manual_schema = schema_with_field_type(
             GraphQLObjectType("IncompleteObject", {})
         )
         msg = validate_schema(manual_schema)[0].message
         assert msg == "Type IncompleteObject must define one or more fields."
 
         manual_schema_2 = schema_with_field_type(
-            GraphQLObjectType("IncompleteObject", lambda: {})
+            GraphQLObjectType("IncompleteObject", dict)
         )
         msg = validate_schema(manual_schema_2)[0].message
         assert msg == "Type IncompleteObject must define one or more fields."
 
     def rejects_an_object_type_with_incorrectly_named_fields():
         schema = schema_with_field_type(
             GraphQLObjectType("SomeObject", {"__badName": GraphQLField(GraphQLString)})
@@ -745,21 +743,22 @@
             SomeUnionType,
             SomeEnumType,
             SomeInputObjectType,
         ]
         for member_type in bad_union_member_types:
             # invalid union type cannot be built with Python
             bad_union = GraphQLUnionType(
-                "BadUnion", types=[member_type]  # type: ignore
+                "BadUnion",
+                types=[member_type],  # type: ignore
             )
             bad_schema = schema_with_field_type(bad_union)
             assert validate_schema(bad_schema) == [
                 {
                     "message": "Union type BadUnion can only include Object types,"
-                    + f" it cannot include {inspect(member_type)}."
+                    f" it cannot include {inspect(member_type)}."
                 }
             ]
 
 
 def describe_type_system_input_objects_must_have_fields():
     def accepts_an_input_object_type_with_fields():
         schema = build_schema(
@@ -1002,40 +1001,40 @@
             "BadObject", {"badField": GraphQLField(type_)}
         )
         return GraphQLSchema(
             GraphQLObjectType("Query", {"f": GraphQLField(bad_object_type)}),
             types=[SomeObjectType],
         )
 
-    @mark.parametrize("type_", output_types, ids=get_name)
+    @pytest.mark.parametrize("type_", output_types, ids=get_name)
     def accepts_an_output_type_as_an_object_field_type(type_):
         schema = _schema_with_object_field(type_)
         assert validate_schema(schema) == []
 
     def rejects_an_empty_object_field_type():
         # noinspection PyTypeChecker
         schema = _schema_with_object_field(None)  # type: ignore
         assert validate_schema(schema) == [
             {
                 "message": "The type of BadObject.badField must be Output Type"
                 " but got: None."
             }
         ]
 
-    @mark.parametrize("type_", not_output_types, ids=get_name)
+    @pytest.mark.parametrize("type_", not_output_types, ids=get_name)
     def rejects_a_non_output_type_as_an_object_field_type(type_):
         schema = _schema_with_object_field(type_)
         assert validate_schema(schema) == [
             {
                 "message": "The type of BadObject.badField must be Output Type"
                 f" but got: {type_}."
             }
         ]
 
-    @mark.parametrize("type_", not_graphql_types, ids=get_name)
+    @pytest.mark.parametrize("type_", not_graphql_types, ids=get_name)
     def rejects_a_non_type_value_as_an_object_field_type(type_):
         schema = _schema_with_object_field(type_)
         assert validate_schema(schema) == [
             {
                 "message": "The type of BadObject.badField must be Output Type"
                 f" but got: {inspect(type_)}.",
             },
@@ -1297,15 +1296,15 @@
             interfaces=[bad_interface_type],
         )
         return GraphQLSchema(
             GraphQLObjectType("Query", {"f": GraphQLField(bad_interface_type)}),
             types=[bad_implementing_type, SomeObjectType],
         )
 
-    @mark.parametrize("type_", output_types, ids=get_name)
+    @pytest.mark.parametrize("type_", output_types, ids=get_name)
     def accepts_an_output_type_as_an_interface_field_type(type_):
         schema = _schema_with_interface_field(type_)
         assert validate_schema(schema) == []
 
     def rejects_an_empty_interface_field_type():
         # noinspection PyTypeChecker
         schema = _schema_with_interface_field(None)  # type: ignore
@@ -1316,29 +1315,29 @@
             },
             {
                 "message": "The type of BadInterface.badField must be Output Type"
                 " but got: None.",
             },
         ]
 
-    @mark.parametrize("type_", not_output_types, ids=get_name)
+    @pytest.mark.parametrize("type_", not_output_types, ids=get_name)
     def rejects_a_non_output_type_as_an_interface_field_type(type_):
         schema = _schema_with_interface_field(type_)
         assert validate_schema(schema) == [
             {
                 "message": "The type of BadImplementing.badField must be Output Type"
                 f" but got: {type_}.",
             },
             {
                 "message": "The type of BadInterface.badField must be Output Type"
                 f" but got: {type_}.",
             },
         ]
 
-    @mark.parametrize("type_", not_graphql_types, ids=get_name)
+    @pytest.mark.parametrize("type_", not_graphql_types, ids=get_name)
     def rejects_a_non_type_value_as_an_interface_field_type(type_):
         schema = _schema_with_interface_field(type_)
         assert validate_schema(schema) == [
             {
                 "message": "The type of BadImplementing.badField must be Output Type"
                 f" but got: {inspect(type_)}.",
             },
@@ -1411,15 +1410,15 @@
                     "BadDirective",
                     [DirectiveLocation.QUERY],
                     args,
                 )
             ],
         )
 
-    @mark.parametrize("type_", input_types, ids=get_name)
+    @pytest.mark.parametrize("type_", input_types, ids=get_name)
     def accepts_an_input_type_as_a_field_arg_type(type_):
         schema = _schema_with_arg(type_)
         assert validate_schema(schema) == []
 
     def rejects_an_empty_field_arg_type():
         # noinspection PyTypeChecker
         schema = _schema_with_arg(None)  # type: ignore
@@ -1430,29 +1429,29 @@
             },
             {
                 "message": "The type of BadObject.badField(badArg:) must be Input Type"
                 " but got: None."
             },
         ]
 
-    @mark.parametrize("type_", not_input_types, ids=get_name)
+    @pytest.mark.parametrize("type_", not_input_types, ids=get_name)
     def rejects_a_non_input_type_as_a_field_arg_type(type_):
         schema = _schema_with_arg(type_)
         assert validate_schema(schema) == [
             {
                 "message": "The type of @BadDirective(badArg:) must be Input Type"
                 f" but got: {type_}."
             },
             {
                 "message": "The type of BadObject.badField(badArg:) must be Input Type"
                 f" but got: {type_}."
             },
         ]
 
-    @mark.parametrize("type_", not_graphql_types, ids=get_name)
+    @pytest.mark.parametrize("type_", not_graphql_types, ids=get_name)
     def rejects_a_non_type_value_as_a_field_arg_type(type_):
         schema = _schema_with_arg(type_)
         assert validate_schema(schema) == [
             {
                 "message": "The type of @BadDirective(badArg:) must be Input Type"
                 f" but got: {inspect(type_)}."
             },
@@ -1528,40 +1527,40 @@
                         GraphQLString,
                         args={"badArg": GraphQLArgument(bad_input_object_type)},
                     )
                 },
             )
         )
 
-    @mark.parametrize("type_", input_types, ids=get_name)
+    @pytest.mark.parametrize("type_", input_types, ids=get_name)
     def accepts_an_input_type_as_an_input_field_type(type_):
         schema = _schema_with_input_field(type_)
         assert validate_schema(schema) == []
 
     def rejects_an_empty_input_field_type():
         # noinspection PyTypeChecker
         schema = _schema_with_input_field(None)  # type: ignore
         assert validate_schema(schema) == [
             {
                 "message": "The type of BadInputObject.badField must be Input Type"
                 " but got: None."
             }
         ]
 
-    @mark.parametrize("type_", not_input_types, ids=get_name)
+    @pytest.mark.parametrize("type_", not_input_types, ids=get_name)
     def rejects_a_non_input_type_as_an_input_field_type(type_):
         schema = _schema_with_input_field(type_)
         assert validate_schema(schema) == [
             {
                 "message": "The type of BadInputObject.badField must be Input Type"
                 f" but got: {type_}."
             }
         ]
 
-    @mark.parametrize("type_", not_graphql_types, ids=get_name)
+    @pytest.mark.parametrize("type_", not_graphql_types, ids=get_name)
     def rejects_a_non_type_value_as_an_input_field_type(type_):
         schema = _schema_with_input_field(type_)
         assert validate_schema(schema) == [
             {
                 "message": "The type of BadInputObject.badField must be Input Type"
                 f" but got: {inspect(type_)}."
             },
@@ -2502,27 +2501,25 @@
             },
         ]
 
 
 def describe_assert_valid_schema():
     def does_not_throw_on_valid_schemas():
         schema = build_schema(
-            (
-                """
+            """
              type Query {
                foo: String
              }
             """
-            )
         )
         assert_valid_schema(schema)
 
     def combines_multiple_errors():
         schema = build_schema("type SomeType")
-        with raises(TypeError) as exc_info:
+        with pytest.raises(TypeError) as exc_info:
             assert_valid_schema(schema)
         assert (
             str(exc_info.value)
             == dedent(
                 """
             Query root type must be provided.
```

### Comparing `graphql_core-3.3.0a3/tests/utilities/test_ast_from_value.py` & `graphql_core-3.3.0a4/tests/utilities/test_ast_from_value.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,11 +1,10 @@
 from math import inf, nan
 
-from pytest import raises
-
+import pytest
 from graphql.error import GraphQLError
 from graphql.language import (
     BooleanValueNode,
     EnumValueNode,
     FloatValueNode,
     IntValueNode,
     ListValueNode,
@@ -54,26 +53,26 @@
 
         assert ast_from_value(123.0, GraphQLInt) == IntValueNode(value="123")
 
         assert ast_from_value(1e4, GraphQLInt) == IntValueNode(value="10000")
 
         # GraphQL spec does not allow coercing non-integer values to Int to
         # avoid accidental data loss.
-        with raises(GraphQLError) as exc_info:
+        with pytest.raises(GraphQLError) as exc_info:
             assert ast_from_value(123.5, GraphQLInt)
         msg = str(exc_info.value)
         assert msg == "Int cannot represent non-integer value: 123.5"
 
         # Note: outside the bounds of 32bit signed int.
-        with raises(GraphQLError) as exc_info:
+        with pytest.raises(GraphQLError) as exc_info:
             assert ast_from_value(1e40, GraphQLInt)
         msg = str(exc_info.value)
         assert msg == "Int cannot represent non 32-bit signed integer value: 1e+40"
 
-        with raises(GraphQLError) as exc_info:
+        with pytest.raises(GraphQLError) as exc_info:
             ast_from_value(nan, GraphQLInt)
         msg = str(exc_info.value)
         assert msg == "Int cannot represent non-integer value: nan"
 
     def converts_float_values_to_float_asts():
         # luckily in Python we can discern between float and int
         assert ast_from_value(-1, GraphQLFloat) == FloatValueNode(value="-1")
@@ -122,15 +121,15 @@
 
         assert ast_from_value(123, GraphQLID) == IntValueNode(value="123")
 
         assert ast_from_value("123", GraphQLID) == IntValueNode(value="123")
 
         assert ast_from_value("01", GraphQLID) == StringValueNode(value="01")
 
-        with raises(GraphQLError) as exc_info:
+        with pytest.raises(GraphQLError) as exc_info:
             assert ast_from_value(False, GraphQLID)
         assert str(exc_info.value) == "ID cannot represent value: False"
 
         assert ast_from_value(None, GraphQLID) == NullValueNode()
 
         assert ast_from_value(Undefined, GraphQLString) is None
 
@@ -140,38 +139,38 @@
             serialize=lambda value: value,
         )
 
         assert ast_from_value("value", pass_through_scalar) == StringValueNode(
             value="value"
         )
 
-        with raises(TypeError) as exc_info:
+        with pytest.raises(TypeError) as exc_info:
             assert ast_from_value(nan, pass_through_scalar)
         assert str(exc_info.value) == "Cannot convert value to AST: nan."
 
-        with raises(TypeError) as exc_info:
+        with pytest.raises(TypeError) as exc_info:
             ast_from_value(inf, pass_through_scalar)
         assert str(exc_info.value) == "Cannot convert value to AST: inf."
 
         return_null_scalar = GraphQLScalarType(
             "ReturnNullScalar",
-            serialize=lambda value: None,
+            serialize=lambda value: None,  # noqa: ARG005
         )
 
         assert ast_from_value("value", return_null_scalar) is None
 
         class SomeClass:
             pass
 
         return_custom_class_scalar = GraphQLScalarType(
             "ReturnCustomClassScalar",
-            serialize=lambda value: SomeClass(),
+            serialize=lambda value: SomeClass(),  # noqa: ARG005
         )
 
-        with raises(TypeError) as exc_info:
+        with pytest.raises(TypeError) as exc_info:
             ast_from_value("value", return_custom_class_scalar)
         msg = str(exc_info.value)
         assert msg == "Cannot convert value to AST: <SomeClass instance>."
 
     def does_not_convert_non_null_values_to_null_value():
         non_null_boolean = GraphQLNonNull(GraphQLBoolean)
         assert ast_from_value(None, non_null_boolean) is None
@@ -184,20 +183,20 @@
 
     def converts_string_values_to_enum_asts_if_possible():
         assert ast_from_value("HELLO", my_enum) == EnumValueNode(value="HELLO")
 
         assert ast_from_value(complex_value, my_enum) == EnumValueNode(value="COMPLEX")
 
         # Note: case sensitive
-        with raises(GraphQLError) as exc_info:
+        with pytest.raises(GraphQLError) as exc_info:
             ast_from_value("hello", my_enum)
         assert exc_info.value.message == "Enum 'MyEnum' cannot represent value: 'hello'"
 
         # Note: not a valid enum value
-        with raises(GraphQLError) as exc_info:
+        with pytest.raises(GraphQLError) as exc_info:
             ast_from_value("UNKNOWN_VALUE", my_enum)
         assert (
             exc_info.value.message
             == "Enum 'MyEnum' cannot represent value: 'UNKNOWN_VALUE'"
         )
 
     def converts_list_values_to_list_asts():
```

### Comparing `graphql_core-3.3.0a3/tests/utilities/test_ast_to_dict.py` & `graphql_core-3.3.0a4/tests/utilities/test_ast_to_dict.py`

 * *Files 1% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 
 
 def describe_ast_to_disc():
     def converts_name_node_to_dict():
         node = NameNode(value="test")
         res = ast_to_dict(node)
         assert res == {"kind": "name", "value": "test"}
-        assert list(res)[0] == "kind"
+        assert next(iter(res)) == "kind"
         assert ast_to_dict(node, locations=True) == res
         assert node.to_dict() == res
         assert node.to_dict(locations=True) == res
 
     def converts_two_name_nodes_to_list():
         nodes = [NameNode(value="foo"), NameNode(value="bar")]
         res = ast_to_dict(nodes)
@@ -118,15 +118,15 @@
                     "interfaces": [],
                     "kind": "object_type_definition",
                     "name": {"kind": "name", "value": "User"},
                 },
             ],
             "kind": "document",
         }
-        assert list(res)[0] == "kind"
+        assert next(iter(res)) == "kind"
 
     def converts_simple_schema_to_dict_with_locations():
         ast = parse(
             """
             type Query {
               me: User
             }
@@ -376,15 +376,15 @@
                             },
                         }
                     ],
                 }
             ],
             "kind": "document",
         }
-        assert list(res)[0] == "kind"
+        assert next(iter(res)) == "kind"
 
     def converts_simple_query_to_dict_with_locations():
         ast = parse(
             """
             query HeroForEpisode($ep: Episode!) {
               hero(episode: $ep) {
                 name
```

### Comparing `graphql_core-3.3.0a3/tests/utilities/test_build_ast_schema.py` & `graphql_core-3.3.0a4/tests/utilities/test_build_ast_schema.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,15 +1,14 @@
 import pickle
 import sys
 from collections import namedtuple
 from copy import deepcopy
 from typing import Union
 
-from pytest import mark, raises
-
+import pytest
 from graphql import graphql_sync
 from graphql.language import DocumentNode, InterfaceTypeDefinitionNode, parse, print_ast
 from graphql.type import (
     GraphQLArgument,
     GraphQLBoolean,
     GraphQLDeprecatedDirective,
     GraphQLEnumType,
@@ -37,15 +36,14 @@
 )
 from graphql.utilities import build_ast_schema, build_schema, print_schema, print_type
 
 from ..fixtures import big_schema_sdl  # noqa: F401
 from ..star_wars_schema import star_wars_schema
 from ..utils import dedent
 
-
 try:
     from typing import TypeAlias
 except ImportError:  # Python < 3.10
     from typing_extensions import TypeAlias
 
 
 def cycle_sdl(sdl: str) -> str:
@@ -64,20 +62,22 @@
     GraphQLArgument, GraphQLEnumValue, GraphQLField, GraphQLInputField, GraphQLNamedType
 ]
 
 TypeWithExtensionAstNodes: TypeAlias = GraphQLNamedType
 
 
 def expect_ast_node(obj: TypeWithAstNode, expected: str) -> None:
-    assert obj is not None and obj.ast_node is not None
+    assert obj is not None
+    assert obj.ast_node is not None
     assert print_ast(obj.ast_node) == expected
 
 
 def expect_extension_ast_nodes(obj: TypeWithExtensionAstNodes, expected: str) -> None:
-    assert obj is not None and obj.extension_ast_nodes is not None
+    assert obj is not None
+    assert obj.extension_ast_nodes is not None
     assert "\n\n".join(print_ast(node) for node in obj.extension_ast_nodes) == expected
 
 
 def describe_schema_builder():
     def can_use_built_schema_for_limited_execution():
         schema = build_ast_schema(
             parse(
@@ -85,15 +85,17 @@
                 type Query {
                   str: String
                 }
                 """
             )
         )
 
-        root_value = namedtuple("Data", "str")(123)  # type: ignore
+        root_value = namedtuple(  # noqa: PYI024
+            "Data", "str"
+        )(123)  # type: ignore
 
         result = graphql_sync(schema=schema, source="{ str }", root_value=root_value)
         assert result == ({"str": "123"}, None)
 
     def can_build_a_schema_directly_from_the_source():
         schema = build_schema(
             """
@@ -500,15 +502,16 @@
 
             type Query {
               hello: Hello
             }
             """
         )
         errors = validate_schema(schema)
-        assert errors and isinstance(errors, list)
+        assert errors
+        assert isinstance(errors, list)
 
     def custom_scalar():
         sdl = dedent(
             """
             scalar CustomScalar
 
             type Query {
@@ -1158,15 +1161,15 @@
 
     def rejects_invalid_sdl():
         sdl = """
             type Query {
               foo: String @unknown
             }
             """
-        with raises(TypeError) as exc_info:
+        with pytest.raises(TypeError) as exc_info:
             build_schema(sdl)
         assert str(exc_info.value) == "Unknown directive '@unknown'."
 
     def allows_to_disable_sdl_validation():
         sdl = """
             type Query {
               foo: String @unknown
@@ -1177,15 +1180,15 @@
 
     def throws_on_unknown_types():
         sdl = """
             type Query {
               unknown: UnknownType
             }
             """
-        with raises(TypeError) as exc_info:
+        with pytest.raises(TypeError) as exc_info:
             build_schema(sdl, assume_valid_sdl=True)
         assert str(exc_info.value).endswith("Unknown type: 'UnknownType'.")
 
     def describe_deepcopy_and_pickle():  # pragma: no cover
         sdl = print_schema(star_wars_schema)
 
         def can_deep_copy_schema():
@@ -1222,29 +1225,29 @@
             # pickle and unpickle the schema
             loaded = pickle.loads(pickle.dumps(schema))
             # create a deepcopy of the unpickled schema
             copied = deepcopy(loaded)
             # check that printing the copied schema gives the same SDL
             assert print_schema(copied) == sdl
 
-    @mark.slow
+    @pytest.mark.slow()
     def describe_deepcopy_and_pickle_big():  # pragma: no cover
-        @mark.timeout(20)
+        @pytest.mark.timeout(20)
         def can_deep_copy_big_schema(big_schema_sdl):  # noqa: F811
             # use our printing conventions
             big_schema_sdl = cycle_sdl(big_schema_sdl)
 
             # create a schema from the big SDL
             schema = build_schema(big_schema_sdl, assume_valid_sdl=True)
             # create a deepcopy of the schema
             copied = deepcopy(schema)
             # check that printing the copied schema gives the same SDL
             assert print_schema(copied) == big_schema_sdl
 
-        @mark.timeout(60)
+        @pytest.mark.timeout(60)
         def can_pickle_and_unpickle_big_schema(big_schema_sdl):  # noqa: F811
             # use our printing conventions
             big_schema_sdl = cycle_sdl(big_schema_sdl)
 
             limit = sys.getrecursionlimit()
             sys.setrecursionlimit(max(limit, 4000))  # needed for pickle
 
@@ -1268,15 +1271,15 @@
                 assert len(dumped) < 25 * len(big_schema_sdl)
                 loaded = pickle.loads(dumped)
                 assert print_schema(loaded) == big_schema_sdl
 
             finally:
                 sys.setrecursionlimit(limit)
 
-        @mark.timeout(60)
+        @pytest.mark.timeout(60)
         def can_deep_copy_pickled_big_schema(big_schema_sdl):  # noqa: F811
             # use our printing conventions
             big_schema_sdl = cycle_sdl(big_schema_sdl)
 
             limit = sys.getrecursionlimit()
             sys.setrecursionlimit(max(limit, 4000))  # needed for pickle
```

### Comparing `graphql_core-3.3.0a3/tests/utilities/test_build_client_schema.py` & `graphql_core-3.3.0a4/tests/utilities/test_build_client_schema.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,11 +1,10 @@
 from typing import cast
 
-from pytest import raises
-
+import pytest
 from graphql import graphql_sync
 from graphql.type import (
     GraphQLArgument,
     GraphQLBoolean,
     GraphQLEnumType,
     GraphQLEnumValue,
     GraphQLField,
@@ -324,15 +323,15 @@
               one(
                 """This is an int arg"""
                 intArg: Int
               ): String
 
               """A field with a two args"""
               two(
-                """This is an list of int arg"""
+                """This is a list of int arg"""
                 listArg: [Int]
 
                 """This is a required arg"""
                 requiredArg: Boolean!
               ): String
             }
             '''
@@ -647,25 +646,25 @@
             }
 
             directive @SomeDirective on QUERY
             """
         )
 
         def throws_when_introspection_is_missing_schema_property():
-            with raises(TypeError) as exc_info:
+            with pytest.raises(TypeError) as exc_info:
                 # noinspection PyTypeChecker
                 build_client_schema(None)  # type: ignore
 
             assert str(exc_info.value) == (
                 "Invalid or incomplete introspection result. Ensure that you"
                 " are passing the 'data' attribute of an introspection response"
                 " and no 'errors' were returned alongside: None."
             )
 
-            with raises(TypeError) as exc_info:
+            with pytest.raises(TypeError) as exc_info:
                 # noinspection PyTypeChecker
                 build_client_schema({})  # type: ignore
 
             assert str(exc_info.value) == (
                 "Invalid or incomplete introspection result. Ensure that you"
                 " are passing the 'data' attribute of an introspection response"
                 " and no 'errors' were returned alongside: {}."
@@ -676,15 +675,15 @@
 
             introspection["__schema"]["types"] = [
                 type_
                 for type_ in introspection["__schema"]["types"]
                 if type_["name"] != "Query"
             ]
 
-            with raises(TypeError) as exc_info:
+            with pytest.raises(TypeError) as exc_info:
                 build_client_schema(introspection)
 
             assert str(exc_info.value) == (
                 "Invalid or incomplete schema, unknown type: Query."
                 " Ensure that a full introspection query is used"
                 " in order to build a client schema."
             )
@@ -700,45 +699,45 @@
             introspection = introspection_from_schema(schema)
             introspection["__schema"]["types"] = [
                 type_
                 for type_ in introspection["__schema"]["types"]
                 if type_["name"] != "Float"
             ]
 
-            with raises(TypeError) as exc_info:
+            with pytest.raises(TypeError) as exc_info:
                 build_client_schema(introspection)
 
             assert str(exc_info.value).endswith(
                 "Invalid or incomplete schema, unknown type: Float."
                 " Ensure that a full introspection query is used"
                 " in order to build a client schema."
             )
 
         def throws_when_type_reference_is_missing_name():
             introspection = introspection_from_schema(dummy_schema)
             query_type = cast(IntrospectionType, introspection["__schema"]["queryType"])
             assert query_type["name"] == "Query"
             del query_type["name"]  # type: ignore
 
-            with raises(TypeError) as exc_info:
+            with pytest.raises(TypeError) as exc_info:
                 build_client_schema(introspection)
 
             assert str(exc_info.value) == "Unknown type reference: {}."
 
         def throws_when_missing_kind():
             introspection = introspection_from_schema(dummy_schema)
             query_type_introspection = next(
                 type_
                 for type_ in introspection["__schema"]["types"]
                 if type_["name"] == "Query"
             )
             assert query_type_introspection["kind"] == "OBJECT"
             del query_type_introspection["kind"]
 
-            with raises(
+            with pytest.raises(
                 TypeError,
                 match=r"^Invalid or incomplete introspection result\."
                 " Ensure that a full introspection query is used"
                 r" in order to build a client schema: {'name': 'Query', .*}\.$",
             ):
                 build_client_schema(introspection)
 
@@ -752,15 +751,15 @@
                     if type_["name"] == "Query"
                 ),
             )
 
             assert query_type_introspection["interfaces"] == []
             del query_type_introspection["interfaces"]  # type: ignore
 
-            with raises(
+            with pytest.raises(
                 TypeError,
                 match="^Query interfaces cannot be resolved."
                 " Introspection result missing interfaces:"
                 r" {'kind': 'OBJECT', 'name': 'Query', .*}\.$",
             ):
                 build_client_schema(introspection)
 
@@ -791,15 +790,15 @@
                     if type_["name"] == "Query"
                 ),
             )
 
             assert query_type_introspection["fields"]
             del query_type_introspection["fields"]  # type: ignore
 
-            with raises(
+            with pytest.raises(
                 TypeError,
                 match="^Query fields cannot be resolved."
                 " Introspection result missing fields:"
                 r" {'kind': 'OBJECT', 'name': 'Query', .*}\.$",
             ):
                 build_client_schema(introspection)
 
@@ -814,15 +813,15 @@
                 ),
             )
 
             field = query_type_introspection["fields"][0]
             assert field["args"]
             del field["args"]  # type: ignore
 
-            with raises(
+            with pytest.raises(
                 TypeError,
                 match="^Query fields cannot be resolved."
                 r" Introspection result missing field args: {'name': 'foo', .*}\.$",
             ):
                 build_client_schema(introspection)
 
         def throws_when_output_type_is_used_as_an_arg_type():
@@ -836,15 +835,15 @@
                 ),
             )
 
             arg = query_type_introspection["fields"][0]["args"][0]
             assert arg["type"]["name"] == "String"
             arg["type"]["name"] = "SomeUnion"
 
-            with raises(TypeError) as exc_info:
+            with pytest.raises(TypeError) as exc_info:
                 build_client_schema(introspection)
 
             assert str(exc_info.value).startswith(
                 "Query fields cannot be resolved."
                 " Introspection must provide input type for arguments,"
                 " but received: SomeUnion."
             )
@@ -860,15 +859,15 @@
                 ),
             )
 
             input_field = input_object_type_introspection["inputFields"][0]
             assert input_field["type"]["name"] == "String"
             input_field["type"]["name"] = "SomeUnion"
 
-            with raises(TypeError) as exc_info:
+            with pytest.raises(TypeError) as exc_info:
                 build_client_schema(introspection)
 
             assert str(exc_info.value).startswith(
                 "SomeInputObject fields cannot be resolved."
                 " Introspection must provide input type for input fields,"
                 " but received: SomeUnion."
             )
@@ -884,15 +883,15 @@
                 ),
             )
 
             field = query_type_introspection["fields"][0]
             assert field["type"]["name"] == "String"
             field["type"]["name"] = "SomeInputObject"
 
-            with raises(TypeError) as exc_info:
+            with pytest.raises(TypeError) as exc_info:
                 build_client_schema(introspection)
 
             assert str(exc_info.value).startswith(
                 "Query fields cannot be resolved."
                 " Introspection must provide output type for fields,"
                 " but received: SomeInputObject."
             )
@@ -907,15 +906,15 @@
                     if type_["name"] == "SomeUnion"
                 ),
             )
 
             assert some_union_introspection["possibleTypes"]
             del some_union_introspection["possibleTypes"]  # type: ignore
 
-            with raises(
+            with pytest.raises(
                 TypeError,
                 match="^Introspection result missing possibleTypes:"
                 r" {'kind': 'UNION', 'name': 'SomeUnion', .*}\.$",
             ):
                 build_client_schema(introspection)
 
         def throws_when_missing_enum_values():
@@ -928,15 +927,15 @@
                     if type_["name"] == "SomeEnum"
                 ),
             )
 
             assert some_enum_introspection["enumValues"]
             del some_enum_introspection["enumValues"]  # type: ignore
 
-            with raises(
+            with pytest.raises(
                 TypeError,
                 match="^Introspection result missing enumValues:"
                 r" {'kind': 'ENUM', 'name': 'SomeEnum', .*}\.$",
             ):
                 build_client_schema(introspection)
 
         def throws_when_missing_input_fields():
@@ -949,45 +948,45 @@
                     if type_["name"] == "SomeInputObject"
                 ),
             )
 
             assert some_input_object_introspection["inputFields"]
             del some_input_object_introspection["inputFields"]  # type: ignore
 
-            with raises(
+            with pytest.raises(
                 TypeError,
                 match="^Introspection result missing inputFields:"
                 r" {'kind': 'INPUT_OBJECT', 'name': 'SomeInputObject', .*}\.$",
             ):
                 build_client_schema(introspection)
 
         def throws_when_missing_directive_locations():
             introspection = introspection_from_schema(dummy_schema)
             some_directive_introspection = introspection["__schema"]["directives"][0]
 
             assert some_directive_introspection["name"] == "SomeDirective"
             assert some_directive_introspection["locations"] == ["QUERY"]
             del some_directive_introspection["locations"]  # type: ignore
 
-            with raises(
+            with pytest.raises(
                 TypeError,
                 match="^Introspection result missing directive locations:"
                 r" {'name': 'SomeDirective', .*}\.$",
             ):
                 build_client_schema(introspection)
 
         def throws_when_missing_directive_args():
             introspection = introspection_from_schema(dummy_schema)
             some_directive_introspection = introspection["__schema"]["directives"][0]
 
             assert some_directive_introspection["name"] == "SomeDirective"
             assert some_directive_introspection["args"] == []
             del some_directive_introspection["args"]  # type: ignore
 
-            with raises(
+            with pytest.raises(
                 TypeError,
                 match="^Introspection result missing directive args:"
                 r" {'name': 'SomeDirective', .*}\.$",
             ):
                 build_client_schema(introspection)
 
     def describe_very_deep_decorators_are_not_supported():
@@ -998,15 +997,15 @@
                   foo: [[[[[[[[String]]]]]]]]
                 }
                 """
             )
 
             introspection = introspection_from_schema(schema)
 
-            with raises(TypeError) as exc_info:
+            with pytest.raises(TypeError) as exc_info:
                 build_client_schema(introspection)
 
             assert str(exc_info.value) == (
                 "Query fields cannot be resolved."
                 " Decorated type deeper than introspection query."
             )
 
@@ -1017,15 +1016,15 @@
                   foo: [[[[String!]!]!]!]
                 }
                 """
             )
 
             introspection = introspection_from_schema(schema)
 
-            with raises(TypeError) as exc_info:
+            with pytest.raises(TypeError) as exc_info:
                 build_client_schema(introspection)
 
             assert str(exc_info.value) == (
                 "Query fields cannot be resolved."
                 " Decorated type deeper than introspection query."
             )
 
@@ -1065,15 +1064,15 @@
 
             assert foo_introspection["interfaces"] == []
             # we need to patch here since invalid interfaces cannot be built with Python
             foo_introspection["interfaces"] = [
                 {"kind": "OBJECT", "name": "Foo", "ofType": None}
             ]
 
-            with raises(TypeError) as exc_info:
+            with pytest.raises(TypeError) as exc_info:
                 build_client_schema(introspection)
             assert str(exc_info.value) == (
                 "Foo interfaces cannot be resolved."
                 " Expected Foo to be a GraphQL Interface type."
             )
 
         def recursive_union():
@@ -1095,13 +1094,13 @@
             assert foo_introspection["kind"] == "UNION"
             assert foo_introspection["possibleTypes"] == []
             # we need to patch here since invalid unions cannot be built with Python
             foo_introspection["possibleTypes"] = [
                 {"kind": "UNION", "name": "Foo", "ofType": None}
             ]
 
-            with raises(TypeError) as exc_info:
+            with pytest.raises(TypeError) as exc_info:
                 build_client_schema(introspection)
             assert str(exc_info.value) == (
                 "Foo types cannot be resolved."
                 " Expected Foo to be a GraphQL Object type."
             )
```

### Comparing `graphql_core-3.3.0a3/tests/utilities/test_coerce_input_value.py` & `graphql_core-3.3.0a4/tests/utilities/test_coerce_input_value.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,12 +1,11 @@
 from math import nan
 from typing import Any, List, NamedTuple, Union
 
-from pytest import raises
-
+import pytest
 from graphql.error import GraphQLError
 from graphql.pyutils import Undefined
 from graphql.type import (
     GraphQLEnumType,
     GraphQLFloat,
     GraphQLInputField,
     GraphQLInputObjectType,
@@ -358,22 +357,22 @@
 
         def returns_nested_null_for_nested_null_values():
             result = _coerce_value([42, [None], None], TestNestedList)
             assert expect_value(result) == [[42], [None], None]
 
     def describe_with_default_on_error():
         def throw_error_without_path():
-            with raises(GraphQLError) as exc_info:
+            with pytest.raises(GraphQLError) as exc_info:
                 assert coerce_input_value(None, GraphQLNonNull(GraphQLInt))
             assert exc_info.value.message == (
                 "Invalid value None: Expected non-nullable type 'Int!' not to be None."
             )
 
         def throw_error_with_path():
-            with raises(GraphQLError) as exc_info:
+            with pytest.raises(GraphQLError) as exc_info:
                 assert coerce_input_value(
                     [None], GraphQLList(GraphQLNonNull(GraphQLInt))
                 )
             assert exc_info.value.message == (
                 "Invalid value None at 'value[0]':"
                 " Expected non-nullable type 'Int!' not to be None."
             )
```

### Comparing `graphql_core-3.3.0a3/tests/utilities/test_concat_ast.py` & `graphql_core-3.3.0a4/tests/utilities/test_concat_ast.py`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/tests/utilities/test_extend_schema.py` & `graphql_core-3.3.0a4/tests/utilities/test_extend_schema.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,11 +1,10 @@
 from typing import Union
 
-from pytest import raises
-
+import pytest
 from graphql import graphql_sync
 from graphql.language import parse, print_ast
 from graphql.type import (
     GraphQLArgument,
     GraphQLBoolean,
     GraphQLEnumValue,
     GraphQLField,
@@ -26,15 +25,14 @@
     specified_directives,
     validate_schema,
 )
 from graphql.utilities import build_schema, concat_ast, extend_schema, print_schema
 
 from ..utils import dedent
 
-
 try:
     from typing import TypeAlias
 except ImportError:  # Python < 3.10
     from typing_extensions import TypeAlias
 
 
 TypeWithAstNode: TypeAlias = Union[
@@ -49,20 +47,22 @@
 TypeWithExtensionAstNodes: TypeAlias = Union[
     GraphQLNamedType,
     GraphQLSchema,
 ]
 
 
 def expect_extension_ast_nodes(obj: TypeWithExtensionAstNodes, expected: str) -> None:
-    assert obj is not None and obj.extension_ast_nodes is not None
+    assert obj is not None
+    assert obj.extension_ast_nodes is not None
     assert "\n\n".join(print_ast(node) for node in obj.extension_ast_nodes) == expected
 
 
 def expect_ast_node(obj: TypeWithAstNode, expected: str) -> None:
-    assert obj is not None and obj.ast_node is not None
+    assert obj is not None
+    assert obj.ast_node is not None
     assert print_ast(obj.ast_node) == expected
 
 
 def expect_schema_changes(
     schema: GraphQLSchema, extended_schema: GraphQLSchema, expected: str
 ) -> None:
     schema_definitions = {
@@ -131,14 +131,24 @@
         assert extended_schema.get_type("Float") is GraphQLFloat
         assert extended_schema.get_type("String") is GraphQLString
         assert extended_schema.get_type("Boolean") is GraphQLBoolean
         assert extended_schema.get_type("ID") is GraphQLID
 
         assert extended_schema.directives == specified_directives
 
+    def preserves_original_schema_config():
+        description = "A schema description"
+        extensions = {"foo": "bar"}
+        schema = GraphQLSchema(description=description, extensions=extensions)
+
+        extended_schema = extend_schema(schema, parse("scalar Bar"))
+
+        assert extended_schema.description == description
+        assert extended_schema.extensions is extensions
+
     def extends_objects_by_adding_new_fields():
         schema = build_schema(
             '''
             type Query {
               someObject: SomeObject
             }
 
@@ -1311,15 +1321,15 @@
         assert validate_schema(extended_schema) == []
         expect_schema_changes(schema, extended_schema, extension_sdl)
 
     def rejects_invalid_sdl():
         schema = GraphQLSchema()
         extend_ast = parse("extend schema @unknown")
 
-        with raises(TypeError) as exc_info:
+        with pytest.raises(TypeError) as exc_info:
             extend_schema(schema, extend_ast)
         assert str(exc_info.value) == "Unknown directive '@unknown'."
 
     def allows_to_disable_sdl_validation():
         schema = GraphQLSchema()
         extend_ast = parse("extend schema @unknown")
 
@@ -1331,27 +1341,27 @@
         ast = parse(
             """
             type Query {
               unknown: UnknownType
             }
             """
         )
-        with raises(TypeError) as exc_info:
+        with pytest.raises(TypeError) as exc_info:
             extend_schema(schema, ast, assume_valid_sdl=True)
         assert str(exc_info.value).endswith("Unknown type: 'UnknownType'.")
 
     def does_not_allow_replacing_a_default_directive():
         schema = GraphQLSchema()
         extend_ast = parse(
             """
             directive @include(if: Boolean!) on FIELD | FRAGMENT_SPREAD
             """
         )
 
-        with raises(TypeError) as exc_info:
+        with pytest.raises(TypeError) as exc_info:
             extend_schema(schema, extend_ast)
         assert str(exc_info.value).startswith(
             "Directive '@include' already exists in the schema."
             " It cannot be redefined."
         )
 
     def does_not_allow_replacing_an_existing_enum_value():
@@ -1366,15 +1376,15 @@
             """
             extend enum SomeEnum {
               ONE
             }
             """
         )
 
-        with raises(TypeError) as exc_info:
+        with pytest.raises(TypeError) as exc_info:
             extend_schema(schema, extend_ast)
         assert str(exc_info.value).startswith(
             "Enum value 'SomeEnum.ONE' already exists in the schema."
             " It cannot also be defined in this type extension."
         )
 
     def describe_can_add_additional_root_operation_types():
```

### Comparing `graphql_core-3.3.0a3/tests/utilities/test_find_breaking_changes.py` & `graphql_core-3.3.0a4/tests/utilities/test_find_breaking_changes.py`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/tests/utilities/test_get_introspection_query.py` & `graphql_core-3.3.0a4/tests/utilities/test_get_introspection_query.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,15 +1,14 @@
 import re
 from typing import Pattern
 
 from graphql.language import parse
 from graphql.utilities import build_schema, get_introspection_query
 from graphql.validation import validate
 
-
 dummy_schema = build_schema(
     """
   type Query {
     dummy: String
   }
   """
 )
```

### Comparing `graphql_core-3.3.0a3/tests/utilities/test_get_operation_ast.py` & `graphql_core-3.3.0a4/tests/utilities/test_get_operation_ast.py`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/tests/utilities/test_introspection_from_schema.py` & `graphql_core-3.3.0a4/tests/utilities/test_introspection_from_schema.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,13 +1,12 @@
 import pickle
 import sys
 from copy import deepcopy
 
-from pytest import mark
-
+import pytest
 from graphql.type import GraphQLField, GraphQLObjectType, GraphQLSchema, GraphQLString
 from graphql.utilities import (
     IntrospectionQuery,
     build_client_schema,
     build_schema,
     introspection_from_schema,
     print_schema,
@@ -102,28 +101,28 @@
             # pickle and unpickle the schema
             loaded = pickle.loads(pickle.dumps(schema))
             # create a deepcopy of the unpickled schema
             copied = deepcopy(loaded)
             # check that introspecting the copied schema gives the same result
             assert introspection_from_schema(copied) == introspected_schema
 
-    @mark.slow
+    @pytest.mark.slow()
     def describe_deepcopy_and_pickle_big():  # pragma: no cover
-        @mark.timeout(20)
+        @pytest.mark.timeout(20)
         def can_deep_copy_big_schema(big_schema_sdl):  # noqa: F811
             # introspect the original big schema
             big_schema = build_schema(big_schema_sdl)
             expected_introspection = introspection_from_schema(big_schema)
 
             # create a deepcopy of the schema
             copied = deepcopy(big_schema)
             # check that introspecting the copied schema gives the same result
             assert introspection_from_schema(copied) == expected_introspection
 
-        @mark.timeout(60)
+        @pytest.mark.timeout(60)
         def can_pickle_and_unpickle_big_schema(big_schema_sdl):  # noqa: F811
             # introspect the original big schema
             big_schema = build_schema(big_schema_sdl)
             expected_introspection = introspection_from_schema(big_schema)
             size_introspection = len(str(expected_introspection))
 
             limit = sys.getrecursionlimit()
@@ -149,15 +148,15 @@
 
                 # check that introspecting the re-pickled schema gives the same result
                 assert introspection_from_schema(loaded) == expected_introspection
 
             finally:
                 sys.setrecursionlimit(limit)
 
-        @mark.timeout(60)
+        @pytest.mark.timeout(60)
         def can_deep_copy_pickled_big_schema(big_schema_sdl):  # noqa: F811
             # introspect the original big schema
             big_schema = build_schema(big_schema_sdl)
             expected_introspection = introspection_from_schema(big_schema)
 
             limit = sys.getrecursionlimit()
             sys.setrecursionlimit(max(limit, 4000))  # needed for pickle
```

### Comparing `graphql_core-3.3.0a3/tests/utilities/test_lexicographic_sort_schema.py` & `graphql_core-3.3.0a4/tests/utilities/test_lexicographic_sort_schema.py`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/tests/utilities/test_print_schema.py` & `graphql_core-3.3.0a4/tests/utilities/test_print_schema.py`

 * *Files 0% similar despite different names*

```diff
@@ -83,15 +83,15 @@
               singleField: [String]!
             }
             """
         )
 
     def prints_list_of_non_null_string_field():
         schema = build_single_field_schema(
-            GraphQLField((GraphQLList(GraphQLNonNull(GraphQLString))))
+            GraphQLField(GraphQLList(GraphQLNonNull(GraphQLString)))
         )
         assert expect_printed_schema(schema) == dedent(
             """
             type Query {
               singleField: [String!]
             }
             """
```

### Comparing `graphql_core-3.3.0a3/tests/utilities/test_separate_operations.py` & `graphql_core-3.3.0a4/tests/utilities/test_separate_operations.py`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/tests/utilities/test_sort_value_node.py` & `graphql_core-3.3.0a4/tests/utilities/test_sort_value_node.py`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/tests/utilities/test_strip_ignored_characters.py` & `graphql_core-3.3.0a4/tests/utilities/test_strip_ignored_characters.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,11 +1,10 @@
 from typing import Optional
 
-from pytest import raises
-
+import pytest
 from graphql.error import GraphQLSyntaxError
 from graphql.language import Lexer, Source, TokenKind, parse
 from graphql.utilities import strip_ignored_characters
 
 from ..fixtures import kitchen_sink_query, kitchen_sink_sdl  # noqa: F401
 from ..utils import dedent
 
@@ -85,15 +84,15 @@
             """
             )
         )
 
         assert strip_ignored_characters(source) == "{foo{bar}}"
 
     def report_document_with_invalid_token():
-        with raises(GraphQLSyntaxError) as exc_info:
+        with pytest.raises(GraphQLSyntaxError) as exc_info:
             strip_ignored_characters('{ foo(arg: "\n"')
 
         assert str(exc_info.value) == dedent(
             """
             Syntax Error: Unterminated string.
 
             GraphQL request:1:13
```

### Comparing `graphql_core-3.3.0a3/tests/utilities/test_strip_ignored_characters_fuzz.py` & `graphql_core-3.3.0a4/tests/utilities/test_strip_ignored_characters_fuzz.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,19 +1,17 @@
 from json import dumps
 from typing import Optional
 
-from pytest import mark
-
+import pytest
 from graphql.error import GraphQLSyntaxError
 from graphql.language import Lexer, Source, TokenKind
 from graphql.utilities import strip_ignored_characters
 
 from ..utils import dedent, gen_fuzz_strings
 
-
 ignored_tokens = [
     # UnicodeBOM
     "\uFEFF",  # Byte Order Mark (U+FEFF)
     # WhiteSpace
     "\t",  # Horizontal Tab (U+0009)
     " ",  # Space (U+0020)
     # LineTerminator
@@ -71,42 +69,42 @@
     lexer = Lexer(Source(s))
     value = lexer.advance().value
     assert lexer.advance().kind == TokenKind.EOF, "Expected EOF"
     return value
 
 
 def describe_strip_ignored_characters():
-    @mark.slow
-    @mark.timeout(10)
+    @pytest.mark.slow()
+    @pytest.mark.timeout(10)
     def strips_documents_with_random_combination_of_ignored_characters():
         for ignored in ignored_tokens:
             ExpectStripped(ignored).to_equal("")
 
             for another_ignored in ignored_tokens:
                 ExpectStripped(ignored + another_ignored).to_equal("")
 
         ExpectStripped("".join(ignored_tokens)).to_equal("")
 
-    @mark.slow
-    @mark.timeout(10)
+    @pytest.mark.slow()
+    @pytest.mark.timeout(10)
     def strips_random_leading_and_trailing_ignored_tokens():
         for token in punctuator_tokens + non_punctuator_tokens:
             for ignored in ignored_tokens:
                 ExpectStripped(ignored + token).to_equal(token)
                 ExpectStripped(token + ignored).to_equal(token)
 
                 for another_ignored in ignored_tokens:
                     ExpectStripped(token + ignored + ignored).to_equal(token)
                     ExpectStripped(ignored + another_ignored + token).to_equal(token)
 
             ExpectStripped("".join(ignored_tokens) + token).to_equal(token)
             ExpectStripped(token + "".join(ignored_tokens)).to_equal(token)
 
-    @mark.slow
-    @mark.timeout(10)
+    @pytest.mark.slow()
+    @pytest.mark.timeout(10)
     def strips_random_ignored_tokens_between_punctuator_tokens():
         for left in punctuator_tokens:
             for right in punctuator_tokens:
                 for ignored in ignored_tokens:
                     ExpectStripped(left + ignored + right).to_equal(left + right)
 
                     for another_ignored in ignored_tokens:
@@ -114,16 +112,16 @@
                             left + ignored + another_ignored + right
                         ).to_equal(left + right)
 
                 ExpectStripped(left + "".join(ignored_tokens) + right).to_equal(
                     left + right
                 )
 
-    @mark.slow
-    @mark.timeout(10)
+    @pytest.mark.slow()
+    @pytest.mark.timeout(10)
     def strips_random_ignored_tokens_between_punctuator_and_non_punctuator_tokens():
         for non_punctuator in non_punctuator_tokens:
             for punctuator in punctuator_tokens:
                 for ignored in ignored_tokens:
                     ExpectStripped(punctuator + ignored + non_punctuator).to_equal(
                         punctuator + non_punctuator
                     )
@@ -133,16 +131,16 @@
                             punctuator + ignored + another_ignored + non_punctuator
                         ).to_equal(punctuator + non_punctuator)
 
                 ExpectStripped(
                     punctuator + "".join(ignored_tokens) + non_punctuator
                 ).to_equal(punctuator + non_punctuator)
 
-    @mark.slow
-    @mark.timeout(10)
+    @pytest.mark.slow()
+    @pytest.mark.timeout(10)
     def strips_random_ignored_tokens_between_non_punctuator_and_punctuator_tokens():
         for non_punctuator in non_punctuator_tokens:
             for punctuator in punctuator_tokens:
                 # Special case for that is handled in the below test
                 if punctuator == "...":
                     continue
 
@@ -156,16 +154,16 @@
                             non_punctuator + ignored + another_ignored + punctuator
                         ).to_equal(non_punctuator + punctuator)
 
                 ExpectStripped(
                     non_punctuator + "".join(ignored_tokens) + punctuator
                 ).to_equal(non_punctuator + punctuator)
 
-    @mark.slow
-    @mark.timeout(10)
+    @pytest.mark.slow()
+    @pytest.mark.timeout(10)
     def replace_random_ignored_tokens_between_non_punctuator_and_spread_with_space():
         for non_punctuator in non_punctuator_tokens:
             for ignored in ignored_tokens:
                 ExpectStripped(non_punctuator + ignored + "...").to_equal(
                     non_punctuator + " ..."
                 )
 
@@ -174,16 +172,16 @@
                         non_punctuator + ignored + another_ignored + " ..."
                     ).to_equal(non_punctuator + " ...")
 
             ExpectStripped(non_punctuator + "".join(ignored_tokens) + "...").to_equal(
                 non_punctuator + " ..."
             )
 
-    @mark.slow
-    @mark.timeout(10)
+    @pytest.mark.slow()
+    @pytest.mark.timeout(10)
     def replace_random_ignored_tokens_between_non_punctuator_tokens_with_space():
         for left in non_punctuator_tokens:
             for right in non_punctuator_tokens:
                 for ignored in ignored_tokens:
                     ExpectStripped(left + ignored + right).to_equal(left + " " + right)
 
                     for another_ignored in ignored_tokens:
@@ -191,27 +189,27 @@
                             left + ignored + another_ignored + right
                         ).to_equal(left + " " + right)
 
                 ExpectStripped(left + "".join(ignored_tokens) + right).to_equal(
                     left + " " + right
                 )
 
-    @mark.slow
-    @mark.timeout(10)
+    @pytest.mark.slow()
+    @pytest.mark.timeout(10)
     def does_not_strip_random_ignored_tokens_embedded_in_the_string():
         for ignored in ignored_tokens:
             ExpectStripped(dumps(ignored)).to_stay_the_same()
 
             for another_ignored in ignored_tokens:
                 ExpectStripped(dumps(ignored + another_ignored)).to_stay_the_same()
 
         ExpectStripped(dumps("".join(ignored_tokens))).to_stay_the_same()
 
-    @mark.slow
-    @mark.timeout(10)
+    @pytest.mark.slow()
+    @pytest.mark.timeout(10)
     def does_not_strip_random_ignored_tokens_embedded_in_the_block_string():
         ignored_tokens_without_formatting = [
             token
             for token in ignored_tokens
             if token not in ["\n", "\r", "\r\n", "\t", " "]
         ]
 
@@ -223,16 +221,16 @@
                     '"""|' + ignored + another_ignored + '|"""'
                 ).to_stay_the_same()
 
         ExpectStripped(
             '"""|' + "".join(ignored_tokens_without_formatting) + '|"""'
         ).to_stay_the_same()
 
-    @mark.slow
-    @mark.timeout(80)
+    @pytest.mark.slow()
+    @pytest.mark.timeout(80)
     def strips_ignored_characters_inside_random_block_strings():
         # Testing with length >7 is taking exponentially more time. However it is
         # highly recommended to test with increased limit if you make any change.
         for fuzz_str in gen_fuzz_strings(allowed_chars='\n\t "a\\', max_length=7):
             test_str = f'"""{fuzz_str}"""'
 
             try:
```

### Comparing `graphql_core-3.3.0a3/tests/utilities/test_type_comparators.py` & `graphql_core-3.3.0a4/tests/utilities/test_type_comparators.py`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/tests/utilities/test_type_from_ast.py` & `graphql_core-3.3.0a4/tests/utilities/test_type_from_ast.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,8 @@
-from pytest import raises
-
+import pytest
 from graphql.language import TypeNode, parse_type
 from graphql.type import GraphQLList, GraphQLNonNull, GraphQLObjectType
 from graphql.utilities import type_from_ast
 
 from ..validation.harness import test_schema
 
 
@@ -28,11 +27,11 @@
         assert isinstance(type_for_node, GraphQLNonNull)
         of_type = type_for_node.of_type
         assert isinstance(of_type, GraphQLObjectType)
         assert of_type.name == "Cat"
 
     def for_unspecified_type_node():
         node = TypeNode()
-        with raises(TypeError) as exc_info:
+        with pytest.raises(TypeError) as exc_info:
             type_from_ast(test_schema, node)
         msg = str(exc_info.value)
         assert msg == "Unexpected type node: <TypeNode instance>."
```

### Comparing `graphql_core-3.3.0a3/tests/utilities/test_type_info.py` & `graphql_core-3.3.0a4/tests/utilities/test_type_info.py`

 * *Files 1% similar despite different names*

```diff
@@ -20,15 +20,14 @@
     get_named_type,
     is_composite_type,
 )
 from graphql.utilities import TypeInfo, TypeInfoVisitor, build_schema
 
 from ..fixtures import kitchen_sink_query  # noqa: F401
 
-
 test_schema = build_schema(
     """
     interface Pet {
       name: String
     }
 
     type Dog implements Pet {
@@ -181,15 +180,15 @@
             """
         )
 
         visited_fields: List[Tuple[Optional[str], Optional[str]]] = []
 
         class TestVisitor(Visitor):
             @staticmethod
-            def enter_field(self, node: OperationDefinitionNode, *_args):
+            def enter_field(*_args):
                 parent_type = type_info.get_parent_type()
                 type_name = getattr(type_info.get_parent_type(), "name", None)
                 field_def = type_info.get_field_def()
                 fields = getattr(parent_type, "fields", {})
                 fields = dict(
                     **fields,
                     __type=TypeMetaFieldDef,
@@ -347,14 +346,16 @@
                         arguments=node.arguments,
                         directives=node.directives,
                         selection_set=SelectionSetNode(
                             selections=[FieldNode(name=NameNode(value="__typename"))]
                         ),
                     )
 
+                return None
+
             @staticmethod
             def leave(*args):
                 parent_type = type_info.get_parent_type()
                 type_ = type_info.get_type()
                 input_type = type_info.get_input_type()
                 node = args[0]
                 visited.append(
```

### Comparing `graphql_core-3.3.0a3/tests/utilities/test_value_from_ast.py` & `graphql_core-3.3.0a4/tests/utilities/test_value_from_ast.py`

 * *Files 1% similar despite different names*

```diff
@@ -108,23 +108,23 @@
         assert _value_from('"BLUE"', test_enum) is Undefined
         assert _value_from("null", test_enum) is None
         assert _value_from("NULL", test_enum) is None
         assert _value_from("NULL", GraphQLNonNull(test_enum)) is None
         assert isnan(_value_from("NAN", test_enum))
         assert _value_from("NO_CUSTOM_VALUE", test_enum) is Undefined
 
-    # Boolean!
+    # make a Boolean!
     non_null_bool = GraphQLNonNull(GraphQLBoolean)
-    # [Boolean]
+    # make a [Boolean]
     list_of_bool = GraphQLList(GraphQLBoolean)
-    # [Boolean!]
+    # make a [Boolean!]
     list_of_non_null_bool = GraphQLList(non_null_bool)
-    # [Boolean]!
+    # make a [Boolean]!
     non_null_list_of_bool = GraphQLNonNull(list_of_bool)
-    # [Boolean!]!
+    # make a [Boolean!]!
     non_null_list_of_non_mull_bool = GraphQLNonNull(list_of_non_null_bool)
 
     def coerces_to_null_unless_non_null():
         assert _value_from("null", GraphQLBoolean) is None
         assert _value_from("null", non_null_bool) is Undefined
 
     def coerces_lists_of_values():
```

### Comparing `graphql_core-3.3.0a3/tests/utilities/test_value_from_ast_untyped.py` & `graphql_core-3.3.0a4/tests/utilities/test_value_from_ast_untyped.py`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/tests/utils/assert_equal_awaitables_or_values.py` & `graphql_core-3.3.0a4/tests/utils/assert_equal_awaitables_or_values.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,14 @@
 import asyncio
 from typing import Awaitable, Tuple, TypeVar, cast
 
 from graphql.pyutils import is_awaitable
 
 from .assert_matching_values import assert_matching_values
 
-
 __all__ = ["assert_equal_awaitables_or_values"]
 
 T = TypeVar("T")
 
 
 def assert_equal_awaitables_or_values(*items: T) -> T:
     """Check whether the items are the same and either all awaitables or all values."""
```

### Comparing `graphql_core-3.3.0a3/tests/utils/test_assert_equal_awaitables_or_values.py` & `graphql_core-3.3.0a4/tests/utils/test_assert_equal_awaitables_or_values.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,54 +1,54 @@
-from pytest import mark, raises
+import pytest
 
 from . import assert_equal_awaitables_or_values
 
 
 def describe_assert_equal_awaitables_or_values():
     def throws_when_given_unequal_values():
-        with raises(AssertionError):
+        with pytest.raises(AssertionError):
             assert_equal_awaitables_or_values({}, {}, {"test": "test"})
 
     def does_not_throw_when_given_equal_values():
         test_value = {"test": "test"}
         assert (
             assert_equal_awaitables_or_values(test_value, test_value, test_value)
             == test_value
         )
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def does_not_throw_when_given_equal_awaitables():
         async def test_value():
             return {"test": "test"}
 
         assert (
             await assert_equal_awaitables_or_values(
                 test_value(), test_value(), test_value()
             )
             == await test_value()
         )
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def throws_when_given_unequal_awaitables():
         async def test_value(value):
             return value
 
-        with raises(AssertionError):
+        with pytest.raises(AssertionError):
             await assert_equal_awaitables_or_values(
                 test_value({}), test_value({}), test_value({"test": "test"})
             )
 
-    @mark.asyncio
+    @pytest.mark.asyncio()
     async def throws_when_given_mixture_of_equal_values_and_awaitables():
         async def test_value():
             return {"test": "test"}
 
         value1 = await test_value()
         value2 = test_value()
 
-        with raises(
+        with pytest.raises(
             AssertionError,
             match=r"Received an invalid mixture of promises and values\.",
         ):
             await assert_equal_awaitables_or_values(value1, value2)
 
         assert await value2 == value1
```

### Comparing `graphql_core-3.3.0a3/tests/utils/test_dedent.py` & `graphql_core-3.3.0a4/tests/utils/test_dedent.py`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/tests/utils/test_gen_fuzz_strings.py` & `graphql_core-3.3.0a4/tests/utils/test_gen_fuzz_strings.py`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/tests/validation/harness.py` & `graphql_core-3.3.0a4/tests/validation/harness.py`

 * *Files 0% similar despite different names*

```diff
@@ -3,15 +3,14 @@
 from graphql.error import GraphQLError
 from graphql.language import parse
 from graphql.type import GraphQLSchema
 from graphql.utilities import build_schema
 from graphql.validation import SDLValidationRule, ValidationRule
 from graphql.validation.validate import validate, validate_sdl
 
-
 __all__ = [
     "test_schema",
     "assert_validation_errors",
     "assert_sdl_validation_errors",
 ]
 
 test_schema = build_schema(
```

### Comparing `graphql_core-3.3.0a3/tests/validation/test_defer_stream_directive_label.py` & `graphql_core-3.3.0a4/tests/validation/test_defer_stream_directive_label.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,13 @@
 from functools import partial
 
 from graphql.validation import DeferStreamDirectiveLabel
 
 from .harness import assert_validation_errors
 
-
 assert_errors = partial(assert_validation_errors, DeferStreamDirectiveLabel)
 
 assert_valid = partial(assert_errors, errors=[])
 
 
 def describe_defer_stream_label():
     def defer_fragments_with_no_label():
```

### Comparing `graphql_core-3.3.0a3/tests/validation/test_defer_stream_directive_on_root_field.py` & `graphql_core-3.3.0a4/tests/validation/test_defer_stream_directive_on_root_field.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,15 +1,14 @@
 from functools import partial
 
 from graphql.utilities import build_schema
 from graphql.validation import DeferStreamDirectiveOnRootField
 
 from .harness import assert_validation_errors
 
-
 schema = build_schema(
     """
     type Message {
       body: String
       sender: String
     }
 
@@ -167,15 +166,15 @@
         )
 
     def defer_fragment_spread_on_nested_subscription_field():
         assert_valid(
             """
             subscription {
               subscriptionField {
-                ...nestedFragment
+                ...nestedFragment @defer
               }
             }
             fragment nestedFragment on Message {
               body
             }
             """
         )
```

### Comparing `graphql_core-3.3.0a3/tests/validation/test_executable_definitions.py` & `graphql_core-3.3.0a4/tests/validation/test_executable_definitions.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,14 +1,13 @@
 from functools import partial
 
 from graphql.validation import ExecutableDefinitionsRule
 
 from .harness import assert_validation_errors
 
-
 assert_errors = partial(assert_validation_errors, ExecutableDefinitionsRule)
 
 assert_valid = partial(assert_errors, errors=[])
 
 
 def describe_validate_executable_definitions():
     def with_only_operation():
```

### Comparing `graphql_core-3.3.0a3/tests/validation/test_fields_on_correct_type.py` & `graphql_core-3.3.0a4/tests/validation/test_fields_on_correct_type.py`

 * *Files 0% similar despite different names*

```diff
@@ -3,15 +3,14 @@
 from graphql.language import parse
 from graphql.type import GraphQLSchema
 from graphql.utilities import build_schema
 from graphql.validation import FieldsOnCorrectTypeRule, validate
 
 from .harness import assert_validation_errors
 
-
 test_schema = build_schema(
     """
     interface Pet {
       name: String
     }
 
     type Dog implements Pet {
```

### Comparing `graphql_core-3.3.0a3/tests/validation/test_fragments_on_composite_types.py` & `graphql_core-3.3.0a4/tests/validation/test_fragments_on_composite_types.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,14 +1,13 @@
 from functools import partial
 
 from graphql.validation import FragmentsOnCompositeTypesRule
 
 from .harness import assert_validation_errors
 
-
 assert_errors = partial(assert_validation_errors, FragmentsOnCompositeTypesRule)
 
 assert_valid = partial(assert_errors, errors=[])
 
 
 def describe_validate_fragments_on_composite_types():
     def object_is_valid_fragment_type():
```

### Comparing `graphql_core-3.3.0a3/tests/validation/test_known_argument_names.py` & `graphql_core-3.3.0a4/tests/validation/test_known_argument_names.py`

 * *Files 0% similar despite different names*

```diff
@@ -4,15 +4,14 @@
 from graphql.validation import KnownArgumentNamesRule
 from graphql.validation.rules.known_argument_names import (
     KnownArgumentNamesOnDirectivesRule,
 )
 
 from .harness import assert_sdl_validation_errors, assert_validation_errors
 
-
 assert_errors = partial(assert_validation_errors, KnownArgumentNamesRule)
 
 assert_valid = partial(assert_errors, errors=[])
 
 assert_sdl_errors = partial(
     assert_sdl_validation_errors, KnownArgumentNamesOnDirectivesRule
 )
```

### Comparing `graphql_core-3.3.0a3/tests/validation/test_known_directives.py` & `graphql_core-3.3.0a4/tests/validation/test_known_directives.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,15 +1,14 @@
 from functools import partial
 
 from graphql.utilities import build_schema
 from graphql.validation import KnownDirectivesRule
 
 from .harness import assert_sdl_validation_errors, assert_validation_errors
 
-
 schema_with_directives = build_schema(
     """
     type Query {
       dummy: String
     }
 
     directive @onQuery on QUERY
```

### Comparing `graphql_core-3.3.0a3/tests/validation/test_known_fragment_names.py` & `graphql_core-3.3.0a4/tests/validation/test_known_fragment_names.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,14 +1,13 @@
 from functools import partial
 
 from graphql.validation import KnownFragmentNamesRule
 
 from .harness import assert_validation_errors
 
-
 assert_errors = partial(assert_validation_errors, KnownFragmentNamesRule)
 
 assert_valid = partial(assert_errors, errors=[])
 
 
 def describe_validate_known_fragment_names():
     def known_fragment_names_are_valid():
```

### Comparing `graphql_core-3.3.0a3/tests/validation/test_known_type_names.py` & `graphql_core-3.3.0a4/tests/validation/test_known_type_names.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,15 +1,14 @@
 from functools import partial
 
 from graphql.utilities import build_schema
 from graphql.validation import KnownTypeNamesRule
 
 from .harness import assert_sdl_validation_errors, assert_validation_errors
 
-
 assert_errors = partial(assert_validation_errors, KnownTypeNamesRule)
 
 assert_valid = partial(assert_errors, errors=[])
 
 assert_sdl_errors = partial(assert_sdl_validation_errors, KnownTypeNamesRule)
 
 assert_sdl_valid = partial(assert_sdl_errors, errors=[])
```

### Comparing `graphql_core-3.3.0a3/tests/validation/test_lone_anonymous_operation.py` & `graphql_core-3.3.0a4/tests/validation/test_lone_anonymous_operation.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,14 +1,13 @@
 from functools import partial
 
 from graphql.validation import LoneAnonymousOperationRule
 
 from .harness import assert_validation_errors
 
-
 assert_errors = partial(assert_validation_errors, LoneAnonymousOperationRule)
 
 assert_valid = partial(assert_errors, errors=[])
 
 
 def describe_validate_anonymous_operation_must_be_alone():
     def no_operations():
```

### Comparing `graphql_core-3.3.0a3/tests/validation/test_lone_schema_definition.py` & `graphql_core-3.3.0a4/tests/validation/test_lone_schema_definition.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,15 +1,14 @@
 from functools import partial
 
 from graphql.utilities import build_schema
 from graphql.validation.rules.lone_schema_definition import LoneSchemaDefinitionRule
 
 from .harness import assert_sdl_validation_errors
 
-
 assert_sdl_errors = partial(assert_sdl_validation_errors, LoneSchemaDefinitionRule)
 
 assert_sdl_valid = partial(assert_sdl_errors, errors=[])
 
 
 def describe_validate_schema_definition_should_be_alone():
     def no_schema():
```

### Comparing `graphql_core-3.3.0a3/tests/validation/test_no_deprecated.py` & `graphql_core-3.3.0a4/tests/validation/test_no_deprecated.py`

 * *Files identical despite different names*

### Comparing `graphql_core-3.3.0a3/tests/validation/test_no_fragment_cycles.py` & `graphql_core-3.3.0a4/tests/validation/test_no_fragment_cycles.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,14 +1,13 @@
 from functools import partial
 
 from graphql.validation import NoFragmentCyclesRule
 
 from .harness import assert_validation_errors
 
-
 assert_errors = partial(assert_validation_errors, NoFragmentCyclesRule)
 
 assert_valid = partial(assert_errors, errors=[])
 
 
 def describe_validate_no_circular_fragment_spreads():
     def single_reference_is_valid():
```

### Comparing `graphql_core-3.3.0a3/tests/validation/test_no_schema_introspection.py` & `graphql_core-3.3.0a4/tests/validation/test_no_schema_introspection.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,15 +1,14 @@
 from functools import partial
 
 from graphql.utilities import build_schema
 from graphql.validation import NoSchemaIntrospectionCustomRule
 
 from .harness import assert_validation_errors
 
-
 schema = build_schema(
     """
     type Query {
       someQuery: SomeType
     }
 
     type SomeType {
```

### Comparing `graphql_core-3.3.0a3/tests/validation/test_no_undefined_variables.py` & `graphql_core-3.3.0a4/tests/validation/test_no_undefined_variables.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,14 +1,13 @@
 from functools import partial
 
 from graphql.validation import NoUndefinedVariablesRule
 
 from .harness import assert_validation_errors
 
-
 assert_errors = partial(assert_validation_errors, NoUndefinedVariablesRule)
 
 assert_valid = partial(assert_errors, errors=[])
 
 
 def describe_validate_no_undefined_variables():
     def all_variables_defined():
```

### Comparing `graphql_core-3.3.0a3/tests/validation/test_no_unused_fragments.py` & `graphql_core-3.3.0a4/tests/validation/test_no_unused_fragments.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,14 +1,13 @@
 from functools import partial
 
 from graphql.validation import NoUnusedFragmentsRule
 
 from .harness import assert_validation_errors
 
-
 assert_errors = partial(assert_validation_errors, NoUnusedFragmentsRule)
 
 assert_valid = partial(assert_errors, errors=[])
 
 
 def describe_validate_no_unused_fragments():
     def all_fragment_names_are_used():
```

### Comparing `graphql_core-3.3.0a3/tests/validation/test_no_unused_variables.py` & `graphql_core-3.3.0a4/tests/validation/test_no_unused_variables.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,14 +1,13 @@
 from functools import partial
 
 from graphql.validation import NoUnusedVariablesRule
 
 from .harness import assert_validation_errors
 
-
 assert_errors = partial(assert_validation_errors, NoUnusedVariablesRule)
 
 assert_valid = partial(assert_errors, errors=[])
 
 
 def describe_validate_no_unused_variables():
     def uses_all_variables():
```

### Comparing `graphql_core-3.3.0a3/tests/validation/test_overlapping_fields_can_be_merged.py` & `graphql_core-3.3.0a4/tests/validation/test_overlapping_fields_can_be_merged.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,15 +1,14 @@
 from functools import partial
 
 from graphql.utilities import build_schema
 from graphql.validation import OverlappingFieldsCanBeMergedRule
 
 from .harness import assert_validation_errors
 
-
 assert_errors = partial(assert_validation_errors, OverlappingFieldsCanBeMergedRule)
 
 assert_valid = partial(assert_errors, errors=[])
 
 
 def describe_validate_overlapping_fields_can_be_merged():
     def unique_fields():
@@ -160,14 +159,31 @@
             [
                 {
                     "message": "Fields 'name' conflict because they have differing"
                     " stream directives. Use different aliases on the fields"
                     " to fetch both if this was intentional.",
                     "locations": [(3, 15), (4, 15)],
                 }
+            ],
+        )
+
+    def different_stream_directive_extra_argument():
+        assert_errors(
+            """
+            fragment conflictingArgs on Dog {
+              name @stream(label: "streamLabel", initialCount: 1)
+              name @stream(label: "streamLabel", initialCount: 1, extraArg: true)
+            }""",
+            [
+                {
+                    "message": "Fields 'name' conflict because they have differing"
+                    " stream directives. Use different aliases on the fields"
+                    " to fetch both if this was intentional.",
+                    "locations": [(3, 15), (4, 15)],
+                }
             ],
         )
 
     def mix_of_stream_and_no_stream():
         assert_errors(
             """
             fragment conflictingArgs on Dog {
```

### Comparing `graphql_core-3.3.0a3/tests/validation/test_possible_fragment_spreads.py` & `graphql_core-3.3.0a4/tests/validation/test_possible_fragment_spreads.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,15 +1,14 @@
 from functools import partial
 
 from graphql.utilities import build_schema
 from graphql.validation import PossibleFragmentSpreadsRule
 
 from .harness import assert_validation_errors
 
-
 test_schema = build_schema(
     """
     interface Being {
       name: String
     }
 
     interface Pet implements Being {
```

### Comparing `graphql_core-3.3.0a3/tests/validation/test_possible_type_extensions.py` & `graphql_core-3.3.0a4/tests/validation/test_possible_type_extensions.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,14 @@
 from functools import partial
 
 from graphql.utilities import build_schema
 from graphql.validation.rules.possible_type_extensions import PossibleTypeExtensionsRule
 
 from .harness import assert_sdl_validation_errors
 
-
 assert_errors = partial(assert_sdl_validation_errors, PossibleTypeExtensionsRule)
 
 assert_valid = partial(assert_errors, errors=[])
 
 
 def describe_validate_possible_type_extensions():
     def no_extensions():
```

### Comparing `graphql_core-3.3.0a3/tests/validation/test_provided_required_arguments.py` & `graphql_core-3.3.0a4/tests/validation/test_provided_required_arguments.py`

 * *Files 0% similar despite different names*

```diff
@@ -4,15 +4,14 @@
 from graphql.validation import ProvidedRequiredArgumentsRule
 from graphql.validation.rules.provided_required_arguments import (
     ProvidedRequiredArgumentsOnDirectivesRule,
 )
 
 from .harness import assert_sdl_validation_errors, assert_validation_errors
 
-
 assert_errors = partial(assert_validation_errors, ProvidedRequiredArgumentsRule)
 
 assert_valid = partial(assert_errors, errors=[])
 
 assert_sdl_errors = partial(
     assert_sdl_validation_errors, ProvidedRequiredArgumentsOnDirectivesRule
 )
```

### Comparing `graphql_core-3.3.0a3/tests/validation/test_scalar_leafs.py` & `graphql_core-3.3.0a4/tests/validation/test_scalar_leafs.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,14 +1,13 @@
 from functools import partial
 
 from graphql.validation import ScalarLeafsRule
 
 from .harness import assert_validation_errors
 
-
 assert_errors = partial(assert_validation_errors, ScalarLeafsRule)
 
 assert_valid = partial(assert_errors, errors=[])
 
 
 def describe_validate_scalar_leafs():
     def valid_scalar_selection():
```

### Comparing `graphql_core-3.3.0a3/tests/validation/test_single_field_subscriptions.py` & `graphql_core-3.3.0a4/tests/validation/test_single_field_subscriptions.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,14 @@
 from functools import partial
 
 from graphql.utilities import build_schema
 from graphql.validation import SingleFieldSubscriptionsRule
 
 from .harness import assert_validation_errors
 
-
 schema = build_schema(
     """
     type Message {
       body: String
       sender: String
     }
```

### Comparing `graphql_core-3.3.0a3/tests/validation/test_stream_directive_on_list_field.py` & `graphql_core-3.3.0a4/tests/validation/test_stream_directive_on_list_field.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,14 +1,13 @@
 from functools import partial
 
 from graphql.validation import StreamDirectiveOnListField
 
 from .harness import assert_validation_errors
 
-
 assert_errors = partial(assert_validation_errors, StreamDirectiveOnListField)
 
 assert_valid = partial(assert_errors, errors=[])
 
 
 def describe_stream_directive_on_list_field():
     def stream_on_list_field():
```

### Comparing `graphql_core-3.3.0a3/tests/validation/test_unique_argument_definition_names.py` & `graphql_core-3.3.0a4/tests/validation/test_unique_argument_definition_names.py`

 * *Files 0% similar despite different names*

```diff
@@ -2,15 +2,14 @@
 
 from graphql.validation.rules.unique_argument_definition_names import (
     UniqueArgumentDefinitionNamesRule,
 )
 
 from .harness import assert_sdl_validation_errors
 
-
 assert_sdl_errors = partial(
     assert_sdl_validation_errors, UniqueArgumentDefinitionNamesRule
 )
 
 assert_sdl_valid = partial(assert_sdl_errors, errors=[])
```

### Comparing `graphql_core-3.3.0a3/tests/validation/test_unique_argument_names.py` & `graphql_core-3.3.0a4/tests/validation/test_unique_argument_names.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,14 +1,13 @@
 from functools import partial
 
 from graphql.validation import UniqueArgumentNamesRule
 
 from .harness import assert_validation_errors
 
-
 assert_errors = partial(assert_validation_errors, UniqueArgumentNamesRule)
 
 assert_valid = partial(assert_errors, errors=[])
 
 
 def describe_validate_unique_argument_names():
     def no_arguments_on_field():
```

### Comparing `graphql_core-3.3.0a3/tests/validation/test_unique_directive_names.py` & `graphql_core-3.3.0a4/tests/validation/test_unique_directive_names.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,15 +1,14 @@
 from functools import partial
 
 from graphql.utilities import build_schema
 from graphql.validation.rules.unique_directive_names import UniqueDirectiveNamesRule
 
 from .harness import assert_sdl_validation_errors
 
-
 assert_errors = partial(assert_sdl_validation_errors, UniqueDirectiveNamesRule)
 
 assert_valid = partial(assert_errors, errors=[])
 
 
 def describe_validate_unique_directive_names():
     def no_directive():
```

### Comparing `graphql_core-3.3.0a3/tests/validation/test_unique_directives_per_location.py` & `graphql_core-3.3.0a4/tests/validation/test_unique_directives_per_location.py`

 * *Files 0% similar despite different names*

```diff
@@ -2,15 +2,14 @@
 
 from graphql.language import parse
 from graphql.utilities import extend_schema
 from graphql.validation import UniqueDirectivesPerLocationRule
 
 from .harness import assert_sdl_validation_errors, assert_validation_errors, test_schema
 
-
 extension_sdl = """
   directive @directive on FIELD | FRAGMENT_DEFINITION
   directive @directiveA on FIELD | FRAGMENT_DEFINITION
   directive @directiveB on FIELD | FRAGMENT_DEFINITION
   directive @repeatable repeatable on FIELD | FRAGMENT_DEFINITION
 """
 schema_with_directives = extend_schema(test_schema, parse(extension_sdl))
```

### Comparing `graphql_core-3.3.0a3/tests/validation/test_unique_enum_value_names.py` & `graphql_core-3.3.0a4/tests/validation/test_unique_enum_value_names.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,15 +1,14 @@
 from functools import partial
 
 from graphql.utilities import build_schema
 from graphql.validation.rules.unique_enum_value_names import UniqueEnumValueNamesRule
 
 from .harness import assert_sdl_validation_errors
 
-
 assert_errors = partial(assert_sdl_validation_errors, UniqueEnumValueNamesRule)
 
 assert_valid = partial(assert_errors, errors=[])
 
 
 def describe_validate_unique_field_definition_names():
     def no_values():
```

### Comparing `graphql_core-3.3.0a3/tests/validation/test_unique_field_definition_names.py` & `graphql_core-3.3.0a4/tests/validation/test_unique_field_definition_names.py`

 * *Files 0% similar despite different names*

```diff
@@ -3,15 +3,14 @@
 from graphql.utilities import build_schema
 from graphql.validation.rules.unique_field_definition_names import (
     UniqueFieldDefinitionNamesRule,
 )
 
 from .harness import assert_sdl_validation_errors
 
-
 assert_errors = partial(assert_sdl_validation_errors, UniqueFieldDefinitionNamesRule)
 
 assert_valid = partial(assert_errors, errors=[])
 
 
 def describe_validate_unique_field_definition_names():
     def no_fields():
```

### Comparing `graphql_core-3.3.0a3/tests/validation/test_unique_fragment_names.py` & `graphql_core-3.3.0a4/tests/validation/test_unique_fragment_names.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,14 +1,13 @@
 from functools import partial
 
 from graphql.validation import UniqueFragmentNamesRule
 
 from .harness import assert_validation_errors
 
-
 assert_errors = partial(assert_validation_errors, UniqueFragmentNamesRule)
 
 assert_valid = partial(assert_errors, errors=[])
 
 
 def describe_validate_unique_fragment_names():
     def no_fragments():
```

### Comparing `graphql_core-3.3.0a3/tests/validation/test_unique_input_field_names.py` & `graphql_core-3.3.0a4/tests/validation/test_unique_input_field_names.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,14 +1,13 @@
 from functools import partial
 
 from graphql.validation import UniqueInputFieldNamesRule
 
 from .harness import assert_validation_errors
 
-
 assert_errors = partial(assert_validation_errors, UniqueInputFieldNamesRule)
 
 assert_valid = partial(assert_errors, errors=[])
 
 
 def describe_validate_unique_input_field_names():
     def input_object_with_fields():
```

### Comparing `graphql_core-3.3.0a3/tests/validation/test_unique_operation_names.py` & `graphql_core-3.3.0a4/tests/validation/test_unique_operation_names.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,14 +1,13 @@
 from functools import partial
 
 from graphql.validation import UniqueOperationNamesRule
 
 from .harness import assert_validation_errors
 
-
 assert_errors = partial(assert_validation_errors, UniqueOperationNamesRule)
 
 assert_valid = partial(assert_errors, errors=[])
 
 
 def describe_validate_unique_operation_names():
     def no_operations():
```

### Comparing `graphql_core-3.3.0a3/tests/validation/test_unique_operation_types.py` & `graphql_core-3.3.0a4/tests/validation/test_unique_operation_types.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,15 +1,14 @@
 from functools import partial
 
 from graphql.utilities import build_schema
 from graphql.validation.rules.unique_operation_types import UniqueOperationTypesRule
 
 from .harness import assert_sdl_validation_errors
 
-
 assert_errors = partial(assert_sdl_validation_errors, UniqueOperationTypesRule)
 
 assert_valid = partial(assert_errors, errors=[])
 
 
 def describe_validate_unique_operation_types():
     def no_schema_definition():
```

### Comparing `graphql_core-3.3.0a3/tests/validation/test_unique_type_names.py` & `graphql_core-3.3.0a4/tests/validation/test_unique_type_names.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,15 +1,14 @@
 from functools import partial
 
 from graphql.utilities import build_schema
 from graphql.validation.rules.unique_type_names import UniqueTypeNamesRule
 
 from .harness import assert_sdl_validation_errors
 
-
 assert_errors = partial(assert_sdl_validation_errors, UniqueTypeNamesRule)
 
 assert_valid = partial(assert_errors, errors=[])
 
 
 def describe_validate_unique_type_names():
     def no_types():
```

### Comparing `graphql_core-3.3.0a3/tests/validation/test_unique_variable_names.py` & `graphql_core-3.3.0a4/tests/validation/test_unique_variable_names.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,14 +1,13 @@
 from functools import partial
 
 from graphql.validation import UniqueVariableNamesRule
 
 from .harness import assert_validation_errors
 
-
 assert_errors = partial(assert_validation_errors, UniqueVariableNamesRule)
 
 assert_valid = partial(assert_errors, errors=[])
 
 
 def describe_validate_unique_variable_names():
     def unique_variable_names():
```

### Comparing `graphql_core-3.3.0a3/tests/validation/test_validation.py` & `graphql_core-3.3.0a4/tests/validation/test_validation.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,8 @@
-from pytest import raises
-
+import pytest
 from graphql.error import GraphQLError
 from graphql.language import parse
 from graphql.utilities import TypeInfo, build_schema
 from graphql.validation import ValidationRule, validate
 
 from .harness import test_schema
 
@@ -42,15 +41,15 @@
         errors = validate(test_schema, doc)
         assert errors == [
             {"message": "Cannot query field 'unknown' on type 'QueryRoot'."}
         ]
 
     def deprecated_validates_using_a_custom_type_info():
         # This TypeInfo will never return a valid field.
-        type_info = TypeInfo(test_schema, None, lambda *args: None)
+        type_info = TypeInfo(test_schema, None, lambda *_args: None)
 
         doc = parse(
             """
             query {
               human {
                 pets {
                   ... on Cat {
@@ -160,9 +159,9 @@
         }
 
     def pass_through_exceptions_from_rules():
         class CustomRule(ValidationRule):
             def enter_field(self, *_args):
                 raise RuntimeError("Error from custom rule!")
 
-        with raises(RuntimeError, match="^Error from custom rule!$"):
+        with pytest.raises(RuntimeError, match="^Error from custom rule!$"):
             validate(test_schema, doc, [CustomRule], max_errors=1)
```

### Comparing `graphql_core-3.3.0a3/tests/validation/test_values_of_correct_type.py` & `graphql_core-3.3.0a4/tests/validation/test_values_of_correct_type.py`

 * *Files 0% similar despite different names*

```diff
@@ -9,15 +9,14 @@
     GraphQLSchema,
     GraphQLString,
 )
 from graphql.validation import ValuesOfCorrectTypeRule
 
 from .harness import assert_validation_errors
 
-
 assert_errors = partial(assert_validation_errors, ValuesOfCorrectTypeRule)
 
 assert_valid = partial(assert_errors, errors=[])
 
 
 def describe_validate_values_of_correct_type():
     def describe_valid_values():
@@ -1044,15 +1043,15 @@
 
             assert str(errors[0].original_error) == (
                 "Invalid scalar is always invalid: 123"
             )
 
         def reports_error_for_custom_scalar_that_returns_undefined():
             custom_scalar = GraphQLScalarType(
-                "CustomScalar", parse_value=lambda value: Undefined
+                "CustomScalar", parse_value=lambda _value: Undefined
             )
 
             schema = GraphQLSchema(
                 GraphQLObjectType(
                     "Query",
                     {
                         "invalidArg": GraphQLField(
```

### Comparing `graphql_core-3.3.0a3/tests/validation/test_variables_are_input_types.py` & `graphql_core-3.3.0a4/tests/validation/test_variables_are_input_types.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,14 +1,13 @@
 from functools import partial
 
 from graphql.validation import VariablesAreInputTypesRule
 
 from .harness import assert_validation_errors
 
-
 assert_errors = partial(assert_validation_errors, VariablesAreInputTypesRule)
 
 assert_valid = partial(assert_errors, errors=[])
 
 
 def describe_validate_variables_are_input_types():
     def unknown_types_are_ignored():
```

### Comparing `graphql_core-3.3.0a3/tests/validation/test_variables_in_allowed_position.py` & `graphql_core-3.3.0a4/tests/validation/test_variables_in_allowed_position.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,14 +1,13 @@
 from functools import partial
 
 from graphql.validation import VariablesInAllowedPositionRule
 
 from .harness import assert_validation_errors
 
-
 assert_errors = partial(assert_validation_errors, VariablesInAllowedPositionRule)
 
 assert_valid = partial(assert_errors, errors=[])
 
 
 def describe_validate_variables_are_in_allowed_positions():
     def boolean_to_boolean():
```

### Comparing `graphql_core-3.3.0a3/tox.ini` & `graphql_core-3.3.0a4/tox.ini`

 * *Files 13% similar despite different names*

```diff
@@ -1,66 +1,54 @@
 [tox]
-envlist = py3{7,8,9,10,11}, pypy39, black, flake8, isort, mypy, docs
+envlist = py3{7,8,9,10,11,12}, pypy3{9,10}, ruff, mypy, docs
 isolated_build = true
 
 [gh-actions]
 python =
     3: py311
     3.7: py37
     3.8: py38
     3.9: py39
     3.10: py310
     3.11: py311
-    pypy3: pypy39
+    3.12: py312
+    pypy3: pypy9
     pypy3.9: pypy39
+    pypy3.10: pypy310
 
-[testenv:black]
-basepython = python3.11
-deps = black==23.3.0
+[testenv:ruff]
+basepython = python3.12
+deps = ruff>=0.2.1,<0.3
 commands  =
-    black src tests -t py310 --check
-
-[testenv:flake8]
-basepython = python3.11
-deps =
-    flake8>=6,<7
-    flake8-bandit>=4.1,<5
-    flake8-bugbear==23.5.9
-commands =
-    flake8 src tests
-
-[testenv:isort]
-basepython = python3.11
-deps = isort>=5.12,<6
-commands =
-    isort src tests --check-only
+    ruff check src tests
+    ruff format --check src tests
 
 [testenv:mypy]
-basepython = python3.11
+basepython = python3.12
 deps =
-    mypy==1.3.0
-    pytest>=7.3,<8
+    mypy>=1.8.0,<1.9
+    pytest>=8.0,<9
 commands =
     mypy src tests
 
 [testenv:docs]
-basepython = python3.10
+basepython = python3.12
 deps =
-    sphinx>=5.3,<6
-    sphinx_rtd_theme>=1.1,<2
+    sphinx>=7,<8
+    sphinx_rtd_theme>=2.0,<3
 commands =
     sphinx-build -b html -nEW docs docs/_build/html
 
 [testenv]
 deps =
-    pytest>=7.3,<8
-    pytest-asyncio>=0.21,<1
+    pytest>=7.4,<9
+    pytest-asyncio>=0.21.1,<1
     pytest-benchmark>=4,<5
     pytest-cov>=4.1,<5
-    pytest-describe>=2.1,<3
-    pytest-timeout>=2.1,<3
-    py37,py38,py39,pypy39: typing-extensions>=4.5,<5
+    pytest-describe>=2.2,<3
+    pytest-timeout>=2.2,<3
+    py37,py38,py39,pypy39: typing-extensions>=4.7.1,<5
 commands =
-    # to also run the time-consuming tests: tox -e py310 -- --run-slow
-    # to run the benchmarks: tox -e py310 -- -k benchmarks --benchmark-enable
-    py37,py38,py39,py311,pypy39: pytest tests {posargs}
-    py310: pytest tests {posargs: --cov-report=term-missing --cov=graphql --cov=tests --cov-fail-under=100}
+    # to also run the time-consuming tests: tox -e py311 -- --run-slow
+    # to run the benchmarks: tox -e py311 -- -k benchmarks --benchmark-enable
+    py37,py38,py39,py310,py311,pypy39,pypy310: pytest tests {posargs}
+    py312: pytest tests {posargs: --cov-report=term-missing --cov=graphql --cov=tests --cov-fail-under=100}
```

### Comparing `graphql_core-3.3.0a3/PKG-INFO` & `graphql_core-3.3.0a4/PKG-INFO`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: graphql-core
-Version: 3.3.0a3
+Version: 3.3.0a4
 Summary: GraphQL-core is a Python port of GraphQL.js,the JavaScript reference implementation for GraphQL.
 Home-page: https://github.com/graphql-python/graphql-core
 License: MIT
 Keywords: graphql
 Author: Christoph Zwerschke
 Author-email: cito@online.de
 Requires-Python: >=3.7,<4.0
@@ -13,15 +13,17 @@
 Classifier: License :: OSI Approved :: MIT License
 Classifier: Programming Language :: Python :: 3
 Classifier: Programming Language :: Python :: 3.7
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
 Classifier: Programming Language :: Python :: 3.11
-Requires-Dist: typing-extensions (>=4.5,<5.0) ; python_version < "3.10"
+Classifier: Programming Language :: Python :: 3.12
+Requires-Dist: typing-extensions (>=4.7.1,<5.0.0) ; python_version < "3.8"
+Requires-Dist: typing-extensions (>=4.9,<5.0) ; python_version >= "3.8" and python_version < "3.10"
 Project-URL: Changelog, https://github.com/graphql-python/graphql-core/releases
 Project-URL: Documentation, https://graphql-core-3.readthedocs.io/
 Project-URL: Repository, https://github.com/graphql-python/graphql-core
 Description-Content-Type: text/markdown
 
 # GraphQL-core 3
 
@@ -36,17 +38,17 @@
 [![Code Style](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/ambv/black)
 
 An extensive test suite with over 2300 unit tests and 100% coverage comprises a
 replication of the complete test suite of GraphQL.js, making sure this port is
 reliable and compatible with GraphQL.js.
 
 The current stable version 3.2.3 of GraphQL-core is up-to-date with GraphQL.js
-version 16.6.0 and supports Python version 3.6 and newer.
+version 16.6.0 and supports Python version 3.7 and newer.
 
-You can also try out the latest alpha version 3.3.0a3 of GraphQL-core
+You can also try out the latest alpha version 3.3.0a4 of GraphQL-core
 which is up-to-date with GraphQL.js version 17.0.0a2.
 Please note that this new minor version of GraphQL-core does not support
 Python 3.6 anymore.
 
 Note that for various reasons, GraphQL-core does not use SemVer like GraphQL.js.
 Changes in the major version of GraphQL.js are reflected in the minor version of
 GraphQL-core instead. This means there can be breaking changes in the API
@@ -217,21 +219,22 @@
   Python versions
 * to be very close to the GraphQL.js reference implementation, while still providing
   a Pythonic API and code style
 * to make extensive use of Python type hints, similar to how GraphQL.js used Flow
   (and is now using TypeScript)
 * to use [black](https://github.com/ambv/black) to achieve a consistent code style
   while saving time and mental energy for more important matters
+  (we are now using [ruff](https://github.com/astral-sh/ruff) instead)
 * to replicate the complete Mocha-based test suite of GraphQL.js
   using [pytest](https://docs.pytest.org/)
   with [pytest-describe](https://pypi.org/project/pytest-describe/)
 
 Some restrictions (mostly in line with the design goals):
 
-* requires Python 3.6 or newer
+* requires Python 3.6 or newer (Python 3.7 and newer in latest version)
 * does not support some already deprecated methods and options of GraphQL.js
 * supports asynchronous operations only via async.io
   (does not support the additional executors in GraphQL-core)
 
 
 ## Integration with other libraries and roadmap
```

